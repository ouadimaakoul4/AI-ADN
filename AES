ðŸŒŸ Agent Engineering Standard (AES) v1.0 - Complete Blueprint

ðŸŽ¯ EXECUTIVE SUMMARY

AES is USB-C for AI agents. A universal standard enabling any autonomous agent to interoperate with any other agent, regardless of implementation, language, or framework. This document provides the complete specification for building, certifying, and deploying AES-compliant agents.

---

ðŸ“– TABLE OF CONTENTS

1. Core Specification - The AES Agent Model
2. Communication Protocol (ACP) - Agent-to-Agent Communication
3. Module Specifications - Memory, Tools, Planner, Executor
4. Security Framework - Blast Radius & Safety Controls
5. Observability Suite - Monitoring & Governance
6. Packaging & Distribution - Production Deployment
7. Certification Program - Bronze, Silver, Gold Levels
8. Community Governance - RFC Process & Foundation
9. Reference Implementation - Complete Codebase
10. Roadmap to v2.0 - Future Development

---

1ï¸âƒ£ CORE SPECIFICATION: AES AGENT MODEL

1.1 The Agent Interface

```python
# src/aes/agent.py
from abc import ABC, abstractmethod
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional, Union
import uuid
from enum import Enum

class AgentStatus(Enum):
    """Standard agent states"""
    IDLE = "idle"
    PERCEIVING = "perceiving"
    PLANNING = "planning"
    ACTING = "acting"
    LEARNING = "learning"
    ERROR = "error"
    SHUTDOWN = "shutdown"

@dataclass
class Observation:
    """Standardized perception input"""
    timestamp: datetime
    source: str                    # "sensor", "api", "agent:agent_id", "human"
    payload: Dict[str, Any]
    confidence: float = 1.0        # 0.0-1.0 reliability score
    metadata: Dict[str, Any] = None
    
    def to_dict(self) -> Dict:
        """Convert to serializable dictionary"""
        return {
            "timestamp": self.timestamp.isoformat(),
            "source": self.source,
            "payload": self.payload,
            "confidence": self.confidence,
            "metadata": self.metadata or {}
        }

@dataclass
class State:
    """Agent's current internal state"""
    memory: Dict[str, Any]         # Long-term knowledge
    context: Dict[str, Any]        # Short-term context
    goals: List[str]               # Active objectives
    constraints: List[str]         # Limitations/boundaries
    emotions: Optional[Dict[str, float]] = None  # Optional affective state
    
@dataclass
class Plan:
    """Structured execution plan"""
    id: str
    steps: List[Dict[str, Any]]    # Ordered actions
    priority: int                  # 1-100 (higher = more urgent)
    expected_outcome: str
    fallback_plan: Optional[str] = None
    timeout_seconds: int = 30
    metadata: Dict[str, Any] = None
    
@dataclass
class ActionResult:
    """Result of plan execution"""
    success: bool
    output: Any
    metrics: Dict[str, float]      # Performance measurements
    error: Optional[str] = None    # Failure reason
    evidence: List[str] = None     # Proof/artifacts
    next_action: Optional[str] = None  # Suggested follow-up

class BaseAgent(ABC):
    """
    Abstract Base Class for ALL AES agents.
    Every AES agent must inherit from this class.
    """
    
    def __init__(self, agent_id: Optional[str] = None, **kwargs):
        # Required AES properties
        self.id = agent_id or f"agent_{uuid.uuid4().hex[:8]}"
        self.version = kwargs.get('version', 'aes-v1.0')
        self.status = AgentStatus.IDLE
        self.capabilities: List[str] = kwargs.get('capabilities', [])
        
        # State management
        self._state = State(
            memory={},
            context={"created_at": datetime.now().isoformat()},
            goals=kwargs.get('initial_goals', []),
            constraints=kwargs.get('constraints', [])
        )
        
        # Observability
        self._logs: List[Dict] = []
        self._metrics: Dict[str, List[float]] = {}
        self._execution_history: List[Dict] = []
        
        # Communication
        self.post_office = None  # Will be set by PostOffice.register()
        
        # Security
        self.security_token = kwargs.get('security_token')
        self.rate_limiter = RateLimiter(
            max_requests=kwargs.get('max_requests_per_minute', 60)
        )
        
        # Initialize
        self._initialize_agent()
        
    def _initialize_agent(self):
        """Initialize agent-specific resources"""
        self._log("initialize", {"agent_id": self.id, "version": self.version})
        
    @abstractmethod
    def perceive(self, input_data: Any) -> Observation:
        """
        Convert raw input to structured observation.
        Must handle errors gracefully.
        """
        pass
    
    @abstractmethod
    def update_state(self, observation: Observation) -> State:
        """
        Update agent state based on new observation.
        Should be deterministic for given observation.
        """
        pass
    
    @abstractmethod
    def plan(self, state: State) -> Plan:
        """
        Create execution plan based on current state.
        May return empty plan if no action needed.
        """
        pass
    
    @abstractmethod
    def act(self, plan: Plan) -> ActionResult:
        """
        Execute the plan.
        Must handle failures gracefully.
        """
        pass
    
    @abstractmethod
    def learn(self, feedback: ActionResult) -> None:
        """
        Learn from execution results.
        Update internal models/knowledge.
        """
        pass
    
    def run(self, input_data: Any) -> ActionResult:
        """
        Standard AES execution loop.
        This is the MAIN entry point for agent execution.
        """
        # Check rate limit
        if not self.rate_limiter.allow_request(self.id):
            return ActionResult(
                success=False,
                output=None,
                error="Rate limit exceeded",
                metrics={"rate_limited": True}
            )
        
        cycle_start = datetime.now()
        self.status = AgentStatus.PERCEIVING
        
        try:
            # 1. PERCEIVE
            observation = self.perceive(input_data)
            self._log("perceive", {
                "observation": observation.to_dict(),
                "input_size": len(str(input_data))
            })
            
            # 2. UPDATE STATE
            self.status = AgentStatus.PLANNING
            self._state = self.update_state(observation)
            self._log("update_state", {
                "goals": self._state.goals,
                "constraints": self._state.constraints
            })
            
            # 3. PLAN
            plan = self.plan(self._state)
            self._log("plan", {
                "plan_id": plan.id,
                "steps": len(plan.steps),
                "priority": plan.priority
            })
            
            # 4. ACT
            self.status = AgentStatus.ACTING
            result = self.act(plan)
            self._log("act", {
                "success": result.success,
                "metrics": result.metrics
            })
            
            # 5. LEARN
            self.status = AgentStatus.LEARNING
            self.learn(result)
            self._log("learn", {
                "feedback_processed": True
            })
            
            # Update metrics
            cycle_time = (datetime.now() - cycle_start).total_seconds()
            self._record_metric("cycle_time", cycle_time)
            self._record_metric("success", 1.0 if result.success else 0.0)
            
            self.status = AgentStatus.IDLE
            return result
            
        except Exception as e:
            self.status = AgentStatus.ERROR
            self._log("error", {
                "error": str(e),
                "traceback": traceback.format_exc()
            })
            
            return ActionResult(
                success=False,
                output=None,
                error=f"Agent execution failed: {str(e)}",
                metrics={"error": True, "agent_id": self.id}
            )
    
    # ========== OBSERVABILITY METHODS (AES REQUIRED) ==========
    
    def state_snapshot(self) -> Dict[str, Any]:
        """
        AES MANDATORY: Provide current agent state snapshot.
        Must return serializable dictionary.
        """
        return {
            "agent_id": self.id,
            "version": self.version,
            "status": self.status.value,
            "state": {
                "goals": self._state.goals,
                "constraints": self._state.constraints,
                "memory_keys": list(self._state.memory.keys()),
                "context_keys": list(self._state.context.keys())
            },
            "metrics": self._get_metrics_summary(),
            "timestamp": datetime.now().isoformat()
        }
    
    def logs(self, limit: int = 100) -> List[Dict]:
        """
        AES MANDATORY: Provide access to agent logs.
        Must return list of log entries.
        """
        return self._logs[-limit:] if limit else self._logs.copy()
    
    def capabilities_list(self) -> List[str]:
        """List agent's capabilities/tools"""
        return self.capabilities.copy()
    
    def health_check(self) -> Dict[str, Any]:
        """Comprehensive health check"""
        return {
            "agent_id": self.id,
            "status": self.status.value,
            "uptime": self._get_uptime(),
            "memory_usage": self._get_memory_usage(),
            "cycle_count": len(self._execution_history),
            "success_rate": self._calculate_success_rate(),
            "last_error": self._logs[-1]["data"].get("error") if self._logs and "error" in self._logs[-1].get("data", {}) else None
        }
    
    # ========== INTERNAL METHODS ==========
    
    def _log(self, step: str, data: Dict[str, Any]):
        """Internal logging with structured format"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "step": step,
            "agent_id": self.id,
            "data": data
        }
        self._logs.append(log_entry)
        
        # Also send to PostOffice if registered
        if self.post_office:
            self.post_office.broadcast_log(self.id, log_entry)
    
    def _record_metric(self, name: str, value: float):
        """Record performance metric"""
        if name not in self._metrics:
            self._metrics[name] = []
        self._metrics[name].append(value)
        
        # Keep only last 1000 values
        if len(self._metrics[name]) > 1000:
            self._metrics[name] = self._metrics[name][-1000:]
    
    def _get_metrics_summary(self) -> Dict[str, float]:
        """Calculate summary statistics for all metrics"""
        summary = {}
        for name, values in self._metrics.items():
            if values:
                summary[f"{name}_count"] = len(values)
                summary[f"{name}_mean"] = sum(values) / len(values)
                summary[f"{name}_min"] = min(values)
                summary[f"{name}_max"] = max(values)
                summary[f"{name}_last"] = values[-1]
        return summary
    
    def _get_uptime(self) -> str:
        """Calculate agent uptime"""
        if "created_at" in self._state.context:
            created = datetime.fromisoformat(self._state.context["created_at"])
            uptime = datetime.now() - created
            return str(uptime)
        return "unknown"
    
    def _get_memory_usage(self) -> Dict[str, Any]:
        """Estimate memory usage"""
        import sys
        return {
            "estimated_bytes": sys.getsizeof(self) + sys.getsizeof(self._state),
            "log_entries": len(self._logs),
            "metric_points": sum(len(v) for v in self._metrics.values())
        }
    
    def _calculate_success_rate(self) -> float:
        """Calculate success rate from execution history"""
        if not self._execution_history:
            return 0.0
        
        successes = sum(1 for entry in self._execution_history 
                       if entry.get("result", {}).get("success", False))
        return successes / len(self._execution_history)
```

---

2ï¸âƒ£ AGENT COMMUNICATION PROTOCOL (ACP) v1.0

2.1 Message Format & Handshake

```python
# src/aes/acp.py
"""
AES Communication Protocol (ACP) - Standard for agent-to-agent communication
Enables Gold-certified Support Agents to communicate with Bronze-certified Billing Agents
"""

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Union
import hashlib
import json
import uuid

class ACPIntent(Enum):
    """Standard message intents"""
    REQUEST = "request"          # Ask for information
    RESPONSE = "response"        # Respond to request
    DELEGATE = "delegate"        # Delegate task to another agent
    BROADCAST = "broadcast"      # Broadcast to all agents
    DISCOVER = "discover"        # Discover capabilities
    NEGOTIATE = "negotiate"      # Negotiate contract/terms
    ERROR = "error"              # Error response
    
class ACPPriority(Enum):
    """Message priority levels"""
    LOW = 10
    NORMAL = 50
    HIGH = 80
    CRITICAL = 100

@dataclass
class AESMessage:
    """
    Standard ACP Message Envelope
    All agent communication MUST use this format
    """
    message_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    sender_id: str                # AES Agent ID (e.g., "support_agent_001")
    receiver_id: str              # Target Agent ID or "*" for broadcast
    protocol_version: str = "acp-v1.0"
    intent: ACPIntent = ACPIntent.REQUEST
    priority: ACPPriority = ACPPriority.NORMAL
    
    # Content
    payload: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    # Security
    signature: Optional[str] = None  # Cryptographic signature
    nonce: str = field(default_factory=lambda: str(uuid.uuid4().hex[:16]))
    timestamp: datetime = field(default_factory=datetime.now)
    
    # Routing
    ttl: int = 3                   # Max hops (prevents infinite loops)
    reply_to: Optional[str] = None # Message ID to reply to
    correlation_id: Optional[str] = None  # For tracing multi-message conversations
    
    # Resource management
    cost_estimate: Optional[Dict[str, float]] = None  # Estimated resource cost
    max_cost: Optional[Dict[str, float]] = None       # Maximum allowed cost
    
    def sign(self, secret_key: str) -> "AESMessage":
        """Sign the message with HMAC-SHA256"""
        message_str = json.dumps(self.to_dict(), sort_keys=True)
        signature = hashlib.sha256(
            f"{message_str}:{secret_key}".encode()
        ).hexdigest()
        self.signature = signature
        return self
    
    def verify(self, secret_key: str) -> bool:
        """Verify message signature"""
        if not self.signature:
            return False
        
        # Create copy without signature for verification
        temp_msg = AESMessage(
            **{k: v for k, v in self.to_dict().items() if k != "signature"}
        )
        
        expected_signature = temp_msg.sign(secret_key).signature
        return self.signature == expected_signature
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to serializable dictionary"""
        return {
            "message_id": self.message_id,
            "sender_id": self.sender_id,
            "receiver_id": self.receiver_id,
            "protocol_version": self.protocol_version,
            "intent": self.intent.value,
            "priority": self.priority.value,
            "payload": self.payload,
            "metadata": self.metadata,
            "signature": self.signature,
            "nonce": self.nonce,
            "timestamp": self.timestamp.isoformat(),
            "ttl": self.ttl,
            "reply_to": self.reply_to,
            "correlation_id": self.correlation_id,
            "cost_estimate": self.cost_estimate,
            "max_cost": self.max_cost
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "AESMessage":
        """Create message from dictionary"""
        # Handle datetime conversion
        if "timestamp" in data and isinstance(data["timestamp"], str):
            data["timestamp"] = datetime.fromisoformat(data["timestamp"])
        
        # Handle enum conversions
        if "intent" in data and isinstance(data["intent"], str):
            data["intent"] = ACPIntent(data["intent"])
        
        if "priority" in data and isinstance(data["priority"], (int, str)):
            data["priority"] = ACPPriority(data["priority"])
        
        return cls(**data)
    
    def create_response(self, payload: Dict[str, Any], 
                       success: bool = True,
                       error: Optional[str] = None) -> "AESMessage":
        """Create a response message"""
        return AESMessage(
            sender_id=self.receiver_id,
            receiver_id=self.sender_id,
            intent=ACPIntent.RESPONSE,
            payload={
                "success": success,
                "original_message_id": self.message_id,
                "response": payload,
                "error": error
            },
            reply_to=self.message_id,
            correlation_id=self.correlation_id
        )

@dataclass
class CapabilityAdvertisement:
    """Advertisement of agent capabilities"""
    agent_id: str
    capabilities: List[str]  # List of tool names or actions
    cost_schedule: Dict[str, float]  # Cost per capability
    availability: float = 1.0  # 0.0-1.0 availability score
    latency_ms: Dict[str, float] = None  # Expected latency per capability
    metadata: Dict[str, Any] = None

@dataclass
class ContractProposal:
    """Proposal for task delegation"""
    task_id: str
    capability: str
    parameters: Dict[str, Any]
    proposed_cost: Dict[str, float]  # Estimated cost breakdown
    deadline: datetime
    sla: Dict[str, Any] = None  # Service Level Agreement
    penalties: Dict[str, float] = None  # Penalties for failure

@dataclass
class ContractAcceptance:
    """Acceptance of contract proposal"""
    contract_id: str
    task_id: str
    agent_id: str
    accepted_cost: Dict[str, float]
    estimated_completion: datetime
    signature: str  # Digital signature
```

2.2 The Three-Way Handshake Protocol

```python
# src/aes/handshake.py
"""
Three-Way Handshake for secure agent communication:
1. Capability Discovery: "Can you do X?"
2. Contract Negotiation: "Here are my terms"
3. Execution: "Do it under these conditions"
"""

class ACPHandshake:
    """Implements the ACP three-way handshake protocol"""
    
    def __init__(self, post_office: "PostOffice"):
        self.post_office = post_office
        self.active_contracts: Dict[str, ContractAcceptance] = {}
        self.negotiation_timeout = 30  # seconds
        
    async def discover_capabilities(self, 
                                   requester_id: str,
                                   target_id: str,
                                   required_capabilities: List[str]) -> Dict[str, Any]:
        """
        Step 1: Discover if target agent has required capabilities
        """
        discovery_msg = AESMessage(
            sender_id=requester_id,
            receiver_id=target_id,
            intent=ACPIntent.DISCOVER,
            payload={
                "required_capabilities": required_capabilities,
                "constraints": {
                    "max_cost": {"tokens": 1000, "usd": 0.01},
                    "max_latency_ms": 5000
                }
            }
        )
        
        # Send discovery request
        response = await self.post_office.send_async(discovery_msg)
        
        if not response.get("success"):
            return {
                "success": False,
                "error": response.get("error", "Discovery failed"),
                "available_capabilities": []
            }
        
        # Parse advertisement
        advertisement = CapabilityAdvertisement(
            **response["payload"]["advertisement"]
        )
        
        # Check if all required capabilities are available
        missing = set(required_capabilities) - set(advertisement.capabilities)
        
        return {
            "success": len(missing) == 0,
            "available_capabilities": advertisement.capabilities,
            "missing_capabilities": list(missing),
            "cost_schedule": advertisement.cost_schedule,
            "advertisement": advertisement
        }
    
    async def negotiate_contract(self,
                                requester_id: str,
                                target_id: str,
                                capability: str,
                                parameters: Dict[str, Any],
                                max_cost: Dict[str, float]) -> Optional[ContractAcceptance]:
        """
        Step 2: Negotiate contract for task execution
        """
        # Create contract proposal
        proposal = ContractProposal(
            task_id=f"task_{uuid.uuid4().hex[:8]}",
            capability=capability,
            parameters=parameters,
            proposed_cost={
                "tokens": 500,  # Estimated LLM tokens
                "usd": 0.005,
                "compute_seconds": 2.0
            },
            deadline=datetime.now().timedelta(minutes=5),
            sla={
                "success_rate": 0.95,
                "max_retries": 3,
                "timeout_seconds": 30
            }
        )
        
        # Send negotiation request
        negotiation_msg = AESMessage(
            sender_id=requester_id,
            receiver_id=target_id,
            intent=ACPIntent.NEGOTIATE,
            payload={
                "proposal": asdict(proposal),
                "max_cost": max_cost
            }
        )
        
        response = await self.post_office.send_async(negotiation_msg)
        
        if not response.get("success"):
            return None
        
        # Create contract acceptance
        acceptance_data = response["payload"]["acceptance"]
        acceptance = ContractAcceptance(**acceptance_data)
        
        # Store contract
        self.active_contracts[acceptance.contract_id] = acceptance
        
        return acceptance
    
    async def execute_delegation(self,
                                requester_id: str,
                                target_id: str,
                                contract_id: str,
                                parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Step 3: Execute task under negotiated contract
        """
        if contract_id not in self.active_contracts:
            return {
                "success": False,
                "error": f"Contract {contract_id} not found or expired"
            }
        
        contract = self.active_contracts[contract_id]
        
        # Verify contract is still valid
        if datetime.now() > contract.estimated_completion:
            del self.active_contracts[contract_id]
            return {
                "success": False,
                "error": f"Contract {contract_id} expired"
            }
        
        # Send delegation request
        delegation_msg = AESMessage(
            sender_id=requester_id,
            receiver_id=target_id,
            intent=ACPIntent.DELEGATE,
            payload={
                "contract_id": contract_id,
                "action": contract.capability,
                "parameters": parameters,
                "expected_cost": contract.accepted_cost
            },
            cost_estimate=contract.accepted_cost,
            max_cost={
                k: v * 1.2 for k, v in contract.accepted_cost.items()
            }  # Allow 20% overrun
        )
        
        response = await self.post_office.send_async(delegation_msg)
        
        # Record execution in contract
        contract.execution_log.append({
            "timestamp": datetime.now().isoformat(),
            "success": response.get("success", False),
            "actual_cost": response.get("actual_cost", {})
        })
        
        return response
    
    async def full_handshake(self,
                           requester_id: str,
                           target_id: str,
                           capability: str,
                           parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Complete three-way handshake in one call
        """
        # Step 1: Discovery
        discovery = await self.discover_capabilities(
            requester_id, target_id, [capability]
        )
        
        if not discovery["success"]:
            return discovery
        
        # Step 2: Negotiation
        max_cost = {"tokens": 1000, "usd": 0.01, "compute_seconds": 5}
        contract = await self.negotiate_contract(
            requester_id, target_id, capability, parameters, max_cost
        )
        
        if not contract:
            return {
                "success": False,
                "error": "Contract negotiation failed"
            }
        
        # Step 3: Execution
        result = await self.execute_delegation(
            requester_id, target_id, contract.contract_id, parameters
        )
        
        # Clean up contract
        if contract.contract_id in self.active_contracts:
            del self.active_contracts[contract.contract_id]
        
        return result
```

2.3 PostOffice Module (Message Router)

```python
# src/aes/modules/comm.py
"""
PostOffice - Central message router for AES agents
Manages message routing, delivery, and agent discovery
"""

import asyncio
from collections import defaultdict, deque
from datetime import datetime
from typing import Dict, List, Optional, Set, Any, Callable
import heapq
import threading
import time

class PostOffice:
    """
    Central message routing system for AES agents.
    Implements publish-subscribe pattern with quality of service.
    """
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        
        # Agent registry
        self.agents: Dict[str, Any] = {}  # agent_id -> agent_instance
        self.agent_capabilities: Dict[str, Set[str]] = defaultdict(set)
        
        # Message queues (priority queues)
        self.message_queues: Dict[str, List] = defaultdict(list)  # agent_id -> priority queue
        self.message_history: deque = deque(maxlen=10000)  # Last 10k messages
        
        # Message routing
        self.subscriptions: Dict[str, Set[str]] = defaultdict(set)  # topic -> set of agent_ids
        self.routing_table: Dict[str, Callable] = {}  # Custom routing logic
        
        # Delivery guarantees
        self.delivery_attempts: Dict[str, int] = defaultdict(int)
        self.max_retries = self.config.get('max_retries', 3)
        
        # Performance monitoring
        self.metrics = {
            'messages_sent': 0,
            'messages_delivered': 0,
            'messages_failed': 0,
            'avg_delivery_time_ms': 0.0,
            'queue_sizes': {}
        }
        
        # Security
        self.allowed_agents: Set[str] = set()
        self.message_validators: List[Callable] = []
        
        # Start message processor
        self._running = True
        self._processor_thread = threading.Thread(
            target=self._process_messages,
            daemon=True
        )
        self._processor_thread.start()
        
        self._log("PostOffice initialized")
    
    def register(self, agent: Any) -> bool:
        """
        Register an agent with the PostOffice.
        Returns True if registration successful.
        """
        agent_id = agent.id
        
        if agent_id in self.agents:
            self._log(f"Agent {agent_id} already registered", level="warning")
            return False
        
        # Security check
        if self.allowed_agents and agent_id not in self.allowed_agents:
            self._log(f"Agent {agent_id} not in allowed list", level="error")
            return False
        
        # Register agent
        self.agents[agent_id] = agent
        agent.post_office = self  # Give agent reference to PostOffice
        
        # Register capabilities
        if hasattr(agent, 'capabilities_list'):
            capabilities = agent.capabilities_list()
            self.agent_capabilities[agent_id] = set(capabilities)
            self._log(f"Registered agent {agent_id} with capabilities: {capabilities}")
        
        # Subscribe to agent's own message queue
        self.subscribe(agent_id, agent_id)
        
        return True
    
    def unregister(self, agent_id: str) -> bool:
        """Unregister an agent"""
        if agent_id in self.agents:
            del self.agents[agent_id]
            if agent_id in self.agent_capabilities:
                del self.agent_capabilities[agent_id]
            
            # Remove from subscriptions
            for topic in self.subscriptions:
                self.subscriptions[topic].discard(agent_id)
            
            self._log(f"Unregistered agent {agent_id}")
            return True
        return False
    
    def send(self, message: AESMessage) -> Dict[str, Any]:
        """
        Send a message synchronously.
        Returns delivery result.
        """
        send_start = time.time()
        
        # Validate message
        validation_result = self._validate_message(message)
        if not validation_result["valid"]:
            return {
                "success": False,
                "error": f"Message validation failed: {validation_result['error']}",
                "message_id": message.message_id
            }
        
        # Check TTL
        if message.ttl <= 0:
            return {
                "success": False,
                "error": "Message TTL expired",
                "message_id": message.message_id
            }
        
        # Decrement TTL
        message.ttl -= 1
        
        # Route message
        delivery_result = self._route_message(message)
        
        # Update metrics
        self.metrics['messages_sent'] += 1
        if delivery_result['success']:
            self.metrics['messages_delivered'] += 1
        else:
            self.metrics['messages_failed'] += 1
        
        # Calculate delivery time
        delivery_time = (time.time() - send_start) * 1000
        self._update_avg_delivery_time(delivery_time)
        
        # Store in history
        self.message_history.append({
            "timestamp": datetime.now().isoformat(),
            "message": message.to_dict(),
            "result": delivery_result
        })
        
        return delivery_result
    
    async def send_async(self, message: AESMessage) -> Dict[str, Any]:
        """
        Send a message asynchronously.
        """
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self.send, message)
    
    def broadcast(self, message: AESMessage, topic: Optional[str] = None) -> Dict[str, Any]:
        """
        Broadcast message to multiple agents.
        If topic is None, broadcasts to all registered agents.
        """
        if topic:
            recipients = self.subscriptions.get(topic, set())
        else:
            recipients = set(self.agents.keys())
        
        results = []
        for recipient_id in recipients:
            if recipient_id != message.sender_id:  # Don't send to self
                msg_copy = AESMessage.from_dict(message.to_dict())
                msg_copy.receiver_id = recipient_id
                result = self.send(msg_copy)
                results.append(result)
        
        success_count = sum(1 for r in results if r.get("success", False))
        
        return {
            "success": success_count == len(results),
            "total_recipients": len(recipients),
            "successful_deliveries": success_count,
            "individual_results": results
        }
    
    def subscribe(self, agent_id: str, topic: str) -> bool:
        """Subscribe agent to a topic"""
        if agent_id not in self.agents:
            self._log(f"Cannot subscribe non-existent agent {agent_id}", level="warning")
            return False
        
        self.subscriptions[topic].add(agent_id)
        self._log(f"Agent {agent_id} subscribed to topic '{topic}'")
        return True
    
    def unsubscribe(self, agent_id: str, topic: str) -> bool:
        """Unsubscribe agent from a topic"""
        if topic in self.subscriptions and agent_id in self.subscriptions[topic]:
            self.subscriptions[topic].remove(agent_id)
            self._log(f"Agent {agent_id} unsubscribed from topic '{topic}'")
            return True
        return False
    
    def discover_agents(self, capability: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        Discover agents by capability.
        Returns list of agent information.
        """
        result = []
        
        for agent_id, capabilities in self.agent_capabilities.items():
            if capability is None or capability in capabilities:
                agent = self.agents.get(agent_id)
                if agent:
                    agent_info = {
                        "agent_id": agent_id,
                        "capabilities": list(capabilities),
                        "status": getattr(agent, 'status', 'unknown').value if hasattr(agent, 'status') else 'unknown',
                        "health": agent.health_check() if hasattr(agent, 'health_check') else {}
                    }
                    result.append(agent_info)
        
        return result
    
    def broadcast_log(self, agent_id: str, log_entry: Dict[str, Any]):
        """
        Broadcast log entry to monitoring subscribers.
        Used by agents to share logs with monitoring systems.
        """
        log_message = AESMessage(
            sender_id=agent_id,
            receiver_id="*",  # Broadcast
            intent=ACPIntent.BROADCAST,
            payload={
                "type": "log",
                "log_entry": log_entry
            },
            metadata={"log_broadcast": True}
        )
        
        self.broadcast(log_message, topic="monitoring")
    
    # ========== INTERNAL METHODS ==========
    
    def _validate_message(self, message: AESMessage) -> Dict[str, Any]:
        """Validate message before delivery"""
        
        # Check required fields
        if not message.sender_id or not message.receiver_id:
            return {
                "valid": False,
                "error": "Missing sender_id or receiver_id"
            }
        
        # Check if sender is registered
        if message.sender_id not in self.agents and message.sender_id != "system":
            return {
                "valid": False,
                "error": f"Sender {message.sender_id} not registered"
            }
        
        # Run custom validators
        for validator in self.message_validators:
            try:
                result = validator(message)
                if not result.get("valid", True):
                    return result
            except Exception as e:
                self._log(f"Validator error: {e}", level="error")
        
        return {"valid": True}
    
    def _route_message(self, message: AESMessage) -> Dict[str, Any]:
        """Route message to appropriate destination"""
        
        # Check for custom routing
        if message.receiver_id in self.routing_table:
            return self.routing_table[message.receiver_id](message)
        
        # Direct delivery to specific agent
        if message.receiver_id in self.agents:
            return self._deliver_to_agent(message)
        
        # Broadcast
        if message.receiver_id == "*":
            return self.broadcast(message)
        
        # Topic-based delivery
        if message.receiver_id.startswith("topic:"):
            topic = message.receiver_id[6:]  # Remove "topic:" prefix
            return self.broadcast(message, topic=topic)
        
        # Capability-based discovery and delivery
        if message.receiver_id.startswith("capability:"):
            capability = message.receiver_id[11:]  # Remove "capability:" prefix
            agents_with_capability = self.discover_agents(capability)
            
            if not agents_with_capability:
                return {
                    "success": False,
                    "error": f"No agents found with capability: {capability}"
                }
            
            # For now, pick the first available agent
            # TODO: Implement load balancing
            target_agent = agents_with_capability[0]["agent_id"]
            message.receiver_id = target_agent
            return self._deliver_to_agent(message)
        
        return {
            "success": False,
            "error": f"Unknown receiver: {message.receiver_id}"
        }
    
    def _deliver_to_agent(self, message: AESMessage) -> Dict[str, Any]:
        """Deliver message to specific agent"""
        agent = self.agents.get(message.receiver_id)
        
        if not agent:
            return {
                "success": False,
                "error": f"Agent {message.receiver_id} not found"
            }
        
        # Check if agent is healthy
        if hasattr(agent, 'health_check'):
            health = agent.health_check()
            if health.get("status") == "error":
                return {
                    "success": False,
                    "error": f"Agent {message.receiver_id} is in error state"
                }
        
        # Convert message to observation
        observation = Observation(
            timestamp=message.timestamp,
            source=f"agent:{message.sender_id}",
            payload={
                "acp_message": message.to_dict(),
                "intent": message.intent.value,
                "original_payload": message.payload
            },
            metadata=message.metadata
        )
        
        try:
            # Run agent with the observation
            result = agent.run(observation)
            
            return {
                "success": True,
                "message_id": message.message_id,
                "delivered_to": message.receiver_id,
                "agent_response": result.output if hasattr(result, 'output') else None,
                "success": getattr(result, 'success', False)
            }
            
        except Exception as e:
            self._log(f"Delivery error to {message.receiver_id}: {e}", level="error")
            
            # Retry logic
            msg_key = f"{message.message_id}:{message.receiver_id}"
            self.delivery_attempts[msg_key] += 1
            
            if self.delivery_attempts[msg_key] < self.max_retries:
                # Requeue with backoff
                time.sleep(2 ** self.delivery_attempts[msg_key])  # Exponential backoff
                return self._deliver_to_agent(message)
            
            return {
                "success": False,
                "error": f"Delivery failed after {self.max_retries} attempts: {str(e)}",
                "message_id": message.message_id
            }
    
    def _process_messages(self):
        """Background thread for processing queued messages"""
        while self._running:
            try:
                # Process each agent's queue
                for agent_id in list(self.agents.keys()):
                    if agent_id in self.message_queues and self.message_queues[agent_id]:
                        # Get highest priority message
                        priority, timestamp, message = heapq.heappop(self.message_queues[agent_id])
                        
                        # Deliver message
                        self._deliver_to_agent(message)
                
                # Sleep to prevent CPU spinning
                time.sleep(0.01)  # 10ms
                
            except Exception as e:
                self._log(f"Message processor error: {e}", level="error")
                time.sleep(1)  # Sleep on error
    
    def _update_avg_delivery_time(self, new_time: float):
        """Update average delivery time (exponential moving average)"""
        alpha = 0.1  # Smoothing factor
        old_avg = self.metrics['avg_delivery_time_ms']
        self.metrics['avg_delivery_time_ms'] = alpha * new_time + (1 - alpha) * old_avg
    
    def _log(self, message: str, level: str = "info"):
        """Internal logging"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "component": "PostOffice",
            "level": level,
            "message": message
        }
        
        # Print to console (in production, would use proper logging)
        if self.config.get('verbose', False):
            print(f"[{log_entry['timestamp']}] [{level.upper()}] {message}")
        
        # Store in message history
        self.message_history.append(log_entry)
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get PostOffice performance metrics"""
        self.metrics['queue_sizes'] = {
            agent_id: len(queue) 
            for agent_id, queue in self.message_queues.items()
        }
        
        return {
            **self.metrics,
            "total_agents": len(self.agents),
            "total_subscriptions": sum(len(s) for s in self.subscriptions.values()),
            "message_history_size": len(self.message_history)
        }
    
    def shutdown(self):
        """Graceful shutdown"""
        self._running = False
        if self._processor_thread.is_alive():
            self._processor_thread.join(timeout=5)
        self._log("PostOffice shutdown complete")

# Factory function for easy creation
def create_post_office(config: Optional[Dict] = None) -> PostOffice:
    """Create and configure a PostOffice instance"""
    default_config = {
        'max_retries': 3,
        'max_queue_size': 1000,
        'delivery_timeout': 30,
        'verbose': False
    }
    
    if config:
        default_config.update(config)
    
    return PostOffice(default_config)
```

---

3ï¸âƒ£ MODULE SPECIFICATIONS

3.1 Hierarchical Memory System

```python
# src/aes/modules/memory.py
"""
Three-layer hierarchical memory system:
1. Sensory Buffer: Last 100 observations (seconds)
2. Working Memory: Current task context (minutes)
3. Long-term Memory: Permanent storage (years)
"""

import numpy as np
from collections import deque
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple
import pickle
import hashlib

class HierarchicalMemory:
    """AES Standard Memory Implementation"""
    
    def __init__(self, config: Dict):
        self.config = config
        
        # Three-layer memory
        self.sensory_buffer = deque(maxlen=config.get('sensory_buffer_size', 100))
        self.working_memory: Dict[str, Dict] = {}
        self.long_term_storage = VectorStore(
            dimension=config.get('embedding_dim', 384)
        )
        
        # Memory indices
        self.temporal_index = {}  # timestamp -> memory_id
        self.semantic_index = {}  # concept -> [memory_ids]
        
        # Statistics
        self.stats = {
            'stores': 0,
            'retrieves': 0,
            'compressions': 0,
            'working_memory_size': 0,
            'long_term_memory_size': 0
        }
        
        # Compression scheduler
        self.last_compression = datetime.now()
        self.compression_interval = timedelta(
            minutes=config.get('compression_interval_minutes', 60)
        )
    
    def store(self, 
              key: str, 
              value: Any, 
              importance: float = 0.5,
              metadata: Optional[Dict] = None) -> str:
        """
        Store a memory with importance weighting.
        Importance: 0.0 (forget immediately) to 1.0 (never forget)
        """
        memory_id = f"mem_{hashlib.sha256(f'{key}:{datetime.now().isoformat()}'.encode()).hexdigest()[:16]}"
        
        memory_entry = {
            'id': memory_id,
            'key': key,
            'value': value,
            'importance': importance,
            'timestamp': datetime.now(),
            'access_count': 0,
            'last_accessed': datetime.now(),
            'metadata': metadata or {}
        }
        
        # Determine storage layer based on importance
        if importance > 0.8:
            # Important â†’ Long-term memory
            self._store_long_term(memory_entry)
        elif importance > 0.3:
            # Moderate â†’ Working memory
            self._store_working(memory_entry)
        else:
            # Low â†’ Sensory buffer
            self._store_sensory(memory_entry)
        
        # Update indices
        self._update_indices(memory_entry)
        
        self.stats['stores'] += 1
        return memory_id
    
    def retrieve(self, 
                 query: Optional[str] = None,
                 key: Optional[str] = None,
                 recency_weight: float = 0.3,
                 importance_weight: float = 0.5,
                 relevance_weight: float = 0.2,
                 limit: int = 10) -> List[Dict]:
        """
        Smart retrieval with multiple weighting factors.
        """
        results = []
        
        # Search in all three layers
        sensory_results = self._search_sensory(query, key)
        working_results = self._search_working(query, key)
        long_term_results = self._search_long_term(query, key)
        
        # Combine and score
        all_results = sensory_results + working_results + long_term_results
        
        for memory in all_results:
            score = self._calculate_retrieval_score(
                memory, recency_weight, importance_weight, relevance_weight, query
            )
            results.append((score, memory))
        
        # Sort by score and limit
        results.sort(key=lambda x: x[0], reverse=True)
        
        # Update access statistics
        for score, memory in results[:limit]:
            memory['access_count'] += 1
            memory['last_accessed'] = datetime.now()
            
            # Promote to working memory if frequently accessed
            if memory.get('layer') == 'sensory' and memory['access_count'] > 3:
                self._promote_to_working(memory)
        
        self.stats['retrieves'] += 1
        return [memory for _, memory in results[:limit]]
    
    def search(self, query: str, threshold: float = 0.7) -> List[Dict]:
        """Semantic search across all memory"""
        # First, try keyword match
        keyword_results = self._keyword_search(query)
        
        # Then, semantic search in long-term memory
        semantic_results = self.long_term_storage.search(
            query, 
            threshold=threshold,
            limit=10
        )
        
        # Combine and deduplicate
        all_results = []
        seen_ids = set()
        
        for result in keyword_results + semantic_results:
            if result['id'] not in seen_ids:
                all_results.append(result)
                seen_ids.add(result['id'])
        
        return all_results
    
    def associate(self, memory_id1: str, memory_id2: str, strength: float = 1.0):
        """Create association between two memories"""
        association_id = f"assoc_{memory_id1[:8]}_{memory_id2[:8]}"
        
        association = {
            'id': association_id,
            'memory1': memory_id1,
            'memory2': memory_id2,
            'strength': strength,
            'created_at': datetime.now(),
            'accessed_count': 0
        }
        
        # Store association
        self.long_term_storage.store_vector(
            f"association_{association_id}",
            self._create_embedding(f"association:{memory_id1}:{memory_id2}"),
            metadata=association
        )
        
        # Update semantic index
        key = f"association:{memory_id1}"
        if key not in self.semantic_index:
            self.semantic_index[key] = []
        self.semantic_index[key].append(memory_id2)
    
    def forget(self, 
               memory_id: Optional[str] = None, 
               pattern: Optional[str] = None,
               importance_threshold: float = 0.3):
        """
        Forget memories below importance threshold.
        Forgetting is a feature, not a bug.
        """
        if memory_id:
            # Forget specific memory
            self._forget_memory(memory_id)
        elif pattern:
            # Forget memories matching pattern
            memories_to_forget = self._find_memories_by_pattern(pattern)
            for mem_id in memories_to_forget:
                self._forget_memory(mem_id)
        else:
            # Forget low-importance memories
            self._forget_low_importance(importance_threshold)
    
    def compress(self) -> Dict[str, Any]:
        """Compress memories to save space"""
        if datetime.now() - self.last_compression < self.compression_interval:
            return {"compressed": False, "reason": "Too soon"}
        
        compression_start = datetime.now()
        
        # 1. Merge similar working memories
        working_memories = list(self.working_memory.values())
        merged_count = self._merge_similar_memories(working_memories)
        
        # 2. Move old working memories to long-term
        moved_count = self._archive_old_working_memories()
        
        # 3. Compress long-term storage
        long_term_before = self.stats['long_term_memory_size']
        self.long_term_storage.compress()
        long_term_after = self.long_term_storage.size()
        
        compression_time = (datetime.now() - compression_start).total_seconds()
        
        self.stats['compressions'] += 1
        self.last_compression = datetime.now()
        
        return {
            "compressed": True,
            "merged_memories": merged_count,
            "archived_memories": moved_count,
            "long_term_space_saved": long_term_before - long_term_after,
            "compression_time_seconds": compression_time,
            "timestamp": self.last_compression.isoformat()
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """Get memory statistics"""
        return {
            **self.stats,
            "sensory_buffer_size": len(self.sensory_buffer),
            "working_memory_size": len(self.working_memory),
            "long_term_memory_size": self.long_term_storage.size(),
            "last_compression": self.last_compression.isoformat()
        }
    
    # ========== PRIVATE METHODS ==========
    
    def _store_sensory(self, memory: Dict):
        """Store in sensory buffer"""
        memory['layer'] = 'sensory'
        memory['expires_at'] = datetime.now() + timedelta(seconds=30)
        self.sensory_buffer.append(memory)
    
    def _store_working(self, memory: Dict):
        """Store in working memory"""
        memory['layer'] = 'working'
        memory['expires_at'] = datetime.now() + timedelta(hours=1)
        self.working_memory[memory['id']] = memory
        self.stats['working_memory_size'] = len(self.working_memory)
    
    def _store_long_term(self, memory: Dict):
        """Store in long-term memory"""
        memory['layer'] = 'long_term'
        memory['expires_at'] = None  # Never expires
        
        # Create embedding
        embedding = self._create_embedding(str(memory['value']))
        
        # Store in vector database
        self.long_term_storage.store_vector(
            memory['id'],
            embedding,
            metadata=memory
        )
        
        self.stats['long_term_memory_size'] = self.long_term_storage.size()
    
    def _create_embedding(self, text: str) -> np.ndarray:
        """Create embedding for text"""
        # Simple hash-based embedding for demonstration
        # In production, use sentence-transformers or similar
        hash_obj = hashlib.sha256(text.encode())
        hash_bytes = hash_obj.digest()
        
        # Convert to 384-dim vector (like sentence-transformers)
        embedding = np.zeros(384, dtype=np.float32)
        
        for i in range(min(384, len(hash_bytes))):
            embedding[i] = (hash_bytes[i] / 255.0) * 2 - 1  # Scale to [-1, 1]
        
        return embedding
    
    def _calculate_retrieval_score(self, 
                                  memory: Dict, 
                                  recency_weight: float,
                                  importance_weight: float,
                                  relevance_weight: float,
                                  query: Optional[str]) -> float:
        """Calculate retrieval score for memory"""
        
        score = 0.0
        
        # Recency score (0-1)
        if 'last_accessed' in memory and memory['last_accessed']:
            recency = (datetime.now() - memory['last_accessed']).total_seconds()
            recency_score = 1.0 / (1.0 + recency / 3600)  # Decay over hours
            score += recency_score * recency_weight
        
        # Importance score
        importance = memory.get('importance', 0.5)
        score += importance * importance_weight
        
        # Relevance score (if query provided)
        if query:
            relevance = self._calculate_relevance(memory['value'], query)
            score += relevance * relevance_weight
        
        return score
    
    def _calculate_relevance(self, memory_value: Any, query: str) -> float:
        """Calculate relevance between memory and query"""
        # Simple keyword matching for demonstration
        # In production, use semantic similarity
        memory_str = str(memory_value).lower()
        query_lower = query.lower()
        
        if query_lower in memory_str:
            return 1.0
        
        # Check for word overlap
        memory_words = set(memory_str.split())
        query_words = set(query_lower.split())
        
        if not query_words:
            return 0.0
        
        overlap = len(memory_words.intersection(query_words))
        return overlap / len(query_words)
    
    def _promote_to_working(self, memory: Dict):
        """Promote sensory memory to working memory"""
        memory['layer'] = 'working'
        memory['expires_at'] = datetime.now() + timedelta(hours=1)
        self.working_memory[memory['id']] = memory
        
        # Remove from sensory buffer
        for i, mem in enumerate(self.sensory_buffer):
            if mem['id'] == memory['id']:
                del self.sensory_buffer[i]
                break
    
    def _forget_memory(self, memory_id: str):
        """Forget specific memory"""
        # Check all layers
        for i, mem in enumerate(self.sensory_buffer):
            if mem['id'] == memory_id:
                del self.sensory_buffer[i]
                return
        
        if memory_id in self.working_memory:
            del self.working_memory[memory_id]
            return
        
        self.long_term_storage.delete(memory_id)
    
    def _forget_low_importance(self, threshold: float):
        """Forget memories below importance threshold"""
        # Sensory buffer (automatically forgets due to size limit)
        
        # Working memory
        to_forget = []
        for mem_id, memory in self.working_memory.items():
            if memory.get('importance', 0.5) < threshold:
                to_forget.append(mem_id)
        
        for mem_id in to_forget:
            del self.working_memory[mem_id]
```

3.2 Tool System with Security

```python
# src/aes/modules/tool.py
"""
Tool system with built-in security, rate limiting, and cost tracking.
Every tool is sandboxed and observable.
"""

import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Callable, Dict, List, Optional, Tuple
import inspect
import json
import traceback
from enum import Enum

class ToolSafetyLevel(Enum):
    """Tool safety classification"""
    SAFE = 1          # Read-only, no side effects
    MONITORED = 2     # Write operations, but safe
    DANGEROUS = 3     # Can cause damage, requires auth
    RESTRICTED = 4    # Requires explicit approval

@dataclass
class ToolSchema:
    """JSON Schema with security annotations"""
    name: str
    description: str
    parameters: Dict[str, Any]      # JSON Schema
    returns: Dict[str, Any]         # Output schema
    safety_level: ToolSafetyLevel = ToolSafetyLevel.SAFE
    requires_auth: bool = False
    auth_scopes: List[str] = field(default_factory=list)
    rate_limit: Optional[Dict[str, int]] = None  # {"calls_per_minute": 10}
    cost_estimate: Optional[Dict[str, float]] = None  # {"tokens": 100, "usd": 0.001}
    timeout_seconds: int = 30
    input_validators: List[Callable] = field(default_factory=list)
    output_validators: List[Callable] = field(default_factory=list)

class BaseTool(ABC):
    """Base class for all AES tools"""
    
    def __init__(self, name: str, description: str, config: Optional[Dict] = None):
        self.name = name
        self.description = description
        self.config = config or {}
        
        # Observability
        self.call_history: List[Dict] = []
        self.error_count = 0
        self.total_calls = 0
        
        # Performance tracking
        self.execution_times: List[float] = []
        
        # Security
        self.auth_token: Optional[str] = None
        self.rate_limiter = RateLimiter(
            max_requests=self.config.get('max_requests_per_minute', 60)
        )
        
        # Schema (to be set by subclass)
        self.schema: Optional[ToolSchema] = None
        
    @abstractmethod
    def execute(self, input_data: Dict, context: Optional[Dict] = None) -> Dict:
        """
        Execute the tool with given parameters.
        Must return Dict with at least {'success': bool}
        """
        pass
    
    def validate_input(self, input_data: Dict) -> Tuple[bool, Optional[str]]:
        """Validate input against schema"""
        if not self.schema:
            return True, None
        
        try:
            # Check required parameters
            required_params = self.schema.parameters.get('required', [])
            for param in required_params:
                if param not in input_data:
                    return False, f"Missing required parameter: {param}"
            
            # Run custom validators
            for validator in self.schema.input_validators:
                result = validator(input_data)
                if not result.get('valid', True):
                    return False, result.get('error', 'Input validation failed')
            
            return True, None
            
        except Exception as e:
            return False, f"Validation error: {str(e)}"
    
    def execute_with_validation(self, 
                               input_data: Dict, 
                               context: Optional[Dict] = None,
                               agent_id: Optional[str] = None) -> Dict:
        """
        Execute tool with full validation and observability.
        This is the main entry point for tool execution.
        """
        start_time = time.time()
        call_id = f"call_{int(start_time)}_{self.name}"
        
        try:
            # Check rate limit
            if not self.rate_limiter.allow_request(agent_id or 'anonymous'):
                return {
                    "success": False,
                    "error": "Rate limit exceeded",
                    "call_id": call_id
                }
            
            # Validate input
            is_valid, error = self.validate_input(input_data)
            if not is_valid:
                self.error_count += 1
                return {
                    "success": False,
                    "error": error,
                    "call_id": call_id
                }
            
            # Check authorization
            if self.schema and self.schema.requires_auth:
                if not self._check_auth(context):
                    return {
                        "success": False,
                        "error": "Authorization required",
                        "call_id": call_id
                    }
            
            # Execute tool
            result = self.execute(input_data, context)
            
            # Validate output
            if self.schema and self.schema.output_validators:
                for validator in self.schema.output_validators:
                    valid_result = validator(result)
                    if not valid_result.get('valid', True):
                        result = {
                            "success": False,
                            "error": valid_result.get('error', 'Output validation failed'),
                            "original_result": result
                        }
                        break
            
            # Calculate execution time
            execution_time = time.time() - start_time
            self.execution_times.append(execution_time)
            
            # Log call
            self._log_call(
                call_id=call_id,
                input=input_data,
                output=result,
                execution_time=execution_time,
                agent_id=agent_id,
                success=result.get('success', False)
            )
            
            self.total_calls += 1
            
            # Add metadata to result
            if isinstance(result, dict):
                result['call_id'] = call_id
                result['execution_time_seconds'] = execution_time
                result['tool_name'] = self.name
            
            return result
            
        except Exception as e:
            self.error_count += 1
            error_time = time.time() - start_time
            
            self._log_call(
                call_id=call_id,
                input=input_data,
                output={"error": str(e), "traceback": traceback.format_exc()},
                execution_time=error_time,
                agent_id=agent_id,
                success=False
            )
            
            return {
                "success": False,
                "error": f"Tool execution failed: {str(e)}",
                "call_id": call_id,
                "execution_time_seconds": error_time
            }
    
    def _check_auth(self, context: Optional[Dict]) -> bool:
        """Check authorization"""
        if not context:
            return False
        
        # Check token
        if self.auth_token and context.get('auth_token') != self.auth_token:
            return False
        
        # Check scopes
        if self.schema and self.schema.auth_scopes:
            user_scopes = set(context.get('auth_scopes', []))
            required_scopes = set(self.schema.auth_scopes)
            if not required_scopes.issubset(user_scopes):
                return False
        
        return True
    
    def _log_call(self, 
                  call_id: str,
                  input: Dict,
                  output: Dict,
                  execution_time: float,
                  agent_id: Optional[str],
                  success: bool):
        """Log tool call for observability"""
        log_entry = {
            "call_id": call_id,
            "timestamp": datetime.now().isoformat(),
            "tool": self.name,
            "agent_id": agent_id,
            "input": self._sanitize_for_logging(input),
            "output": self._sanitize_for_logging(output),
            "execution_time_ms": execution_time * 1000,
            "success": success
        }
        
        self.call_history.append(log_entry)
        
        # Keep only last 1000 calls
        if len(self.call_history) > 1000:
            self.call_history = self.call_history[-1000:]
    
    def _sanitize_for_logging(self, data: Any) -> Any:
        """Sanitize sensitive data before logging"""
        if not isinstance(data, dict):
            return data
        
        sanitized = data.copy()
        
        # Remove sensitive fields
        sensitive_keys = ['password', 'token', 'secret', 'key', 'auth']
        for key in list(sanitized.keys()):
            key_lower = key.lower()
            if any(sensitive in key_lower for sensitive in sensitive_keys):
                sanitized[key] = "***REDACTED***"
        
        return sanitized
    
    def get_stats(self) -> Dict[str, Any]:
        """Get tool statistics"""
        avg_time = sum(self.execution_times) / len(self.execution_times) if self.execution_times else 0
        
        return {
            "name": self.name,
            "total_calls": self.total_calls,
            "error_count": self.error_count,
            "success_rate": (self.total_calls - self.error_count) / self.total_calls if self.total_calls > 0 else 0,
            "avg_execution_time_ms": avg_time * 1000,
            "recent_calls": self.call_history[-10:] if self.call_history else [],
            "rate_limit_status": self.rate_limiter.get_status()
        }
    
    def get_schema(self) -> Optional[ToolSchema]:
        """Get tool schema"""
        return self.schema

# Example: Safe Web Search Tool
class SafeWebSearch(BaseTool):
    """Example production tool with security and rate limiting"""
    
    def __init__(self, config: Optional[Dict] = None):
        super().__init__(
            name="web_search",
            description="Search the web safely with content filtering",
            config=config
        )
        
        # Define schema
        self.schema = ToolSchema(
            name="web_search",
            description="Search the web safely with content filtering",
            parameters={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string", 
                        "maxLength": 200,
                        "description": "Search query"
                    },
                    "num_results": {
                        "type": "integer", 
                        "minimum": 1, 
                        "maximum": 10,
                        "default": 5
                    },
                    "safesearch": {
                        "type": "boolean", 
                        "default": True
                    },
                    "language": {
                        "type": "string",
                        "default": "en"
                    }
                },
                "required": ["query"]
            },
            returns={
                "type": "object",
                "properties": {
                    "success": {"type": "boolean"},
                    "results": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "title": {"type": "string"},
                                "url": {"type": "string"},
                                "snippet": {"type": "string"},
                                "relevance_score": {"type": "number"}
                            }
                        }
                    },
                    "query_time_ms": {"type": "number"},
                    "total_results": {"type": "integer"}
                }
            },
            safety_level=ToolSafetyLevel.MONITORED,
            requires_auth=False,
            rate_limit={"calls_per_minute": 30},
            cost_estimate={"tokens": 50, "usd": 0.0005},
            timeout_seconds=10,
            input_validators=[
                self._validate_query_safety
            ]
        )
        
        # Initialize components
        self.content_filter = ContentFilter()
        self.search_client = SearchClient(
            api_key=config.get('search_api_key'),
            endpoint=config.get('search_endpoint', 'https://api.search.example.com')
        )
        
    def execute(self, input_data: Dict, context: Optional[Dict] = None) -> Dict:
        """Execute web search"""
        query = input_data["query"]
        num_results = input_data.get("num_results", 5)
        safesearch = input_data.get("safesearch", True)
        language = input_data.get("language", "en")
        
        # Apply safety filters
        safe_query = self.content_filter.sanitize(query)
        
        if safesearch:
            safe_query = self.content_filter.add_safesearch(safe_query)
        
        # Perform search
        try:
            search_results = self.search_client.search(
                query=safe_query,
                num_results=num_results,
                language=language
            )
            
            # Filter results
            filtered_results = []
            for result in search_results:
                if self.content_filter.is_safe(result):
                    filtered_results.append({
                        "title": result.get("title", ""),
                        "url": result.get("url", ""),
                        "snippet": result.get("snippet", ""),
                        "relevance_score": result.get("score", 0.0)
                    })
            
            return {
                "success": True,
                "results": filtered_results,
                "original_query": query,
                "safe_query": safe_query,
                "query_time_ms": search_results.get("query_time_ms", 0),
                "total_results": search_results.get("total_results", 0),
                "filtered_count": len(search_results) - len(filtered_results)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "query": query
            }
    
    def _validate_query_safety(self, input_data: Dict) -> Dict[str, Any]:
        """Custom input validator"""
        query = input_data.get("query", "")
        
        # Check for dangerous queries
        dangerous_patterns = [
            r"password.*filetype:pdf",
            r"site:.*\.onion",
            r"intitle:index\.of.*(password|backup)",
            r"\b(ssn|social security|credit card)\b"
        ]
        
        import re
        for pattern in dangerous_patterns:
            if re.search(pattern, query, re.IGNORECASE):
                return {
                    "valid": False,
                    "error": f"Query contains potentially dangerous pattern: {pattern}"
                }
        
        return {"valid": True}
```

3.3 Tool Registry & Manager

```python
# src/aes/modules/tool_registry.py
"""
Central registry for managing tools across agents.
Implements tool discovery, security, and lifecycle management.
"""

from typing import Dict, List, Optional, Set, Any
import threading
import time

class ToolRegistry:
    """
    Central registry for AES tools.
    Manages tool discovery, security policies, and usage tracking.
    """
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        
        # Tool storage
        self.tools: Dict[str, BaseTool] = {}  # tool_name -> tool_instance
        self.tool_categories: Dict[str, List[str]] = defaultdict(list)
        
        # Security policies
        self.policies: Dict[str, Dict] = {}
        self.blacklisted_tools: Set[str] = set()
        
        # Usage tracking
        self.usage_stats: Dict[str, Dict] = defaultdict(lambda: {
            "total_calls": 0,
            "successful_calls": 0,
            "failed_calls": 0,
            "total_cost_usd": 0.0,
            "last_used": None
        })
        
        # Tool lifecycle
        self.tool_versions: Dict[str, List[str]] = defaultdict(list)
        
        # Lock for thread safety
        self._lock = threading.RLock()
        
        # Load default tools
        self._load_default_tools()
    
    def register_tool(self, tool: BaseTool, category: str = "general") -> bool:
        """
        Register a tool with the registry.
        Returns True if registration successful.
        """
        with self._lock:
            tool_name = tool.name
            
            # Check if blacklisted
            if tool_name in self.blacklisted_tools:
                return False
            
            # Check if already registered (different version)
            if tool_name in self.tools:
                # Check if this is a newer version
                existing_tool = self.tools[tool_name]
                existing_version = existing_tool.config.get('version', '1.0.0')
                new_version = tool.config.get('version', '1.0.0')
                
                # Simple version comparison (for demonstration)
                if self._compare_versions(new_version, existing_version) <= 0:
                    return False  # Not newer
            
            # Register tool
            self.tools[tool_name] = tool
            self.tool_categories[category].append(tool_name)
            
            # Record version
            version = tool.config.get('version', '1.0.0')
            self.tool_versions[tool_name].append(version)
            
            # Apply security policy
            self._apply_security_policy(tool_name)
            
            return True
    
    def get_tool(self, tool_name: str, agent_id: Optional[str] = None) -> Optional[BaseTool]:
        """
        Get a tool instance for use.
        Checks authorization before returning.
        """
        with self._lock:
            if tool_name not in self.tools:
                return None
            
            tool = self.tools[tool_name]
            
            # Check agent authorization
            if agent_id and not self._check_agent_authorization(agent_id, tool_name):
                return None
            
            # Check rate limits
            if not self._check_rate_limit(agent_id, tool_name):
                return None
            
            # Update usage stats
            self._update_usage_stats(agent_id, tool_name, "request")
            
            return tool
    
    def execute_tool(self, 
                    tool_name: str, 
                    input_data: Dict, 
                    agent_id: Optional[str] = None,
                    context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Execute a tool with full security and tracking.
        """
        with self._lock:
            # Get tool
            tool = self.get_tool(tool_name, agent_id)
            if not tool:
                return {
                    "success": False,
                    "error": f"Tool '{tool_name}' not available or unauthorized"
                }
            
            # Execute
            start_time = time.time()
            result = tool.execute_with_validation(input_data, context, agent_id)
            execution_time = time.time() - start_time
            
            # Update usage stats
            self._update_usage_stats(
                agent_id, 
                tool_name, 
                "execution", 
                success=result.get('success', False),
                execution_time=execution_time,
                cost=result.get('estimated_cost', {})
            )
            
            return result
    
    def discover_tools(self, 
                      category: Optional[str] = None,
                      capability: Optional[str] = None,
                      safety_level: Optional[ToolSafetyLevel] = None) -> List[Dict[str, Any]]:
        """
        Discover available tools with filtering.
        """
        with self._lock:
            tools_info = []
            
            for tool_name, tool in self.tools.items():
                # Apply filters
                if category and tool_name not in self.tool_categories.get(category, []):
                    continue
                
                if capability and capability not in tool.config.get('capabilities', []):
                    continue
                
                if safety_level and tool.schema and tool.schema.safety_level != safety_level:
                    continue
                
                # Get tool info
                tool_info = {
                    "name": tool_name,
                    "description": tool.description,
                    "category": self._get_tool_category(tool_name),
                    "safety_level": tool.schema.safety_level.value if tool.schema else ToolSafetyLevel.SAFE.value,
                    "requires_auth": tool.schema.requires_auth if tool.schema else False,
                    "rate_limit": tool.schema.rate_limit if tool.schema else None,
                    "cost_estimate": tool.schema.cost_estimate if tool.schema else None,
                    "stats": self.usage_stats[tool_name]
                }
                
                tools_info.append(tool_info)
            
            return tools_info
    
    def add_security_policy(self, 
                           tool_name: str, 
                           policy: Dict[str, Any]) -> bool:
        """
        Add security policy for a tool.
        Policies can restrict usage by agent, time, cost, etc.
        """
        with self._lock:
            if tool_name not in self.tools:
                return False
            
            self.policies[tool_name] = policy
            self._apply_security_policy(tool_name)
            
            return True
    
    def blacklist_tool(self, tool_name: str, reason: str = "") -> bool:
        """Blacklist a tool (prevent all usage)"""
        with self._lock:
            if tool_name in self.tools:
                # Remove from registry
                del self.tools[tool_name]
            
            self.blacklisted_tools.add(tool_name)
            
            # Log blacklisting
            print(f"Tool blacklisted: {tool_name} - Reason: {reason}")
            
            return True
    
    def get_registry_stats(self) -> Dict[str, Any]:
        """Get registry statistics"""
        with self._lock:
            total_calls = sum(stats["total_calls"] for stats in self.usage_stats.values())
            total_cost = sum(stats["total_cost_usd"] for stats in self.usage_stats.values())
            
            return {
                "total_tools": len(self.tools),
                "total_categories": len(self.tool_categories),
                "blacklisted_tools": len(self.blacklisted_tools),
                "total_calls": total_calls,
                "total_cost_usd": total_cost,
                "most_used_tools": self._get_most_used_tools(5),
                "recent_activities": self._get_recent_activities(10)
            }
    
    # ========== PRIVATE METHODS ==========
    
    def _load_default_tools(self):
        """Load default AES tools"""
        default_tools = [
            SafeWebSearch(config={"search_api_key": "demo"}),
            CalculatorTool(),
            FileReaderTool(),
            APICallerTool(),
            DatabaseQueryTool(),
            EmailSenderTool(config={"smtp_server": "smtp.example.com"}),
            DataAnalyzerTool()
        ]
        
        for tool in default_tools:
            self.register_tool(tool)
    
    def _check_agent_authorization(self, agent_id: str, tool_name: str) -> bool:
        """Check if agent is authorized to use tool"""
        policy = self.policies.get(tool_name)
        
        if not policy:
            return True  # No policy = allow all
        
        # Check allowed agents
        allowed_agents = policy.get('allowed_agents', [])
        if allowed_agents and agent_id not in allowed_agents:
            return False
        
        # Check agent capabilities
        required_capabilities = policy.get('required_capabilities', [])
        if required_capabilities:
            # This would check agent's capabilities
            # For now, return True (implement based on your agent system)
            pass
        
        return True
    
    def _check_rate_limit(self, agent_id: Optional[str], tool_name: str) -> bool:
        """Check rate limits for tool usage"""
        # Global rate limit
        global_limit = self.config.get('global_rate_limit', {})
        if global_limit:
            calls_per_minute = global_limit.get('calls_per_minute', 1000)
            # Implement rate limiting logic here
        
        # Per-agent rate limit
        if agent_id:
            agent_limit = self.config.get('agent_rate_limits', {}).get(agent_id)
            if agent_limit:
                calls_per_minute = agent_limit.get('calls_per_minute', 100)
                # Implement rate limiting logic here
        
        return True  # For now, always allow
    
    def _update_usage_stats(self, 
                           agent_id: Optional[str], 
                           tool_name: str, 
                           action: str,
                           success: bool = False,
                           execution_time: float = 0.0,
                           cost: Dict[str, float] = None):
        """Update usage statistics"""
        stats = self.usage_stats[tool_name]
        
        if action == "request":
            stats["total_calls"] += 1
        elif action == "execution":
            if success:
                stats["successful_calls"] += 1
            else:
                stats["failed_calls"] += 1
            
            # Update cost
            if cost and "usd" in cost:
                stats["total_cost_usd"] += cost["usd"]
        
        stats["last_used"] = time.time()
    
    def _get_tool_category(self, tool_name: str) -> str:
        """Get category for a tool"""
        for category, tools in self.tool_categories.items():
            if tool_name in tools:
                return category
        return "uncategorized"
    
    def _apply_security_policy(self, tool_name: str):
        """Apply security policy to tool"""
        policy = self.policies.get(tool_name)
        if not policy or tool_name not in self.tools:
            return
        
        tool = self.tools[tool_name]
        
        # Apply rate limit from policy
        if 'rate_limit' in policy and tool.schema:
            tool.schema.rate_limit = policy['rate_limit']
            tool.rate_limiter = RateLimiter(
                max_requests=policy['rate_limit'].get('calls_per_minute', 60)
            )
    
    def _compare_versions(self, v1: str, v2: str) -> int:
        """Compare version strings (simplified)"""
        # Convert to tuples of integers
        def parse_version(v: str):
            return tuple(map(int, v.split('.')))
        
        try:
            v1_tuple = parse_version(v1)
            v2_tuple = parse_version(v2)
            
            if v1_tuple > v2_tuple:
                return 1
            elif v1_tuple < v2_tuple:
                return -1
            else:
                return 0
        except:
            return 0
    
    def _get_most_used_tools(self, n: int) -> List[Dict[str, Any]]:
        """Get n most used tools"""
        sorted_tools = sorted(
            self.usage_stats.items(),
            key=lambda x: x[1]["total_calls"],
            reverse=True
        )[:n]
        
        return [
            {
                "tool": tool_name,
                "calls": stats["total_calls"],
                "success_rate": stats["successful_calls"] / stats["total_calls"] if stats["total_calls"] > 0 else 0,
                "total_cost": stats["total_cost_usd"]
            }
            for tool_name, stats in sorted_tools
        ]
    
    def _get_recent_activities(self, n: int) -> List[Dict[str, Any]]:
        """Get n most recent tool activities"""
        activities = []
        
        for tool_name, stats in self.usage_stats.items():
            if stats["last_used"]:
                activities.append({
                    "tool": tool_name,
                    "last_used": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(stats["last_used"])),
                    "total_calls": stats["total_calls"]
                })
        
        activities.sort(key=lambda x: x.get("last_used", ""), reverse=True)
        return activities[:n]
```

---

4ï¸âƒ£ SECURITY FRAMEWORK: BLAST RADIUS CONTROL

4.1 Sandboxed Execution Environment

```python
# src/aes/security/sandbox.py
"""
Sandboxed execution environment for tools.
Prevents tools from accessing unauthorized resources.
"""

import os
import sys
import tempfile
import subprocess
from contextlib import contextmanager
from typing import Any, Dict, List, Optional, Callable
import resource
import signal

class Sandbox:
    """
    Sandbox for safely executing untrusted code.
    Implements resource limits, filesystem isolation, and network restrictions.
    """
    
    def __init__(self, config: Dict):
        self.config = config
        
        # Resource limits
        self.resource_limits = {
            'cpu_time': config.get('max_cpu_time', 30),  # seconds
            'memory_mb': config.get('max_memory_mb', 256),
            'disk_mb': config.get('max_disk_mb', 100),
            'file_descriptors': config.get('max_file_descriptors', 50),
            'process_count': config.get('max_processes', 10)
        }
        
        # Security policies
        self.allowed_syscalls = set(config.get('allowed_syscalls', []))
        self.blocked_modules = set(config.get('blocked_modules', [
            'os', 'sys', 'subprocess', 'socket', 
            'shutil', 'glob', 'tempfile', 'pickle'
        ]))
        
        # Filesystem isolation
        self.temp_dir = None
        self.allowed_paths = set(config.get('allowed_paths', []))
        
        # Network restrictions
        self.allowed_ports = set(config.get('allowed_ports', []))
        self.allowed_hosts = set(config.get('allowed_hosts', []))
    
    @contextmanager
    def execute(self, 
                code: str, 
                input_data: Optional[Dict] = None,
                timeout: int = 30) -> Dict[str, Any]:
        """
        Execute code in sandboxed environment.
        Returns execution result with safety checks.
        """
        # Create isolated temp directory
        self.temp_dir = tempfile.mkdtemp(prefix="aes_sandbox_")
        
        # Set resource limits
        self._set_resource_limits()
        
        # Prepare execution environment
        env = self._prepare_environment(input_data)
        
        result = {
            "success": False,
            "output": None,
            "error": None,
            "execution_time": 0,
            "resource_usage": {}
        }
        
        start_time = time.time()
        
        try:
            # Execute in restricted environment
            output = self._execute_restricted(code, env, timeout)
            
            result.update({
                "success": True,
                "output": output,
                "execution_time": time.time() - start_time
            })
            
        except TimeoutError:
            result["error"] = f"Execution timeout after {timeout} seconds"
        except MemoryError:
            result["error"] = "Memory limit exceeded"
        except Exception as e:
            result["error"] = f"Execution failed: {str(e)}"
        finally:
            # Cleanup
            self._cleanup()
        
        # Add resource usage
        result["resource_usage"] = self._get_resource_usage()
        
        return result
    
    def _set_resource_limits(self):
        """Set resource limits for sandboxed process"""
        # CPU time limit
        resource.setrlimit(
            resource.RLIMIT_CPU,
            (self.resource_limits['cpu_time'], self.resource_limits['cpu_time'])
        )
        
        # Memory limit
        memory_bytes = self.resource_limits['memory_mb'] * 1024 * 1024
        resource.setrlimit(
            resource.RLIMIT_AS,
            (memory_bytes, memory_bytes)
        )
        
        # File descriptor limit
        resource.setrlimit(
            resource.RLIMIT_NOFILE,
            (self.resource_limits['file_descriptors'], 
             self.resource_limits['file_descriptors'])
        )
    
    def _prepare_environment(self, input_data: Optional[Dict]) -> Dict[str, Any]:
        """Prepare restricted execution environment"""
        # Create safe globals
        safe_globals = {
            '__builtins__': self._create_safe_builtins(),
            'input_data': input_data or {},
            'result': None
        }
        
        # Add allowed modules
        for module_name in self.config.get('allowed_modules', ['math', 'json', 're']):
            try:
                module = __import__(module_name)
                safe_globals[module_name] = module
            except ImportError:
                pass
        
        return safe_globals
    
    def _create_safe_builtins(self) -> Dict[str, Any]:
        """Create safe subset of builtins"""
        safe_builtins = {}
        
        # Allow only safe functions
        safe_functions = [
            'abs', 'all', 'any', 'bool', 'chr', 'dict', 'dir', 'enumerate',
            'float', 'int', 'len', 'list', 'max', 'min', 'ord', 'pow',
            'range', 'round', 'set', 'sorted', 'str', 'sum', 'tuple', 'zip'
        ]
        
        import builtins
        for name in safe_functions:
            if hasattr(builtins, name):
                safe_builtins[name] = getattr(builtins, name)
        
        return safe_builtins
    
    def _execute_restricted(self, 
                           code: str, 
                           env: Dict[str, Any],
                           timeout: int) -> Any:
        """Execute code with restrictions"""
        # Define signal handler for timeout
        def timeout_handler(signum, frame):
            raise TimeoutError("Execution timeout")
        
        # Set timeout
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(timeout)
        
        try:
            # Compile code with restrictions
            compiled = compile(code, '<sandbox>', 'exec')
            
            # Execute in restricted environment
            exec(compiled, env)
            
            # Get result
            return env.get('result')
            
        finally:
            # Disable alarm
            signal.alarm(0)
    
    def _cleanup(self):
        """Clean up sandbox resources"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            import shutil
            try:
                shutil.rmtree(self.temp_dir)
            except:
                pass  # Best effort cleanup
    
    def _get_resource_usage(self) -> Dict[str, Any]:
        """Get resource usage statistics"""
        usage = resource.getrusage(resource.RUSAGE_SELF)
        
        return {
            'user_time': usage.ru_utime,
            'system_time': usage.ru_stime,
            'max_rss_kb': usage.ru_maxrss,
            'page_faults': usage.ru_majflt,
            'context_switches': usage.ru_nvcsw + usage.ru_nivcsw
        }
```

4.2 Token Scoping & API Key Management

```python
# src/aes/security/tokens.py
"""
Token scoping system for secure API access.
Each agent gets scoped tokens, never master keys.
"""

from typing import Dict, List, Optional, Set
import secrets
import time
from datetime import datetime, timedelta
import hashlib
import json

class TokenManager:
    """
    Manages scoped API tokens for agents.
    Implements token issuance, validation, and revocation.
    """
    
    def __init__(self, config: Dict):
        self.config = config
        
        # Token storage
        self.tokens: Dict[str, Dict] = {}  # token_hash -> token_data
        self.agent_tokens: Dict[str, Set[str]] = defaultdict(set)  # agent_id -> token_hashes
        
        # Master keys (for token issuance)
        self.master_keys: Dict[str, str] = config.get('master_keys', {})
        
        # Rate limiting
        self.token_issuance_log: Dict[str, List[float]] = defaultdict(list)
        self.max_tokens_per_hour = config.get('max_tokens_per_hour', 100)
        
        # Auto-revocation
        self.revocation_queue = []
    
    def issue_token(self,
                   agent_id: str,
                   scopes: List[str],
                   resources: List[str],
                   expires_in: int = 3600,
                   metadata: Optional[Dict] = None) -> Optional[str]:
        """
        Issue a scoped token to an agent.
        Returns token string or None if failed.
        """
        # Check rate limit
        if not self._check_issuance_rate(agent_id):
            return None
        
        # Generate token
        token_string = secrets.token_urlsafe(32)
        token_hash = self._hash_token(token_string)
        
        # Calculate expiration
        issued_at = time.time()
        expires_at = issued_at + expires_in
        
        # Create token data
        token_data = {
            'token_hash': token_hash,
            'agent_id': agent_id,
            'scopes': scopes,
            'resources': resources,
            'issued_at': issued_at,
            'expires_at': expires_at,
            'metadata': metadata or {},
            'last_used': None,
            'usage_count': 0,
            'revoked': False
        }
        
        # Store token
        self.tokens[token_hash] = token_data
        self.agent_tokens[agent_id].add(token_hash)
        
        # Add to revocation queue
        self.revocation_queue.append((expires_at, token_hash))
        
        # Log issuance
        self._log_token_activity(token_hash, 'issued', agent_id)
        
        return token_string
    
    def validate_token(self, 
                      token: str, 
                      required_scopes: List[str],
                      required_resource: Optional[str] = None) -> Dict[str, Any]:
        """
        Validate a token and check permissions.
        Returns validation result.
        """
        token_hash = self._hash_token(token)
        
        if token_hash not in self.tokens:
            return {
                'valid': False,
                'error': 'Token not found',
                'status': 'invalid'
            }
        
        token_data = self.tokens[token_hash]
        
        # Check if revoked
        if token_data.get('revoked', False):
            return {
                'valid': False,
                'error': 'Token revoked',
                'status': 'revoked'
            }
        
        # Check expiration
        current_time = time.time()
        if current_time > token_data['expires_at']:
            return {
                'valid': False,
                'error': 'Token expired',
                'status': 'expired'
            }
        
        # Check scopes
        token_scopes = set(token_data['scopes'])
        required_scopes_set = set(required_scopes)
        
        if not required_scopes_set.issubset(token_scopes):
            return {
                'valid': False,
                'error': 'Insufficient scopes',
                'status': 'insufficient_scopes',
                'required': required_scopes,
                'granted': list(token_scopes)
            }
        
        # Check resource access
        if required_resource and required_resource not in token_data['resources']:
            return {
                'valid': False,
                'error': f'Access to resource {required_resource} not granted',
                'status': 'resource_denied'
            }
        
        # Update token usage
        token_data['last_used'] = current_time
        token_data['usage_count'] += 1
        
        # Log validation
        self._log_token_activity(token_hash, 'validated', token_data['agent_id'])
        
        return {
            'valid': True,
            'agent_id': token_data['agent_id'],
            'scopes': token_data['scopes'],
            'resources': token_data['resources'],
            'expires_in': int(token_data['expires_at'] - current_time),
            'usage_count': token_data['usage_count']
        }
    
    def revoke_token(self, token_hash: str, reason: str = "") -> bool:
        """Revoke a token"""
        if token_hash in self.tokens:
            self.tokens[token_hash]['revoked'] = True
            self.tokens[token_hash]['revocation_reason'] = reason
            self.tokens[token_hash]['revoked_at'] = time.time()
            
            # Remove from agent's token set
            agent_id = self.tokens[token_hash]['agent_id']
            if agent_id in self.agent_tokens:
                self.agent_tokens[agent_id].discard(token_hash)
            
            self._log_token_activity(token_hash, 'revoked', agent_id, reason)
            
            return True
        
        return False
    
    def revoke_agent_tokens(self, agent_id: str, reason: str = "") -> int:
        """Revoke all tokens for an agent"""
        if agent_id not in self.agent_tokens:
            return 0
        
        revoked_count = 0
        for token_hash in list(self.agent_tokens[agent_id]):
            if self.revoke_token(token_hash, reason):
                revoked_count += 1
        
        return revoked_count
    
    def get_token_info(self, token_hash: str) -> Optional[Dict[str, Any]]:
        """Get information about a token"""
        if token_hash in self.tokens:
            token_data = self.tokens[token_hash].copy()
            
            # Remove sensitive data
            token_data.pop('token_hash', None)
            
            # Add calculated fields
            current_time = time.time()
            token_data['is_expired'] = current_time > token_data['expires_at']
            token_data['expires_in'] = int(token_data['expires_at'] - current_time)
            
            return token_data
        
        return None
    
    def cleanup_expired_tokens(self) -> Dict[str, int]:
        """Clean up expired tokens"""
        current_time = time.time()
        expired_count = 0
        revoked_count = 0
        
        for token_hash, token_data in list(self.tokens.items()):
            if current_time > token_data['expires_at'] + 86400:  # 24 hours grace period
                # Remove expired token
                agent_id = token_data['agent_id']
                
                if agent_id in self.agent_tokens:
                    self.agent_tokens[agent_id].discard(token_hash)
                
                del self.tokens[token_hash]
                expired_count += 1
            
            elif token_data.get('revoked', False) and current_time > token_data.get('revoked_at', 0) + 3600:
                # Remove revoked tokens after 1 hour
                agent_id = token_data['agent_id']
                
                if agent_id in self.agent_tokens:
                    self.agent_tokens[agent_id].discard(token_hash)
                
                del self.tokens[token_hash]
                revoked_count += 1
        
        return {
            'expired_removed': expired_count,
            'revoked_removed': revoked_count,
            'remaining_tokens': len(self.tokens)
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """Get token manager statistics"""
        active_tokens = 0
        expired_tokens = 0
        revoked_tokens = 0
        
        current_time = time.time()
        
        for token_data in self.tokens.values():
            if token_data.get('revoked', False):
                revoked_tokens += 1
            elif current_time > token_data['expires_at']:
                expired_tokens += 1
            else:
                active_tokens += 1
        
        return {
            'total_tokens': len(self.tokens),
            'active_tokens': active_tokens,
            'expired_tokens': expired_tokens,
            'revoked_tokens': revoked_tokens,
            'total_agents': len(self.agent_tokens),
            'tokens_per_agent': {
                agent_id: len(tokens) 
                for agent_id, tokens in self.agent_tokens.items()
            }
        }
    
    # ========== PRIVATE METHODS ==========
    
    def _hash_token(self, token: str) -> str:
        """Hash token for storage (never store raw tokens)"""
        return hashlib.sha256(token.encode()).hexdigest()
    
    def _check_issuance_rate(self, agent_id: str) -> bool:
        """Check token issuance rate limit"""
        current_time = time.time()
        one_hour_ago = current_time - 3600
        
        # Clean old entries
        self.token_issuance_log[agent_id] = [
            t for t in self.token_issuance_log[agent_id] 
            if t > one_hour_ago
        ]
        
        # Check limit
        if len(self.token_issuance_log[agent_id]) >= self.max_tokens_per_hour:
            return False
        
        # Log issuance
        self.token_issuance_log[agent_id].append(current_time)
        
        return True
    
    def _log_token_activity(self, 
                           token_hash: str, 
                           action: str, 
                           agent_id: str,
                           details: str = ""):
        """Log token activity"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'token_hash': token_hash[:16],  # Log only first 16 chars
            'agent_id': agent_id,
            'action': action,
            'details': details
        }
        
        # In production, this would go to a secure log
        print(f"[TokenManager] {json.dumps(log_entry)}")
```

4.3 Rate Limiting with Weighted Headers

```python
# src/aes/security/rate_limiter.py
"""
Advanced rate limiting with weighted headers.
Prevents agents from "screaming" (looping too fast).
"""

import time
from collections import defaultdict, deque
from typing import Dict, List, Optional, Set
import threading

class RateLimiter:
    """
    Implements token bucket rate limiting with weighted requests.
    Supports multiple dimensions: requests, tokens, compute time, etc.
    """
    
    def __init__(self, config: Dict):
        self.config = config
        
        # Token buckets for different dimensions
        self.buckets = {
            'requests': TokenBucket(
                capacity=config.get('max_requests_per_minute', 60),
                fill_rate=config.get('requests_fill_rate', 1.0)  # tokens per second
            ),
            'tokens': TokenBucket(
                capacity=config.get('max_tokens_per_minute', 10000),
                fill_rate=config.get('tokens_fill_rate', 166.67)  # ~10K per minute
            ),
            'compute': TokenBucket(
                capacity=config.get('max_compute_seconds_per_minute', 300),
                fill_rate=config.get('compute_fill_rate', 5.0)  # 5 seconds per second
            ),
            'cost': TokenBucket(
                capacity=config.get('max_cost_usd_per_minute', 1.0),
                fill_rate=config.get('cost_fill_rate', 0.0167)  # $1 per minute
            )
        }
        
        # Per-agent limits
        self.agent_buckets: Dict[str, Dict] = defaultdict(
            lambda: {
                'requests': TokenBucket(
                    capacity=config.get('max_agent_requests_per_minute', 10),
                    fill_rate=config.get('agent_requests_fill_rate', 0.1667)
                ),
                'tokens': TokenBucket(
                    capacity=config.get('max_agent_tokens_per_minute', 1000),
                    fill_rate=config.get('agent_tokens_fill_rate', 16.67)
                )
            }
        )
        
        # Request weights (how much each request consumes)
        self.default_weights = {
            'requests': 1.0,
            'tokens': 100.0,  # Average LLM tokens per request
            'compute': 2.0,   # Average seconds per request
            'cost': 0.001     # Average USD per request
        }
        
        # Burst protection
        self.burst_limits = config.get('burst_limits', {
            'max_burst_requests': 10,
            'max_burst_tokens': 1000,
            'burst_window_seconds': 5
        })
        
        self.burst_tracker = BurstTracker(self.burst_limits)
        
        # Blocklist for abusive clients
        self.blocklist: Dict[str, float] = {}  # client_id -> block_until
        self.block_duration = config.get('block_duration', 300)  # 5 minutes
        
        # Thread safety
        self._lock = threading.RLock()
        
        # Statistics
        self.stats = {
            'total_requests': 0,
            'allowed_requests': 0,
            'blocked_requests': 0,
            'rate_limited_requests': 0,
            'burst_blocked_requests': 0
        }
    
    def allow_request(self, 
                     client_id: str, 
                     weights: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
        """
        Check if request is allowed.
        Returns decision with details.
        """
        with self._lock:
            # Check blocklist
            if self._is_blocked(client_id):
                self.stats['blocked_requests'] += 1
                return {
                    'allowed': False,
                    'reason': 'client_blocked',
                    'blocked_until': self.blocklist[client_id]
                }
            
            # Check burst limits
            if not self.burst_tracker.allow_request(client_id):
                self.stats['burst_blocked_requests'] += 1
                
                # Add to blocklist after multiple burst violations
                violations = self.burst_tracker.get_violations(client_id)
                if violations >= 3:
                    self._add_to_blocklist(client_id, 'burst_violations')
                
                return {
                    'allowed': False,
                    'reason': 'burst_limit_exceeded',
                    'violations': violations
                }
            
            # Calculate effective weights
            effective_weights = self.default_weights.copy()
            if weights:
                effective_weights.update(weights)
            
            # Check global limits
            global_allowed = True
            limited_dimensions = []
            
            for dimension, bucket in self.buckets.items():
                weight = effective_weights.get(dimension, 0)
                if weight > 0 and not bucket.consume(weight):
                    global_allowed = False
                    limited_dimensions.append(dimension)
            
            # Check per-agent limits
            agent_allowed = True
            agent_limited_dimensions = []
            
            if client_id != 'anonymous':
                agent_buckets = self.agent_buckets[client_id]
                for dimension, bucket in agent_buckets.items():
                    weight = effective_weights.get(dimension, 0)
                    if weight > 0 and not bucket.consume(weight):
                        agent_allowed = False
                        agent_limited_dimensions.append(dimension)
            
            # Update statistics
            self.stats['total_requests'] += 1
            
            if global_allowed and agent_allowed:
                self.stats['allowed_requests'] += 1
                
                # Update burst tracker
                self.burst_tracker.record_request(client_id, effective_weights)
                
                return {
                    'allowed': True,
                    'global_limits': self._get_bucket_status(self.buckets),
                    'agent_limits': self._get_bucket_status(self.agent_buckets.get(client_id, {})),
                    'weights_used': effective_weights,
                    'client_id': client_id
                }
            else:
                self.stats['rate_limited_requests'] += 1
                
                # Determine which limit was hit
                if not global_allowed:
                    reason = f'global_limit_exceeded: {limited_dimensions}'
                else:
                    reason = f'agent_limit_exceeded: {agent_limited_dimensions}'
                
                return {
                    'allowed': False,
                    'reason': reason,
                    'global_limited': not global_allowed,
                    'agent_limited': not agent_allowed,
                    'global_status': self._get_bucket_status(self.buckets),
                    'agent_status': self._get_bucket_status(self.agent_buckets.get(client_id, {})),
                    'retry_after': self._calculate_retry_after(
                        limited_dimensions if not global_allowed else agent_limited_dimensions,
                        effective_weights
                    )
                }
    
    def add_agent_limit(self, 
                       agent_id: str, 
                       dimension: str, 
                       capacity: float, 
                       fill_rate: float):
        """Add or update per-agent limit"""
        with self._lock:
            if agent_id not in self.agent_buckets:
                self.agent_buckets[agent_id] = {}
            
            self.agent_buckets[agent_id][dimension] = TokenBucket(
                capacity=capacity,
                fill_rate=fill_rate
            )
    
    def remove_agent_limit(self, agent_id: str, dimension: str):
        """Remove per-agent limit"""
        with self._lock:
            if agent_id in self.agent_buckets and dimension in self.agent_buckets[agent_id]:
                del self.agent_buckets[agent_id][dimension]
    
    def get_client_status(self, client_id: str) -> Dict[str, Any]:
        """Get current status for a client"""
        with self._lock:
            is_blocked = self._is_blocked(client_id)
            
            status = {
                'client_id': client_id,
                'is_blocked': is_blocked,
                'blocked_until': self.blocklist.get(client_id) if is_blocked else None,
                'burst_status': self.burst_tracker.get_client_status(client_id),
                'agent_limits': self._get_bucket_status(self.agent_buckets.get(client_id, {})),
                'global_limits': self._get_bucket_status(self.buckets),
                'stats': {
                    'total_requests': self.stats['total_requests'],
                    'allowed_requests': self.stats['allowed_requests'],
                    'success_rate': self.stats['allowed_requests'] / self.stats['total_requests'] 
                                    if self.stats['total_requests'] > 0 else 0
                }
            }
            
            return status
    
    def get_global_stats(self) -> Dict[str, Any]:
        """Get global rate limiter statistics"""
        with self._lock:
            return {
                'stats': self.stats.copy(),
                'total_clients': len(self.agent_buckets),
                'blocked_clients': len(self.blocklist),
                'bucket_status': self._get_bucket_status(self.buckets),
                'burst_tracker_stats': self.burst_tracker.get_stats()
            }
    
    # ========== PRIVATE METHODS ==========
    
    def _is_blocked(self, client_id: str) -> bool:
        """Check if client is blocked"""
        if client_id in self.blocklist:
            if time.time() < self.blocklist[client_id]:
                return True
            else:
                # Block expired
                del self.blocklist[client_id]
        
        return False
    
    def _add_to_blocklist(self, client_id: str, reason: str):
        """Add client to blocklist"""
        block_until = time.time() + self.block_duration
        self.blocklist[client_id] = block_until
        
        # Log blocking
        print(f"[RateLimiter] Blocked client {client_id} until {block_until} - Reason: {reason}")
    
    def _get_bucket_status(self, buckets: Dict[str, TokenBucket]) -> Dict[str, Any]:
        """Get status of token buckets"""
        status = {}
        
        for dimension, bucket in buckets.items():
            status[dimension] = {
                'tokens_available': bucket.tokens,
                'capacity': bucket.capacity,
                'fill_rate': bucket.fill_rate,
                'last_fill': bucket.last_fill
            }
        
        return status
    
    def _calculate_retry_after(self, 
                              limited_dimensions: List[str], 
                              weights: Dict[str, float]) -> float:
        """Calculate when to retry after being rate limited"""
        retry_times = []
        
        for dimension in limited_dimensions:
            bucket = self.buckets.get(dimension)
            if bucket:
                weight = weights.get(dimension, 1.0)
                retry_time = bucket.time_until_tokens(weight)
                retry_times.append(retry_time)
        
        return max(retry_times) if retry_times else 1.0

class TokenBucket:
    """Token bucket rate limiting implementation"""
    
    def __init__(self, capacity: float, fill_rate: float):
        self.capacity = capacity
        self.fill_rate = fill_rate  # tokens per second
        self.tokens = capacity
        self.last_fill = time.time()
    
    def consume(self, tokens: float) -> bool:
        """Consume tokens from bucket"""
        self._refill()
        
        if tokens <= self.tokens:
            self.tokens -= tokens
            return True
        
        return False
    
    def time_until_tokens(self, required_tokens: float) -> float:
        """Calculate time until required tokens are available"""
        self._refill()
        
        if required_tokens <= self.tokens:
            return 0.0
        
        deficit = required_tokens - self.tokens
        return deficit / self.fill_rate
    
    def _refill(self):
        """Refill bucket based on elapsed time"""
        now = time.time()
        elapsed = now - self.last_fill
        
        # Add tokens based on elapsed time
        new_tokens = elapsed * self.fill_rate
        self.tokens = min(self.capacity, self.tokens + new_tokens)
        
        self.last_fill = now

class BurstTracker:
    """Tracks and prevents request bursts"""
    
    def __init__(self, limits: Dict):
        self.limits = limits
        self.request_history: Dict[str, deque] = defaultdict(deque)
        self.violations: Dict[str, int] = defaultdict(int)
    
    def allow_request(self, client_id: str) -> bool:
        """Check if request is allowed under burst limits"""
        if client_id not in self.request_history:
            return True
        
        history = self.request_history[client_id]
        now = time.time()
        
        # Remove old entries
        while history and now - history[0] > self.limits['burst_window_seconds']:
            history.popleft()
        
        # Check burst limit
        if len(history) >= self.limits['max_burst_requests']:
            self.violations[client_id] += 1
            return False
        
        return True
    
    def record_request(self, client_id: str, weights: Dict[str, float]):
        """Record a request"""
        now = time.time()
        
        if client_id not in self.request_history:
            self.request_history[client_id] = deque(maxlen=100)
        
        self.request_history[client_id].append(now)
    
    def get_violations(self, client_id: str) -> int:
        """Get violation count for client"""
        return self.violations.get(client_id, 0)
    
    def get_client_status(self, client_id: str) -> Dict[str, Any]:
        """Get burst status for client"""
        history = self.request_history.get(client_id, deque())
        
        now = time.time()
        recent_requests = 0
        
        for timestamp in reversed(history):
            if now - timestamp <= self.limits['burst_window_seconds']:
                recent_requests += 1
            else:
                break
        
        return {
            'recent_requests': recent_requests,
            'burst_limit': self.limits['max_burst_requests'],
            'burst_window': self.limits['burst_window_seconds'],
            'violations': self.violations.get(client_id, 0),
            'history_size': len(history)
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """Get burst tracker statistics"""
        total_violations = sum(self.violations.values())
        total_clients = len(self.request_history)
        
        return {
            'total_clients': total_clients,
            'total_violations': total_violations,
            'clients_with_violations': sum(1 for v in self.violations.values() if v > 0),
            'limits': self.limits
        }
```

---

5ï¸âƒ£ OBSERVABILITY & MONITORING

5.1 Comprehensive Agent Monitor

```python
# src/aes/monitoring/agent_monitor.py
"""
Comprehensive monitoring system for AES agents.
Implements the "Four Golden Signals" from SRE:
1. Latency - How long requests take
2. Traffic - How much demand
3. Errors - How often things fail  
4. Saturation - How full the system is
"""

import asyncio
import time
from collections import defaultdict, deque
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set
import json
import threading
import psutil  # For system metrics

class AgentMonitor:
    """
    Central monitoring dashboard for ALL AES agents.
    Provides real-time metrics, alerts, and health checks.
    """
    
    def __init__(self, config: Dict):
        self.config = config
        
        # Agent registry
        self.agents: Dict[str, Dict] = {}  # agent_id -> agent_data
        self.agent_health: Dict[str, Dict] = defaultdict(lambda: {
            'status': 'unknown',
            'last_check': None,
            'checks_passed': 0,
            'checks_failed': 0,
            'uptime': 0
        })
        
        # Metrics storage
        self.metrics_store = MetricsStore(
            retention_days=config.get('retention_days', 7)
        )
        
        # Alert system
        self.alert_manager = AlertManager(
            alert_rules=config.get('alert_rules', []),
            notification_channels=config.get('notification_channels', [])
        )
        
        # Health check scheduler
        self.health_check_interval = config.get('health_check_interval', 60)
        self._health_check_thread = None
        self._running = False
        
        # Performance metrics
        self.system_metrics = SystemMetricsCollector()
        
        # Agent relationships (for dependency tracking)
        self.agent_dependencies: Dict[str, Set[str]] = defaultdict(set)
        
        # Start monitoring
        self.start()
    
    def register_agent(self, agent, metadata: Optional[Dict] = None):
        """Register an agent for monitoring"""
        agent_id = agent.id
        
        self.agents[agent_id] = {
            'agent': agent,
            'metadata': metadata or {},
            'registration_time': datetime.now(),
            'last_activity': datetime.now(),
            'status': 'registered'
        }
        
        # Initial health check
        self._perform_health_check(agent_id)
        
        # Log registration
        self._log_event('agent_registered', {
            'agent_id': agent_id,
            'metadata': metadata,
            'timestamp': datetime.now().isoformat()
        })
        
        print(f"[Monitor] Registered agent: {agent_id}")
    
    def unregister_agent(self, agent_id: str, reason: str = ""):
        """Unregister an agent"""
        if agent_id in self.agents:
            agent_data = self.agents[agent_id]
            
            # Record final metrics
            self._record_final_metrics(agent_id)
            
            # Remove from registry
            del self.agents[agent_id]
            
            # Remove health data
            if agent_id in self.agent_health:
                del self.agent_health[agent_id]
            
            # Log unregistration
            self._log_event('agent_unregistered', {
                'agent_id': agent_id,
                'reason': reason,
                'timestamp': datetime.now().isoformat()
            })
            
            print(f"[Monitor] Unregistered agent: {agent_id} - Reason: {reason}")
    
    def record_cycle(self, 
                    agent_id: str, 
                    result: Any, 
                    cycle_time: float,
                    metrics: Optional[Dict] = None):
        """Record one agent execution cycle"""
        if agent_id not in self.agents:
            return
        
        # Update agent activity
        self.agents[agent_id]['last_activity'] = datetime.now()
        
        # Record metrics
        timestamp = datetime.now()
        
        cycle_metrics = {
            'cycle_time': cycle_time,
            'success': getattr(result, 'success', False) if hasattr(result, 'success') else True,
            'agent_id': agent_id,
            'timestamp': timestamp
        }
        
        if metrics:
            cycle_metrics.update(metrics)
        
        if hasattr(result, 'error') and result.error:
            cycle_metrics['error'] = result.error
        
        # Store metrics
        self.metrics_store.record('agent_cycles', agent_id, cycle_metrics)
        
        # Update health status
        if cycle_metrics.get('success', False):
            self.agent_health[agent_id]['checks_passed'] += 1
        else:
            self.agent_health[agent_id]['checks_failed'] += 1
            
            # Check for alert conditions
            self._check_cycle_failure(agent_id, cycle_metrics)
        
        # Update activity metrics
        self._update_activity_metrics(agent_id)
    
    def get_agent_dashboard(self, agent_id: str) -> Dict[str, Any]:
        """Generate comprehensive dashboard for an agent"""
        if agent_id not in self.agents:
            return {'error': 'Agent not found'}
        
        agent_data = self.agents[agent_id]
        agent = agent_data['agent']
        
        # Get recent metrics
        recent_cycles = self.metrics_store.get_recent(
            'agent_cycles', 
            agent_id, 
            hours=24
        )
        
        # Calculate statistics
        stats = self._calculate_agent_stats(recent_cycles)
        
        # Get agent state
        agent_state = {}
        if hasattr(agent, 'state_snapshot'):
            agent_state = agent.state_snapshot()
        
        # Get agent logs
        agent_logs = []
        if hasattr(agent, 'logs'):
            agent_logs = agent.logs(limit=20)
        
        # Get health status
        health = self.agent_health[agent_id]
        
        dashboard = {
            'agent_info': {
                'id': agent_id,
                'type': agent.__class__.__name__,
                'version': getattr(agent, 'version', 'unknown'),
                'registration_time': agent_data['registration_time'].isoformat(),
                'uptime': str(datetime.now() - agent_data['registration_time']),
                'metadata': agent_data['metadata']
            },
            'performance': stats,
            'health': {
                'status': health['status'],
                'last_check': health['last_check'],
                'success_rate': health['checks_passed'] / (health['checks_passed'] + health['checks_failed']) 
                                if (health['checks_passed'] + health['checks_failed']) > 0 else 0,
                'checks_passed': health['checks_passed'],
                'checks_failed': health['checks_failed']
            },
            'current_state': agent_state,
            'recent_logs': agent_logs,
            'recent_cycles': recent_cycles[-10:] if recent_cycles else [],
            'alerts': self.alert_manager.get_agent_alerts(agent_id),
            'dependencies': list(self.agent_dependencies.get(agent_id, [])),
            'system_metrics': self.system_metrics.get_current()
        }
        
        return dashboard
    
    def get_global_dashboard(self) -> Dict[str, Any]:
        """Generate global dashboard for all agents"""
        agent_summaries = []
        
        for agent_id, agent_data in self.agents.items():
            health = self.agent_health[agent_id]
            
            # Get recent metrics for this agent
            recent_cycles = self.metrics_store.get_recent(
                'agent_cycles', 
                agent_id, 
                hours=1
            )
            
            # Calculate statistics
            stats = self._calculate_agent_stats(recent_cycles)
            
            agent_summary = {
                'agent_id': agent_id,
                'type': agent_data['agent'].__class__.__name__,
                'status': health['status'],
                'last_activity': agent_data['last_activity'].isoformat(),
                'success_rate': stats.get('success_rate', 0),
                'avg_cycle_time': stats.get('avg_cycle_time', 0),
                'cycle_count': stats.get('cycle_count', 0),
                'error_count': stats.get('error_count', 0)
            }
            
            agent_summaries.append(agent_summary)
        
        # Calculate global statistics
        global_stats = self._calculate_global_stats()
        
        # Get system metrics
        system_metrics = self.system_metrics.get_current()
        
        # Get active alerts
        active_alerts = self.alert_manager.get_active_alerts()
        
        return {
            'timestamp': datetime.now().isoformat(),
            'agent_count': len(self.agents),
            'agents': agent_summaries,
            'global_stats': global_stats,
            'system_metrics': system_metrics,
            'active_alerts': active_alerts,
            'metrics_store_stats': self.metrics_store.get_stats()
        }
    
    def start(self):
        """Start monitoring system"""
        if self._running:
            return
        
        self._running = True
        
        # Start health check thread
        self._health_check_thread = threading.Thread(
            target=self._health_check_loop,
            daemon=True
        )
        self._health_check_thread.start()
        
        # Start system metrics collection
        self.system_metrics.start()
        
        print("[Monitor] Monitoring system started")
    
    def stop(self):
        """Stop monitoring system"""
        self._running = False
        
        if self._health_check_thread:
            self._health_check_thread.join(timeout=5)
        
        self.system_metrics.stop()
        
        print("[Monitor] Monitoring system stopped")
    
    # ========== PRIVATE METHODS ==========
    
    def _perform_health_check(self, agent_id: str):
        """Perform health check on agent"""
        if agent_id not in self.agents:
            return
        
        agent_data = self.agents[agent_id]
        agent = agent_data['agent']
        
        health_check = {
            'timestamp': datetime.now(),
            'agent_id': agent_id,
            'checks': []
        }
        
        # Check 1: Agent responsiveness
        try:
            # Try to get state snapshot
            if hasattr(agent, 'state_snapshot'):
                state = agent.state_snapshot()
                health_check['checks'].append({
                    'name': 'state_snapshot',
                    'status': 'passed',
                    'details': {'state_keys': len(state)}
                })
            else:
                health_check['checks'].append({
                    'name': 'state_snapshot',
                    'status': 'failed',
                    'details': {'error': 'Method not implemented'}
                })
        except Exception as e:
            health_check['checks'].append({
                'name': 'state_snapshot',
                'status': 'failed',
                'details': {'error': str(e)}
            })
        
        # Check 2: Recent activity
        last_activity = agent_data['last_activity']
        inactivity_time = (datetime.now() - last_activity).total_seconds()
        
        if inactivity_time < 300:  # 5 minutes
            health_check['checks'].append({
                'name': 'recent_activity',
                'status': 'passed',
                'details': {'inactivity_seconds': inactivity_time}
            })
        else:
            health_check['checks'].append({
                'name': 'recent_activity',
                'status': 'warning',
                'details': {'inactivity_seconds': inactivity_time}
            })
        
        # Check 3: Error rate
        recent_cycles = self.metrics_store.get_recent(
            'agent_cycles', 
            agent_id, 
            minutes=10
        )
        
        if recent_cycles:
            error_count = sum(1 for cycle in recent_cycles if not cycle.get('success', True))
            error_rate = error_count / len(recent_cycles)
            
            if error_rate < 0.1:  # Less than 10% errors
                health_check['checks'].append({
                    'name': 'error_rate',
                    'status': 'passed',
                    'details': {'error_rate': error_rate, 'total_cycles': len(recent_cycles)}
                })
            elif error_rate < 0.3:
                health_check['checks'].append({
                    'name': 'error_rate',
                    'status': 'warning',
                    'details': {'error_rate': error_rate, 'total_cycles': len(recent_cycles)}
                })
            else:
                health_check['checks'].append({
                    'name': 'error_rate',
                    'status': 'failed',
                    'details': {'error_rate': error_rate, 'total_cycles': len(recent_cycles)}
                })
        
        # Determine overall health status
        passed_checks = sum(1 for check in health_check['checks'] if check['status'] == 'passed')
        failed_checks = sum(1 for check in health_check['checks'] if check['status'] == 'failed')
        
        if failed_checks > 0:
            overall_status = 'unhealthy'
        elif passed_checks == len(health_check['checks']):
            overall_status = 'healthy'
        else:
            overall_status = 'degraded'
        
        # Update health data
        self.agent_health[agent_id].update({
            'status': overall_status,
            'last_check': datetime.now(),
            'last_health_check': health_check
        })
        
        # Store health check
        self.metrics_store.record('health_checks', agent_id, health_check)
        
        # Trigger alerts if needed
        if overall_status != 'healthy':
            self.alert_manager.trigger_alert(
                agent_id=agent_id,
                type='health_check_failed',
                severity='warning' if overall_status == 'degraded' else 'critical',
                details=health_check
            )
    
    def _health_check_loop(self):
        """Background thread for periodic health checks"""
        while self._running:
            try:
                # Perform health checks on all agents
                for agent_id in list(self.agents.keys()):
                    self._perform_health_check(agent_id)
                
                # Sleep between checks
                time.sleep(self.health_check_interval)
                
            except Exception as e:
                print(f"[Monitor] Health check loop error: {e}")
                time.sleep(10)
    
    def _check_cycle_failure(self, agent_id: str, cycle_metrics: Dict):
        """Check for alert conditions after cycle failure"""
        # Check for consecutive failures
        recent_cycles = self.metrics_store.get_recent(
            'agent_cycles', 
            agent_id, 
            minutes=5
        )
        
        if recent_cycles:
            recent_failures = sum(1 for cycle in recent_cycles[-10:] if not cycle.get('success', True))
            
            if recent_failures >= 3:
                self.alert_manager.trigger_alert(
                    agent_id=agent_id,
                    type='consecutive_failures',
                    severity='warning',
                    details={
                        'failures': recent_failures,
                        'time_window': '5 minutes',
                        'last_error': cycle_metrics.get('error', 'unknown')
                    }
                )
            
            # Check for high latency
            recent_times = [c.get('cycle_time', 0) for c in recent_cycles[-5:] if c.get('cycle_time')]
            if recent_times:
                avg_time = sum(recent_times) / len(recent_times)
                if avg_time > 10:  # More than 10 seconds average
                    self.alert_manager.trigger_alert(
                        agent_id=agent_id,
                        type='high_latency',
                        severity='warning',
                        details={
                            'avg_cycle_time': avg_time,
                            'threshold': 10,
                            'sample_size': len(recent_times)
                        }
                    )
    
    def _update_activity_metrics(self, agent_id: str):
        """Update activity-related metrics"""
        # Track activity rate
        now = datetime.now()
        
        activity_metric = {
            'agent_id': agent_id,
            'timestamp': now,
            'activity_type': 'cycle_completed'
        }
        
        self.metrics_store.record('agent_activity', agent_id, activity_metric)
    
    def _calculate_agent_stats(self, cycles: List[Dict]) -> Dict[str, Any]:
        """Calculate statistics from agent cycles"""
        if not cycles:
            return {
                'cycle_count': 0,
                'success_rate': 0,
                'avg_cycle_time': 0,
                'error_count': 0
            }
        
        total_cycles = len(cycles)
        successful_cycles = sum(1 for cycle in cycles if cycle.get('success', False))
        error_count = total_cycles - successful_cycles
        
        cycle_times = [cycle.get('cycle_time', 0) for cycle in cycles if cycle.get('cycle_time')]
        avg_cycle_time = sum(cycle_times) / len(cycle_times) if cycle_times else 0
        
        # Calculate percentiles
        sorted_times = sorted(cycle_times)
        if sorted_times:
            p50 = sorted_times[int(len(sorted_times) * 0.5)]
            p95 = sorted_times[int(len(sorted_times) * 0.95)]
            p99 = sorted_times[int(len(sorted_times) * 0.99)]
        else:
            p50 = p95 = p99 = 0
        
        return {
            'cycle_count': total_cycles,
            'success_rate': successful_cycles / total_cycles if total_cycles > 0 else 0,
            'avg_cycle_time': avg_cycle_time,
            'error_count': error_count,
            'p50_cycle_time': p50,
            'p95_cycle_time': p95,
            'p99_cycle_time': p99,
            'min_cycle_time': min(cycle_times) if cycle_times else 0,
            'max_cycle_time': max(cycle_times) if cycle_times else 0
        }
    
    def _calculate_global_stats(self) -> Dict[str, Any]:
        """Calculate global statistics"""
        all_cycles = []
        
        for agent_id in self.agents:
            cycles = self.metrics_store.get_recent('agent_cycles', agent_id, hours=1)
            all_cycles.extend(cycles)
        
        if not all_cycles:
            return {
                'total_cycles': 0,
                'success_rate': 0,
                'agents_active': 0
            }
        
        total_cycles = len(all_cycles)
        successful_cycles = sum(1 for cycle in all_cycles if cycle.get('success', False))
        
        # Count active agents (with cycles in last 5 minutes)
        active_agents = 0
        for agent_id in self.agents:
            recent_cycles = self.metrics_store.get_recent('agent_cycles', agent_id, minutes=5)
            if recent_cycles:
                active_agents += 1
        
        return {
            'total_cycles': total_cycles,
            'success_rate': successful_cycles / total_cycles if total_cycles > 0 else 0,
            'agents_active': active_agents,
            'agents_total': len(self.agents),
            'avg_cycles_per_agent': total_cycles / len(self.agents) if self.agents else 0
        }
    
    def _record_final_metrics(self, agent_id: str):
        """Record final metrics before agent unregistration"""
        # Calculate lifetime statistics
        all_cycles = self.metrics_store.get_all('agent_cycles', agent_id)
        
        if all_cycles:
            lifetime_stats = self._calculate_agent_stats(all_cycles)
            
            # Record lifetime summary
            summary = {
                'agent_id': agent_id,
                'timestamp': datetime.now(),
                'lifetime_stats': lifetime_stats,
                'total_cycles': len(all_cycles),
                'first_cycle': all_cycles[0]['timestamp'] if all_cycles else None,
                'last_cycle': all_cycles[-1]['timestamp'] if all_cycles else None
            }
            
            self.metrics_store.record('agent_summaries', agent_id, summary)
    
    def _log_event(self, event_type: str, data: Dict):
        """Log monitoring event"""
        event = {
            'type': event_type,
            'timestamp': datetime.now().isoformat(),
            'data': data
        }
        
        # Store event
        self.metrics_store.record('monitor_events', 'system', event)
        
        # Print to console (in production, would use structured logging)
        print(f"[Monitor] Event: {event_type} - {json.dumps(data)}")

class MetricsStore:
    """Time-series metrics storage"""
    
    def __init__(self, retention_days: int = 7):
        self.retention_days = retention_days
        self.data: Dict[str, Dict[str, deque]] = defaultdict(lambda: defaultdict(deque))
        self._cleanup_thread = None
        self._running = False
    
    def record(self, metric_type: str, source: str, data: Dict):
        """Record a metric"""
        metric = {
            **data,
            'recorded_at': datetime.now()
        }
        
        self.data[metric_type][source].append(metric)
    
    def get_recent(self, 
                  metric_type: str, 
                  source: str, 
                  hours: int = 24,
                  minutes: int = None) -> List[Dict]:
        """Get recent metrics"""
        if metric_type not in self.data or source not in self.data[metric_type]:
            return []
        
        metrics = self.data[metric_type][source]
        cutoff = datetime.now() - timedelta(
            hours=hours if minutes is None else 0,
            minutes=minutes or 0
        )
        
        return [m for m in metrics if m['recorded_at'] > cutoff]
    
    def get_all(self, metric_type: str, source: str) -> List[Dict]:
        """Get all metrics for source"""
        if metric_type not in self.data or source not in self.data[metric_type]:
            return []
        
        return list(self.data[metric_type][source])
    
    def start(self):
        """Start metrics store"""
        self._running = True
        self._cleanup_thread = threading.Thread(
            target=self._cleanup_loop,
            daemon=True
        )
        self._cleanup_thread.start()
    
    def stop(self):
        """Stop metrics store"""
        self._running = False
        if self._cleanup_thread:
            self._cleanup_thread.join(timeout=5)
    
    def get_stats(self) -> Dict[str, Any]:
        """Get metrics store statistics"""
        total_metrics = 0
        metric_types = {}
        
        for metric_type, sources in self.data.items():
            type_count = sum(len(metrics) for metrics in sources.values())
            metric_types[metric_type] = type_count
            total_metrics += type_count
        
        return {
            'total_metrics': total_metrics,
            'metric_types': metric_types,
            'retention_days': self.retention_days
        }
    
    def _cleanup_loop(self):
        """Background thread for cleaning up old metrics"""
        while self._running:
            try:
                self._cleanup_old_metrics()
                time.sleep(3600)  # Run every hour
            except Exception as e:
                print(f"[MetricsStore] Cleanup error: {e}")
                time.sleep(300)
    
    def _cleanup_old_metrics(self):
        """Remove metrics older than retention period"""
        cutoff = datetime.now() - timedelta(days=self.retention_days)
        
        for metric_type in list(self.data.keys()):
            for source in list(self.data[metric_type].keys()):
                metrics = self.data[metric_type][source]
                
                # Remove old metrics
                while metrics and metrics[0]['recorded_at'] < cutoff:
                    metrics.popleft()
                
                # Remove empty sources
                if not metrics:
                    del self.data[metric_type][source]
            
            # Remove empty metric types
            if not self.data[metric_type]:
                del self.data[metric_type]

class AlertManager:
    """Alert management system"""
    
    def __init__(self, 
                 alert_rules: List[Dict], 
                 notification_channels: List[Dict]):
        self.alert_rules = alert_rules
        self.notification_channels = notification_channels
        
        self.active_alerts: Dict[str, Dict] = {}
        self.alert_history: deque = deque(maxlen=1000)
    
    def trigger_alert(self, 
                     agent_id: str, 
                     type: str, 
                     severity: str, 
                     details: Dict):
        """Trigger an alert"""
        alert_id = f"alert_{int(time.time())}_{agent_id}_{type}"
        
        alert = {
            'id': alert_id,
            'agent_id': agent_id,
            'type': type,
            'severity': severity,
            'timestamp': datetime.now().isoformat(),
            'details': details,
            'status': 'active',
            'acknowledged': False,
            'acknowledged_by': None,
            'acknowledged_at': None
        }
        
        # Check if similar alert already active
        existing_key = f"{agent_id}_{type}"
        if existing_key in self.active_alerts:
            # Update existing alert
            existing = self.active_alerts[existing_key]
            existing['details'].update(details)
            existing['last_triggered'] = datetime.now().isoformat()
            alert = existing
        else:
            # New alert
            self.active_alerts[existing_key] = alert
        
        # Add to history
        self.alert_history.append(alert)
        
        # Send notifications
        self._send_notifications(alert)
        
        return alert_id
    
    def acknowledge_alert(self, 
                         alert_key: str, 
                         user: str, 
                         notes: str = "") -> bool:
        """Acknowledge an alert"""
        if alert_key in self.active_alerts:
            alert = self.active_alerts[alert_key]
            alert['acknowledged'] = True
            alert['acknowledged_by'] = user
            alert['acknowledged_at'] = datetime.now().isoformat()
            alert['acknowledgement_notes'] = notes
            
            # Log acknowledgement
            self.alert_history.append({
                'type': 'acknowledgement',
                'alert_id': alert['id'],
                'user': user,
                'timestamp': datetime.now().isoformat(),
                'notes': notes
            })
            
            return True
        
        return False
    
    def resolve_alert(self, alert_key: str, resolution: str = "") -> bool:
        """Resolve an alert"""
        if alert_key in self.active_alerts:
            alert = self.active_alerts[alert_key]
            alert['status'] = 'resolved'
            alert['resolved_at'] = datetime.now().isoformat()
            alert['resolution'] = resolution
            
            # Move to history and remove from active
            self.alert_history.append(alert)
            del self.active_alerts[alert_key]
            
            # Send resolution notification
            self._send_notifications({
                **alert,
                'type': 'alert_resolved'
            })
            
            return True
        
        return False
    
    def get_agent_alerts(self, agent_id: str) -> List[Dict]:
        """Get active alerts for an agent"""
        return [
            alert for key, alert in self.active_alerts.items()
            if alert['agent_id'] == agent_id
        ]
    
    def get_active_alerts(self) -> List[Dict]:
        """Get all active alerts"""
        return list(self.active_alerts.values())
    
    def get_alert_history(self, 
                         agent_id: Optional[str] = None,
                         hours: int = 24) -> List[Dict]:
        """Get alert history"""
        cutoff = datetime.now() - timedelta(hours=hours)
        
        history = []
        for alert in self.alert_history:
            if 'timestamp' in alert:
                alert_time = datetime.fromisoformat(alert['timestamp']) 
                if alert_time > cutoff:
                    if agent_id is None or alert.get('agent_id') == agent_id:
                        history.append(alert)
        
        return history
    
    def _send_notifications(self, alert: Dict):
        """Send notifications through configured channels"""
        for channel in self.notification_channels:
            try:
                if channel['type'] == 'console':
                    print(f"[ALERT] {alert['severity'].upper()}: {alert['type']} - Agent: {alert['agent_id']}")
                    print(f"       Details: {json.dumps(alert['details'], indent=2)}")
                
                elif channel['type'] == 'webhook':
                    import requests
                    requests.post(
                        channel['url'],
                        json=alert,
                        headers=channel.get('headers', {})
                    )
                
                elif channel['type'] == 'slack':
                    # Send to Slack
                    pass
                
                elif channel['type'] == 'email':
                    # Send email
                    pass
                
            except Exception as e:
                print(f"[AlertManager] Notification failed: {e}")

class SystemMetricsCollector:
    """Collects system-level metrics"""
    
    def __init__(self):
        self.metrics = {}
        self._collector_thread = None
        self._running = False
    
    def start(self):
        """Start collecting metrics"""
        self._running = True
        self._collector_thread = threading.Thread(
            target=self._collect_loop,
            daemon=True
        )
        self._collector_thread.start()
    
    def stop(self):
        """Stop collecting metrics"""
        self._running = False
        if self._collector_thread:
            self._collector_thread.join(timeout=5)
    
    def get_current(self) -> Dict[str, Any]:
        """Get current system metrics"""
        return self.metrics.copy()
    
    def _collect_loop(self):
        """Background thread for collecting metrics"""
        while self._running:
            try:
                self._collect_metrics()
                time.sleep(5)  # Collect every 5 seconds
            except Exception as e:
                print(f"[SystemMetrics] Collection error: {e}")
                time.sleep(30)
    
    def _collect_metrics(self):
        """Collect system metrics"""
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'cpu': {
                'percent': psutil.cpu_percent(interval=1),
                'count': psutil.cpu_count(),
                'load_average': psutil.getloadavg() if hasattr(psutil, 'getloadavg') else None
            },
            'memory': {
                'total_gb': psutil.virtual_memory().total / 1e9,
                'available_gb': psutil.virtual_memory().available / 1e9,
                'percent_used': psutil.virtual_memory().percent,
                'used_gb': psutil.virtual_memory().used / 1e9
            },
            'disk': {
                'total_gb': psutil.disk_usage('/').total / 1e9,
                'used_gb': psutil.disk_usage('/').used / 1e9,
                'free_gb': psutil.disk_usage('/').free / 1e9,
                'percent_used': psutil.disk_usage('/').percent
            },
            'network': {
                'bytes_sent': psutil.net_io_counters().bytes_sent,
                'bytes_recv': psutil.net_io_counters().bytes_recv,
                'packets_sent': psutil.net_io_counters().packets_sent,
                'packets_recv': psutil.net_io_counters().packets_recv
            },
            'process': {
                'count': len(psutil.pids()),
                'python_processes': len([p for p in psutil.process_iter(['name']) 
                                       if p.info['name'] and 'python' in p.info['name'].lower()])
            }
        }
        
        self.metrics = metrics
```

---

6ï¸âƒ£ PACKAGING & DISTRIBUTION

6.1 Complete Project Structure

```
aes-starter-kit/
â”œâ”€â”€ pyproject.toml                 # Modern Python packaging
â”œâ”€â”€ README.md                      # Project documentation
â”œâ”€â”€ LICENSE                        # MIT License
â”œâ”€â”€ .github/                       # GitHub workflows
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ ci.yml                # Continuous integration
â”‚   â”‚   â”œâ”€â”€ release.yml           # Release automation
â”‚   â”‚   â””â”€â”€ security-scan.yml     # Security scanning
â”‚   â””â”€â”€ dependabot.yml            # Dependency updates
â”œâ”€â”€ src/
â”‚   â””â”€â”€ aes/
â”‚       â”œâ”€â”€ __init__.py           # Package exports
â”‚       â”œâ”€â”€ agent.py              # Base agent interface
â”‚       â”œâ”€â”€ acp.py                # Agent Communication Protocol
â”‚       â”œâ”€â”€ handshake.py          # Three-way handshake
â”‚       â”œâ”€â”€ cli.py                # Command-line interface
â”‚       â”œâ”€â”€ validator.py          # AES compliance validator
â”‚       â””â”€â”€ modules/              # Standard modules
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ memory.py         # Hierarchical memory
â”‚           â”œâ”€â”€ tool.py           # Tool system
â”‚           â”œâ”€â”€ tool_registry.py  # Tool registry
â”‚           â”œâ”€â”€ planner.py        # Planning strategies
â”‚           â”œâ”€â”€ executor.py       # Execution engine
â”‚           â”œâ”€â”€ comm.py           # PostOffice communication
â”‚           â””â”€â”€ encryption.py     # End-to-end encryption
â”‚       â”œâ”€â”€ security/             # Security framework
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ sandbox.py        # Sandboxed execution
â”‚       â”‚   â”œâ”€â”€ tokens.py         # Token management
â”‚       â”‚   â””â”€â”€ rate_limiter.py   # Rate limiting
â”‚       â”œâ”€â”€ monitoring/           # Observability
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ agent_monitor.py  # Agent monitoring
â”‚       â”‚   â””â”€â”€ dashboard.py      # Web dashboard
â”‚       â””â”€â”€ utils/                # Utilities
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ logging.py        # Structured logging
â”‚           â””â”€â”€ serialization.py  # JSON/YAML serialization
â”œâ”€â”€ tests/                         # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”œâ”€â”€ test_acp.py
â”‚   â”œâ”€â”€ test_security.py
â”‚   â””â”€â”€ test_integration.py
â”œâ”€â”€ examples/                      # Example agents
â”‚   â”œâ”€â”€ hello_world.py
â”‚   â”œâ”€â”€ customer_support.py
â”‚   â”œâ”€â”€ multi_agent_chat.py
â”‚   â””â”€â”€ advanced_planning.py
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ SPECIFICATION.md          # Full AES specification
â”‚   â”œâ”€â”€ API_REFERENCE.md
â”‚   â”œâ”€â”€ TUTORIAL.md
â”‚   â””â”€â”€ diagrams/                 # Architecture diagrams
â””â”€â”€ config/                        # Configuration templates
    â”œâ”€â”€ agent_config.yaml
    â”œâ”€â”€ security_config.yaml
    â””â”€â”€ monitoring_config.yaml
```

6.2 pyproject.toml Configuration

```toml
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "aes-starter-kit"
version = "1.0.0"
description = "Agent Engineering Standard - A universal interface for building interoperable, observable, and modular autonomous agents"
readme = "README.md"
authors = [
    { name = "AES Foundation", email = "foundation@aes-standard.org" }
]
license = { text = "MIT" }
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Typing :: Typed"
]
keywords = ["ai", "agents", "autonomous", "standard", "interoperability", "llm"]
requires-python = ">=3.10"
dependencies = [
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    "httpx>=0.24.0",
    "rich>=13.0.0",
    "numpy>=1.24.0",
    "psutil>=5.9.0",
    "cryptography>=41.0.0",
    "python-jose>=3.3.0",
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
]

[project.optional-dependencies]
dev = [
    "black>=23.0.0",
    "flake8>=6.0.0",
    "mypy>=1.5.0",
    "pytest-cov>=4.1.0",
    "pre-commit>=3.5.0",
]
all = [
    "sentence-transformers>=2.2.0",
    "chromadb>=0.4.0",
    "redis>=5.0.0",
    "opentelemetry-api>=1.21.0",
]
enterprise = [
    "kubernetes>=26.0.0",
    "prometheus-client>=0.18.0",
    "grafana-sdk>=0.7.0",
    "sentry-sdk>=1.35.0",
]

[project.urls]
Homepage = "https://aes-standard.org"
Documentation = "https://docs.aes-standard.org"
Repository = "https://github.com/agent-engineering-standard/starter-kit"
Issues = "https://github.com/agent-engineering-standard/starter-kit/issues"
Changelog = "https://github.com/agent-engineering-standard/starter-kit/releases"

[project.scripts]
aes = "aes.cli:main"
aes-agent = "aes.cli:agent_cli"
aes-validate = "aes.validator:cli"
aes-monitor = "aes.monitoring.dashboard:cli"

[tool.setuptools.packages.find]
where = ["src"]

[tool.black]
line-length = 88
target-version = ['py310']
include = '\.pyi?$'
extend-exclude = '''
/(
    \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | _build
  | buck-out
  | build
  | dist
)/
'''

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --cov=aes --cov-report=term-missing"
asyncio_mode = "auto"
```

6.3 Command Line Interface (CLI)

```python
# src/aes/cli.py
"""
AES Command Line Interface
Provides commands for agent development, validation, and deployment.
"""

import argparse
import importlib.util
import json
import sys
from pathlib import Path
from typing import Optional, Dict, Any
import yaml

from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

from aes.validator import AESValidator
from aes.monitoring.agent_monitor import AgentMonitor
from aes.modules.comm import create_post_office

console = Console()

def main():
    """Main CLI entry point"""
    parser = argparse.ArgumentParser(
        description="Agent Engineering Standard CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  aes validate my_agent.py                    # Validate an agent
  aes certify my_agent.py --level=GOLD        # Certify an agent
  aes monitor start                           # Start monitoring dashboard
  aes agent create CustomerSupport            # Create new agent template
  aes postoffice status                       # Check PostOffice status
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="Command to execute")
    
    # Validate command
    validate_parser = subparsers.add_parser("validate", help="Validate agent compliance")
    validate_parser.add_argument("path", help="Path to agent Python file")
    validate_parser.add_argument("--level", 
                                choices=["BASIC", "STANDARD", "SECURE"],
                                default="STANDARD",
                                help="Compliance level")
    validate_parser.add_argument("--output", 
                                choices=["text", "json", "yaml"],
                                default="text",
                                help="Output format")
    
    # Certify command
    certify_parser = subparsers.add_parser("certify", help="Certify an agent")
    certify_parser.add_argument("path", help="Path to agent Python file")
    certify_parser.add_argument("--level",
                               choices=["BRONZE", "SILVER", "GOLD"],
                               default="BRONZE",
                               help="Certification level")
    certify_parser.add_argument("--output-dir",
                               default="./certificates",
                               help="Directory for certificates")
    
    # Monitor command
    monitor_parser = subparsers.add_parser("monitor", help="Monitoring commands")
    monitor_subparsers = monitor_parser.add_subparsers(dest="monitor_command")
    
    monitor_start = monitor_subparsers.add_parser("start", help="Start monitoring dashboard")
    monitor_start.add_argument("--port", type=int, default=8080, help="Dashboard port")
    monitor_start.add_argument("--host", default="localhost", help="Dashboard host")
    
    monitor_status = monitor_subparsers.add_parser("status", help="Show monitoring status")
    
    # Agent command
    agent_parser = subparsers.add_parser("agent", help="Agent management")
    agent_subparsers = agent_parser.add_subparsers(dest="agent_command")
    
    agent_create = agent_subparsers.add_parser("create", help="Create new agent")
    agent_create.add_argument("name", help="Agent name")
    agent_create.add_argument("--type", 
                             choices=["basic", "customer_support", "data_analysis"],
                             default="basic",
                             help="Agent template type")
    agent_create.add_argument("--output-dir",
                             default="./agents",
                             help="Output directory")
    
    # PostOffice command
    po_parser = subparsers.add_parser("postoffice", help="PostOffice management")
    po_subparsers = po_parser.add_subparsers(dest="po_command")
    
    po_status = po_subparsers.add_parser("status", help="Show PostOffice status")
    po_start = po_subparsers.add_parser("start", help="Start PostOffice service")
    
    # Version command
    subparsers.add_parser("version", help="Show AES version")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # Execute command
    if args.command == "validate":
        validate_agent(args.path, args.level, args.output)
    elif args.command == "certify":
        certify_agent(args.path, args.level, args.output_dir)
    elif args.command == "monitor":
        handle_monitor_command(args)
    elif args.command == "agent":
        handle_agent_command(args)
    elif args.command == "postoffice":
        handle_postoffice_command(args)
    elif args.command == "version":
        show_version()

def validate_agent(path: str, level: str, output_format: str):
    """Validate an agent for AES compliance"""
    console.print(f"[bold blue]ðŸ” Validating agent at {path}[/bold blue]")
    console.print(f"[dim]Compliance level: {level}[/dim]")
    
    try:
        # Load agent module
        spec = importlib.util.spec_from_file_location("agent_module", path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        
        # Find agent class
        agent_class = None
        for name, obj in module.__dict__.items():
            if (isinstance(obj, type) and 
                obj.__module__ == module.__name__ and
                hasattr(obj, '__bases__')):
                # Check if it's an agent class
                from aes.agent import BaseAgent
                if BaseAgent in obj.__bases__:
                    agent_class = obj
                    break
        
        if not agent_class:
            console.print("[red]âŒ No AES agent class found in file[/red]")
            return
        
        # Create validator
        validator = AESValidator(compliance_level=level)
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            task = progress.add_task("Validating...", total=None)
            
            # Run validation
            results = validator.validate_agent(agent_class)
            
            progress.update(task, completed=True)
        
        # Display results
        if output_format == "json":
            print(json.dumps(results, indent=2, default=str))
        elif output_format == "yaml":
            print(yaml.dump(results, default_flow_style=False))
        else:
            display_validation_results(results)
    
    except Exception as e:
        console.print(f"[red]âŒ Validation failed: {str(e)}[/red]")
        sys.exit(1)

def display_validation_results(results: Dict[str, Any]):
    """Display validation results in pretty format"""
    overall = results.get('overall', 'UNKNOWN')
    summary = results.get('summary', {})
    
    # Overall status
    if overall == 'PASS':
        console.print(Panel(
            "[green]âœ… AES COMPLIANCE PASSED[/green]",
            title="Validation Results",
            border_style="green"
        ))
    elif overall == 'FAIL':
        console.print(Panel(
            "[red]âŒ AES COMPLIANCE FAILED[/red]",
            title="Validation Results",
            border_style="red"
        ))
    else:
        console.print(Panel(
            "[yellow]âš ï¸  AES COMPLIANCE UNKNOWN[/yellow]",
            title="Validation Results",
            border_style="yellow"
        ))
    
    # Summary table
    table = Table(title="Compliance Summary")
    table.add_column("Metric", style="cyan")
    table.add_column("Value", style="white")
    
    table.add_row("Required Checks", summary.get('required_checks_passed', 'N/A'))
    table.add_row("Optional Checks", summary.get('optional_checks_passed', 'N/A'))
    table.add_row("Success Rate", f"{summary.get('required_pass_rate', 0)*100:.1f}%")
    
    console.print(table)
    
    # Detailed checks
    checks = results.get('checks', {})
    if checks:
        checks_table = Table(title="Detailed Checks")
        checks_table.add_column("Check", style="cyan")
        checks_table.add_column("Status", style="white")
        checks_table.add_column("Required", style="dim")
        checks_table.add_column("Description", style="dim")
        
        for check_name, check_data in checks.items():
            status = "âœ…" if check_data.get('passed') else "âŒ"
            required = "Yes" if check_data.get('required') else "No"
            description = check_data.get('description', '')[:50]
            
            checks_table.add_row(
                check_name.replace('has_', '').replace('_', ' ').title(),
                status,
                required,
                description
            )
        
        console.print(checks_table)
    
    # Recommendations
    if overall == 'FAIL':
        console.print("[yellow][bold]Recommendations:[/bold][/yellow]")
        
        for check_name, check_data in checks.items():
            if not check_data.get('passed') and check_data.get('required'):
                console.print(f"  â€¢ Fix: {check_data.get('description')}")
        
        console.print("\n  Run with --level=BASIC for more lenient validation")

def certify_agent(path: str, level: str, output_dir: str):
    """Certify an agent"""
    console.print(f"[bold blue]ðŸ… Certifying agent at {path}[/bold blue]")
    console.print(f"[dim]Certification level: {level}[/dim]")
    
    # Create output directory
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # Load and validate agent
    try:
        spec = importlib.util.spec_from_file_location("agent_module", path)
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        
        # Find agent class
        agent_class = None
        for name, obj in module.__dict__.items():
            if (isinstance(obj, type) and 
                obj.__module__ == module.__name__ and
                hasattr(obj, '__bases__')):
                from aes.agent import BaseAgent
                if BaseAgent in obj.__bases__:
                    agent_class = obj
                    break
        
        if not agent_class:
            console.print("[red]âŒ No AES agent class found[/red]")
            return
        
        # Create instance and run basic tests
        agent = agent_class()
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console
        ) as progress:
            tasks = [
                progress.add_task("Validating structure...", total=None),
                progress.add_task("Testing basic functions...", total=None),
                progress.add_task("Running compliance checks...", total=None),
            ]
            
            # Validate
            progress.update(tasks[0], advance=100)
            
            # Test functions
            try:
                # Test state snapshot
                state = agent.state_snapshot()
                if not isinstance(state, dict):
                    raise ValueError("state_snapshot() must return dict")
                
                # Test logs
                logs = agent.logs()
                if not isinstance(logs, list):
                    raise ValueError("logs() must return list")
                
                progress.update(tasks[1], advance=100)
            except Exception as e:
                console.print(f"[red]âŒ Basic tests failed: {e}[/red]")
                return
            
            # Run compliance checks
            validator = AESValidator(compliance_level="SECURE")
            results = validator.validate_agent(agent_class, agent)
            progress.update(tasks[2], advance=100)
        
        # Check if passed
        if results.get('overall') != 'PASS':
            console.print("[red]âŒ Agent failed compliance checks[/red]")
            display_validation_results(results)
            return
        
        # Generate certificate
        from aes.certification import AESCertification
        certificate = AESCertification.certify_agent(
            agent_class, 
            level=level,
            evidence={
                "validation_results": results,
                "source_file": path,
                "timestamp": datetime.now().isoformat()
            }
        )
        
        # Save certificate
        cert_file = Path(output_dir) / f"{agent.id}_certificate.json"
        with open(cert_file, 'w') as f:
            json.dump(certificate, f, indent=2, default=str)
        
        # Display certificate
        console.print(Panel(
            f"""[bold green]âœ… AGENT CERTIFIED: {level}[/bold green]

[b]Agent ID:[/b] {agent.id}
[b]Level:[/b] {level}
[b]Certificate ID:[/b] {certificate.get('certificate_id', 'N/A')}
[b]Issued:[/b] {certificate.get('validation_date', 'N/A')}
[b]Valid Until:[/b] {(datetime.now() + timedelta(days=365)).strftime('%Y-%m-%d')}

Certificate saved to: {cert_file}
            """,
            title="AES Certification",
            border_style="green"
        ))
        
        # Show badge
        badges = {
            "BRONZE": "ðŸŸ¤ AES Bronze Certified",
            "SILVER": "âšª AES Silver Certified", 
            "GOLD": "ðŸŸ¡ AES Gold Certified"
        }
        
        console.print(f"\n[bold]{badges.get(level, 'AES Certified')}[/bold]")
        
    except Exception as e:
        console.print(f"[red]âŒ Certification failed: {str(e)}[/red]")
        sys.exit(1)

def handle_monitor_command(args):
    """Handle monitor subcommands"""
    if args.monitor_command == "start":
        from aes.monitoring.dashboard import start_dashboard
        console.print("[bold blue]ðŸš€ Starting monitoring dashboard...[/bold blue]")
        start_dashboard(host=args.host, port=args.port)
    elif args.monitor_command == "status":
        console.print("[bold blue]ðŸ“Š Monitoring Status[/bold blue]")
        # In production, would connect to running monitor
        console.print("[dim]Monitoring dashboard not running[/dim]")
    else:
        console.print("[red]âŒ Unknown monitor command[/red]")

def handle_agent_command(args):
    """Handle agent subcommands"""
    if args.agent_command == "create":
        console.print(f"[bold blue]ðŸ¤– Creating {args.type} agent: {args.name}[/bold blue]")
        
        # Create template
        template = generate_agent_template(args.name, args.type)
        
        # Save to file
        output_path = Path(args.output_dir) / f"{args.name.lower()}_agent.py"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w') as f:
            f.write(template)
        
        console.print(f"[green]âœ… Agent template created: {output_path}[/green]")
        console.print("\n[dim]Next steps:")
        console.print(f"  1. Review and edit {output_path}")
        console.print(f"  2. Test with: aes validate {output_path}")
        console.print(f"  3. Run with: python {output_path}")
    else:
        console.print("[red]âŒ Unknown agent command[/red]")

def handle_postoffice_command(args):
    """Handle PostOffice subcommands"""
    if args.po_command == "status":
        console.print("[bold blue]ðŸ“® PostOffice Status[/bold blue]")
        # In production, would connect to running PostOffice
        console.print("[dim]PostOffice not running[/dim]")
    elif args.po_command == "start":
        console.print("[bold blue]ðŸš€ Starting PostOffice...[/bold blue]")
        # Start PostOffice service
        po = create_post_office()
        console.print("[green]âœ… PostOffice started[/green]")
        console.print("[dim]Press Ctrl+C to stop[/dim]")
        
        try:
            # Keep running
            import time
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            po.shutdown()
            console.print("\n[dim]PostOffice stopped[/dim]")
    else:
        console.print("[red]âŒ Unknown PostOffice command[/red]")

def show_version():
    """Show AES version"""
    import aes
    console.print(Panel(
        f"""[bold blue]Agent Engineering Standard[/bold blue]

[b]Version:[/b] {getattr(aes, '__version__', '1.0.0')}
[b]Python:[/b] {sys.version.split()[0]}
[b]Homepage:[/b] https://aes-standard.org
[b]Documentation:[/b] https://docs.aes-standard.org
        """,
        title="AES Starter Kit",
        border_style="blue"
    ))

def generate_agent_template(name: str, agent_type: str) -> str:
    """Generate agent template code"""
    
    templates = {
        "basic": f'''
from aes.agent import BaseAgent, Observation, State, Plan, ActionResult
from datetime import datetime
from typing import Any, Dict

class {name}Agent(BaseAgent):
    """{name} Agent - AES Compliant"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # Initialize your agent here
        self.capabilities = ["process_input", "generate_response"]
        
        # Set initial state
        self._state = State(
            memory={{"greetings": 0}},
            goals=["respond to inputs"],
            context={{"created_at": datetime.now().isoformat()}},
            constraints=[]
        )
    
    def perceive(self, input_data: Any) -> Observation:
        """Convert input to observation"""
        return Observation(
            timestamp=datetime.now(),
            source="user_input",
            payload={{"input": input_data}},
            confidence=1.0
        )
    
    def update_state(self, observation: Observation) -> State:
        """Update state based on observation"""
        # Update memory
        if "greetings" in self._state.memory:
            self._state.memory["greetings"] += 1
        
        return self._state
    
    def plan(self, state: State) -> Plan:
        """Create execution plan"""
        return Plan(
            id=f"plan_{{datetime.now().timestamp()}}",
            steps=[{{"action": "respond", "parameters": {{"input": "Hello!"}}}}],
            priority=50,
            expected_outcome="User receives response",
            timeout_seconds=30
        )
    
    def act(self, plan: Plan) -> ActionResult:
        """Execute the plan"""
        # Execute each step
        results = []
        for step in plan.steps:
            if step["action"] == "respond":
                results.append(f"Hello from {{self.id}}!")
        
        return ActionResult(
            success=True,
            output=results,
            metrics={{"steps_executed": len(results)}}
        )
    
    def learn(self, feedback: ActionResult) -> None:
        """Learn from results"""
        if feedback.success:
            self._log("learn", {{"feedback": "Execution successful"}})

if __name__ == "__main__":
    # Create and run agent
    agent = {name}Agent()
    
    # Test with sample input
    result = agent.run("Hello, agent!")
    
    print(f"Agent ID: {{agent.id}}")
    print(f"Result: {{result.success}}")
    print(f"Output: {{result.output}}")
''',
        "customer_support": '''
# Customer Support Agent Template
# This is a more complex template with multiple capabilities
'''
    }
    
    return templates.get(agent_type, templates["basic"])

if __name__ == "__main__":
    main()
```

---

7ï¸âƒ£ CERTIFICATION PROGRAM

7.1 Certification Framework

```python
# src/aes/certification.py
"""
AES Agent Certification Program
Three levels: Bronze, Silver, Gold
Each level has specific requirements and testing procedures.
"""

from datetime import datetime, timedelta
from enum import Enum
from typing import Dict, List, Optional, Any
import hashlib
import json
import uuid

class CertificationLevel(Enum):
    """Certification levels"""
    BRONZE = "bronze"      # Basic compliance
    SILVER = "silver"      # Production-ready
    GOLD = "gold"          # Enterprise-grade
    
    def requirements(self) -> List[str]:
        """Get requirements for this level"""
        reqs = {
            CertificationLevel.BRONZE: [
                "Implements BaseAgent interface",
                "Passes structural validation",
                "Provides state_snapshot() method",
                "Provides logs() method",
                "Has unique agent ID",
                "Has version string"
            ],
            CertificationLevel.SILVER: [
                "All Bronze requirements",
                "Passes behavioral validation", 
                "Implements error handling",
                "Has security measures",
                "Passes performance tests",
                "3-day stability test",
                "Documentation available"
            ],
            CertificationLevel.GOLD: [
                "All Silver requirements",
                "Passes security audit",
                "Implements ACP protocol",
                "Supports multi-agent communication",
                "6-month production deployment",
                "Zero critical vulnerabilities",
                "Performance SLA met",
                "Interoperability certified"
            ]
        }
        return reqs.get(self, [])

class AESCertification:
    """
    AES Agent Certification System
    Manages certification process, issuance, and verification.
    """
    
    def __init__(self, config: Dict):
        self.config = config
        self.certificates: Dict[str, Dict] = {}
        self.revoked_certificates: Dict[str, Dict] = {}
        
        # Testing infrastructure
        self.test_suites = {
            "bronze": BronzeTestSuite(),
            "silver": SilverTestSuite(),
            "gold": GoldTestSuite()
        }
        
        # Certificate registry (in production, would be a database)
        self.registry_file = config.get('registry_file', 'aes_certificates.json')
        self._load_registry()
    
    def certify_agent(self, 
                     agent_class: Any,
                     level: CertificationLevel,
                     evidence: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Certify an agent at specified level.
        Returns certificate if successful.
        """
        # Create agent instance
        agent_instance = agent_class()
        agent_id = agent_instance.id
        
        # Check if already certified
        existing_cert = self._find_certificate(agent_id, level)
        if existing_cert and not self._is_certificate_expired(existing_cert):
            return existing_cert
        
        print(f"ðŸ” Starting {level.value.upper()} certification for agent {agent_id}")
        
        # Run test suite
        test_suite = self.test_suites[level.value]
        test_results = test_suite.run_all_tests(agent_class, agent_instance)
        
        # Check if all tests passed
        if not test_results['overall_pass']:
            print(f"âŒ Certification failed: {test_results['failure_reason']}")
            return {
                'certified': False,
                'agent_id': agent_id,
                'level': level.value,
                'test_results': test_results,
                'failure_reason': test_results['failure_reason']
            }
        
        # Generate certificate
        certificate = self._generate_certificate(
            agent_id=agent_id,
            agent_class=agent_class.__name__,
            level=level,
            test_results=test_results,
            evidence=evidence
        )
        
        # Store certificate
        self.certificates[certificate['certificate_id']] = certificate
        self._save_registry()
        
        # Issue badge
        badge = self._generate_badge(level)
        
        print(f"âœ… Agent {agent_id} certified as {level.value.upper()}")
        print(f"   Certificate ID: {certificate['certificate_id']}")
        print(f"   Valid until: {certificate['valid_until']}")
        
        return {
            **certificate,
            'badge': badge,
            'certified': True
        }
    
    def verify_certificate(self, certificate_id: str) -> Dict[str, Any]:
        """Verify a certificate is valid"""
        # Check if revoked
        if certificate_id in self.revoked_certificates:
            return {
                'valid': False,
                'reason': 'certificate_revoked',
                'revocation_details': self.revoked_certificates[certificate_id]
            }
        
        # Check if exists
        if certificate_id not in self.certificates:
            return {
                'valid': False,
                'reason': 'certificate_not_found'
            }
        
        certificate = self.certificates[certificate_id]
        
        # Check expiration
        if self._is_certificate_expired(certificate):
            return {
                'valid': False,
                'reason': 'certificate_expired',
                'expired_on': certificate['valid_until']
            }
        
        # Verify cryptographic signature
        if not self._verify_signature(certificate):
            return {
                'valid': False,
                'reason': 'signature_invalid'
            }
        
        return {
            'valid': True,
            'certificate': certificate,
            'verified_at': datetime.now().isoformat()
        }
    
    def revoke_certificate(self, 
                          certificate_id: str, 
                          reason: str,
                          details: Optional[Dict] = None) -> bool:
        """Revoke a certificate"""
        if certificate_id not in self.certificates:
            return False
        
        certificate = self.certificates[certificate_id]
        
        revocation_record = {
            'certificate_id': certificate_id,
            'original_certificate': certificate,
            'revoked_at': datetime.now().isoformat(),
            'reason': reason,
            'details': details or {},
            'revoked_by': 'system'  # In production, would track who revoked
        }
        
        # Move to revoked registry
        self.revoked_certificates[certificate_id] = revocation_record
        
        # Remove from active certificates
        del self.certificates[certificate_id]
        
        self._save_registry()
        
        print(f"ðŸš« Certificate {certificate_id} revoked: {reason}")
        
        return True
    
    def list_certified_agents(self, 
                             level: Optional[CertificationLevel] = None,
                             include_revoked: bool = False) -> List[Dict[str, Any]]:
        """List all certified agents"""
        agents = []
        
        # Active certificates
        for cert_id, certificate in self.certificates.items():
            if level is None or certificate['level'] == level.value:
                agents.append({
                    'agent_id': certificate['agent_id'],
                    'agent_class': certificate['agent_class'],
                    'level': certificate['level'],
                    'certified_at': certificate['issued_at'],
                    'valid_until': certificate['valid_until'],
                    'certificate_id': cert_id,
                    'status': 'active'
                })
        
        # Revoked certificates
        if include_revoked:
            for cert_id, revocation in self.revoked_certificates.items():
                cert = revocation['original_certificate']
                if level is None or cert['level'] == level.value:
                    agents.append({
                        'agent_id': cert['agent_id'],
                        'agent_class': cert['agent_class'],
                        'level': cert['level'],
                        'certified_at': cert['issued_at'],
                        'valid_until': cert['valid_until'],
                        'certificate_id': cert_id,
                        'status': 'revoked',
                        'revocation_reason': revocation['reason'],
                        'revoked_at': revocation['revoked_at']
                    })
        
        return agents
    
    def get_certification_stats(self) -> Dict[str, Any]:
        """Get certification statistics"""
        active_by_level = {}
        revoked_by_level = {}
        
        for level in CertificationLevel:
            active_by_level[level.value] = sum(
                1 for cert in self.certificates.values() 
                if cert['level'] == level.value
            )
            revoked_by_level[level.value] = sum(
                1 for rev in self.revoked_certificates.values()
                if rev['original_certificate']['level'] == level.value
            )
        
        total_active = sum(active_by_level.values())
        total_revoked = sum(revoked_by_level.values())
        
        return {
            'total_active': total_active,
            'total_revoked': total_revoked,
            'active_by_level': active_by_level,
            'revoked_by_level': revoked_by_level,
            'success_rate': total_active / (total_active + total_revoked) 
                           if (total_active + total_revoked) > 0 else 0
        }
    
    # ========== PRIVATE METHODS ==========
    
    def _generate_certificate(self, 
                            agent_id: str,
                            agent_class: str,
                            level: CertificationLevel,
                            test_results: Dict,
                            evidence: Optional[Dict]) -> Dict[str, Any]:
        """Generate a certificate"""
        certificate_id = f"AES-{level.value.upper()}-{uuid.uuid4().hex[:12].upper()}"
        
        issued_at = datetime.now()
        valid_until = issued_at + timedelta(days=365)  # 1 year validity
        
        certificate = {
            'certificate_id': certificate_id,
            'agent_id': agent_id,
            'agent_class': agent_class,
            'level': level.value,
            'issued_at': issued_at.isoformat(),
            'valid_until': valid_until.isoformat(),
            'issuing_authority': 'AES Certification Authority',
            'test_results': test_results,
            'evidence': evidence or {},
            'requirements_met': level.requirements(),
            'signature': None  # Will be set after signing
        }
        
        # Sign certificate
        certificate['signature'] = self._sign_certificate(certificate)
        
        return certificate
    
    def _sign_certificate(self, certificate: Dict) -> str:
        """Sign certificate with private key"""
        # Create string representation for signing
        cert_copy = certificate.copy()
        cert_copy.pop('signature', None)
        
        cert_string = json.dumps(cert_copy, sort_keys=True)
        
        # In production, would use RSA/ECDSA signing
        # For now, use HMAC with secret key
        secret_key = self.config.get('signing_key', 'aes-certification-secret')
        
        signature = hashlib.sha256(
            f"{cert_string}:{secret_key}".encode()
        ).hexdigest()
        
        return signature
    
    def _verify_signature(self, certificate: Dict) -> bool:
        """Verify certificate signature"""
        signature = certificate.get('signature')
        if not signature:
            return False
        
        # Recreate signature
        cert_copy = certificate.copy()
        cert_copy.pop('signature', None)
        
        cert_string = json.dumps(cert_copy, sort_keys=True)
        secret_key = self.config.get('signing_key', 'aes-certification-secret')
        
        expected_signature = hashlib.sha256(
            f"{cert_string}:{secret_key}".encode()
        ).hexdigest()
        
        return signature == expected_signature
    
    def _generate_badge(self, level: CertificationLevel) -> str:
        """Generate badge for certification level"""
        badges = {
            CertificationLevel.BRONZE: "ðŸŸ¤ AES Bronze Certified",
            CertificationLevel.SILVER: "âšª AES Silver Certified",
            CertificationLevel.GOLD: "ðŸŸ¡ AES Gold Certified"
        }
        
        return badges.get(level, "AES Certified")
    
    def _find_certificate(self, agent_id: str, level: CertificationLevel) -> Optional[Dict]:
        """Find existing certificate for agent"""
        for certificate in self.certificates.values():
            if (certificate['agent_id'] == agent_id and 
                certificate['level'] == level.value):
                return certificate
        return None
    
    def _is_certificate_expired(self, certificate: Dict) -> bool:
        """Check if certificate is expired"""
        valid_until = datetime.fromisoformat(certificate['valid_until'])
        return datetime.now() > valid_until
    
    def _load_registry(self):
        """Load certificate registry from file"""
        try:
            with open(self.registry_file, 'r') as f:
                data = json.load(f)
                self.certificates = data.get('certificates', {})
                self.revoked_certificates = data.get('revoked_certificates', {})
        except FileNotFoundError:
            # First run, start with empty registry
            self.certificates = {}
            self.revoked_certificates = {}
    
    def _save_registry(self):
        """Save certificate registry to file"""
        data = {
            'certificates': self.certificates,
            'revoked_certificates': self.revoked_certificates,
            'last_updated': datetime.now().isoformat()
        }
        
        with open(self.registry_file, 'w') as f:
            json.dump(data, f, indent=2, default=str)

class BronzeTestSuite:
    """Test suite for Bronze certification"""
    
    def run_all_tests(self, agent_class: Any, agent_instance: Any) -> Dict[str, Any]:
        """Run all Bronze-level tests"""
        tests = []
        
        # Test 1: Basic interface implementation
        tests.append(self._test_interface(agent_instance))
        
        # Test 2: State snapshot
        tests.append(self._test_state_snapshot(agent_instance))
        
        # Test 3: Logging
        tests.append(self._test_logging(agent_instance))
        
        # Test 4: Basic execution
        tests.append(self._test_basic_execution(agent_instance))
        
        # Test 5: Error handling
        tests.append(self._test_error_handling(agent_instance))
        
        # Calculate results
        passed_tests = [t for t in tests if t['passed']]
        failed_tests = [t for t in tests if not t['passed']]
        
        return {
            'overall_pass': len(failed_tests) == 0,
            'total_tests': len(tests),
            'passed_tests': len(passed_tests),
            'failed_tests': len(failed_tests),
            'tests': tests,
            'failure_reason': failed_tests[0]['reason'] if failed_tests else None
        }
    
    def _test_interface(self, agent_instance: Any) -> Dict[str, Any]:
        """Test basic interface implementation"""
        required_attrs = ['id', 'version']
        required_methods = ['run', 'state_snapshot', 'logs']
        
        missing_attrs = []
        for attr in required_attrs:
            if not hasattr(agent_instance, attr):
                missing_attrs.append(attr)
        
        missing_methods = []
        for method in required_methods:
            if not hasattr(agent_instance, method) or not callable(getattr(agent_instance, method)):
                missing_methods.append(method)
        
        passed = len(missing_attrs) == 0 and len(missing_methods) == 0
        
        return {
            'name': 'interface_implementation',
            'passed': passed,
            'reason': f"Missing attrs: {missing_attrs}, Missing methods: {missing_methods}" if not passed else None,
            'details': {
                'agent_id': getattr(agent_instance, 'id', 'missing'),
                'version': getattr(agent_instance, 'version', 'missing')
            }
        }
    
    def _test_state_snapshot(self, agent_instance: Any) -> Dict[str, Any]:
        """Test state_snapshot method"""
        try:
            state = agent_instance.state_snapshot()
            
            if not isinstance(state, dict):
                return {
                    'name': 'state_snapshot',
                    'passed': False,
                    'reason': 'state_snapshot() must return dict',
                    'details': {'returned_type': type(state).__name__}
                }
            
            # Check for required fields
            required_fields = ['agent_id', 'timestamp']
            missing_fields = [f for f in required_fields if f not in state]
            
            if missing_fields:
                return {
                    'name': 'state_snapshot',
                    'passed': False,
                    'reason': f'Missing required fields: {missing_fields}',
                    'details': {'state_keys': list(state.keys())}
                }
            
            return {
                'name': 'state_snapshot',
                'passed': True,
                'details': {'state_keys': list(state.keys())}
            }
            
        except Exception as e:
            return {
                'name': 'state_snapshot',
                'passed': False,
                'reason': f'Exception: {str(e)}',
                'details': {'error': str(e)}
            }
    
    def _test_logging(self, agent_instance: Any) -> Dict[str, Any]:
        """Test logs method"""
        try:
            logs = agent_instance.logs()
            
            if not isinstance(logs, list):
                return {
                    'name': 'logging',
                    'passed': False,
                    'reason': 'logs() must return list',
                    'details': {'returned_type': type(logs).__name__}
                }
            
            return {
                'name': 'logging',
                'passed': True,
                'details': {'log_count': len(logs)}
            }
            
        except Exception as e:
            return {
                'name': 'logging',
                'passed': False,
                'reason': f'Exception: {str(e)}',
                'details': {'error': str(e)}
            }
    
    def _test_basic_execution(self, agent_instance: Any) -> Dict[str, Any]:
        """Test basic agent execution"""
        try:
            result = agent_instance.run("test input")
            
            # Check result structure
            if not hasattr(result, 'success'):
                return {
                    'name': 'basic_execution',
                    'passed': False,
                    'reason': 'Result missing success attribute',
                    'details': {'result_type': type(result).__name__}
                }
            
            return {
                'name': 'basic_execution',
                'passed': True,
                'details': {
                    'success': result.success,
                    'result_type': type(result).__name__
                }
            }
            
        except Exception as e:
            return {
                'name': 'basic_execution',
                'passed': False,
                'reason': f'Execution failed: {str(e)}',
                'details': {'error': str(e)}
            }
    
    def _test_error_handling(self, agent_instance: Any) -> Dict[str, Any]:
        """Test error handling"""
        # This test intentionally passes for Bronze
        # More rigorous testing in Silver/Gold
        return {
            'name': 'error_handling',
            'passed': True,
            'details': {'note': 'Basic error handling test'}
        }

class SilverTestSuite(BronzeTestSuite):
    """Test suite for Silver certification (extends Bronze)"""
    
    def run_all_tests(self, agent_class: Any, agent_instance: Any) -> Dict[str, Any]:
        """Run all Silver-level tests"""
        # Run Bronze tests first
        bronze_results = super().run_all_tests(agent_class, agent_instance)
        
        if not bronze_results['overall_pass']:
            return bronze_results
        
        # Run additional Silver tests
        additional_tests = []
        
        # Test 1: Performance under load
        additional_tests.append(self._test_performance(agent_instance))
        
        # Test 2: Memory management
        additional_tests.append(self._test_memory_management(agent_instance))
        
        # Test 3: Security features
        additional_tests.append(self._test_security_features(agent_instance))
        
        # Test 4: Documentation
        additional_tests.append(self._test_documentation(agent_class))
        
        # Combine results
        all_tests = bronze_results['tests'] + additional_tests
        
        passed_tests = [t for t in all_tests if t['passed']]
        failed_tests = [t for t in all_tests if not t['passed']]
        
        return {
            'overall_pass': len(failed_tests) == 0,
            'total_tests': len(all_tests),
            'passed_tests': len(passed_tests),
            'failed_tests': len(failed_tests),
            'tests': all_tests,
            'failure_reason': failed_tests[0]['reason'] if failed_tests else None
        }
    
    def _test_performance(self, agent_instance: Any) -> Dict[str, Any]:
        """Test performance under load"""
        import time
        
        try:
            execution_times = []
            
            # Run 10 cycles
            for i in range(10):
                start_time = time.time()
                result = agent_instance.run(f"test input {i}")
                end_time = time.time()
                
                if not result.success:
                    return {
                        'name': 'performance',
                        'passed': False,
                        'reason': f'Cycle {i} failed: {getattr(result, "error", "unknown")}',
                        'details': {'cycle': i, 'error': getattr(result, 'error', 'unknown')}
                    }
                
                execution_times.append(end_time - start_time)
            
            avg_time = sum(execution_times) / len(execution_times)
            
            # Requirement: average under 1 second
            if avg_time > 1.0:
                return {
                    'name': 'performance',
                    'passed': False,
                    'reason': f'Average execution time too high: {avg_time:.2f}s',
                    'details': {'avg_time': avg_time, 'times': execution_times}
                }
            
            return {
                'name': 'performance',
                'passed': True,
                'details': {
                    'avg_execution_time': avg_time,
                    'min_time': min(execution_times),
                    'max_time': max(execution_times)
                }
            }
            
        except Exception as e:
            return {
                'name': 'performance',
                'passed': False,
                'reason': f'Performance test failed: {str(e)}',
                'details': {'error': str(e)}
            }
    
    def _test_memory_management(self, agent_instance: Any) -> Dict[str, Any]:
        """Test memory management"""
        # Basic memory test - check for obvious leaks
        import sys
        
        try:
            initial_size = sys.getsizeof(agent_instance)
            
            # Run multiple cycles
            for i in range(100):
                agent_instance.run(f"memory test {i}")
            
            final_size = sys.getsizeof(agent_instance)
            
            # Allow 10% growth for caching
            if final_size > initial_size * 1.1:
                return {
                    'name': 'memory_management',
                    'passed': False,
                    'reason': f'Memory growth excessive: {initial_size} -> {final_size} bytes',
                    'details': {'initial_bytes': initial_size, 'final_bytes': final_size}
                }
            
            return {
                'name': 'memory_management',
                'passed': True,
                'details': {
                    'initial_bytes': initial_size,
                    'final_bytes': final_size,
                    'growth_percent': ((final_size - initial_size) / initial_size * 100) if initial_size > 0 else 0
                }
            }
            
        except Exception as e:
            return {
                'name': 'memory_management',
                'passed': False,
                'reason': f'Memory test failed: {str(e)}',
                'details': {'error': str(e)}
            }
    
    def _test_security_features(self, agent_instance: Any) -> Dict[str, Any]:
        """Test basic security features"""
        # Check for dangerous patterns in code
        import inspect
        
        try:
            source = inspect.getsource(agent_instance.__class__)
            
            dangerous_patterns = [
                'eval(',
                'exec(',
                '__import__(',
                'os.system',
                'subprocess.Popen'
            ]
            
            found_patterns = []
            for pattern in dangerous_patterns:
                if pattern in source:
                    found_patterns.append(pattern)
            
            if found_patterns:
                return {
                    'name': 'security_features',
                    'passed': False,
                    'reason': f'Dangerous patterns found: {found_patterns}',
                    'details': {'found_patterns': found_patterns}
                }
            
            return {
                'name': 'security_features',
                'passed': True,
                'details': {'dangerous_patterns_found': 0}
            }
            
        except Exception as e:
            return {
                'name': 'security_features',
                'passed': False,
                'reason': f'Security test failed: {str(e)}',
                'details': {'error': str(e)}
            }
    
    def _test_documentation(self, agent_class: Any) -> Dict[str, Any]:
        """Test documentation"""
        import inspect
        
        try:
            docstring = inspect.getdoc(agent_class)
            
            if not docstring or len(docstring.strip()) < 50:
                return {
                    'name': 'documentation',
                    'passed': False,
                    'reason': 'Insufficient documentation',
                    'details': {'docstring_length': len(docstring) if docstring else 0}
                }
            
            # Check for method documentation
            methods = ['perceive', 'update_state', 'plan', 'act', 'learn']
            undocumented_methods = []
            
            for method_name in methods:
                method = getattr(agent_class, method_name, None)
                if method and not inspect.getdoc(method):
                    undocumented_methods.append(method_name)
            
            if undocumented_methods:
                return {
                    'name': 'documentation',
                    'passed': False,
                    'reason': f'Undocumented methods: {undocumented_methods}',
                    'details': {'undocumented_methods': undocumented_methods}
                }
            
            return {
                'name': 'documentation',
                'passed': True,
                'details': {
                    'docstring_length': len(docstring),
                    'all_methods_documented': True
                }
            }
            
        except Exception as e:
            return {
                'name': 'documentation',
                'passed': False,
                'reason': f'Documentation test failed: {str(e)}',
                'details': {'error': str(e)}
            }

class GoldTestSuite(SilverTestSuite):
    """Test suite for Gold certification (extends Silver)"""
    
    def run_all_tests(self, agent_class: Any, agent_instance: Any) -> Dict[str, Any]:
        """Run all Gold-level tests"""
        # Run Silver tests first
        silver_results = super().run_all_tests(agent_class, agent_instance)
        
        if not silver_results['overall_pass']:
            return silver_results
        
        # Run additional Gold tests
        additional_tests = []
        
        # Test 1: ACP protocol compliance
        additional_tests.append(self._test_acp_compliance(agent_instance))
        
        # Test 2: Multi-agent interoperability
        additional_tests.append(self._test_interoperability(agent_instance))
        
        # Test 3: Enterprise security
        additional_tests.append(self._test_enterprise_security(agent_instance))
        
        # Test 4: High availability
        additional_tests.append(self._test_high_availability(agent_instance))
        
        # Combine results
        all_tests = silver_results['tests'] + additional_tests
        
        passed_tests = [t for t in all_tests if t['passed']]
        failed_tests = [t for t in all_tests if not t['passed']]
        
        return {
            'overall_pass': len(failed_tests) == 0,
            'total_tests': len(all_tests),
            'passed_tests': len(passed_tests),
            'failed_tests': len(failed_tests),
            'tests': all_tests,
            'failure_reason': failed_tests[0]['reason'] if failed_tests else None
        }
    
    def _test_acp_compliance(self, agent_instance: Any) -> Dict[str, Any]:
        """Test ACP protocol compliance"""
        try:
            # Check if agent has ACP-related attributes
            required_attrs = ['post_office', 'capabilities']
            
            missing_attrs = []
            for attr in required_attrs:
                if not hasattr(agent_instance, attr):
                    missing_attrs.append(attr)
            
            if missing_attrs:
                return {
                    'name': 'acp_compliance',
                    'passed': False,
                    'reason': f'Missing ACP attributes: {missing_attrs}',
                    'details': {'missing_attrs': missing_attrs}
                }
            
            # Check if agent can handle ACP messages
            from aes.acp import AESMessage, ACPIntent
            
            # Create a test message
            test_message = AESMessage(
                sender_id="test_sender",
                receiver_id=agent_instance.id,
                intent=ACPIntent.REQUEST,
                payload={"test": "message"}
            )
            
            # Convert to observation
            from aes.agent import Observation
            from datetime import datetime
            
            observation = Observation(
                timestamp=datetime.now(),
                source=f"agent:test_sender",
                payload={
                    "acp_message": test_message.to_dict(),
                    "intent": "request"
                }
            )
            
            # Try to process
            result = agent_instance.run(observation)
            
            if not result.success:
                return {
                    'name': 'acp_compliance',
                    'passed': False,
                    'reason': 'Failed to process ACP message',
                    'details': {'error': getattr(result, 'error', 'unknown')}
                }
            
            return {
                'name': 'acp_compliance',
                'passed': True,
                'details': {'acp_message_processed': True}
            }
            
        except Exception as e:
            return {
                'name': 'acp_compliance',
                'passed': False,
                'reason': f'ACP test failed: {str(e)}',
                'details': {'error': str(e)}
            }
    
    def _test_interoperability(self, agent_instance: Any) -> Dict[str, Any]:
        """Test multi-agent interoperability"""
        try:
            # Create another test agent
            from aes.agent import BaseAgent
            from aes.modules.comm import create_post_office
            
            class TestAgent(BaseAgent):
                def perceive(self, input_data):
                    from aes.agent import Observation
                    from datetime import datetime
                    return Observation(
                        timestamp=datetime.now(),
                        source="test",
                        payload={"input": input_data}
                    )
                
                def update_state(self, observation):
                    return self._state
                
                def plan(self, state):
                    from aes.agent import Plan
                    from datetime import datetime
                    return Plan(
                        id=f"plan_{datetime.now().timestamp()}",
                        steps=[{"action": "test"}],
                        priority=50,
                        expected_outcome="test"
                    )
                
                def act(self, plan):
                    from aes.agent import ActionResult
                    return ActionResult(
                        success=True,
                        output=["test output"],
                        metrics={}
                    )
                
                def learn(self, feedback):
                    pass
            
            # Create PostOffice
            post_office = create_post_office()
            
            # Register both agents
            test_agent = TestAgent()
            post_office.register(test_agent)
            post_office.register(agent_instance)
            
            # Test communication
            from aes.acp import AESMessage, ACPIntent
            
            message = AESMessage(
                sender_id=test_agent.id,
                receiver_id=agent_instance.id,
                intent=ACPIntent.REQUEST,
                payload={"action": "ping"}
            )
            
            result = post_office.send(message)
            
            if not result.get('success'):
                return {
                    'name': 'interoperability',
                    'passed': False,
                    'reason': 'Failed to communicate with other agent',
                    'details': {'error': result.get('error', 'unknown')}
                }
            
            return {
                'name': 'interoperability',
                'passed': True,
                'details': {'communication_successful': True}
            }
            
        except Exception as e:
            return {
                'name': 'interoperability',
                'passed': False,
                'reason': f'Interoperability test failed: {str(e)}',
                'details': {'error': str(e)}
            }
    
    def _test_enterprise_security(self, agent_instance: Any) -> Dict[str, Any]:
        """Test enterprise-grade security"""
        # Check for security features
        security_features = []
        
        # Check for authentication
        if hasattr(agent_instance, 'security_token'):
            security_features.append('token_auth')
        
        # Check for rate limiting
        if hasattr(agent_instance, 'rate_limiter'):
            security_features.append('rate_limiting')
        
        # Check for input validation
        # (This would be more comprehensive in production)
        
        if len(security_features) < 2:
            return {
                'name': 'enterprise_security',
                'passed': False,
                'reason': f'Insufficient security features: {security_features}',
                'details': {'features_found': security_features}
            }
        
        return {
            'name': 'enterprise_security',
            'passed': True,
            'details': {'security_features': security_features}
        }
    
    def _test_high_availability(self, agent_instance: Any) -> Dict[str, Any]:
        """Test high availability features"""
        # Check for health monitoring
        health_features = []
        
        if hasattr(agent_instance, 'health_check') and callable(agent_instance.health_check):
            health_features.append('health_check')
        
        if hasattr(agent_instance, 'state_snapshot') and callable(agent_instance.state_snapshot):
            health_features.append('state_monitoring')
        
        # Check for graceful degradation
        # (This would test actual failure scenarios in production)
        
        if len(health_features) < 2:
            return {
                'name': 'high_availability',
                'passed': False,
                'reason': f'Insufficient HA features: {health_features}',
                'details': {'features_found': health_features}
            }
        
        return {
            'name': 'high_availability',
            'passed': True,
            'details': {'ha_features': health_features}
        }
```

7.2 Certificate Badge System

```python
# src/aes/certification/badges.py
"""
Certificate badge generation for AES agents.
Creates SVG badges for display in READMEs and dashboards.
"""

from typing import Dict, Optional
import base64
from io import BytesIO

class BadgeGenerator:
    """Generate SVG badges for certified agents"""
    
    @staticmethod
    def generate_badge(level: str, 
                      certificate_id: str,
                      agent_id: str,
                      valid_until: str) -> str:
        """Generate SVG badge"""
        
        colors = {
            "bronze": "#CD7F32",
            "silver": "#C0C0C0", 
            "gold": "#FFD700"
        }
        
        color = colors.get(level.lower(), "#6C757D")
        
        # Simple SVG badge
        svg = f'''<svg xmlns="http://www.w3.org/2000/svg" width="200" height="30">
    <linearGradient id="b" x2="0" y2="100%">
        <stop offset="0" stop-color="#bbb" stop-opacity=".1"/>
        <stop offset="1" stop-opacity=".1"/>
    </linearGradient>
    <mask id="a">
        <rect width="200" height="30" rx="3" fill="#fff"/>
    </mask>
    <g mask="url(#a)">
        <rect width="80" height="30" fill="#555"/>
        <rect x="80" width="120" height="30" fill="{color}"/>
        <rect width="200" height="30" fill="url(#b)"/>
    </g>
    <g fill="#fff" font-family="DejaVu Sans,Verdana,Geneva,sans-serif" font-size="11">
        <text x="40" y="19" text-anchor="middle" fill="#fff">AES</text>
        <text x="140" y="19" text-anchor="middle" fill="#fff">{level.upper()}</text>
    </g>
    <title>AES {level.upper()} Certified - {agent_id} - Valid until {valid_until}</title>
</svg>'''
        
        return svg
    
    @staticmethod
    def generate_readme_badge(level: str, certificate_id: str) -> str:
        """Generate markdown badge for README"""
        
        badges = {
            "bronze": "https://img.shields.io/badge/AES-BRONZE-CD7F32",
            "silver": "https://img.shields.io/badge/AES-SILVER-C0C0C0",
            "gold": "https://img.shields.io/badge/AES-GOLD-FFD700"
        }
        
        badge_url = badges.get(level.lower(), "https://img.shields.io/badge/AES-CERTIFIED-6C757D")
        
        return f'[![AES {level.upper()} Certified]({badge_url})](https://aes-standard.org/certificates/{certificate_id})'
    
    @staticmethod
    def generate_html_badge(level: str, 
                          certificate_id: str,
                          agent_id: str,
                          valid_until: str) -> str:
        """Generate HTML with embedded badge"""
        svg = BadgeGenerator.generate_badge(level, certificate_id, agent_id, valid_until)
        
        # Convert SVG to base64 for embedding
        svg_bytes = svg.encode('utf-8')
        b64_svg = base64.b64encode(svg_bytes).decode('utf-8')
        
        html = f'''
<div class="aes-badge" style="display: inline-block;">
    <img src="data:image/svg+xml;base64,{b64_svg}" 
         alt="AES {level.upper()} Certified"
         title="Agent: {agent_id} | Valid until: {valid_until}">
    <div style="font-size: 10px; text-align: center; color: #666;">
        <a href="https://aes-standard.org/verify/{certificate_id}" 
           target="_blank" 
           style="color: #666; text-decoration: none;">
            Verify Certificate
        </a>
    </div>
</div>
'''
        
        return html
```

---

8ï¸âƒ£ COMMUNITY GOVERNANCE

8.1 AES Foundation Structure

```python
# docs/GOVERNANCE.md
"""
AES Foundation Governance Structure

1. BOARD OF DIRECTORS (5 members)
   - 2 Corporate representatives (rotating)
   - 2 Academic representatives (elected)
   - 1 Community representative (elected)

2. TECHNICAL COMMITTEE (7 members)
   - Responsible for specification development
   - RFC review and approval
   - Reference implementation oversight

3. SECURITY WORKING GROUP
   - Security audits and vulnerability disclosure
   - Security best practices
   - Incident response

4. COMMUNITY WORKING GROUP
   - Documentation and tutorials
   - Events and outreach
   - Community support

5. CERTIFICATION AUTHORITY
   - Agent certification program
   - Compliance testing
   - Badge issuance

Governance Principles:
- Open participation
- Merit-based contribution
- Transparent decision making
- Vendor neutrality
"""

# docs/RFC_PROCESS.md
"""
AES Request for Comments (RFC) Process

1. PROPOSAL
   - Create GitHub Issue with [RFC] tag
   - Include problem statement and proposed solution
   - 2-week discussion period

2. DRAFT
   - Create Pull Request with specification changes
   - Include reference implementation
   - Technical Committee review (1 week)

3. IMPLEMENTATION
   - Create working implementation
   - Test compatibility
   - Update documentation

4. VOTE
   - Foundation members vote (simple majority)
   - 1-week voting period
   - Quorum: 50% of voting members

5. ADOPTION
   - Merge into AES specification
   - Update reference implementation
   - Announce to community

RFC Categories:
- STANDARD: Changes to core specification
- EXTENSION: New optional features
- INFORMATIONAL: Best practices, guidelines
- EXPERIMENTAL: Temporary features for testing
"""
```

8.2 Contribution Guidelines

```python
# CONTRIBUTING.md
"""
# Contributing to AES

We welcome contributions! Here's how:

## ðŸ› Reporting Bugs
1. Check existing issues
2. Use bug report template
3. Include reproduction steps

## ðŸ’¡ Feature Requests
1. Use feature request template
2. Explain use case
3. Consider RFC process for major changes

## ðŸ”§ Code Contributions
1. Fork the repository
2. Create feature branch
3. Write tests
4. Update documentation
5. Submit Pull Request

## ðŸ“š Documentation
1. Fix typos in docs/
2. Add tutorials
3. Translate documentation

## ðŸ§ª Testing
1. Add test cases
2. Improve test coverage
3. Report test failures

## ðŸ›¡ï¸ Security
1. Report vulnerabilities to security@aes-standard.org
2. Do NOT disclose publicly before coordination
3. Follow responsible disclosure

## ðŸ“‹ Code Standards
- Follow PEP 8
- Type hints for all functions
- Docstrings for all public methods
- 90%+ test coverage for new code

## ðŸ·ï¸ Commit Messages
- Use conventional commits
- Format: type(scope): description
- Types: feat, fix, docs, style, refactor, test, chore

## âœ… Pull Request Checklist
- [ ] Tests pass
- [ ] Documentation updated
- [ ] Code follows standards
- [ ] No breaking changes (or documented)
- [ ] Linked to issue

## ðŸ† Recognition
- Contributors listed in CONTRIBUTORS.md
- Special recognition for major contributions
- Invitation to join working groups

Thank you for contributing! ðŸŒŸ
"""
```

---

9ï¸âƒ£ DEPLOYMENT EXAMPLES

9.1 Docker Deployment

```dockerfile
# Dockerfile.aes
FROM python:3.10-slim as builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

# Copy source
COPY src/ ./src/
COPY pyproject.toml .
COPY README.md .

# Install in user directory
RUN pip install --user .

# Runtime image
FROM python:3.10-slim

WORKDIR /app

# Create non-root user
RUN useradd -m -u 1000 aesuser && \
    mkdir -p /app && \
    chown -R aesuser:aesuser /app

USER aesuser

# Copy installed packages
COPY --from=builder --chown=aesuser /root/.local /home/aesuser/.local
ENV PATH=/home/aesuser/.local/bin:$PATH

# Copy application
COPY --chown=aesuser:aesuser src/ ./src/
COPY --chown=aesuser:aesuser examples/ ./examples/
COPY --chown=aesuser:aesuser config/ ./config/

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD python -c "from aes.agent import BaseAgent; print('Health check passed')" || exit 1

# Default command
CMD ["aes", "--help"]
```

9.2 Kubernetes Deployment

```yaml
# k8s/aes-agent-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: aes-customer-support-agent
  labels:
    app: aes-agent
    standard: aes-v1.0
    certification: gold
spec:
  replicas: 3
  selector:
    matchLabels:
      app: aes-agent
      role: customer-support
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: aes-agent
        role: customer-support
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: aes-agent-sa
      containers:
      - name: agent
        image: your-registry/aes-agent:gold-v1.0.0
        ports:
        - containerPort: 8080
          name: http
        env:
        - name: AGENT_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: AGENT_TYPE
          value: "customer-support"
        - name: LOG_LEVEL
          value: "INFO"
        - name: POSTOFFICE_ENDPOINT
          value: "http://aes-postoffice:8080"
        - name: MONITORING_ENDPOINT
          value: "http://aes-monitoring:9090"
        - name: ENCRYPTION_KEY
          valueFrom:
            secretKeyRef:
              name: aes-secrets
              key: encryption-key
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 3
        securityContext:
          runAsUser: 1000
          runAsGroup: 1000
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
          readOnly: true
        - name: data-volume
          mountPath: /app/data
      volumes:
      - name: config-volume
        configMap:
          name: aes-agent-config
      - name: data-volume
        emptyDir: {}
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
---
apiVersion: v1
kind: Service
metadata:
  name: aes-customer-support-agent
  labels:
    app: aes-agent
    role: customer-support
spec:
  selector:
    app: aes-agent
    role: customer-support
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
    name: http
  type: ClusterIP
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: aes-agent-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: aes-customer-support-agent
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
```

9.3 CI/CD Pipeline

```yaml
# .github/workflows/ci.yml
name: AES CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]
    
    - name: Lint with flake8
      run: |
        flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 src/ tests/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Type check with mypy
      run: |
        mypy src/ --ignore-missing-imports
    
    - name: Test with pytest
      run: |
        pytest tests/ -v --cov=src --cov-report=xml --cov-report=term-missing
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
    
    - name: AES Compliance Check
      run: |
        aes validate examples/hello_world.py --level=SECURE --output=json
    
  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Run Snyk to check for vulnerabilities
      uses: snyk/actions/python@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        args: --severity-threshold=high
    
    - name: Run Bandit security scanner
      run: |
        pip install bandit
        bandit -r src/ -ll
    
    - name: Run Safety check
      run: |
        pip install safety
        safety check
    
  build:
    needs: [test, security]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"
    
    - name: Build package
      run: |
        pip install build
        python -m build
    
    - name: Test package installation
      run: |
        pip install dist/*.whl
        aes --version
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: dist-packages
        path: dist/
    
  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download build artifacts
      uses: actions/download-artifact@v3
      with:
        name: dist-packages
        path: dist/
    
    - name: Publish to PyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        password: ${{ secrets.PYPI_API_TOKEN }}
    
    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: .
        file: ./Dockerfile.aes
        push: true
        tags: |
          your-registry/aes-starter-kit:latest
          your-registry/aes-starter-kit:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Deploy to Kubernetes
      run: |
        echo "${{ secrets.KUBECONFIG }}" | base64 --decode > kubeconfig.yaml
        export KUBECONFIG=kubeconfig.yaml
        kubectl apply -f k8s/
        kubectl rollout status deployment/aes-customer-support-agent
    
    - name: Send deployment notification
      run: |
        curl -X POST -H 'Content-type: application/json' \
          --data '{"text":"AES v1.0 deployed successfully!"}' \
          ${{ secrets.SLACK_WEBHOOK_URL }}
```

