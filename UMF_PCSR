A Unified Mathematical Framework for Physics-Constrained Self-Reconfiguring Generative Intelligence

Authors: ouadi Maakoul + Gemini + Grok + chatGpt + Deepseek 

Abstract

This thesis introduces a unified mathematical and computational framework for Physics-Constrained Self-Reconfiguring Generative Intelligence (PC-SRGI). Contemporary generative models achieve remarkable performance through large-scale statistical learning yet lack intrinsic physical consistency, structural plasticity, and energy awareness. We propose a formalism in which generative intelligence is defined as constrained functional approximation under physical, dynamical, and energetic laws. The framework integrates: (1) physics-informed generative transformers, (2) differentiable world models governed by partial differential equations, (3) graph-theoretic structural plasticity through adaptive capsule architectures, (4) explicit computational energy regularization, and (5) symbolic extraction of discovered physical laws. A reference open-source implementation is provided in Python/PyTorch with a deterministic simulation core in Rust. The central claim is that embedding conservation laws, stability constraints, and energy minimization principles directly into generative reasoning yields more robust, adaptive, and autonomous artificial systems. This document presents the complete mathematical foundations, system architecture, implementation design, and theoretical analysis of version 0.6 of the framework.

---

Chapter 1: Introduction

1.1 Motivation

Large-scale generative models, such as transformers and diffusion models, have revolutionized machine learning by approximating high-dimensional distributions:

f_\theta : \mathcal{X} \rightarrow \mathcal{Y}

where \theta denotes learned parameters. These systems excel at pattern recognition and content generation but operate without regard for the physical laws governing the real world. Consequently, they often produce predictions that violate conservation of energy, momentum, or other invariants; they lack the ability to adapt their own computational structure to changing environments; and they consume vast amounts of energy without any awareness of efficiency.

In contrast, intelligent agents in nature are constrained by physics, exhibit structural plasticity (e.g., synaptic pruning and growth), and operate under metabolic energy budgets. To bridge this gap, we propose a framework that redefines intelligence as constrained functional approximation:

\mathcal{I} = \arg\min_{f_\theta} \mathcal{L}(f_\theta; \mathcal{X}, \mathcal{Y}) \quad \text{subject to} \quad \mathcal{C}(f_\theta) = 0

where \mathcal{C} encodes physical laws, dynamical stability, and energy bounds. This thesis develops the mathematical and architectural foundations of such a framework.

1.2 Contributions

The main contributions of this work are:

1. A mathematical formalism for physics-constrained generative modeling, integrating differential constraints, conservation laws, and energy bounds into a single objective.
2. A differentiable world model based on symplectic integration, ensuring long-term stability and energy conservation in learned dynamics, with full end-to-end gradient flow through multi-step rollouts.
3. A graph-theoretic structural plasticity mechanism that enables the model to reconfigure its own architecture (capsules and routing) in response to task demands and energy budgets, including online adaptation.
4. An energy-aware optimization framework that balances task performance against computational cost, leading to Pareto-optimal trade-offs.
5. A symbolic extraction module that translates learned sparse representations into human-readable physical laws.
6. A hybrid Rust/Python implementation that combines the performance and safety of Rust for deterministic simulation with the flexibility of PyTorch for differentiable modeling.
7. Theoretical guarantees on stability, convergence, and conservation, supported by mathematical proofs.

1.3 Outline

Chapter 2 establishes the mathematical foundations. Chapter 3 describes the system architecture. Chapter 4 provides implementation details, including multi-step training and energy-conservation losses. Chapter 5 presents theoretical analysis. Chapter 6 concludes the thesis and outlines future work toward empirical validation.

---

Chapter 2: Mathematical Foundations

2.1 Constrained Functional Approximation

Let \mathcal{X} \subseteq \mathbb{R}^{d_x} be the input space, \mathcal{Y} \subseteq \mathbb{R}^{d_y} the output space, and \mathcal{P} \subseteq \mathbb{R}^{d_p} the space of physical parameters. We seek a parameterized function f_\theta: \mathcal{X} \times \mathcal{P} \rightarrow \mathcal{Y} that minimizes a task loss \mathcal{L}_{\text{task}} while satisfying constraints \mathcal{C}(f_\theta)=0.

Define constraints as:

\mathcal{C}(f_\theta) = \begin{cases}
\mathcal{D}(f_\theta) - g = 0 & \text{(differential constraints)} \\
\nabla \cdot F = 0 & \text{(conservation laws)} \\
E(f_\theta) \leq E_{\max} & \text{(energy bounds)}
\end{cases}

We convert to unconstrained via penalty:

\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{task}} + \lambda_1 \mathcal{L}_{\text{physics}} + \lambda_2 E_{\text{comp}} + \lambda_3 S_{\text{instability}}

2.2 Physics-Informed Generative Transformers

Let \mathcal{T}_\theta denote a transformer. Augment with physics residual:

\mathcal{L}_{\text{physics}} = \left\| \mathcal{D}(\mathcal{T}_\theta(x)) - g(x) \right\|^2

For conservation of Q:

\mathcal{L}_{\text{cons}} = \left\| \frac{dQ}{dt} \right\|^2

2.3 Differentiable World Models with Closed-Loop Dynamics

We define a dynamical system:

s_{t+1} = \Phi_\theta(s_t, a_t)

In continuous time:

\frac{ds}{dt} = F_\theta(s, a)

The neural ODE formulation:

s(t) = s(0) + \int_0^t F_\theta(s(\tau), a(\tau)) d\tau

Stability requires \lambda_{\max}(J_F) < 0.

End-to-end differentiability is achieved by recomputing forces at each step using the current state, allowing gradients to flow through the entire trajectory. Multi-step rollouts further enhance long-horizon learning.

2.4 Symplectic Integration

The Velocity Verlet algorithm for separable Hamiltonian:

\begin{aligned}
p_{n+1/2} &= p_n - \frac{\Delta t}{2} \nabla V(q_n), \\
q_{n+1} &= q_n + \Delta t \, p_{n+1/2}, \\
p_{n+1} &= p_{n+1/2} - \frac{\Delta t}{2} \nabla V(q_{n+1}).
\end{aligned}

This scheme is symplectic, second-order, and time-reversible. In our framework, -\nabla V is predicted by a neural network, and we recompute forces at the new position to maintain symplecticity.

2.5 Structural Plasticity via Graph Optimization

Architecture as dynamic graph G_t = (V_t, E_t). Evolution:

G_{t+1} = \mathcal{R}(G_t, \nabla_\theta \mathcal{L}, E_{\text{comp}})

Optimization objective:

\min_{G_t} \left( \mathcal{L}_{\text{task}} + \alpha C_{\text{energy}}(G_t) + \beta C_{\text{complexity}}(G_t) \right)

Continuous relaxation of binary activation z_i:

z_i \approx \sigma(\gamma_i / \tau)

Output: \sum_i z_i \cdot \text{capsule}_i(x).

Physics-inspired capsules: Each capsule implements a fixed nonlinear primitive (e.g., \sin, \cos, x^2, Gaussian) with learnable linear combination weights, enabling symbolic interpretation. Capsules serve as the final force-prediction head, directly shaping the learned physics.

2.6 Energy-Aware Intelligence

Computational energy:

E_{\text{comp}} = \sum_i w_i \cdot \text{FLOPs}_i

Dynamic budget: E_{\text{comp}}(t) \leq E_{\text{budget}}(t). Energy-regularized optimization yields Pareto frontier.

2.7 Symbolic Extraction

Active capsules form a basis; we apply symbolic regression (PySR) to obtain a concise expression:

f_\theta(x) \approx \sum_{i: z_i > \epsilon} w_i \phi_i(x)

---

Chapter 3: System Architecture

The PC-SRGI framework is hybrid:

· Python/PyTorch: High-level models, differentiable integration, capsule layers, training, symbolic extraction.
· Rust: Deterministic high-performance simulation (optional, for deployment).

Communication via PyO3.

```
┌─────────────────┐      PyO3      ┌─────────────────┐
│   Python Core   │ ◄─────────────► │    Rust Core    │
│ - Transformers  │                  │ - Symplectic    │
│ - Capsule Layers│                  │   Integrator    │
│ - Training Loop │                  │ - Batch Engine  │
│ - Symbolic Extr.│                  └─────────────────┘
└─────────────────┘
```

Data Flow:

1. Input state sequence → transformer predicts hidden representation.
2. Capsule layer (acting as force head) takes hidden and produces force.
3. Forces used in differentiable Velocity Verlet integrator (PyTorch) to advance state over multiple steps.
4. Task loss (e.g., MSE on predicted states) and physics conservation losses (e.g., energy drift) computed.
5. Capsule gates produce energy cost.
6. Gradients flow through the entire multi-step rollout back to transformer and capsules.
7. Gates updated to optimize energy/task; periodic pruning/growth.
8. After training, symbolic extraction from active capsules.

---

Chapter 4: Implementation

4.1 Differentiable Closed-Loop Velocity Verlet

The core integration step recomputes forces at each new state using the transformer and capsule head.

```python
def force_fn(q, p, history, transformer, capsule_layer):
    # history: (batch, seq_len, 2) previous states
    new_state = torch.stack([q, p], dim=-1).unsqueeze(1)  # (batch, 1, 2)
    full_seq = torch.cat([history[:, 1:, :], new_state], dim=1)  # shift window
    hidden = transformer.embedding(full_seq)
    hidden = transformer.transformer(hidden)
    # Capsule layer as force head
    force, _, _ = capsule_layer(hidden[:, -1, :])  # use last hidden
    return force.squeeze(-1)  # (batch,)

def velocity_verlet_step(q, p, history, transformer, capsule_layer, dt):
    dt_half = dt * 0.5
    f = force_fn(q, p, history, transformer, capsule_layer)
    p_half = p + dt_half * f
    q_new = q + dt * p_half
    f_new = force_fn(q_new, p_half, history, transformer, capsule_layer)
    p_new = p_half + dt_half * f_new
    return q_new, p_new, f_new
```

4.2 Multi-Step Rollout Training

To learn long-term dynamics, we unroll multiple steps and accumulate losses.

```python
def rollout(transformer, capsule_layer, x_init, dt, n_steps=20, target_states=None):
    """
    x_init: (batch, seq_len, 2) initial history
    target_states: (batch, n_steps, 2) ground truth future states (optional)
    Returns: predicted states, total task loss, total energy cost
    """
    batch_size = x_init.size(0)
    states = [x_init[:, -1, :]]  # initial state
    history = x_init.clone()
    total_task_loss = 0.0
    total_energy = 0.0

    for step in range(n_steps):
        q = states[-1][:, 0]
        p = states[-1][:, 1]

        q_new, p_new, f_new = velocity_verlet_step(
            q, p, history, transformer, capsule_layer, dt
        )
        states.append(torch.stack([q_new, p_new], dim=-1))

        # Update history (sliding window)
        new_state = states[-1].unsqueeze(1)
        history = torch.cat([history[:, 1:, :], new_state], dim=1)

        if target_states is not None:
            y = target_states[:, step, :]
            total_task_loss += torch.mean((q_new - y[:,0])**2 + (p_new - y[:,1])**2)

        # Energy cost from capsule gates (per step)
        _, energy_cost, _ = capsule_layer(f_new.unsqueeze(-1))
        total_energy += energy_cost

    return torch.stack(states[1:], dim=1), total_task_loss / n_steps, total_energy
```

4.3 Physics-Primitive Capsule Layer as Force Head

Capsules are fixed nonlinear primitives with learnable coefficients, serving as the final layer that maps transformer hidden states to forces.

```python
class PhysicsPrimitiveCapsuleLayer(nn.Module):
    def __init__(self, input_dim, primitives=None, capsule_cost=1.0):
        super().__init__()
        if primitives is None:
            self.primitives = [
                lambda x: x,                     # identity
                lambda x: x**2,
                lambda x: torch.sin(x),
                lambda x: torch.cos(x),
                lambda x: torch.exp(-x**2),      # Gaussian
                lambda x: torch.ones_like(x)     # constant
            ]
        else:
            self.primitives = primitives
        self.num_capsules = len(self.primitives)
        # Learnable coefficients for each primitive (output dimension = 1 for force)
        self.coeffs = nn.Parameter(torch.randn(self.num_capsules, input_dim))
        self.gates = nn.Parameter(torch.ones(self.num_capsules))
        self.temp = 1.0
        self.capsule_cost = capsule_cost

    def forward(self, x):
        # x: (batch, input_dim)
        z = torch.sigmoid(self.gates / self.temp)  # (num_capsules,)
        # Compute each primitive's output
        out = torch.zeros(x.size(0), device=x.device)
        for i, prim in enumerate(self.primitives):
            phi = prim(x)  # (batch, input_dim) or broadcastable
            # Weighted combination: sum over input_dim, then multiply by gate
            # For simplicity, assume phi is elementwise and sum over features.
            # Alternatively, use dot product with coeffs.
            out += z[i] * (phi * self.coeffs[i]).sum(dim=-1)
        energy_cost = self.capsule_cost * z.sum()
        return out, energy_cost, z

    def prune_and_grow(self, threshold=0.1):
        with torch.no_grad():
            z = torch.sigmoid(self.gates)
            active = z > threshold
            self.primitives = [p for p, a in zip(self.primitives, active) if a]
            self.coeffs = nn.Parameter(self.coeffs[active])
            self.gates = nn.Parameter(self.gates[active])
```

4.4 Physics-Constrained Transformer

The transformer now outputs a hidden representation for the capsule layer.

```python
class PhysicsConstrainedTransformer(nn.Module):
    def __init__(self, d_model, nhead, num_layers, input_dim):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)

    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        return x  # hidden states
```

4.5 Training Loop with Energy Conservation Loss

We incorporate an energy conservation loss appropriate for the system (e.g., pendulum).

```python
def energy_conservation_loss(q, p, mass=1.0, g=9.81, L=1.0):
    # Simple pendulum energy
    kinetic = 0.5 * mass * p**2
    potential = mass * g * L * (1 - torch.cos(q))
    total_energy = kinetic + potential
    # Penalize deviation from initial energy (or from constant)
    # Here we penalize variance over the batch (or time)
    return torch.var(total_energy)  # encourage constant energy

def train_step(transformer, capsule_layer, optimizer, x_init, target_states, dt, device):
    transformer.train()
    capsule_layer.train()
    x_init = x_init.to(device)
    target_states = target_states.to(device)

    # Multi-step rollout
    pred_states, task_loss, energy_cost = rollout(
        transformer, capsule_layer, x_init, dt, n_steps=20, target_states=target_states
    )

    # Physics losses
    # For demonstration, we compute energy loss on the last predicted state
    q_last = pred_states[:, -1, 0]
    p_last = pred_states[:, -1, 1]
    energy_loss = energy_conservation_loss(q_last, p_last)

    # Total loss
    total_loss = task_loss + 0.1 * energy_loss + 0.01 * energy_cost

    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()

    # Anneal gate temperature
    capsule_layer.temp *= 0.999

    return total_loss.item()
```

4.6 Rust Core (Optional)

The Rust symplectic engine is kept for deployment and for generating ground truth data. For training, we rely on the differentiable PyTorch version.

```rust
// Full step implementation (matching PyTorch logic)
fn integrate_step(&self, q: f64, p: f64, f_half: f64, f_new: f64) -> (f64, f64) {
    let dt_half = self.dt * 0.5;
    let p_half = p + dt_half * f_half;
    let q_new = q + self.dt * p_half;
    let p_new = p_half + dt_half * f_new;
    (q_new, p_new)
}
```

4.7 Symbolic Extraction

After training, we extract symbolic expressions from active capsules.

```python
def extract_symbolic(capsule_layer, X_train, y_train):
    gates = torch.sigmoid(capsule_layer.gates).detach().cpu().numpy()
    active = gates > 0.5
    if not np.any(active):
        return "No active capsules"

    # Build basis matrix from active primitives
    X_tensor = torch.tensor(X_train, dtype=torch.float32)
    basis = []
    for i, is_active in enumerate(active):
        if is_active:
            phi = capsule_layer.primitives[i](X_tensor).numpy()
            # For symbolic regression, we treat the primitive outputs as features
            # Optionally weight by learned coefficients
            # Here we use raw phi as basis
            basis.append(phi)
    X_basis = np.hstack(basis)

    model = PySRRegressor(
        niterations=100,
        binary_operators=["+", "*", "-", "/"],
        unary_operators=["sin", "cos", "exp", "log"],
        model_selection="accuracy",
        loss="L2DistLoss()",
    )
    model.fit(X_basis, y_train)
    return model.sympy()
```

---

Chapter 5: Theoretical Analysis

5.1 Gated Lipschitz Bound

Theorem 1 (Gated Lipschitz Constant). Let the force field F_\theta be a sum of gated capsule outputs: F_\theta(x) = \sum_{i=1}^N z_i \, f_i(x), where each f_i is L_i-Lipschitz and |z_i| \le 1. Then F_\theta is L-Lipschitz with L \le \sum_i |z_i| L_i \le \sum_i L_i.

Proof. For any x,y:

\|F_\theta(x)-F_\theta(y)\| = \left\| \sum_i z_i (f_i(x)-f_i(y)) \right\| \le \sum_i |z_i| \|f_i(x)-f_i(y)\| \le \sum_i |z_i| L_i \|x-y\|.

Hence the Lipschitz constant is bounded by \sum_i |z_i| L_i. ∎

5.2 Convergence of Structural Evolution

Theorem 2 (Structural Convergence). Let the structural update be a gradient flow on the energy-augmented loss:

\frac{d\gamma_i}{dt} = -\frac{\partial}{\partial \gamma_i} \left( \mathcal{L}_{\text{task}}(\gamma) + \alpha \sum_j \sigma(\gamma_j) + \beta \|\gamma\|_2^2 \right)

where \sigma is the sigmoid function and \alpha,\beta > 0. Assume \mathcal{L}_{\text{task}} is bounded below and smooth. Then the gates \gamma_i converge to a stationary point as t \to \infty.

Proof. Define U(\gamma) = \mathcal{L}_{\text{task}}(\gamma) + \alpha \sum_j \sigma(\gamma_j) + \beta \|\gamma\|_2^2. The term \beta \|\gamma\|_2^2 makes U coercive, and U is smooth. The gradient flow \dot{\gamma} = -\nabla U(\gamma) decreases U monotonically. By LaSalle's invariance principle, bounded trajectories converge to the set of stationary points. ∎

5.3 End-to-End Gradient Flow

Theorem 3 (Differentiability of Closed-Loop Integration). Consider a sequence of K Velocity Verlet steps where forces are recomputed at each step using the same neural network F_\theta. The mapping from initial state (q_0, p_0) to final state (q_K, p_K) is differentiable with respect to \theta, and gradients can be computed via automatic differentiation or the adjoint method.

Proof. Each Verlet step is a composition of differentiable operations (addition, multiplication, and the network F_\theta). Since F_\theta is differentiable by construction, the entire composition is differentiable. The adjoint sensitivity equations can be derived by treating the integrator as a sequence of explicit layers. ∎

5.4 Energy Conservation and Symplecticity

The Velocity Verlet integrator is symplectic and conserves energy up to O(\Delta t^2) over long times for integrable systems. This property is standard; see Hairer et al. [1] for proof.

---

Chapter 6: Conclusion

We have presented PC-SRGI, a unified mathematical and architectural framework for physics-constrained, self-reconfiguring generative intelligence. By integrating symplectic integration, adaptive capsule gating, energy regularization, and symbolic extraction into a single constrained optimization objective, we provide a formal foundation for AI systems that respect physical laws, adapt their structure to computational budgets, and yield interpretable symbolic representations. The implementation features multi-step differentiable rollouts, energy-conservation losses, and physics-primitive capsules as force heads, ensuring that gradients flow through long trajectories and that physical constraints are actively enforced during training. The hybrid Rust/Python design ensures both performance and flexibility. Theoretical analyses establish Lipschitz bounds, convergence guarantees, and differentiability of the closed-loop world model.

Future work will focus on empirical validation on benchmark dynamical systems (harmonic oscillator, pendulum, variable-gravity robotic arm), demonstrating energy conservation, structural adaptation, and symbolic recovery. Additionally, we plan to extend the framework to high-dimensional PDEs, incorporate learned Hamiltonians, and explore hardware-aware energy optimization. The current version provides a solid theoretical and implementation foundation for these next steps.


Appendices

Appendix A: Mathematical Background

This appendix provides a comprehensive review of the mathematical concepts underpinning the PC-SRGI framework. It covers constrained optimization, functional analysis, Hamiltonian mechanics, symplectic integration, graph theory, energy modeling, and symbolic regression. The material is self-contained and includes derivations of key results referenced in the main text.

A.1 Constrained Optimization and Lagrange Multipliers

Consider the problem of minimizing a function f(x) subject to equality constraints c_i(x)=0 for i=1,\dots,m. The method of Lagrange multipliers introduces variables \lambda_i and forms the Lagrangian:

\mathcal{L}(x,\lambda) = f(x) + \sum_{i=1}^m \lambda_i c_i(x).

A necessary condition for optimality (under differentiability and regularity conditions) is that the gradient of the Lagrangian vanishes:

\nabla_x \mathcal{L} = 0, \quad \nabla_\lambda \mathcal{L} = 0.

For inequality constraints c_i(x) \leq 0, we use KKT conditions. In our framework, we often convert hard constraints into soft penalties via penalty methods:

\min_x f(x) + \mu \sum_i c_i(x)^2.

As \mu \to \infty, the solution approaches the constrained optimum. Augmented Lagrangian methods combine penalty and Lagrange multiplier updates for better convergence.

A.2 Functional Analysis and Lipschitz Continuity

A function F: \mathbb{R}^n \to \mathbb{R}^m is Lipschitz continuous if there exists a constant L \geq 0 such that for all x,y:

\|F(x)-F(y)\| \leq L \|x-y\|.

The smallest such L is the Lipschitz constant. Lipschitz continuity is essential for:

· Convergence of gradient descent: If \nabla f is L-Lipschitz, then gradient descent with step size \eta < 2/L converges to a stationary point.
· Stability of dynamical systems: If the vector field F is Lipschitz, solutions to \dot{x}=F(x) exist uniquely and depend continuously on initial conditions.
· Neural network regularity: Lipschitz bounds prevent exploding gradients and improve robustness.

For a differentiable function, the Lipschitz constant of its gradient is the supremum of the spectral norm of the Hessian:

L = \sup_x \|\nabla^2 f(x)\|.

A.3 Hamiltonian Mechanics and Symplectic Geometry

A Hamiltonian system is described by generalized coordinates q \in \mathbb{R}^n and conjugate momenta p \in \mathbb{R}^n. The Hamiltonian H(q,p) (usually the total energy) governs the dynamics via Hamilton's equations:

\dot{q} = \frac{\partial H}{\partial p}, \quad \dot{p} = -\frac{\partial H}{\partial q}.

These can be written compactly using the symplectic matrix J = \begin{pmatrix} 0 & I \\ -I & 0 \end{pmatrix}:

\frac{d}{dt} \begin{pmatrix} q \\ p \end{pmatrix} = J \nabla H.

The symplectic two-form \omega = dq \wedge dp = \sum_i dq_i \wedge dp_i is preserved under Hamiltonian flow: the flow map \varphi_t satisfies \varphi_t^*\omega = \omega. A numerical integrator is symplectic if it preserves this two-form exactly.

For separable Hamiltonians H(q,p) = T(p) + V(q) (kinetic plus potential), Hamilton's equations become:

\dot{q} = \nabla T(p), \quad \dot{p} = -\nabla V(q).

Common choices: T(p) = \frac{1}{2} p^T M^{-1} p (kinetic energy), V(q) potential.

A.4 Numerical Integration and Symplectic Methods

The Velocity Verlet (or Störmer–Verlet) algorithm for a separable Hamiltonian is:

\begin{aligned}
p_{n+1/2} &= p_n - \frac{\Delta t}{2} \nabla V(q_n), \\
q_{n+1} &= q_n + \Delta t \, M^{-1} p_{n+1/2}, \\
p_{n+1} &= p_{n+1/2} - \frac{\Delta t}{2} \nabla V(q_{n+1}).
\end{aligned}

For unit mass (M=I), this simplifies to the form used in the main text. Properties:

· Second-order accurate: Local error O(\Delta t^3), global O(\Delta t^2).
· Symplectic: Preserves the symplectic two-form.
· Time-reversible: Reversing the sign of \Delta t recovers the previous state.
· Energy conservation: For integrable systems, energy error remains bounded over exponentially long times (no secular drift).

The method requires one force evaluation per step (if force depends only on position), but note that forces are evaluated at both the beginning and the end of the step. In our framework, the force -\nabla V is predicted by a neural network, making the integrator differentiable.

A.5 Graph Theory and Dynamic Architectures

A directed graph G = (V,E) consists of a set of nodes V and edges E \subseteq V \times V. In our framework, nodes represent computational capsules (sub-networks), and edges represent weighted information flow. The graph is dynamic: it evolves over time according to a reconfiguration rule \mathcal{R} that depends on gradients and energy constraints.

Key concepts:

· Adjacency matrix: A \in \mathbb{R}^{|V|\times |V|} where A_{ij} is the weight of edge (i,j).
· Node features: h_i \in \mathbb{R}^d for each node (e.g., capsule output).
· Graph neural networks (GNNs) can be used to propagate information.

In our plasticity mechanism, each capsule has a learnable gate \gamma_i that controls its activation via z_i = \sigma(\gamma_i/\tau). The graph structure is implicitly defined by the connectivity of the capsules (e.g., fully connected, or learned via attention).

A.6 Energy Models and Pareto Optimality

Computational energy is modeled as a weighted sum of floating-point operations (FLOPs). For a given module i with gate z_i, the energy contribution is:

E_i = w_i \cdot \text{FLOPs}_i \cdot z_i,

where w_i is hardware-specific energy per FLOP. The total energy is E_{\text{comp}} = \sum_i E_i.

The trade-off between task loss \mathcal{L}_{\text{task}} and energy defines a Pareto frontier: a set of points where no objective can be improved without degrading the other. Multi-objective optimization techniques include:

· Scalarization: Minimize \mathcal{L}_{\text{task}} + \lambda E_{\text{comp}} for various \lambda.
· Evolutionary algorithms.
· Constraint method: Minimize \mathcal{L}_{\text{task}} subject to E_{\text{comp}} \leq \epsilon.

A.7 Symbolic Regression and Sparse Identification

Symbolic regression aims to find a mathematical expression that fits given data. Common approaches:

· Genetic programming (e.g., PySR): Evolves populations of expression trees.
· Sparse regression (e.g., SINDy): Selects a sparse combination of basis functions from a library.

In our framework, after training, the active capsules provide a natural basis \{\phi_i\}. We then apply symbolic regression to find a concise expression of the form:

f(x) \approx \sum_{i: z_i > \epsilon} c_i \phi_i(x).

This bridges the neural representation to interpretable scientific laws.

---

Appendix B: Proofs of Theorems

This appendix contains complete proofs for all theorems stated in the main text.

B.1 Proof of Theorem 1 (Gated Lipschitz Constant)

Theorem 1. Let the force field F_\theta be a sum of gated capsule outputs: F_\theta(x) = \sum_{i=1}^N z_i \, f_i(x), where each f_i is L_i-Lipschitz and |z_i| \le 1. Then F_\theta is L-Lipschitz with L \le \sum_i |z_i| L_i \le \sum_i L_i.

Proof. For any x,y,

\begin{aligned}
\|F_\theta(x)-F_\theta(y)\| &= \left\| \sum_{i=1}^N z_i (f_i(x)-f_i(y)) \right\| \\
&\leq \sum_{i=1}^N |z_i| \|f_i(x)-f_i(y)\| \quad \text{(triangle inequality)} \\
&\leq \sum_{i=1}^N |z_i| L_i \|x-y\| \quad \text{(Lipschitz property of each } f_i).
\end{aligned}

Thus \|F_\theta(x)-F_\theta(y)\| \leq \left(\sum_i |z_i| L_i\right) \|x-y\|. Hence F_\theta is Lipschitz with constant at most \sum_i |z_i| L_i. Since |z_i| \leq 1, this is also bounded by \sum_i L_i. ∎

B.2 Proof of Theorem 2 (Structural Convergence)

Theorem 2. Let the structural update be a gradient flow on the energy-augmented loss:

\frac{d\gamma_i}{dt} = -\frac{\partial}{\partial \gamma_i} \left( \mathcal{L}_{\text{task}}(\gamma) + \alpha \sum_j \sigma(\gamma_j) + \beta \|\gamma\|_2^2 \right),

where \sigma is the sigmoid function and \alpha,\beta > 0. Assume \mathcal{L}_{\text{task}} is bounded below and smooth. Then the gates \gamma_i converge to a stationary point as t \to \infty.

Proof. Define the potential function:

U(\gamma) = \mathcal{L}_{\text{task}}(\gamma) + \alpha \sum_{j=1}^N \sigma(\gamma_j) + \beta \|\gamma\|_2^2.

· Smoothness: \mathcal{L}_{\text{task}} is smooth by assumption; \sigma and \|\cdot\|_2^2 are smooth. Hence U is smooth.
· Coercivity: The term \beta \|\gamma\|_2^2 ensures that U(\gamma) \to \infty as \|\gamma\| \to \infty. Therefore, the sublevel sets \{ \gamma : U(\gamma) \leq c \} are compact.
· Gradient flow: \dot{\gamma} = -\nabla U(\gamma). Then
  \frac{d}{dt} U(\gamma(t)) = \nabla U(\gamma)^T \dot{\gamma} = -\|\nabla U(\gamma)\|^2 \leq 0.
  Thus U is nonincreasing along trajectories.
· Invariance principle (LaSalle): Since trajectories are bounded (by coercivity) and U decreases, they converge to the largest invariant set contained in \{ \gamma : \nabla U(\gamma) = 0 \}, i.e., the set of stationary points.

Therefore, \gamma(t) converges to a stationary point as t \to \infty. ∎

B.3 Proof of Theorem 3 (Differentiability of Closed-Loop Integration)

Theorem 3. Consider a sequence of K Velocity Verlet steps where forces are recomputed at each step using the same neural network F_\theta. The mapping from initial state (q_0, p_0) to final state (q_K, p_K) is differentiable with respect to \theta, and gradients can be computed via automatic differentiation or the adjoint method.

Proof. Each Velocity Verlet step consists of the following operations, assuming unit mass for simplicity:

\begin{aligned}
p_{n+1/2} &= p_n + \frac{\Delta t}{2} F_\theta(q_n), \\
q_{n+1} &= q_n + \Delta t \, p_{n+1/2}, \\
p_{n+1} &= p_{n+1/2} + \frac{\Delta t}{2} F_\theta(q_{n+1}).
\end{aligned}

Each operation is a composition of:

· Addition and multiplication by constants (differentiable).
· Evaluation of the neural network F_\theta (differentiable by construction, since it is built from differentiable layers).

Hence each Verlet step is a differentiable function of (q_n, p_n) and \theta. The composition of K such steps is therefore differentiable with respect to \theta. Gradients can be computed by standard automatic differentiation (backpropagation through time) or by solving the adjoint sensitivity equations if the number of steps is large. ∎

Remark. In practice, automatic differentiation frameworks like PyTorch handle this seamlessly as long as the computation graph is retained. For very long rollouts, checkpointing or adjoint methods may be used to reduce memory.

B.4 Symplecticity of Velocity Verlet (Standard Result)

We provide a sketch of the proof for completeness; details can be found in Hairer et al. [1].

The Velocity Verlet map can be written as a composition of two maps:

\varphi_{\Delta t} = \varphi_{\Delta t/2}^{\text{kick}} \circ \varphi_{\Delta t}^{\text{drift}} \circ \varphi_{\Delta t/2}^{\text{kick}},

where:

· Kick map: (q,p) \mapsto (q, p - \frac{\Delta t}{2} \nabla V(q))
· Drift map: (q,p) \mapsto (q + \Delta t \, p, p)

Each of these maps is symplectic: the Jacobian of the kick map is \begin{pmatrix} I & 0 \\ -\frac{\Delta t}{2} \nabla^2 V(q) & I \end{pmatrix}, which satisfies J^T \Omega J = \Omega where \Omega = \begin{pmatrix} 0 & I \\ -I & 0 \end{pmatrix}. The drift map has Jacobian \begin{pmatrix} I & \Delta t I \\ 0 & I \end{pmatrix}, also symplectic. The composition of symplectic maps is symplectic, so \varphi_{\Delta t} is symplectic.

B.5 Local Stability (Standard Result)

Theorem (Local Exponential Stability). Let \dot{s} = F(s) be a dynamical system with an equilibrium at s^*. Suppose the Jacobian J_F(s^*) has all eigenvalues with real part less than -\delta < 0. Then the equilibrium is locally exponentially stable.

Proof. Linearize around s^*: \dot{\xi} = J_F(s^*) \xi + O(\|\xi\|^2). For sufficiently small perturbations, the nonlinear term is negligible. The solution to the linear system is \xi(t) = e^{J_F(s^*) t} \xi(0). The condition \text{Re}(\lambda) < -\delta implies that \|e^{J_F t}\| \leq C e^{-\delta t} for some constant C. Thus \|\xi(t)\| \leq C e^{-\delta t} \|\xi(0)\|, establishing exponential stability. ∎

---

Appendix C: Rust Core Implementation

This appendix provides the complete Rust implementation of the symplectic integrator and its PyO3 bindings. The Rust core is designed for high-performance, deterministic simulation and can be used for both ground-truth data generation and inference.

C.1 Cargo.toml

```toml
[package]
name = "pc_srgi_core"
version = "0.6.0"
edition = "2021"

[lib]
crate-type = ["cdylib"]

[dependencies]
pyo3 = { version = "0.20", features = ["extension-module"] }
rayon = "1.7"
```

C.2 src/lib.rs

```rust
use pyo3::prelude::*;
use rayon::prelude::*;

/// Symplectic engine performing Velocity Verlet integration.
#[pyclass]
pub struct SymplecticEngine {
    dt: f64,
}

#[pymethods]
impl SymplecticEngine {
    /// Create a new engine with given time step.
    #[new]
    fn new(dt: f64) -> Self {
        Self { dt }
    }

    /// Integrate a batch of states one full step.
    /// Arguments:
    ///   q: flat vector of positions (length n)
    ///   p: flat vector of momenta (length n)
    ///   forces: flat vector of forces at current q (length n)
    /// Returns (new_q, new_p) after one full time step.
    /// Note: This function assumes forces are already computed for the new position.
    ///       For a full step with force recomputation, call twice or use the two-step method.
    fn integrate_batch(&self, q: Vec<f64>, p: Vec<f64>, forces: Vec<f64>) -> (Vec<f64>, Vec<f64>) {
        let n = q.len();
        assert_eq!(p.len(), n);
        assert_eq!(forces.len(), n);

        let dt_half = self.dt * 0.5;
        let (new_q, new_p): (Vec<_>, Vec<_>) = (0..n)
            .into_par_iter()
            .map(|i| {
                let mut qi = q[i];
                let mut pi = p[i];
                let fi = forces[i];

                // half kick
                pi += dt_half * fi;
                // drift
                qi += self.dt * pi;
                // second half-kick would require force at new qi
                (qi, pi)
            })
            .unzip();

        (new_q, new_p)
    }

    /// Full two-stage integration with force at new position.
    /// Use this for correct symplectic step when forces at new position are known.
    fn integrate_full_step(
        &self,
        q: f64,
        p: f64,
        force_at_q: f64,
        force_at_new_q: f64,
    ) -> (f64, f64) {
        let dt_half = self.dt * 0.5;
        let p_half = p + dt_half * force_at_q;
        let q_new = q + self.dt * p_half;
        let p_new = p_half + dt_half * force_at_new_q;
        (q_new, p_new)
    }
}

/// Python module declaration.
#[pymodule]
fn pc_srgi_core(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_class::<SymplecticEngine>()?;
    Ok(())
}
```

C.3 Building and Using the Rust Module

To build the module, run:

```bash
pip install maturin
maturin develop
```

Then in Python:

```python
from pc_srgi_core import SymplecticEngine
engine = SymplecticEngine(dt=0.01)
q_new, p_new = engine.integrate_batch(q, p, forces)
```

For full-step integration with known forces at new positions, call integrate_full_step in a loop.

---

Appendix D: PyTorch Modules

This appendix provides the complete PyTorch implementation of the PC-SRGI framework, including the physics-primitive capsule layer, transformer, multi-step rollout, training loop, and symbolic extraction.

D.1 models/capsule_layer.py

```python
import torch
import torch.nn as nn
import numpy as np

class PhysicsPrimitiveCapsuleLayer(nn.Module):
    """
    Capsule layer where each capsule is a fixed nonlinear primitive.
    The layer serves as the force-prediction head.
    """
    def __init__(self, input_dim, primitives=None, capsule_cost=1.0):
        super().__init__()
        if primitives is None:
            self.primitives = [
                lambda x: x,                     # identity
                lambda x: x**2,
                lambda x: torch.sin(x),
                lambda x: torch.cos(x),
                lambda x: torch.exp(-x**2),      # Gaussian
                lambda x: torch.ones_like(x)     # constant
            ]
        else:
            self.primitives = primitives
        self.num_capsules = len(self.primitives)
        # Learnable coefficients for each primitive (output dimension = 1 for force)
        self.coeffs = nn.Parameter(torch.randn(self.num_capsules, input_dim))
        self.gates = nn.Parameter(torch.ones(self.num_capsules))
        self.temp = 1.0
        self.capsule_cost = capsule_cost

    def forward(self, x):
        """
        x: (batch, input_dim) – hidden state from transformer.
        Returns: force (batch,), energy_cost (scalar), gates (num_capsules)
        """
        z = torch.sigmoid(self.gates / self.temp)  # (num_capsules,)
        # Compute weighted sum of primitives
        out = torch.zeros(x.size(0), device=x.device)
        for i, prim in enumerate(self.primitives):
            phi = prim(x)  # (batch, input_dim)
            # Dot product with coefficient, then gate
            out += z[i] * (phi * self.coeffs[i]).sum(dim=-1)
        energy_cost = self.capsule_cost * z.sum()
        return out, energy_cost, z

    def prune_and_grow(self, threshold=0.1, max_capsules=None):
        """
        Hard prune capsules with gate < threshold, optionally add new random primitives.
        """
        with torch.no_grad():
            z = torch.sigmoid(self.gates)
            active = z > threshold
            self.primitives = [p for p, a in zip(self.primitives, active) if a]
            self.coeffs = nn.Parameter(self.coeffs[active])
            self.gates = nn.Parameter(self.gates[active])
            if max_capsules is not None and len(self.primitives) < max_capsules:
                n_new = max_capsules - len(self.primitives)
                for _ in range(n_new):
                    # Add new primitive: simple linear (can be customized)
                    self.primitives.append(lambda x: x)
                    self.coeffs = nn.Parameter(torch.cat([self.coeffs, torch.randn(1, self.coeffs.size(1))]))
                    self.gates = nn.Parameter(torch.cat([self.gates, torch.zeros(1)]))
```

D.2 models/physformer.py

```python
import torch
import torch.nn as nn

class PhysicsConstrainedTransformer(nn.Module):
    """
    Transformer that outputs hidden representations for the capsule layer.
    """
    def __init__(self, d_model, nhead, num_layers, input_dim):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)

    def forward(self, x):
        """
        x: (batch, seq_len, input_dim)
        Returns: hidden states (batch, seq_len, d_model)
        """
        x = self.embedding(x)
        x = self.transformer(x)
        return x
```

D.3 training/integrator.py

```python
import torch

def force_fn(q, p, history, transformer, capsule_layer):
    """
    Compute force at (q,p) using transformer and capsule layer.
    history: (batch, seq_len, 2) previous states (including current?).
    """
    batch_size = q.size(0)
    # Create new state tensor
    new_state = torch.stack([q, p], dim=-1).unsqueeze(1)  # (batch, 1, 2)
    # Shift window: drop oldest, append new state
    full_seq = torch.cat([history[:, 1:, :], new_state], dim=1)
    hidden = transformer(full_seq)  # (batch, seq_len, d_model)
    # Use last hidden state
    last_hidden = hidden[:, -1, :]  # (batch, d_model)
    force, _, _ = capsule_layer(last_hidden)
    return force

def velocity_verlet_step(q, p, history, transformer, capsule_layer, dt):
    """
    One full Velocity Verlet step with force recomputation.
    """
    dt_half = dt * 0.5
    f = force_fn(q, p, history, transformer, capsule_layer)
    p_half = p + dt_half * f
    q_new = q + dt * p_half
    f_new = force_fn(q_new, p_half, history, transformer, capsule_layer)
    p_new = p_half + dt_half * f_new
    return q_new, p_new, f_new
```

D.4 training/train.py

```python
import torch
import torch.optim as optim

def rollout(transformer, capsule_layer, x_init, dt, n_steps=20, target_states=None):
    """
    Perform multi-step rollout from initial history.
    x_init: (batch, seq_len, 2) initial states (including current as last).
    target_states: (batch, n_steps, 2) ground truth future states (optional).
    Returns: predicted states (batch, n_steps, 2), average task loss, total energy cost.
    """
    batch_size = x_init.size(0)
    states = [x_init[:, -1, :]]  # current state
    history = x_init.clone()
    total_task_loss = 0.0
    total_energy = 0.0

    for step in range(n_steps):
        q = states[-1][:, 0]
        p = states[-1][:, 1]

        q_new, p_new, f_new = velocity_verlet_step(
            q, p, history, transformer, capsule_layer, dt
        )
        states.append(torch.stack([q_new, p_new], dim=-1))

        # Update history (sliding window)
        new_state = states[-1].unsqueeze(1)
        history = torch.cat([history[:, 1:, :], new_state], dim=1)

        if target_states is not None:
            y = target_states[:, step, :]
            total_task_loss += torch.mean((q_new - y[:,0])**2 + (p_new - y[:,1])**2)

        # Energy cost from capsule gates (per step)
        _, energy_cost, _ = capsule_layer(f_new.unsqueeze(-1))
        total_energy += energy_cost

    # Stack predicted states (excluding initial)
    pred_states = torch.stack(states[1:], dim=1)  # (batch, n_steps, 2)
    return pred_states, total_task_loss / n_steps, total_energy

def energy_conservation_loss(q, p, mass=1.0, g=9.81, L=1.0):
    """
    Example energy conservation loss for a simple pendulum.
    Penalizes variance of total energy.
    """
    kinetic = 0.5 * mass * p**2
    potential = mass * g * L * (1 - torch.cos(q))
    total_energy = kinetic + potential
    return torch.var(total_energy)  # encourage constant energy

def train_step(transformer, capsule_layer, optimizer, x_init, target_states, dt, device):
    transformer.train()
    capsule_layer.train()
    x_init = x_init.to(device)
    target_states = target_states.to(device)

    # Multi-step rollout
    pred_states, task_loss, energy_cost = rollout(
        transformer, capsule_layer, x_init, dt, n_steps=20, target_states=target_states
    )

    # Physics losses (example: energy conservation on last state)
    q_last = pred_states[:, -1, 0]
    p_last = pred_states[:, -1, 1]
    energy_loss = energy_conservation_loss(q_last, p_last)

    # Total loss
    lambda_phys = 0.1
    lambda_energy = 0.01
    total_loss = task_loss + lambda_phys * energy_loss + lambda_energy * energy_cost

    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()

    # Anneal gate temperature
    capsule_layer.temp *= 0.999

    return total_loss.item()
```

D.5 symbolic/extractor.py

```python
import torch
import numpy as np
from pysr import PySRRegressor

class SymbolicExtractor:
    def __init__(self, capsule_layer, primitives=None):
        self.capsule_layer = capsule_layer
        if primitives is None:
            self.primitives = ["x", "x**2", "sin(x)", "cos(x)", "exp(x)", "1"]
        else:
            self.primitives = primitives

    def extract(self, X_train, y_train, threshold=0.5):
        """
        X_train: numpy array of input features (n_samples, n_features)
        y_train: numpy array of target values (n_samples,)
        """
        gates = torch.sigmoid(self.capsule_layer.gates).detach().cpu().numpy()
        active = gates > threshold
        if not np.any(active):
            return "No active capsules"

        # Build basis matrix from active primitives
        X_tensor = torch.tensor(X_train, dtype=torch.float32)
        basis = []
        for i, is_active in enumerate(active):
            if is_active:
                # Evaluate primitive on input
                # For simplicity, we assume primitives are callable functions
                # This requires storing the actual primitive functions
                # Here we use a placeholder; in practice, we need to map indices to functions.
                # For demonstration, we treat each primitive as a function of a single variable.
                # This is a simplification; real systems may need multi-variable primitives.
                # We'll just use the primitive output as a feature.
                # We need to have access to the actual primitive functions from capsule_layer.
                # This implementation assumes capsule_layer.primitives contains callables.
                prim_func = self.capsule_layer.primitives[i]
                phi = prim_func(X_tensor).numpy()
                basis.append(phi)
        if not basis:
            return "No active capsules"
        X_basis = np.hstack(basis)

        model = PySRRegressor(
            niterations=100,
            binary_operators=["+", "*", "-", "/"],
            unary_operators=["sin", "cos", "exp", "log"],
            model_selection="accuracy",
            loss="L2DistLoss()",
        )
        model.fit(X_basis, y_train)
        return model.sympy()
```

D.6 run_example.py (Example Usage)

```python
import torch
from models.capsule_layer import PhysicsPrimitiveCapsuleLayer
from models.physformer import PhysicsConstrainedTransformer
from training.train import train_step
from symbolic.extractor import SymbolicExtractor

# Hyperparameters
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
d_model = 64
nhead = 4
num_layers = 2
input_dim = 2  # (q, p)
output_dim = 1  # force
num_capsules = 6
capsule_cost = 1.0
dt = 0.01
lr = 0.001
epochs = 10

# Initialize models
transformer = PhysicsConstrainedTransformer(d_model, nhead, num_layers, input_dim).to(device)
capsule_layer = PhysicsPrimitiveCapsuleLayer(d_model, capsule_cost=capsule_cost).to(device)
optimizer = torch.optim.Adam(list(transformer.parameters()) + list(capsule_layer.parameters()), lr=lr)

# Dummy data (replace with actual data generation)
batch_size = 32
seq_len = 5
x_init = torch.randn(batch_size, seq_len, input_dim)  # initial history
target_states = torch.randn(batch_size, 20, input_dim)  # future states

# Training loop
for epoch in range(epochs):
    loss = train_step(transformer, capsule_layer, optimizer, x_init, target_states, dt, device)
    print(f"Epoch {epoch}, Loss: {loss:.4f}")
    if epoch % 5 == 0:
        capsule_layer.prune_and_grow(threshold=0.1, max_capsules=num_capsules)

# Symbolic extraction (using dummy data)
X_train = torch.randn(100, input_dim).numpy()
y_train = torch.randn(100).numpy()
extractor = SymbolicExtractor(capsule_layer)
symbolic_eq = extractor.extract(X_train, y_train)
print("Discovered equation:", symbolic_eq)
```

---

Appendix E: Configuration and Utility Scripts

This appendix provides configuration files and utility scripts to facilitate reproducibility and experimentation.

E.1 config.yaml

```yaml
model:
  d_model: 64
  nhead: 4
  num_layers: 2
  input_dim: 2  # (q, p)

capsule:
  input_dim: 64  # should match d_model
  capsule_cost: 1.0
  primitives: ["identity", "square", "sin", "cos", "gaussian", "constant"]

training:
  dt: 0.01
  n_steps: 20
  lambda_phys: 0.1
  lambda_energy: 0.01
  lr: 0.001
  epochs: 100
  batch_size: 32
  seq_len: 5

device: cuda
```

E.2 data/generate_pendulum.py

```python
import torch
import numpy as np

def generate_pendulum_data(n_episodes=100, seq_len=5, n_steps=20, dt=0.01, g=9.81, L=1.0, mass=1.0):
    """
    Generate synthetic pendulum trajectories.
    Returns:
        x_init: (n_episodes, seq_len, 2) initial history
        target_states: (n_episodes, n_steps, 2) future states
    """
    x_init = []
    target_states = []
    for _ in range(n_episodes):
        theta0 = np.random.uniform(-np.pi, np.pi)
        omega0 = np.random.uniform(-2.0, 2.0)
        # Simulate using high-precision integrator (e.g., Rust core)
        # For simplicity, we use a simple Euler or Verlet here.
        # In practice, use the Rust engine.
        states = [(theta0, omega0)]
        for i in range(seq_len + n_steps - 1):
            theta, omega = states[-1]
            alpha = - (g / L) * np.sin(theta)
            # Euler (for demonstration; use Verlet for real data)
            theta_new = theta + dt * omega
            omega_new = omega + dt * alpha
            states.append((theta_new, omega_new))
        # Extract initial history and targets
        init = states[:seq_len]
        targets = states[seq_len:seq_len+n_steps]
        x_init.append(init)
        target_states.append(targets)
    return torch.tensor(x_init, dtype=torch.float32), torch.tensor(target_states, dtype=torch.float32)
```

E.3 requirements.txt

```
torch>=2.0
numpy
pysr
pyyaml
matplotlib
```

E.4 Dockerfile (Optional)

```dockerfile
FROM pytorch/pytorch:latest
RUN pip install numpy pysr pyyaml matplotlib
COPY . /workspace
WORKDIR /workspace
CMD ["python", "run_experiment.py"]
```

---

This concludes the appendices. The provided code and mathematical background form the complete foundation for implementing and understanding the PC-SRGI framework.