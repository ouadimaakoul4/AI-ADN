### EAWMA: A Proposed Embodied Agentic World Model Architecture  
**A Framework for Next-Generation Autonomous Intelligence**

**Authors:** Ouadi Maakoul (with AI-assisted contributions acknowledged)  
**Date:** December 22, 2025  

---

### Abstract

This paper proposes the **Embodied Agentic World Model Architecture (EAWMA)**, a conceptual framework that integrates multimodal perception, predictive world modeling, hierarchical planning, episodic memory, and neuro-symbolic reasoning into a Bayesian inference-based system for autonomous intelligence. EAWMA aims to address limitations in current large language models (LLMs), such as hallucinations and lack of grounding, by incorporating grounded simulation and symbolic constraints. Drawing on recent advances like joint-embedding predictive architectures and Gaussian representations, we outline the mathematical foundations, architecture, and proposed research directions. Potential applications include robotic collaboration and ethical AI, though empirical validation remains future work. This is a speculative proposal emphasizing integration ideas for further exploration.

**Keywords:** Embodied AI, World Models, Neuro-Symbolic AI, Hierarchical Planning, Mental World Models, Gaussian Splatting, Joint-Embedding Predictive Architectures, Theory of Mind

---

### 1. Introduction

Large Language Models (LLMs) advance language processing but struggle with grounded causal reasoning and physical interactions [1, 2]. Recent surveys position world models as key for embodied AI, enabling prediction and decision-making in dynamic environments [3]. EAWMA proposes to mitigate LLM shortcomings—like hallucinations, brittle multi-step reasoning, and opacity—through integrated neural-symbolic simulation [4].

The proposed core components include:
- Multimodal perception
- World simulation
- Hierarchical planning
- Episodic memory
- Neuro-symbolic reasoning

EAWMA explores a mental world model for theory-of-mind (ToM) reasoning, potentially inferring user intentions [5]. This could enhance human-AI collaboration, though speculative.

Contributions:
1. Unified Bayesian formalism for perception-action cycles
2. Modular architecture proposal with mental world modeling
3. Suggested research directions with benchmarks

EAWMA seeks to extend frameworks like Google DeepMind's Gato/RT-2 (multimodal but lacking symbolic constraints) [6], PaLM-E (grounded LLMs without hierarchical simulation) [7], and Wayve's driving models (sim-to-real but opaque) [17] by emphasizing explainable integration—hypothetical without results.

---

### 2. Related Work

EAWMA draws from paradigms, proposing extensions:

| Approach              | Key Strengths                       | Limitations                          | Proposed Relation to EAWMA          |
|-----------------------|-------------------------------------|--------------------------------------|-------------------------------------|
| LLMs [1, 2]           | Language, recall                    | No grounding, hallucinations         | Optional interface                  |
| World Models [9]      | Simulation, prediction              | Limited actions/symbols              | Core dynamics (e.g., V-JEPA 2 [10]) |
| RL [11]               | Policy optimization                 | Sample-inefficient                   | Latent planning                     |
| Neuro-Symbolic AI [4] | Logic, explainability               | Weak perception/meta-cognition       | Constraint layer                    |
| Embodied AI [12]      | Grounded learning                   | Task-specific                        | General loop                        |
| Agentic Systems [13]  | Decomposition, tools                | No physical grounding                | Hierarchical goals                   |
| Embodied LLMs [7]     | Multimodal tasks                    | Unpredictable environments           | Adds robust planning                |
| Gato/RT-2 [6]         | Multimodal policies                 | Lacks symbolic constraints           | Proposes neuro-symbolic integration |
| PaLM-E [7]            | Grounded LLMs                       | No hierarchical simulation           | Adds world modeling                 |
| Wayve Driving [17]    | Sim-to-real generalization          | Opaque decision-making               | Aims for explainable simulation     |

Surveys formalize embodied world models in POMDPs with taxonomies [3]. Neuro-symbolic reviews highlight meta-cognition gaps EAWMA explores [4].

---

### 3. Mathematical Foundations

#### 3.1 Notation

Agent at time \( t \): observation \( o_t \in \mathcal{O} \), action \( a_t \in \mathcal{A} \), latent state \( z_t \), belief \( b_t = P(s_t \mid o_{1:t}, a_{1:t-1}) \).

#### 3.2 Perception

Encoder \( q_\phi(z_t \mid o_t) \) yields object-centric latents. ELBO with Chamfer Distance [16]:

\[
\mathcal{L}_{\text{perc}} = \mathbb{E}[\log p(o_t \mid z_t)] - \beta D_{\text{KL}}(q_\phi \parallel p(z_t)) + \lambda \cdot \text{CD}(S_1, S_2)
\]

#### 3.3 World Model

Action-conditioned dynamics (inspired by V-JEPA 2 [10]):

\[
h_{t+1} = f_\psi(h_t, z_t, a_t, \text{context}), \quad z_{t+1} \sim \mathcal{N}(\mu_\psi(h_{t+1}), \Sigma_\psi(h_{t+1}))
\]

#### 3.4 Planning

Hypertree MCTS with self-reflection [15].

#### 3.5 Memory

Product-quantized episodic retrieval.

#### 3.6 Neuro-Symbolic Constraints

Constrained optimization with Logical Credal Networks [4].

#### 3.7 Mental World Model

Extend belief to inferred states: \( b_t^m = P(s_t^j \mid o_{1:t}, a_{1:t-1}, z_t) \) for agent \( j \). Use inverse planning [5]:

\[
P(a_t^j \mid g^j) \propto P(g^j \mid z_{t:t+H}) \cdot P(z_{t:t+H} \mid z_t, a_{t:t+H}^j)
\]

Approximate via particle filtering (O(N agents * d)). Fuse loss: \( \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{perc}} + \beta \mathcal{L}_{\text{dyn}} + \gamma \mathcal{L}_{\text{ToM}} \).

**Example: "Assist User in Fetching Water Without Spilling"**

Robot observes user reach (o_t). Perception: z_t = {z_t^{glass}, z_t^{user}}. Mental model: b_t^m ≈ P(thirst | trajectory). World model: z_{t+1} ~ p_ψ(z_{t+1} | z_t, a_t = "grasp"), using Gaussians [16]. Planning: Hypertree explores paths. Constraints: distance > threshold. Action: Safe pour sequence.

---

### 4. Proposed Architecture

Figure 1 (below) illustrates the overall dataflow: Multimodal observations feed perception, which updates the belief state. Parallel world and mental models provide predictions and intent inference. The hypertree planner generates candidates, filtered by neuro-symbolic constraints. Episodic memory informs retrieval across components.

**Figure 1: EAWMA Architecture Dataflow**

(Description of diagram: Boxes for Perception, Belief State, World Model (parallel to Mental World Model), Hypertree Planner, Neuro-Symbolic Reasoner, Action Output. Arrows: Observations → Perception → Belief; Memory retrieval → Belief/Mental; Goal/Constraints → Planner; Rollouts → Reasoner → Action; Experience storage loop.)

Mental world model parallels simulation for ToM personalization [5].

Specifications:
- **Perception** — Slot attention + Gaussian Splatting [16]
- **World Simulation** — V-JEPA 2-inspired [10]
- **Planning** — Hypertree MCTS [15]
- **Memory** — Differentiable dictionary
- **Reasoner** — Fuzzy logic + differential privacy [4]
- **Training** — Staged pretraining on datasets like OpenDV-2K, joint fine-tuning with fused loss.

Feasibility: O(TBd²) challenging for real-time; sparse approximations help.

---

### 5. Implementation Details

#### 5.1 Pseudo-Code

```python
class MentalWorldModel:
    def predict_intent(self, obs, context):
        # Sample candidate goals from prior/context
        goals = self.sample_goals(context, k=10)  # e.g., thirst, fatigue
        # Likelihood via forward simulation
        likelihoods = [self.world_model.goal_likelihood(g, obs) for g in goals]
        return goals[argmax(likelihoods)]  # Approximate inverse planning

class EAWMAAgent:
    def __init__(self, config):
        self.perception = PerceptionModule(config)
        self.world_model = WorldModel(config)
        self.mental_model = MentalWorldModel(config)
        self.planner = HypertreePlanner(config)
        self.memory = EpisodicMemory(config)
        self.reasoner = NeuroSymbolicReasoner(config)

    def update_belief(self, observation):
        latent = self.perception.encode(observation)
        context = self.memory.retrieve(latent, k=3)
        intent = self.mental_model.predict_intent(observation, context)
        self.belief_state = self.world_model.fuse(latent, context, intent)
        return self.belief_state

    def plan_action(self, goal, constraints):
        candidates = self.planner.hypertree_mcts(root=self.belief_state, goal=goal, simulations=500)
        feasible = []
        for plan in candidates:
            trajectory = self.world_model.rollout(self.belief_state, plan.actions)
            if self.reasoner.evaluate(trajectory, constraints) > 0.9:
                feasible.append(plan)
        return max(feasible, key=lambda p: p.expected_reward) if feasible else fallback_safe_action()

    def execute_step(self, observation, goal, constraints):
        belief = self.update_belief(observation)
        plan = self.plan_action(goal, constraints)
        action = plan.next_action()
        self.memory.store({'belief': belief, 'action': action, 'intent': intent})
        return action
```

#### 5.2 Computational Complexity

| Component     | Training                  | Inference               | Memory   | Notes                          |
|---------------|---------------------------|-------------------------|----------|--------------------------------|
| Perception    | O(BDHW)                   | O(BCHW)                 | O(BC)    |                                |
| World Model   | O(TBd²)                   | O(Bd²)                  | O(d²)    | Approximations for real-time   |
| Planning      | O(NSd)                    | O(Sd)                   | O(S)     | Hypertree reduces branches     |
| Memory        | O(NlogN)                  | O(logN)                 | O(N)     |                                |
| Reasoner      | O(C·L)                    | O(C·L)                  | O(C·L)   |                                |
| Mental Model  | O(k * rollout)            | O(k * d)                | O(d)     | k=10 samples; particle filter  |

---

### 6. Proposed Research Directions

1. Simulation Validation → Test in MiniGrid/Crafter against DreamerV3 [9].
2. Embodiment → Deploy on UR5/Spot, evaluate sim-to-real [17].
3. Scalable Learning → Explore continual/multi-agent.
4. General Evaluation → Use CausalVQA for ToM [18].

---

### 7. Expected Impacts and Limitations

EAWMA could support robotics/healthcare, aligning with embodied initiatives [19].

**Limitations**:
- Computational costs: ToM explodes without approximations.
- Failure modes: Intent misattribution risks unsafe actions; brittleness in novel settings.
- Speculation: No validation; joint training untested.
- Scope: Integration-focused; needs data/ethics handling.

Future: Scale-down implementation on one task.

---

### 8. Conclusion

EAWMA proposes a grounded framework integrating recent advances. As conceptual, it requires validation.

---

### 9. References

[1] Brown et al., NeurIPS 2020.  
[2] OpenAI, arXiv:2303.08774.  
[3] Li et al., arXiv:2510.16732, 2025.  
[4] Colelough & Regli, arXiv:2501.05435, 2025.  
[5] Shi et al., arXiv:2408.12574, 2025.  
[6] Reed et al. (Gato), arXiv:2205.06175; Driess et al. (RT-2), arXiv:2307.15818.  
[7] Driess et al., arXiv:2303.03378.  
[9] Hafner et al., ICLR 2020.  
[10] Assran et al., arXiv:2506.09985, 2025.  
[11] Sutton & Barto, MIT Press 2018.  
[12] Gupta et al., CVPR 2017.  
[13] Xi et al., arXiv:2309.07864.  
[15] Gui et al., arXiv:2505.02322, 2025.  
[16] Lu et al., arXiv:2506.19842 (ManiGaussian++), 2025; earlier ManiGaussian ECCV 2024.  
[17] Wayve.ai reports, 2025.  
[18] CausalVQA benchmarks.  
[19] Singer & Zvenyhorodskyi, Carnegie Endowment, 2025.

### Figure 1: EAWMA Architecture Dataflow

Detailed textual representation (ASCII art) of the EAWMA architecture, illustrating the perception-action cycle with parallel world and mental modeling, memory integration, and constrained planning:

```
                          +-------------------------+
                          | Multimodal Observations |
                          +-------------------------+
                                       |
                                       v
                          +-------------------------+
                          |     Perception Module   |
                          | (Gaussian Splatting,    |
                          |  Slot Attention)        |
                          +-------------------------+
                                       |
                                       v
                          +-------------------------+     +---------------------+
                          |       Belief State      |<----+   Episodic Memory   |
                          |     (Bayesian Fuse)     |     | (Retrieval & Store) |
                          +-------------------------+     +---------------------+
                                       |                           ^
                                       |                           |
                  +--------------------+--------------------+      |
                  |                                       |      |
                  v                                       v      |
        +-----------------+                     +---------------------+
        |  World Model    |                     |  Mental World Model |
        | (V-JEPA 2-style |                     | (ToM Inverse        |
        |  Dynamics)      |                     |  Planning, k=10)    |
        +-----------------+                     +---------------------+
                  |                                       |
                  +-------------------+--------------------+
                                      |
                                      v
                          +-------------------------+
                          |    Hypertree Planner    |
                          | (MCTS with Self-Reflection)|
                          +-------------------------+
                                       ^
                                       |
                               +-------+-----------------+
                               |                         |
                       Goal / Constraints        (Candidate Rollouts)
                                       |
                                       v
                          +-------------------------+
                          | Neuro-Symbolic Reasoner |
                          | (Logical Credal Nets,   |
                          |  Fuzzy Constraints)     |
                          +-------------------------+
                                       |
                                       v
                          +-------------------------+
                          |       Action Output     |
                          +-------------------------+
                                       |
                                       v
                          +-------------------------+
                          |    Experience Storage   |
                          +-------------------------+
                                       |
                                       +-------------------> (Loop back to Memory)
```

**Description:**
- **Central Loop:** Observations flow through perception to update the belief state, informed by episodic memory retrieval.
- **Parallel Prediction:** Belief feeds both the World Model (physical dynamics) and Mental World Model (intent/ToM inference).
- **Planning & Constraints:** Hypertree planner generates candidates using predictions; neuro-symbolic reasoner filters for safety/logic.
- **Feedback:** Actions produce experiences stored in memory for lifelong adaptation.

This diagram captures the modular, closed-loop design proposed in Section 4. It highlights the Bayesian fusion at the belief state and the role of memory in personalization.

