Design and Architecture of a Modular Reconfigurable Amphibious Robot (MRAR)



Abstract

This thesis proposes the design and system architecture of a novel, modular, non‑humanoid robotic platform, directly inspired by the reconfigurable robots depicted in the film Interstellar. The proposed robot—named the Multi‑Environment Reconfigurable Robot (MRAR)—is engineered for robust operation in extreme and unstructured environments, including amphibious terrains, disaster zones, and extraterrestrial surfaces. The architecture emphasizes geometric simplicity, structural robustness, inherent redundancy, and multi‑modal locomotion through modular reconfiguration. This work defines the complete mechanical architecture, electronic system design, hierarchical control framework, and modular software stack required to implement a functional prototype. Foundational mathematical formulations for articulated rigid‑body dynamics, stability control on compliant and fluid media, and reconfiguration planning are introduced to guide implementation. The thesis culminates in a proposed specification for a proof‑of‑concept prototype and outlines a detailed roadmap for future work, including dynamic simulation, iterative prototyping, and experimental validation.


Table of Contents

1. Introduction
2. System Overview
3. Mechanical Design and Physical Modeling
4. Electronics and Embedded Systems
5. Control System Design
6. Software Architecture
7. Simulation and Sim2Real Pipeline
8. Prototype Specification and Implementation Roadmap
9. Expected Applications
10. Conclusion and Future Work
    Bibliography
    Appendices

Chapter 1: Introduction

1.1 Motivation

The field of robotics has long been captivated by humanoid forms, aiming to replicate human dexterity and navigation. However, for deployment in extreme environments—characterized by unpredictability, hazardous terrain, and limited communication—this anthropomorphic approach introduces significant mechanical complexity, high power consumption, and vulnerability to failure. Inspired by the fictional robots TARS and CASE from the film Interstellar, this thesis explores an alternative paradigm: the modular rigid‑segment robot.

These cinematic robots demonstrate key advantages that are highly desirable for real‑world extreme‑environment robotics:

· Mechanical Robustness: A form factor devoid of exposed limbs and delicate manipulators lends itself to a highly durable, impact‑resistant structure.
· Redundancy and Fault Tolerance: The loss of a single module or joint does not necessarily equate to mission failure, as the remaining system can often reconfigure to compensate.
· Geometric Reconfigurability: The ability to alter its own shape allows the robot to adapt its locomotion strategy (e.g., rolling, walking, stabilizing) and interact with its environment in ways a fixed‑form robot cannot.
· Simplified Control Strategies: While the overall system is complex, the control of individual rigid links and rotary joints can be more mathematically tractable than the high‑degree‑of‑freedom control required for a humanoid.
· Environmental Adaptability: A rectangular, modular form can be inherently more stable in high winds, more easily sealed against water ingress, and more efficiently packed for transport.

This thesis argues that structural intelligence, embodied through modularity and reconfigurability, is a more effective design principle than anthropomorphic mimicry for a class of missions demanding extreme durability and adaptability.

1.2 Research Objectives

The primary objectives of this thesis are to:

1. Conceptualize and Design a modular robotic architecture composed of rigid, articulated segments, drawing direct inspiration from non‑humanoid cinematic concepts.
2. Define the Mechanical and Electronic Specifications for each module type, including structural materials, joint actuation, power distribution, and computational hardware, with a focus on environmental sealing (amphibious capability).
3. Develop a Foundational Locomotion and Stabilization Model based on articulated rigid‑body dynamics, including mathematical formulations for stability in both terrestrial and aquatic environments.
4. Propose a Hierarchical Software Architecture that supports reconfiguration, autonomous navigation, and teleoperation, leveraging existing middleware (e.g., ROS 2).
5. Provide a Concrete Implementation Roadmap for a functional prototype, outlining the necessary steps for simulation, fabrication, and experimental validation.

1.3 Thesis Outline

This thesis is structured as follows: Chapter 2 provides a system overview of the MRAR concept. Chapter 3 details the mechanical design, including structure, joints, kinematics, and buoyancy. Chapter 4 defines the electronics and sensor architecture. Chapter 5 develops the control system framework and mathematical models. Chapter 6 describes the layered software architecture. Chapter 7 introduces the simulation pipeline essential for validating control algorithms before hardware deployment. Chapter 8 presents a conceptual prototype specification and an implementation roadmap. Chapter 9 explores potential applications, and Chapter 10 concludes with a discussion of future work.

---

Chapter 2: System Overview

2.1 Robot Concept: The MRAR Platform

The Multi‑Environment Reconfigurable Robot (MRAR) is conceived as a series of identical or functionally distinct rectangular modules connected by high‑torque, single‑degree‑of‑freedom (DOF) rotational joints. This chained serial configuration allows for a wide range of configurations, enabling the robot to transition between distinct operational modes. Unlike humanoid designs, this platform treats “limbs” and “torso” as interchangeable structural members.

2.2 Module‑Based Architecture

The MRAR is composed of a minimum of five primary modules to achieve basic functionality and demonstrate reconfigurability. Each module is structurally self‑contained but connected via a standardized electromechanical interface.

1. Core Module (M0): The central hub containing the main onboard computer (for high‑level processing), the primary power distribution unit, the main Inertial Measurement Unit (IMU), and the communication radios (e.g., Wi‑Fi, LTE, or custom RF link). This module does not articulate relative to itself but serves as the root for the kinematic chain.
2. Articulated Segments (M1, M2, M3, M4): Four identical actuated modules. Each contains a high‑torque rotary actuator at one end, a local microcontroller for low‑level joint control, and structural housing. This modularity simplifies manufacturing, reduces spare part complexity, and allows for hot‑swapping in a laboratory setting.
3. Sensor Head Module (M5 – Optional Add‑on): A dedicated module that attaches to the end of the kinematic chain. It houses the primary environmental perception sensors: an RGB‑D camera, a 2D LiDAR, and auxiliary sensors. This module could have its own 1‑2 DOF actuated neck to decouple sensor pointing from body configuration.
4. Specialized Payload Modules (Future): The architecture is designed to accommodate future modules, such as a manipulator arm module, a scientific instrument module (e.g., spectrometer), or a high‑density battery module.

2.3 Operational Modes

The MRAR supports several distinct configurations that enable multi‑modal locomotion and adaptability:

· Monolith Mode (Vertical Stabilization): The robot elongates vertically, providing a high vantage point for sensing and communication. Stability is maintained by active joint control, akin to an inverted pendulum.
· Tripedal/Quadrupedal Gait: By articulating its modules, the robot can lower its center of mass and create multiple ground contact points, forming a stable, low‑profile platform for rough terrain traversal. The robot can use three or four ground contact points depending on the terrain.
· Rolling Configuration (Tumbling): The robot can curl into a loop or “O” shape and use its actuators to initiate a rolling motion, offering a highly efficient mode of locomotion on relatively flat or gently sloped surfaces.
· Amphibious Mode (Flotation and Paddling): By adjusting its geometry, the robot can maximize its hydrodynamic profile or create air pockets, enabling it to float and maneuver on the water’s surface. The outer segments can act as paddles for propulsion.

---

Chapter 3: Mechanical Design and Physical Modeling

3.1 Structural Design and Materials

The structural housing for each module must balance strength, weight, and environmental protection.

Material Candidates:

· Aluminum Alloy (e.g., 6061‑T6): Excellent strength‑to‑weight ratio, machinability, and cost‑effectiveness. Suitable for the primary load‑bearing chassis.
· Carbon Fiber Composite: For weight‑critical applications (e.g., aerospace). Offers superior stiffness and lower mass but is more complex to manufacture and integrate with sealed enclosures.
· Marine‑Grade Stainless Steel (e.g., 316L): For critical fasteners and components exposed to high corrosive stress, though heavier.

Design Constraints:

· Waterproof Enclosure: Each module must be an IP68‑rated sealed unit. This requires precision‑machined housings with O‑ring or gasket seals at all interfaces, including the joint output shaft.
· Corrosion Resistance: All external materials and coatings must be selected for operation in saltwater environments. Anodized aluminum, stainless steel fasteners, and specialized marine paints are essential.
· Modular Interface: The mechanical connection between modules must be rigid, repeatable, and allow for quick disassembly. A bolted flange interface with precision locating pins is proposed. This interface also houses the waterproof electrical connector.

3.2 Joint Design and Actuation

Each degree of freedom is realized by a single‑axis rotary actuator located within one of the articulated segments.

Kinematic Structure: For a five‑module robot (Core + 4 identical segments), the total degrees of freedom are

\text{DOF} = n - 1 = 4,

where n is the number of modules. The joint axes are arranged parallel to each other and perpendicular to the long axis of the modules, enabling planar articulation.

Actuator Requirements:

· High Torque Density: To lift the weight of subsequent modules and any payload. A target peak torque of 120–150 Nm is estimated.
· Integrated Sensing: The actuator unit must incorporate a high‑resolution absolute encoder (for position) and a torque/current sensor (for force control).
· Sealed Housing: The actuator itself must be a sealed unit, or its output shaft must pass through a high‑quality rotary seal in the module’s bulkhead.
· Backdrivability / Low Impedance: For safe interaction and advanced control strategies, a low gear ratio (e.g., using a frameless torque motor with a low‑backlash harmonic drive) is preferable to a highly geared DC motor.

3.3 The Concentric Joint Topology

The “seamless” look of the MRAR is achieved through a Nested Coaxial Actuator assembly. In this design, the motor is housed within Module A, while the output spline of the Harmonic Drive is bolted to the structural bulkhead of Module B. This arrangement hides the joint mechanism entirely within the module envelopes, preserving the clean rectangular aesthetic while allowing full 360° rotation.

Cable Management: By utilizing hollow‑shaft reducers, the power bus and CAN‑bus wiring pass through the center of the rotation axis. This eliminates external cable loops that would otherwise snag on debris or degrade during amphibious submersions.

Thermal Coupling: To manage heat in sealed IP68 modules, the motor stators are thermally bridged to the 6061‑T6 aluminum chassis using high‑conductivity thermal pads (thermal conductivity k \approx 5.0\,\text{W/m·K}). This conducts waste heat to the outer shell, where it can be dissipated to the surrounding air or water.

3.4 Kinematic Modeling

The robot is modeled as a kinematic chain of rigid bodies. The configuration is described by the joint angles \mathbf{q} = [q_1, q_2, q_3, q_4]^T.

Forward Kinematics: The pose (position and orientation) of any module can be computed using standard homogeneous transformation matrices based on joint angles. For module i, the transformation from the base (core) frame is

\mathbf{T}_i(\mathbf{q}) = \mathbf{T}_1(q_1) \mathbf{T}_2(q_2) \cdots \mathbf{T}_i(q_i).

Differential Kinematics: The Jacobian matrix \mathbf{J}(\mathbf{q}) relates joint velocities to the end‑effector (sensor head) twist \mathbf{v} (linear and angular velocity):

\mathbf{v} = \mathbf{J}(\mathbf{q}) \dot{\mathbf{q}}.

3.5 Buoyancy and Hydrostatic Stability

For amphibious operation, the robot must manage buoyancy and maintain stability.

Buoyancy Calculation: The net buoyant force on a submerged module is given by Archimedes’ principle:

F_b = \rho_{\text{fluid}} \, g \, V_{\text{displaced}},

where \rho_{\text{fluid}} is the density of the fluid (e.g., 1000\,\text{kg/m}^3 for freshwater, \approx 1025\,\text{kg/m}^3 for seawater), g is gravity, and V_{\text{displaced}} is the volume of the module. To achieve neutral or positive buoyancy, the average density of the module (\rho_{\text{module}} = m_{\text{module}} / V_{\text{module}}) must be less than or equal to \rho_{\text{fluid}}. This may necessitate the use of syntactic foam or sealed air cavities within the modules.

Static Stability: When floating, the robot must resist capsizing. Static stability is achieved if the center of mass (COM) is located below the center of buoyancy (COB). For a reconfigurable robot, the COM changes with configuration. The control system must therefore ensure that for a given configuration,

z_{\text{COM}} < z_{\text{COB}},

where z denotes the vertical coordinate. If this condition is violated, active joint movements must be used to maintain orientation.

3.6 Geometric Constraints and CAD Specifications

To prevent mechanical jamming during multi‑module reconfiguration, the corner radius r of each rectangular module must satisfy

r \geq \frac{w}{2} \left( \sqrt{2} - 1 \right),

where w is the width of the module. This ensures that when two modules rotate 45^\circ relative to each other, the diagonal distance does not exceed the allotted clearance.

The conceptual dimensions for each module are:

· Individual Module: 1400 \times 180 \times 120 mm (maintaining a 1:3:9 ratio approximately).
· Total Span (Flat): 1400 \times 900 mm.
· Wall Thickness: 3.5 mm, optimized for stiffness vs. buoyancy.

3.7 Bill of Materials

Table 3.1 presents the estimated bill of materials for a five‑module functional prototype.

Table 3.1: Bill of Materials for MRAR Prototype

Item Description Qty Est. Cost (USD)
T‑Motor AK80‑64 Frameless BLDC with integrated 64:1 controller 4 $2,400
Harmonic Drive SHF‑25 Hollow‑shaft gear (100:1) for zero backlash 4 $3,200
Cross‑Roller Bearings High‑moment capacity support for joint axles 8 $600
Custom 7075 Axles CNC‑machined hollow structural connectors 4 $800
Aluminum 6061‑T6 Shells 3mm CNC‑folded and welded module casings 5 $2,500
Internal Rib Skeleton Water‑jet cut 5mm aluminum internal braces 15 $450
IP68 Rotary Seals Nitrile rubber gaskets for joint interfaces 8 $120
Polycarbonate Windows IR‑transparent for LiDAR/Depth sensors 5 $150
NVIDIA Jetson AGX Orin Primary AI/Vision computation (Central Module) 1 $1,900
Ouster OS0‑32 LiDAR Ultra‑wide FOV for 3D mapping/localization 1 $3,500
OAK‑D Pro Camera Depth sensing and spatial AI (Stereo Vision) 2 $600
BNO055 IMU 9‑axis absolute orientation (one per segment) 5 $150
Teensy 4.1 Real‑time motor command bridge (CAN‑Bus) 2 $60
12S LiPo Battery Pack 44.4V, 10,000mAh (High Discharge) 2 $500
BMS (Smart) Bluetooth‑enabled 60A Battery Management System 1 $120
Solid‑State Relay For emergency remote power kill‑switch 1 $80
IP68 Cable Glands For waterproof internal wire routing 12 $40
Total   $17,170

Mass Estimate: 42–48 kg.

---

Chapter 4: Electronics and Embedded Systems

4.1 Power System

· Power Source: A high‑energy‑density Lithium‑ion battery pack (e.g., 18650 or pouch cells) will be housed in the Core Module and potentially distributed in specialized battery modules. A nominal voltage of 48 V is chosen to minimize current for high‑power actuators, reducing I²R losses in cabling.
· Power Distribution: A centralized Power Distribution Unit (PDU) in the Core Module will manage power from the main battery. It will provide regulated 48 V, 24 V (for sensors/compute), and 5 V (for logic) buses. These buses are routed through the modular connectors to all other modules. The PDU includes solid‑state switches for overcurrent protection and individual module power cycling.

4.2 Sensor Suite

Proprioception (Internal State):

· High‑Precision IMU (e.g., BNO055) located in each module for distributed attitude estimation.
· Absolute joint encoders in each actuator for precise position feedback.
· Motor current sensors for torque estimation.

Exteroception (Environment):

· RGB‑D Camera (OAK‑D Pro): Mounted in the Sensor Head for visual odometry, object detection, and 3D mapping.
· 2D/3D LiDAR (Ouster OS0‑32): For long‑range, high‑precision mapping and localization in dusty or low‑light conditions, essential for extraterrestrial or disaster scenarios.
· Depth/Pressure Sensor: For underwater operations, to measure depth and rate of descent/ascent.
· Temperature/Humidity Sensors: Internal to modules for health monitoring.

Table 4.1: Sensor Suite Specifications

Sensor Model Purpose Interface
LiDAR Ouster OS0‑32 3D mapping, localization Ethernet
Depth Camera OAK‑D Pro Visual odometry, obstacle detection USB 3.0
IMU BNO055 Orientation per module I²C
Pressure Sensor MS5837 Depth measurement (underwater) I²C

4.3 Computation Architecture

A two‑level hierarchical computing architecture balances real‑time control and high‑level processing.

· Low‑Level Control (Distributed): Each actuated module (M1–M4) will contain a dedicated microcontroller (Teensy 4.1). This MCU runs a real‑time firmware loop (at 1–10 kHz) that:
  · Reads the joint encoder.
  · Implements a low‑level PID current/velocity loop.
  · Communicates with the central computer via a robust fieldbus (CAN bus) over the module interconnect.
· High‑Level Control (Centralized): The Core Module houses an embedded computer (NVIDIA Jetson AGX Orin). This computer runs a full Linux OS and ROS 2. It is responsible for:
  · Sensor data processing (vision, LiDAR).
  · State estimation and localization (EKF).
  · Motion planning and reconfiguration.
  · Running the high‑level control laws (MPC).
  · User interaction and communication.

---

Chapter 5: Control System Design

5.1 Rigid‑Body Dynamics

The equations of motion for the articulated robot are derived from the Euler‑Lagrange formalism and are expressed in the standard form for robotic manipulators:

\mathbf{M}(\mathbf{q})\ddot{\mathbf{q}} + \mathbf{C}(\mathbf{q},\dot{\mathbf{q}})\dot{\mathbf{q}} + \mathbf{G}(\mathbf{q}) + \boldsymbol{\tau}_{\text{ext}} = \boldsymbol{\tau},

where:

· \mathbf{q}, \dot{\mathbf{q}}, \ddot{\mathbf{q}} are vectors of joint position, velocity, and acceleration.
· \mathbf{M}(\mathbf{q}) is the joint‑space inertia matrix.
· \mathbf{C}(\mathbf{q},\dot{\mathbf{q}}) is the matrix representing Coriolis and centrifugal forces.
· \mathbf{G}(\mathbf{q}) is the gravity loading vector.
· \boldsymbol{\tau} is the vector of joint torques.
· \boldsymbol{\tau}_{\text{ext}} represents external torques (e.g., from ground contact, fluid drag).

5.2 Stabilization and Configuration Control

For a dynamically balancing robot (e.g., in Monolith Mode), the control objective is to maintain a desired pose despite disturbances.

· Linearized Control: For small deviations from a nominal standing configuration, the dynamics can be linearized. A simple PD controller with gravity compensation can then be used:
  \boldsymbol{\tau} = \mathbf{M}(\mathbf{q}) \left( \mathbf{K}_p (\mathbf{q}_{\text{des}} - \mathbf{q}) + \mathbf{K}_d (\dot{\mathbf{q}}_{\text{des}} - \dot{\mathbf{q}}) \right) + \mathbf{G}(\mathbf{q}).
· Advanced Control for Reconfiguration: For transitions between configurations or locomotion, more sophisticated methods are required. Model Predictive Control (MPC) is a promising approach. An MPC controller solves an online optimization problem at each timestep to find a sequence of future joint torques that minimizes a cost function (e.g., tracking error, energy use) over a prediction horizon, while respecting constraints (joint limits, torque limits, stability constraints like Zero Moment Point).

5.3 Locomotion and Gait Planning

Locomotion emerges from the coordinated motion of the joints.

· Configuration‑Space Planning: A high‑level planner determines a sequence of key configurations (e.g., from standing to a quadruped‑like stance). A local planner then generates smooth joint trajectories to move between these configurations.
· Modular Gait Generation: For rolling locomotion, a cyclic pattern of joint angles is generated, analogous to a traveling wave. For a “walking” gait on uneven terrain, the robot would use its joints to sequentially lift and place modules to gain traction, potentially using foothold planning based on LiDAR data.
· Reinforcement Learning: As an alternative to model‑based gait generation, reinforcement learning (RL) can be employed within a simulation environment to discover robust and efficient gaits. The policy observes joint states, IMU readings, and terrain heightmaps, and outputs target joint torques.

5.4 Reconfiguration Transition Logic

To transition from Monolith Mode to Rolling Mode, the controller must manage the system’s potential energy. The trajectory \mathbf{q}(t) is calculated to ensure the Projection of the Center of Mass (PCOM) stays within the Support Polygon (SP) during quasi‑static transitions:

\text{PCOM}(\mathbf{q}(t)) \in \text{SP}(\mathbf{q}(t)) \quad \forall t.

For dynamic transitions (e.g., during a tumble), the controller must additionally manage angular momentum to ensure that the robot does not tip uncontrollably. The angular momentum \mathbf{H}_G about the center of mass must satisfy

\mathbf{H}_G = \sum_i \left( \mathbf{r}_{i/G} \times m_i \dot{\mathbf{r}}_{i/G} + \mathbf{I}_i \boldsymbol{\omega}_i \right),

and the rate of change of angular momentum is balanced by the net moment from external forces.

5.5 Gait Implementation: The Tumbling Motion

The signature rolling motion of the MRAR is achieved by generating a traveling wave of joint angles. A simple sinusoidal trajectory with phase offsets between adjacent joints can produce a rolling loop:

q_i(t) = A \sin\left(2\pi f t - (i-1)\phi\right), \quad i = 1,\ldots,4,

where A is the amplitude (e.g., \pi/2), f is the frequency, and \phi is the phase shift (e.g., \pi/2). This cyclic motion curls the robot into an approximate circle and shifts the contact point with the ground, causing the robot to roll.

However, pure sinusoidal motion may not produce forward translation; an asymmetric timing (slow curl, fast kick) is often required. The controller must maximize the angular impulse at the moment the COM passes over the contact edge to generate forward momentum.

---

Chapter 6: Software Architecture

6.1 Middleware and Framework (ROS 2)

The software system will be built on ROS 2 (Robot Operating System 2). ROS 2 provides a robust, modular framework with:

· Inter‑Process Communication: Via a publish‑subscribe model (topics) and a client‑server model (services/actions).
· Hardware Abstraction: Drivers for sensors and actuators can be wrapped as ROS 2 nodes.
· Standard Messages: Provides standard message types for transforms (tf2), sensor data, and control commands.
· Simulation Integration: Seamless integration with Gazebo or Ignition simulators.

6.2 Node Architecture and Communication

The architecture is divided into logical layers: Perception, Estimation, Planning, and Actuation.

A. Perception & Localization Nodes

· /ouster_driver: Interfaces with the LiDAR to publish point cloud data on the /points topic.
· /depth_camera_node: Publishes RGB‑D data for close‑range obstacle avoidance.
· /imu_filter_madgwick: Fuses raw data from the five BNO055 IMUs to provide a stable orientation.
· /robot_localization_ekf: An Extended Kalman Filter that fuses IMU, LiDAR odometry, and joint encoders into a single /odom transform.

B. Planning & Logic Nodes

· /bt_navigator: Uses Behavior Trees to switch between “Walking,” “Tumbling,” and “Amphibious” modes.
· /nav2_planner: Calculates the global path based on the 3D voxel map.
· /kinematics_engine: A custom node that calculates Inverse Kinematics (IK) for the specific module configuration currently active.

C. Actuation & Hardware Interface

· /ros2_control_node: The core controller manager. It hosts the /joint_trajectory_controller.
· /can_bus_manager: A specialized node (running on micro‑ROS) that translates ROS 2 commands into CAN‑bus packets for the BLDC motors.

Table 6.1: ROS2 Topic Map

Topic Name Message Type Purpose
/cmd_vel geometry_msgs/Twist High‑level movement commands (X, Y, Yaw).
/joint_states sensor_msgs/JointState Real‑time position/velocity of the 4 joints.
/scan sensor_msgs/LaserScan 2D slice of LiDAR data for fast avoidance.
/mode_switch std_msgs/String Triggers reconfiguration.

6.3 Lifecycle Management and Hardware Abstraction

Because this robot is modular, each segment should be treated as a Lifecycle Node. This allows the central computer to:

· Configure a module when it is electronically detected.
· Activate the motor controllers only when the structural lock is confirmed.
· Deactivate segments to save power during “Monolith Mode” (stationary sensing).

A custom ros2_control hardware component plugin will be developed for the BLDC drivers, minimizing latency between the planning layer and the physical motor movement.

6.4 Distributed Communication Flow

The system’s “Nervous System” relies on a synchronized heartbeat between the Jetson AGX and the distributed Teensy MCUs. The Jetson publishes desired joint positions or torques at a fixed rate (e.g., 100 Hz), and each Teensy responds with its current joint state. A CAN bus with a priority‑based arbitration scheme ensures that high‑priority commands (e.g., emergency stop) are delivered with minimal latency. The heartbeat mechanism allows the Jetson to detect a failed module and trigger a reconfiguration or safe shutdown.

---

Chapter 7: Simulation and Sim2Real Pipeline

Before physical fabrication, the MRAR must undergo rigorous validation in a simulated environment. This chapter outlines the simulation strategy to de‑risk the mechanical design and validate the control architectures proposed in Chapter 5.

7.1 Simulation Environment Selection

Two primary environments are considered:

· Gazebo (Ignition Fortress): The standard for ROS 2 integration. It offers robust physics engines (ODE, Bullet, DART) and sensor simulation (LiDAR, IMU, cameras).
· NVIDIA Isaac Sim: Leverages RTX hardware for photorealistic rendering and physics. Particularly useful for training perception algorithms and testing the robot in digitally‑twinned extreme environments (e.g., lunar surfaces, flooded urban canyons).

Recommendation: A hybrid approach is proposed. Gazebo will be used for rapid control prototyping and gait development due to its low computational overhead and tight ROS 2 integration. Isaac Sim will be used for final validation and perception pipeline training due to its superior domain randomization capabilities.

7.2 URDF Modeling and Dynamic Parameter Estimation

A Unified Robot Description Format (URDF) file will be created based on the CAD dimensions from Chapter 3. Key parameters to be defined in the URDF:

· Inertial Properties: Mass, center of mass (COM), and inertia tensors for each module, derived from the CAD model’s material properties (Carbon Fiber shell, Aluminum skeleton, LiPo battery mass distribution).
· Joint Dynamics: Friction coefficients, damping, and effort limits for the Harmonic Drive actuators.
· Contact Dynamics: Coulomb friction coefficients between the module surfaces and various terrains (concrete, sand, mud, ice).

The dynamic equation (5.1) is the core computational model within the simulator. The simulator will solve this equation at each timestep, allowing us to observe the robot’s behavior under the proposed control laws.

7.3 Gait Discovery and Validation

The simulation will serve as a sandbox for gait development. Two approaches will be tested:

1. Model‑Based Trajectory Optimization: Using libraries like trajopt or OMPL to find collision‑free paths for the 4‑DOF system to achieve reconfiguration (e.g., folding from “Monolith Mode” to “Rolling Configuration”).
2. Reinforcement Learning (RL) for Locomotion: Utilizing the simulation environment to train policies for robust locomotion. The observation space will include joint angles, IMU readings, and terrain heightmaps (from simulated LiDAR). The action space will be target joint torques or positions. The reward function will be shaped to encourage:
   · Forward velocity (r_{\text{vel}} = v_x / v_{\text{max}})
   · Energy efficiency (r_{\text{energy}} = - \sum |\tau \cdot \dot{q}|)
   · Stability (r_{\text{stable}} = 1 - |\phi_{\text{pitch}}| / \phi_{\text{max}})

7.4 Sim2Real Gap Analysis

A critical component of this thesis will be quantifying the “Sim2Real” gap. Upon building the prototype (Chapter 8), the following comparison will be made:

· Parameter Discrepancy: Compare the simulated joint friction/damping with the real actuator data.
· Latency Analysis: Measure the end‑to‑end latency in the real ROS 2 pipeline (from sensor read to motor command) and inject similar latency into the simulation to understand its effect on stability.
· Domain Randomization: In the final RL training phase, physical parameters (mass, friction, motor strength) will be randomized in simulation. A policy that performs well across a wide range of randomized parameters is more likely to transfer successfully to the real robot.

This simulation‑first approach ensures that by the time the expensive 7075 aluminum axles are machined and the Harmonic Drives are purchased, there is high confidence that the MRAR will actually stand up and walk.

---

Chapter 8: Prototype Specification and Implementation Roadmap

8.1 Conceptual Prototype Parameters

Parameter Value / Specification Notes
Overall Height 1.4 m (upright) Variable based on configuration.
Total Mass 45 kg Target mass, depends on actuator selection.
Number of Modules 5 (Core + 4 Identical Articulated) Minimum for demonstrating reconfigurability.
Degrees of Freedom 4 All joints are parallel rotary axes.
Joint Actuator 120–150 Nm peak, Integrated Harmonic Drive Custom or off‑the‑shelf.
Battery Capacity 1.5 kWh @ 48 V Estimated 2–4 hours of mixed‑mode operation.
Main Computer NVIDIA Jetson AGX Orin For high‑performance perception and planning.
Microcontrollers Teensy 4.1 per joint For real‑time low‑level control.
Key Sensors LiDAR, RGB‑D Camera, IMU, Joint Encoders As detailed in Section 4.2.

8.2 URDF Description for Simulation

To enable simulation, the robot is described using the Unified Robot Description Format (URDF). Below is the core structure for the five‑module MRAR. The full URDF will be included in Appendix A.

```xml
<?xml version="1.0"?>
<robot name="mrar_prototype" xmlns:xacro="http://ros.org/wiki/xacro">

  <material name="brushed_aluminum">
    <color rgba="0.6 0.6 0.63 1.0"/>
  </material>

  <xacro:macro name="mrar_module" params="name">
    <link name="${name}">
      <visual>
        <geometry>
          <box size="0.12 0.18 1.4"/>
        </geometry>
        <material name="brushed_aluminum"/>
      </visual>
      <collision>
        <geometry>
          <box size="0.12 0.18 1.4"/>
        </geometry>
      </collision>
      <inertial>
        <mass value="9.0"/>
        <inertia ixx="1.49" ixy="0" ixz="0" iyy="1.48" iyz="0" izz="0.03"/>
      </inertial>
    </link>
  </xacro:macro>

  <xacro:mrar_module name="base_link"/>

  <joint name="joint_1" type="revolute">
    <parent link="base_link"/>
    <child link="module_1"/>
    <origin xyz="0 0.18 0" rpy="0 0 0"/>
    <axis xyz="1 0 0"/>
    <limit lower="-3.1415" upper="3.1415" effort="150" velocity="1.5"/>
    <dynamics damping="0.5" friction="1.0"/>
  </joint>
  <xacro:mrar_module name="module_1"/>

  <joint name="joint_2" type="revolute">
    <parent link="module_1"/>
    <child link="module_2"/>
    <origin xyz="0 0.18 0" rpy="0 0 0"/>
    <axis xyz="1 0 0"/>
    <limit lower="-3.1415" upper="3.1415" effort="150" velocity="1.5"/>
    <dynamics damping="0.5" friction="1.0"/>
  </joint>
  <xacro:mrar_module name="module_2"/>

  <joint name="joint_3" type="revolute">
    <parent link="module_2"/>
    <child link="module_3"/>
    <origin xyz="0 0.18 0" rpy="0 0 0"/>
    <axis xyz="1 0 0"/>
    <limit lower="-3.1415" upper="3.1415" effort="150" velocity="1.5"/>
    <dynamics damping="0.5" friction="1.0"/>
  </joint>
  <xacro:mrar_module name="module_3"/>

  <joint name="joint_4" type="revolute">
    <parent link="module_3"/>
    <child link="module_4"/>
    <origin xyz="0 0.18 0" rpy="0 0 0"/>
    <axis xyz="1 0 0"/>
    <limit lower="-3.1415" upper="3.1415" effort="150" velocity="1.5"/>
    <dynamics damping="0.5" friction="1.0"/>
  </joint>
  <xacro:mrar_module name="module_4"/>

  <gazebo>
    <plugin name="gazebo_ros2_control" filename="libgazebo_ros2_control.so">
      <parameters>$(find mrar_description)/config/mrar_controllers.yaml</parameters>
    </plugin>
  </gazebo>

</robot>
```

8.3 Gait Implementation Node (Python)

The tumbling gait can be implemented as a ROS 2 node that publishes joint trajectories. A basic sinusoidal trajectory is shown below; more sophisticated gaits will be developed through optimization and learning.

```python
import rclpy
from rclpy.node import Node
from std_msgs.msg import Float64MultiArray
import math
import time

class TumbleGaitPublisher(Node):
    def __init__(self):
        super().__init__('tumble_gait_publisher')
        self.publisher_ = self.create_publisher(
            Float64MultiArray, 
            '/joint_position_controller/commands', 
            10)
        self.timer_period = 0.02  # 50 Hz
        self.timer = self.create_timer(self.timer_period, self.timer_callback)
        self.start_time = time.time()
        self.get_logger().info('MRAR Tumble Gait Node Started')

    def timer_callback(self):
        elapsed = time.time() - self.start_time
        msg = Float64MultiArray()

        # Gait parameters
        frequency = 1.0       # Hz
        amplitude = math.pi / 2  # 90 degrees
        phase_offset = math.pi / 2

        q1 = amplitude * math.sin(2 * math.pi * frequency * elapsed)
        q2 = amplitude * math.sin(2 * math.pi * frequency * elapsed - phase_offset)
        q3 = amplitude * math.sin(2 * math.pi * frequency * elapsed - 2 * phase_offset)
        q4 = amplitude * math.sin(2 * math.pi * frequency * elapsed - 3 * phase_offset)

        msg.data = [q1, q2, q3, q4]
        self.publisher_.publish(msg)

def main(args=None):
    rclpy.init(args=args)
    tumble_node = TumbleGaitPublisher()
    rclpy.spin(tumble_node)
    tumble_node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

8.4 Implementation Roadmap

1. Phase 1: Dynamic Simulation (Gazebo/Isaac Sim)
   · Build a URDF model of the MRAR.
   · Implement the control system (Chapter 5) and software architecture (Chapter 6) in simulation.
   · Validate locomotion gaits, reconfiguration, and basic autonomy.
2. Phase 1.5: Single‑Module Prototyping
   · Design and fabricate a single, non‑actuated module to test the structural design, sealing, and electrical interconnect.
   · Develop and test a single joint actuator unit to verify torque, speed, and control performance.
3. Phase 2: Two‑Module Testbed
   · Assemble two articulated modules with the core module.
   · Implement low‑level CAN communication and joint control.
   · Validate basic dynamics and control on a single joint.
4. Phase 3: Full 5‑Module Prototype Assembly
   · Fabricate all modules.
   · Integrate the full electronics and software stack.
   · Begin testing on flat ground.
5. Phase 4: Experimental Validation
   · Perform systematic testing of locomotion modes (rolling, “walking”).
   · Test reconfiguration capabilities.
   · Conduct preliminary amphibious tests in a controlled pool, validating the buoyancy model and stability control.

---

Chapter 9: Expected Applications

· Marine Infrastructure Inspection: Autonomous inspection of underwater bridge pilings, ship hulls, and offshore platforms, operating in turbulent and corrosive environments.
· Disaster Response: Searching for survivors in flooded urban environments or unstable rubble where wheeled or legged robots cannot easily go.
· Planetary Exploration: A lander‑deployed robot for exploring lunar lava tubes or Martian canyon systems, capable of rolling for efficient travel and standing for high‑view reconnaissance.
· Autonomous Infrastructure Monitoring: Long‑term monitoring of pipelines, railways, or power lines in remote areas, reconfiguring to navigate diverse terrain.

---

Chapter 10: Conclusion and Future Work

This thesis has presented the conceptual design and system architecture for the Multi‑Environment Reconfigurable Robot (MRAR), a modular, non‑humanoid platform inspired by cinematic robotics. The work has defined the mechanical, electronic, control, and software requirements for such a system, providing a foundational blueprint for implementation. The key contribution is the synthesis of a robust, redundancy‑focused design philosophy with a concrete, technically feasible architecture.

Future work will focus on:

· Detailed Dynamic Simulation: Developing high‑fidelity simulations to explore complex behaviors and optimize control parameters before hardware construction.
· CAD Modeling and Finite Element Analysis (FEA): Creating detailed CAD models of each module and performing FEA to optimize structural integrity and minimize weight.
· Waterproof Actuator Design: Engineering a custom high‑torque, fully‑sealed rotary actuator suitable for the amphibious environment.
· Reinforcement Learning for Locomotion: Exploring the use of RL to discover and refine robust, adaptive gaits for the MRAR, particularly for uneven and unpredictable terrain.
· Multi‑Robot Coordination: Investigating how a team of MRAR units could collaborate for tasks like constructing temporary shelters or performing cooperative manipulation of large objects.

By following this roadmap, the MRAR concept can transition from a theoretical design inspired by science fiction to a tangible, capable robot ready to tackle the challenges of extreme environments.

Appendices

Appendix A: Full URDF Description for MRAR

A.1 Overview

The Unified Robot Description Format (URDF) is an XML format used to represent the kinematics, dynamics, and visual properties of a robot in simulation and for real‑time control. For the MRAR, we employ a xacro macro to reduce redundancy, as all four articulated modules are identical. The URDF defines five links (one core base and four modules) connected by four revolute joints. Inertial parameters are estimated from the CAD model, assuming a uniform mass distribution for each module. The joint axes are aligned with the X‑axis to enable planar articulation.

A.2 URDF with Xacro Macros

The following URDF file (mrar.urdf.xacro) can be processed by xacro to generate the final URDF for simulation or real‑robot control.

```xml
<?xml version="1.0"?>
<robot name="mrar_prototype" xmlns:xacro="http://ros.org/wiki/xacro">

  <!-- Material definition for visualization -->
  <material name="brushed_aluminum">
    <color rgba="0.6 0.6 0.63 1.0"/>
  </material>

  <!-- Macro for a single module (link) -->
  <xacro:macro name="mrar_module" params="name">
    <link name="${name}">
      <visual>
        <geometry>
          <!-- Dimensions: width (X) = 0.12 m, depth (Y) = 0.18 m, height (Z) = 1.4 m -->
          <box size="0.12 0.18 1.4"/>
        </geometry>
        <material name="brushed_aluminum"/>
      </visual>
      <collision>
        <geometry>
          <box size="0.12 0.18 1.4"/>
        </geometry>
      </collision>
      <inertial>
        <mass value="9.0"/>  <!-- each module approx 9 kg -->
        <!-- Inertia tensor for a solid cuboid about its center of mass:
             Ixx = (m/12)*(dy^2 + dz^2) = (9/12)*(0.18^2 + 1.4^2) = 0.75*(0.0324+1.96) = 1.4943
             Iyy = (m/12)*(dx^2 + dz^2) = 0.75*(0.0144+1.96) = 1.4808
             Izz = (m/12)*(dx^2 + dy^2) = 0.75*(0.0144+0.0324) = 0.0351
             Products of inertia are zero due to symmetry. -->
        <inertia ixx="1.4943" ixy="0.0" ixz="0.0" iyy="1.4808" iyz="0.0" izz="0.0351"/>
      </inertial>
    </link>
  </xacro:macro>

  <!-- Instantiate the core module (base_link) -->
  <xacro:mrar_module name="base_link"/>

  <!-- Joint 1: connects base_link to module_1 -->
  <joint name="joint_1" type="revolute">
    <parent link="base_link"/>
    <child link="module_1"/>
    <!-- Origin at the interface between base_link and module_1.
         Since modules are 0.18 m deep in Y, the next module's origin is shifted by +0.18 m in Y.
         The joint axis is located at the face, so no additional offset in X or Z. -->
    <origin xyz="0 0.18 0" rpy="0 0 0"/>
    <axis xyz="1 0 0"/>  <!-- rotation about X-axis -->
    <limit lower="-3.1415" upper="3.1415" effort="150" velocity="1.5"/>
    <dynamics damping="0.5" friction="1.0"/>
  </joint>

  <!-- Module 1 -->
  <xacro:mrar_module name="module_1"/>

  <!-- Joint 2: connects module_1 to module_2 -->
  <joint name="joint_2" type="revolute">
    <parent link="module_1"/>
    <child link="module_2"/>
    <origin xyz="0 0.18 0" rpy="0 0 0"/>
    <axis xyz="1 0 0"/>
    <limit lower="-3.1415" upper="3.1415" effort="150" velocity="1.5"/>
    <dynamics damping="0.5" friction="1.0"/>
  </joint>

  <xacro:mrar_module name="module_2"/>

  <!-- Joint 3: connects module_2 to module_3 -->
  <joint name="joint_3" type="revolute">
    <parent link="module_2"/>
    <child link="module_3"/>
    <origin xyz="0 0.18 0" rpy="0 0 0"/>
    <axis xyz="1 0 0"/>
    <limit lower="-3.1415" upper="3.1415" effort="150" velocity="1.5"/>
    <dynamics damping="0.5" friction="1.0"/>
  </joint>

  <xacro:mrar_module name="module_3"/>

  <!-- Joint 4: connects module_3 to module_4 -->
  <joint name="joint_4" type="revolute">
    <parent link="module_3"/>
    <child link="module_4"/>
    <origin xyz="0 0.18 0" rpy="0 0 0"/>
    <axis xyz="1 0 0"/>
    <limit lower="-3.1415" upper="3.1415" effort="150" velocity="1.5"/>
    <dynamics damping="0.5" friction="1.0"/>
  </joint>

  <xacro:mrar_module name="module_4"/>

  <!-- Gazebo plugin for ros2_control -->
  <gazebo>
    <plugin name="gazebo_ros2_control" filename="libgazebo_ros2_control.so">
      <parameters>$(find mrar_description)/config/mrar_controllers.yaml</parameters>
    </plugin>
  </gazebo>

</robot>
```

A.3 Explanation of Key Parameters

· Inertia values: Calculated using the standard formula for a rectangular prism about its geometric center. The orientation of the module is such that its longest dimension (1.4 m) is along the Z‑axis. This matches the standing configuration.
· Joint limits: The revolute joints are capable of continuous rotation (±180°), allowing full 360° motion if required. The effort limit (150 Nm) reflects the peak torque capability of the selected actuators.
· Dynamics parameters: The damping and friction values are initial estimates; they will be tuned through system identification once the physical prototype is available.

A.4 Usage

To generate the final URDF for simulation, run:

```bash
xacro mrar.urdf.xacro > mrar.urdf
```

Then the URDF can be used in Gazebo or with the robot_state_publisher.

---

Appendix B: Microcontroller Firmware Pseudocode

B.1 Overview

Each actuated module (M1–M4) contains a Teensy 4.1 microcontroller responsible for:

· Reading the absolute joint encoder (via SPI or SSI).
· Reading motor current sensors (analog inputs).
· Executing a PID position/velocity loop at 1 kHz.
· Communicating with the central Jetson over CAN bus.
· Monitoring temperature and safety limits.

B.2 CAN Message Protocol

The CAN bus operates at 1 Mbps using extended 29‑bit identifiers. Each module has a unique CAN ID (1–4). The following message types are defined:

Message ID Direction Data (8 bytes) Description
0x01 Jetson → Module [float32 desired_position, float32 feedforward_torque] Position command
0x02 Jetson → Module [float32 kp, float32 kd] PID gains update
0x03 Module → Jetson [float32 position, float32 velocity, float32 torque, uint16_t status] Status feedback (1 kHz)
0x04 Jetson → Module [uint8_t mode] (0=idle,1=position,2=velocity,3=torque) Control mode
0x05 Module → Jetson [float32 temperature, float32 voltage] Health monitoring (10 Hz)

B.3 Main Loop Pseudocode

```cpp
#include <Arduino.h>
#include <FlexCAN_T4.h>
#include <Encoder.h>  // Placeholder for absolute encoder library

// Pin definitions
#define ENC_CS_PIN    10
#define ENC_CLK_PIN   11
#define ENC_DATA_PIN  12
#define CURRENT_SENSE_PIN A0
#define MOTOR_PWM_PIN  5
#define MOTOR_DIR_PIN  6
#define TEMP_SENSE_PIN A1

// CAN object
FlexCAN_T4<CAN1, RX_SIZE_256, TX_SIZE_16> Can0;
CAN_message_t rxMsg;
CAN_message_t txMsg;

// Global variables
float desired_position = 0.0;
float measured_position = 0.0;
float measured_velocity = 0.0;
float measured_current = 0.0;  // proportional to torque
float kp = 50.0, kd = 2.0;      // PID gains
int control_mode = 1;            // default position mode
uint32_t last_cmd_time = 0;
const uint32_t watchdog_timeout = 100; // ms

// Timer for control loop
IntervalTimer controlTimer;

// Function prototypes
void readEncoder();
void readCurrent();
void computePID();
void sendCANFeedback();
void CANReceiveHandler(const CAN_message_t &msg);
void controlLoop();

void setup() {
    Serial.begin(115200);
    
    // Initialize CAN
    Can0.begin();
    Can0.setBaudRate(1000000);
    Can0.onReceive(CANReceiveHandler);
    
    // Initialize encoder (SPI)
    pinMode(ENC_CS_PIN, OUTPUT);
    digitalWrite(ENC_CS_PIN, HIGH);
    SPI.begin();
    
    // Initialize motor PWM
    pinMode(MOTOR_PWM_PIN, OUTPUT);
    pinMode(MOTOR_DIR_PIN, OUTPUT);
    analogWriteFrequency(MOTOR_PWM_PIN, 20000); // 20 kHz PWM
    
    // Start control timer at 1 kHz
    controlTimer.begin(controlLoop, 1000); // microseconds
}

void loop() {
    // Health monitoring at 10 Hz
    static uint32_t last_health = 0;
    if (millis() - last_health > 100) {
        last_health = millis();
        sendHealth();
    }
    
    // Watchdog: if no command from Jetson for 100 ms, stop motors
    if (millis() - last_cmd_time > watchdog_timeout) {
        analogWrite(MOTOR_PWM_PIN, 0);
        digitalWrite(MOTOR_DIR_PIN, LOW);
    }
}

void controlLoop() {
    readEncoder();
    readCurrent();
    computePID();
    sendCANFeedback();
}

void readEncoder() {
    // SPI communication with absolute encoder (e.g., AMT23)
    digitalWrite(ENC_CS_PIN, LOW);
    uint16_t raw = SPI.transfer16(0x0000);
    digitalWrite(ENC_CS_PIN, HIGH);
    measured_position = (float)raw * (2.0 * PI / 65536.0); // convert to radians
    
    // Simple velocity estimation by finite difference
    static float prev_position = 0;
    static uint32_t prev_time = micros();
    uint32_t now = micros();
    float dt = (now - prev_time) * 1e-6;
    if (dt > 0) {
        measured_velocity = (measured_position - prev_position) / dt;
    }
    prev_position = measured_position;
    prev_time = now;
}

void readCurrent() {
    int adc = analogRead(CURRENT_SENSE_PIN);
    // Convert ADC to current based on sensor sensitivity (e.g., 0.1 V/A)
    measured_current = (adc * 3.3 / 1024.0 - 1.65) / 0.1; // example
}

void computePID() {
    static float integral = 0;
    float error = desired_position - measured_position;
    
    // Anti-windup
    float output = kp * error + kd * (-measured_velocity); // D on measurement
    // For torque control, output is directly commanded torque (Nm)
    // Convert torque to PWM duty cycle and direction
    float torque_limit = 150.0; // Nm max
    float torque_cmd = constrain(output, -torque_limit, torque_limit);
    
    // Map torque to PWM (positive torque = one direction, negative = opposite)
    int pwm = (int)(fabs(torque_cmd) / torque_limit * 255);
    bool dir = (torque_cmd >= 0) ? HIGH : LOW;
    analogWrite(MOTOR_PWM_PIN, pwm);
    digitalWrite(MOTOR_DIR_PIN, dir);
}

void sendCANFeedback() {
    txMsg.id = 0x03; // Status message
    txMsg.len = 8;
    float data[4] = {measured_position, measured_velocity, measured_current, 0};
    memcpy(txMsg.buf, data, 8);
    Can0.write(txMsg);
}

void sendHealth() {
    txMsg.id = 0x05; // Health message
    txMsg.len = 8;
    float temp = analogRead(TEMP_SENSE_PIN) * 3.3 / 1024.0 * 100.0; // example
    float voltage = 48.0; // read from voltage divider
    float data[2] = {temp, voltage};
    memcpy(txMsg.buf, data, 8);
    Can0.write(txMsg);
}

void CANReceiveHandler(const CAN_message_t &msg) {
    last_cmd_time = millis();
    switch (msg.id) {
        case 0x01: { // position command
            float desired;
            memcpy(&desired, msg.buf, 4);
            desired_position = desired;
            // Optionally read feedforward torque from second 4 bytes
            break;
        }
        case 0x02: { // PID gains
            float kp_new, kd_new;
            memcpy(&kp_new, msg.buf, 4);
            memcpy(&kd_new, msg.buf+4, 4);
            kp = kp_new;
            kd = kd_new;
            break;
        }
        case 0x04: { // control mode
            control_mode = msg.buf[0];
            break;
        }
    }
}
```

B.4 Compilation and Deployment

The code is compiled using Arduino IDE or PlatformIO with the Teensyduino core. The CAN library used is FlexCAN_T4. The firmware must be flashed onto each Teensy 4.1 with its unique CAN ID set via a configuration EEPROM or a physical DIP switch.

---

Appendix C: ROS 2 Launch and Configuration Files

C.1 Overview

This appendix provides the necessary ROS 2 launch files and configuration to simulate the MRAR in Gazebo and to control the real robot. The files are organized within a typical ROS 2 package named mrar_bringup.

C.2 Controllers Configuration (mrar_controllers.yaml)

This YAML file configures the controllers for the ros2_control framework. It defines a joint state controller and a joint trajectory controller.

```yaml
controller_manager:
  ros__parameters:
    update_rate: 100  # Hz

    joint_state_controller:
      type: joint_state_controller/JointStateController

    joint_trajectory_controller:
      type: joint_trajectory_controller/JointTrajectoryController

joint_trajectory_controller:
  ros__parameters:
    joints:
      - joint_1
      - joint_2
      - joint_3
      - joint_4
    command_interfaces:
      - position
    state_interfaces:
      - position
      - velocity
    open_loop_control: true
    allow_integration_in_goal_trajectories: true
    constraints:
      stopped_velocity_tolerance: 0.01
      goal_time: 0.5
```

C.3 Launch File for Simulation (sim_bringup.launch.py)

This launch file starts Gazebo with an empty world, spawns the MRAR robot, and loads the controllers.

```python
import os
from launch import LaunchDescription
from launch.actions import ExecuteProcess, IncludeLaunchDescription, RegisterEventHandler
from launch.event_handlers import OnProcessExit
from launch.launch_description_sources import PythonLaunchDescriptionSource
from launch.substitutions import FindExecutable, PathJoinSubstitution
from launch_ros.substitutions import FindPackageShare
from launch_ros.actions import Node

def generate_launch_description():
    pkg_mrar_description = FindPackageShare('mrar_description')
    pkg_mrar_bringup = FindPackageShare('mrar_bringup')
    pkg_gazebo_ros = FindPackageShare('gazebo_ros')

    # Paths
    urdf_path = PathJoinSubstitution([pkg_mrar_description, 'urdf', 'mrar.urdf'])
    world_path = PathJoinSubstitution([pkg_mrar_bringup, 'worlds', 'empty.world'])
    controllers_yaml = PathJoinSubstitution([pkg_mrar_bringup, 'config', 'mrar_controllers.yaml'])

    # Start Gazebo server
    start_gazebo_server = IncludeLaunchDescription(
        PythonLaunchDescriptionSource([pkg_gazebo_ros, '/launch', '/gzserver.launch.py']),
        launch_arguments={'world': world_path}.items()
    )

    # Start Gazebo client
    start_gazebo_client = IncludeLaunchDescription(
        PythonLaunchDescriptionSource([pkg_gazebo_ros, '/launch', '/gzclient.launch.py'])
    )

    # Robot state publisher
    robot_state_publisher = Node(
        package='robot_state_publisher',
        executable='robot_state_publisher',
        parameters=[{'robot_description': open(urdf_path).read()}]
    )

    # Spawn robot in Gazebo
    spawn_entity = Node(
        package='gazebo_ros',
        executable='spawn_entity.py',
        arguments=['-entity', 'mrar', '-topic', 'robot_description'],
        output='screen'
    )

    # Load controllers
    load_controllers = ExecuteProcess(
        cmd=[FindExecutable(name='ros2'), 'control', 'load_controller', '--set-state', 'active',
             'joint_state_controller'],
        output='screen'
    )

    load_traj_controller = ExecuteProcess(
        cmd=[FindExecutable(name='ros2'), 'control', 'load_controller', '--set-state', 'active',
             'joint_trajectory_controller'],
        output='screen'
    )

    return LaunchDescription([
        start_gazebo_server,
        start_gazebo_client,
        robot_state_publisher,
        spawn_entity,
        RegisterEventHandler(
            OnProcessExit(
                target_action=spawn_entity,
                on_exit=[load_controllers]
            )
        ),
        RegisterEventHandler(
            OnProcessExit(
                target_action=load_controllers,
                on_exit=[load_traj_controller]
            )
        )
    ])
```

C.4 Launch File for Real Robot (real_bringup.launch.py)

For the physical robot, a hardware interface is required. This example assumes a custom mrar_hardware package implementing the ros2_control hardware interface for CAN communication.

```python
import os
from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument
from launch.substitutions import LaunchConfiguration
from launch_ros.actions import Node
from launch_ros.substitutions import FindPackageShare

def generate_launch_description():
    pkg_mrar_description = FindPackageShare('mrar_description')
    pkg_mrar_bringup = FindPackageShare('mrar_bringup')

    urdf_path = os.path.join(pkg_mrar_description, 'urdf', 'mrar.urdf')
    controllers_yaml = os.path.join(pkg_mrar_bringup, 'config', 'mrar_controllers.yaml')

    with open(urdf_path, 'r') as f:
        robot_description = f.read()

    robot_state_publisher = Node(
        package='robot_state_publisher',
        executable='robot_state_publisher',
        parameters=[{'robot_description': robot_description}]
    )

    # Controller manager with hardware interface
    control_node = Node(
        package='controller_manager',
        executable='ros2_control_node',
        parameters=[{'robot_description': robot_description}, controllers_yaml],
        output='screen'
    )

    # Spawn controllers
    spawn_joint_state_controller = Node(
        package='controller_manager',
        executable='spawner',
        arguments=['joint_state_controller'],
        output='screen'
    )

    spawn_joint_trajectory_controller = Node(
        package='controller_manager',
        executable='spawner',
        arguments=['joint_trajectory_controller'],
        output='screen'
    )

    return LaunchDescription([
        robot_state_publisher,
        control_node,
        spawn_joint_state_controller,
        spawn_joint_trajectory_controller
    ])
```

C.5 Usage Instructions

1. Simulation:
   ```bash
   ros2 launch mrar_bringup sim_bringup.launch.py
   ```
2. Real robot:
   ```bash
   ros2 launch mrar_bringup real_bringup.launch.py
   ```
3. Send a trajectory:
   ```bash
   ros2 run mrar_bringup tumble_gait_node.py
   ```

---

These appendices provide the necessary implementation details to reproduce the simulation environment, embedded firmware, and ROS 2 control stack for the MRAR. All files are intended to be part of a public repository accompanying the thesis.

