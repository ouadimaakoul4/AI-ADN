Archive-Based Multimodal AGI

A Foundational Framework Integrating Information Geometry, Non-Equilibrium Thermodynamics, and Hybrid Architectures

Author: ouadi Maakoul + All USA GPT

Abstract

This thesis presents a comprehensive mathematical and architectural framework for Archive-Based Multimodal Artificial General Intelligence (ABM-AGI). Moving beyond purely statistical large language models, we propose that historical archives—characterized by temporal density, multimodal integration, provenance structure, and causal grounding—provide a uniquely valuable substrate for developing general intelligence. The framework integrates information geometry, non-equilibrium thermodynamics (via the Maximum Caliber principle), dynamical systems theory, and Bayesian inference into a unified hybrid architecture. We derive the Archive Free Energy functional, formalize a Maximum Algorithmic Caliber principle for path selection, and introduce a geometrodynamic latent space where concepts evolve on a Riemannian manifold equipped with a Fisher information metric. The architecture combines transformer-based multimodal encoders, neural stochastic differential equations for temporal dynamics, a Bayesian inference engine with variational path integrals, and an action selection module based on expected caliber. We provide theoretical guarantees for convergence, derive conditions for emergent generalization (a phase transition from memorization to world simulation), and introduce a hallucination constraint grounded in causal consistency. Detailed algorithms, loss functions, and implementation roadmaps are presented, along with proposals for synthetic and real-world archival benchmarks. This work establishes a rigorous foundation for AGI research that respects the epistemic authority of historical evidence while enabling creative extrapolation within physical and causal constraints.

---

1. Introduction

1.1 The AGI Challenge

The pursuit of Artificial General Intelligence (AGI) remains one of the most profound scientific and engineering challenges of the twenty-first century. While contemporary AI systems demonstrate remarkable capabilities in narrow domains—language modeling, computer vision, game playing, and robotic control—they fundamentally fail to achieve the adaptable, general intelligence characteristic of biological cognition. This limitation persists despite exponential growth in computational resources, model parameters, and training data. Current architectures largely pursue increasingly complex individual systems, resulting in what some researchers characterize as "brittle intelligence": systems that perform well in narrow domains but fail to demonstrate genuine adaptability, causal reasoning, or transfer learning across fundamentally different contexts.

The core problem lies in the nature of training data and learning objectives. Most modern AI systems are trained on web-scale datasets optimized for statistical regularities, using objectives such as next-token prediction or contrastive learning. While these approaches yield impressive pattern-matching capabilities, they do not imbue models with an understanding of the underlying causal structures that generate data. As a result, such systems are prone to hallucination, lack robustness to distribution shift, and cannot reason counterfactually.

1.2 The Archive Hypothesis

This thesis proposes that historical archives and behavioral logs constitute a uniquely valuable substrate for developing general intelligence. Unlike web-scale datasets, archives possess four critical properties essential for AGI:

1. Temporal Density: Archives capture processes unfolding through time, enabling causal inference and temporal reasoning.
2. Multimodal Integration: Archives naturally contain text, images, sensor readings, logs, and structured data in causally-linked configurations.
3. Provenance Structure: Archives maintain traceable chains of evidence, enabling verification and attribution; each entry carries an epistemic weight based on its source.
4. Causal Grounding: Archives record actual historical processes with genuine cause-effect relationships, unlike synthetic datasets or web content that may contain misinformation.

We argue that these properties make archives a closed-loop ground truth for training systems that must maintain historical consistency. An AGI trained on such data learns not merely statistical correlations but the actual dynamical laws that governed the recorded phenomena. This enables the system to reconstruct coherent timelines, answer causal queries, and make predictions that respect the physical and social constraints embedded in the archive.

The central hypothesis states: Intelligence capable of generalization emerges when a system can model the latent dynamics that generated observed archival data, enabling prediction, counterfactual reasoning, and intervention planning across domains.

1.3 Research Questions and Contributions

This thesis addresses four interconnected research questions:

Q1 (Representation): How can multimodal archival data be embedded into a unified mathematical structure that preserves temporal, causal, and cross-modal relationships, while respecting provenance and epistemic weight?

Q2 (Dynamics): What dynamical laws govern the evolution of concepts, behaviors, and interactions in latent spaces, and how can these be derived from physical first principles such as maximum caliber?

Q3 (Inference): How can hybrid architectures combine neural pattern recognition with principled probabilistic inference to reason under uncertainty across archival evidence, while suppressing hallucinations?

Q4 (Generalization): What mathematical conditions characterize the transition from narrow task performance to genuine generalization (e.g., zero-shot causal inference), and how can these be induced through archival learning?

The main contributions of this thesis are:

· A formal definition of an archive as a temporally-indexed stochastic process with provenance and causal structure.
· The Archive Free Energy functional, unifying information theory, thermodynamics, and Bayesian inference.
· The Maximum Algorithmic Caliber principle for selecting paths in latent space, with a tractable variational approximation.
· A geometrodynamic latent space where concepts reside on a Riemannian manifold with Fisher information metric, enabling geodesic distances and parallel transport for analogical reasoning.
· A hybrid architecture combining multimodal encoders, neural SDEs, a Bayesian inference engine with hallucination constraint, and an action selection module based on expected caliber.
· Theoretical conditions for emergent generalization as a phase transition in latent space.
· A causal consistency metric to quantify alignment with archival ground truth.
· Detailed algorithms and loss functions for end-to-end learning.

1.4 Thesis Outline

The remainder of this thesis is organized as follows. Chapter 2 establishes the mathematical foundations: information theory, probabilistic inference, information geometry, dynamical systems, non-equilibrium thermodynamics, gauge theory, and causal inference. Chapter 3 formalizes the concept of an archive and argues for its epistemic superiority. Chapter 4 presents the complete ABM-AGI architecture, detailing each component and its mathematical underpinnings. Chapter 5 provides the learning and inference algorithms, including loss functions and optimization procedures. Chapter 6 offers theoretical analysis, including convergence guarantees, generalization bounds, the phase transition theorem, and the hallucination constraint. Chapter 7 proposes experimental evaluations using synthetic and real-world archives, defining metrics and benchmarks. Chapter 8 discusses limitations, ethical considerations, and future work. Chapter 9 concludes the thesis.

---

2. Mathematical Foundations

2.1 Information Theory and Algorithmic Information

2.1.1 Shannon Entropy and Mutual Information

Let $\mathcal{X}$ be a discrete observation space. For a random variable $X$ with probability mass function $p(x)$, the Shannon entropy is:

H(X) = -\sum_{x \in \mathcal{X}} p(x) \log p(x).

For continuous variables with density $p(x)$, the differential entropy is:

H(X) = -\int_{\mathcal{X}} p(x) \log p(x) dx.

The mutual information between two variables $X$ and $Y$ measures their statistical dependence:

I(X;Y) = H(X) - H(X|Y) = \int\int p(x,y) \log \frac{p(x,y)}{p(x)p(y)} dx dy.

For a set of modalities $\{X_1,\ldots,X_m\}$, the total cross-modal information is:

I_{\text{total}} = \sum_{i<j} I(X_i;X_j) + \sum_i H(X_i).

2.1.2 Kolmogorov Complexity and Minimum Description Length

For a finite binary string $x$, the Kolmogorov complexity $K(x)$ is the length of the shortest program that outputs $x$ on a universal Turing machine:

K(x) = \min_{p: U(p)=x} \ell(p).

The conditional complexity $K(x|y)$ is defined analogously. The algorithmic mutual information between two strings is:

I_{\text{alg}}(x:y) = K(x) + K(y) - K(x,y).

For an archival sequence $A = (a_1,\ldots,a_T)$, the algorithmic complexity of the archive is:

K(A) = \min\left\{K(T) + \sum_{t=1}^T K(a_t | a_{1:t-1})\right\}.

The Minimum Description Length (MDL) principle asserts that the best hypothesis $H$ for data $D$ minimizes $L(H) + L(D|H)$, where $L$ denotes description length. For archival modeling, we seek a latent dynamical system $\Theta$ minimizing:

\mathcal{L}_{\text{MDL}}(\Theta) = K(\Theta) + \sum_{t=1}^T K(a_t | \Theta, a_{1:t-1}).

2.2 Probabilistic Inference

2.2.1 Bayesian Hierarchical Models

For a latent state $\theta$ and observed data $x$, Bayes' theorem gives:

p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)} = \frac{p(x|\theta)p(\theta)}{\int p(x|\theta')p(\theta')d\theta'}.

For sequential archival data $a_{1:T}$, the posterior over latent dynamics $\theta$ is:

p(\theta|a_{1:T}) \propto p(\theta) \prod_{t=1}^T p(a_t|a_{1:t-1},\theta).

A three-level hierarchical model for archives is:

a_t | \theta_t \sim p(a_t|\theta_t), \quad \theta_t | \phi \sim p(\theta_t|\phi), \quad \phi \sim p(\phi).

2.2.2 Graphical Models and Dynamic Bayesian Networks

A directed acyclic graph $G=(V,E)$ encodes conditional independencies: $p(x_V) = \prod_{v\in V} p(x_v | x_{\text{pa}(v)})$. For temporal data, a Dynamic Bayesian Network (DBN) represents the evolution of latent states $z_t$ and observations $a_t$:

p(a_{1:T}, z_{1:T}) = p(z_1) \prod_{t=2}^T p(z_t|z_{t-1}) \prod_{t=1}^T p(a_t|z_t).

2.3 Information Geometry

2.3.1 Fisher Information Metric

For a parametric family $p(x|\theta)$, the Fisher information matrix is:

g_{ij}(\theta) = \mathbb{E}_{p(x|\theta)}\left[\frac{\partial \log p(x|\theta)}{\partial \theta^i} \frac{\partial \log p(x|\theta)}{\partial \theta^j}\right].

This defines a Riemannian metric on the statistical manifold $\mathcal{M} = \{p(x|\theta) : \theta \in \Theta\}$:

ds^2 = \sum_{i,j} g_{ij}(\theta) d\theta^i d\theta^j.

2.3.2 Natural Gradient

The natural gradient ascent direction on the statistical manifold is:

\tilde{\nabla} L(\theta) = G(\theta)^{-1} \nabla L(\theta),

where $G(\theta)$ is the Fisher information matrix. This accounts for the curvature of the parameter space.

2.3.3 Geodesics on Statistical Manifolds

Geodesic curves satisfy:

\frac{d^2 \theta^k}{dt^2} + \sum_{i,j} \Gamma^k_{ij} \frac{d\theta^i}{dt} \frac{d\theta^j}{dt} = 0,

with Christoffel symbols:

\Gamma^k_{ij} = \frac{1}{2} \sum_m g^{km} \left(\frac{\partial g_{mj}}{\partial \theta^i} + \frac{\partial g_{mi}}{\partial \theta^j} - \frac{\partial g_{ij}}{\partial \theta^m}\right).

Geodesic distance provides a natural measure of dissimilarity between distributions.

2.4 Dynamical Systems Theory

2.4.1 State-Space Models and Stochastic Differential Equations

A general stochastic dynamical system is:

z_{t+1} = f(z_t, u_t, \epsilon_t), \quad a_t = g(z_t, \eta_t),

with latent state $z_t \in \mathbb{R}^n$, controls $u_t$, process noise $\epsilon_t$, and observation noise $\eta_t$. In continuous time, a stochastic differential equation (SDE) models the evolution:

dz_t = \mu(z_t, t) dt + \sigma(z_t, t) dW_t,

where $W_t$ is a Wiener process.

2.4.2 Lyapunov Exponents and Attractor Dynamics

For a deterministic system $z_{t+1}=f(z_t)$, Lyapunov exponents measure sensitivity to initial conditions:

\lambda_i = \lim_{T\to\infty} \frac{1}{T} \log \left\| \frac{\partial f^T}{\partial z_0} \cdot v_i \right\|.

Positive exponents indicate chaos; negative exponents indicate stability. The sum of positive exponents gives the Kolmogorov-Sinai entropy. Attractors (fixed points, limit cycles, strange attractors) characterize long-term behavior.

2.5 Non-Equilibrium Thermodynamics

2.5.1 Maximum Entropy and Maximum Caliber Principles

The Maximum Entropy principle selects the distribution $p(x)$ that maximizes entropy $H(p)$ subject to constraints $\mathbb{E}[f_k(x)] = F_k$, yielding the Gibbs distribution:

p(x) = \frac{1}{Z(\lambda)} \exp\left(-\sum_k \lambda_k f_k(x)\right).

The Maximum Caliber principle extends this to paths $\Gamma = \{x_0,\ldots,x_T\}$: maximize path entropy (caliber) $\mathcal{C} = -\sum_\Gamma p(\Gamma) \log p(\Gamma)$ subject to constraints $\mathbb{E}[g_m(\Gamma)] = G_m$, giving:

p(\Gamma) = \frac{1}{\mathcal{Z}(\gamma)} \exp\left(-\sum_m \gamma_m g_m(\Gamma)\right).

2.5.2 Path Integrals and Free Energy

The path integral formulation expresses the probability of a path as $p(\Gamma) \propto e^{-S(\Gamma)}$, where $S$ is an action. The free energy of a path is $F(\Gamma) = E(\Gamma) - \frac{1}{\beta} S(\Gamma)$, with $E$ energy and $S$ entropy. The path probability is $p(\Gamma) \propto e^{-\beta F(\Gamma)}$.

2.5.3 Algorithmic Thermodynamics

Following Tadaki, define algorithmic temperature $T$ and algorithmic free energy $F = U - TS$, where $U$ is Kolmogorov complexity of a program and $S$ is algorithmic entropy (log number of programs with same output). The Maximum Algorithmic Caliber principle selects the path distribution maximizing caliber under computational constraints.

2.6 Gauge Theory and Geometric Structure

2.6.1 Gauge Symmetry in Transformers

Self-attention exhibits a $GL(d_h)$ gauge symmetry: simultaneous transformations $Q \to Q\Lambda^{-1}$, $K \to K\Lambda^T$, $V \to V\Lambda$ leave the attention output invariant. The attention matrix transforms as a connection: $A \to \Lambda A \Lambda^{-1}$.

2.6.2 Spontaneous Symmetry Breaking and Rank Collapse

Rank collapse in deep transformers corresponds to spontaneous symmetry breaking. The order parameter is the rank $r$ of the representation matrix. The free energy as a function of rank exhibits minima at symmetry-broken phases.

2.7 Causal Inference

2.7.1 Structural Causal Models and Do-Calculus

A causal model is a triple $M = (U,V,F)$ where $U$ are exogenous variables, $V$ endogenous, and $F$ structural equations $v_i = f_i(pa_i, u_i)$. The do-operator $do(X=x)$ represents intervention, and the do-calculus provides rules for computing interventional distributions from observational data.

2.7.2 Causal Discovery from Observational Data

Algorithms such as PC and FCI infer causal graphs from conditional independencies. Additive noise models test causal directions by assuming $Y = f(X) + \epsilon$ with $\epsilon \perp X$ for one direction.

---

3. The Archive as Causal Ground Truth

3.1 Formal Definition of an Archive

An archive $\mathcal{A}$ is a tuple:

\mathcal{A} = (T, \mathcal{M}, \mathcal{E}, \mathcal{C}, \mathcal{P}, \mathcal{W}),

where:

· $T$ is a totally ordered time set (indices).
· $\mathcal{M} = \{M_1,\ldots,M_k\}$ is a set of modalities.
· $\mathcal{E} = \{e_t : t \in T\}$ is a set of events, each $e_t = (m_t, a_t)$ with modality $m_t \in \mathcal{M}$ and content $a_t$.
· $\mathcal{C}$ is a set of causal relations $c: e_i \to e_j$ (directed edges).
· $\mathcal{P}$ is a set of provenance relations $p: e_i \to \text{source}$, where source may be another event or an external entity.
· $\mathcal{W}: \mathcal{E} \to \mathbb{R}^+$ assigns an epistemic weight to each event based on source reliability.

3.1.1 Temporal Structure

The archive generates a filtration of $\sigma$-algebras $\mathcal{F}_t = \sigma(\{e_s : s \leq t\})$, representing information up to time $t$. The hazard rate for event occurrence is:

\lambda(t|\mathcal{F}_{t-}) = \lim_{dt\to 0} \frac{P(\text{event in }[t,t+dt)|\mathcal{F}_{t-})}{dt}.

3.1.2 Provenance and Epistemic Weight

Provenance tracks the origin of each event, enabling trust-weighted inference. The weight $w(e)$ reflects confidence in the event's veracity. Events from primary sources (e.g., sensor logs) receive higher weight than secondary sources (e.g., summaries).

3.1.3 Causal Structure

The causal graph $G$ over events encodes true cause-effect relationships from the historical process. Unlike purely statistical associations, these are grounded in physical or social mechanisms.

3.2 Epistemic Superiority of Archives

3.2.1 Comparison with Web-Scale Data

Web-scale datasets (e.g., Common Crawl) are characterized by:

· Lack of temporal coherence: documents are timestamped inconsistently.
· Absence of causal grounding: correlations may be spurious.
· Provenance ambiguity: sources are often unreliable or conflicting.
· Statistical noise: misinformation, duplication, and sampling bias.

Archives, in contrast, provide:

· Temporal coherence: events are ordered and often have precise timestamps.
· Causal ground truth: relationships reflect actual mechanisms.
· Provenance tracking: each event has a verifiable source.
· Historical consistency: the archive tells a single coherent story (modulo missing data).

3.2.2 Historical Consistency as a Training Signal

Training on archives enforces a consistency constraint: the model must learn to reconstruct a timeline that aligns with all evidence, weighted by provenance. This encourages the discovery of latent dynamics that generated the data, rather than superficial correlations.

3.3 The Archive Hypothesis Revisited

Archive Hypothesis (Formal): Let $\mathcal{A}$ be an archive generated by an underlying dynamical system $\mathcal{S}$ with latent state $z_t$ and observation process $a_t = h(z_t) + \text{noise}$. A learning machine trained on $\mathcal{A}$ with an objective that minimizes prediction error while respecting causal and provenance constraints will converge to a model $\hat{\mathcal{S}}$ that is isomorphic to $\mathcal{S}$ in its causal structure and latent dynamics, up to the limits of identifiability. This enables generalization to novel interventions and counterfactuals consistent with $\mathcal{S}$.

---

4. ABM-AGI Architecture

4.1 System Overview

The ABM-AGI architecture consists of five integrated modules (Figure 4.1):

1. Multimodal Ingestion Layer: Encodes raw archival events into unified latent representations, incorporating provenance weights.
2. Geometrodynamic Latent Space: Maintains a Riemannian manifold of concepts with Fisher information metric; supports geodesic distances and parallel transport.
3. Temporal Dynamics Module: Models evolution of latent states via neural SDEs and transformer-based temporal encoding, regularized by Lyapunov spectrum.
4. Bayesian Inference Engine: Performs variational inference with structured posteriors, computing the Archive Free Energy and enforcing a hallucination constraint.
5. Action Selection Module: Chooses actions (e.g., queries, interventions, predictions) to maximize expected caliber, using a variational path integral policy.

4.2 Multimodal Ingestion Layer

4.2.1 Modal-Specific Encoders

For each modality $m \in \mathcal{M}$, define an encoder $E_m: \mathcal{X}_m \to \mathbb{R}^{d_m}$:

· Text: Transformer encoder with positional embeddings.
· Image: Vision Transformer (ViT) or CNN.
· Audio: Spectrogram CNN + transformer.
· Sensor/Structured Data: MLP or GNN.

Let $e_t = (m_t, a_t)$ be an event. The raw encoding is $z_t^{(0)} = E_{m_t}(a_t) \in \mathbb{R}^{d_{m_t}}$.

4.2.2 Hypergraph Provenance Encoding

Provenance relations form a hypergraph over events. We encode provenance via a graph attention network that aggregates information from source events:

\tilde{z}_t = z_t^{(0)} + \sum_{s \in \text{sources}(t)} \alpha_{ts} W_p z_s^{(0)},

where $\alpha_{ts}$ are attention weights based on provenance type and temporal distance. Epistemic weights $w(e_t)$ are used to scale gradients during training (events with low weight contribute less to learning).

4.2.3 Cross-Modal Alignment via Geodesic Similarity

To align representations across modalities, we project all $\tilde{z}_t$ into a common latent space $\mathbb{R}^d$ via linear projections $P_m$. The cross-modal alignment loss encourages corresponding events (e.g., same timestamp, different modalities) to be close in the latent manifold, measured by geodesic distance rather than Euclidean distance:

\mathcal{L}_{\text{align}} = \sum_{(t,t') \in \text{correspondences}} d_{\text{geo}}(P_{m_t}\tilde{z}_t, P_{m_{t'}}\tilde{z}_{t'})^2,

where $d_{\text{geo}}$ is the geodesic distance on the latent manifold (defined below). This respects the curved geometry of the semantic space.

4.3 Geometrodynamic Latent Space

4.3.1 Riemannian Metric from Fisher Information

Let $p_\theta(a|z)$ be the observation model (decoder). The Fisher information metric on the latent manifold is:

g_{ij}(z) = \mathbb{E}_{p(a|z)}\left[\frac{\partial \log p(a|z)}{\partial z^i} \frac{\partial \log p(a|z)}{\partial z^j}\right] + \lambda \delta_{ij},

where the $\lambda$ term ensures positive definiteness. This metric captures the sensitivity of observations to changes in latent state; regions where small changes in $z$ cause large changes in observations are "steep" and geodesics should avoid cutting through them unless necessary.

4.3.2 Geodesic Distance and Parallel Transport

The geodesic distance between two latent points $z_1, z_2$ is:

d_{\text{geo}}(z_1, z_2) = \inf_{\gamma: \gamma(0)=z_1, \gamma(1)=z_2} \int_0^1 \sqrt{g_{ij}(\gamma(t)) \dot{\gamma}^i(t) \dot{\gamma}^j(t)} dt.

Parallel transport of a vector $v$ along a geodesic $\gamma$ satisfies $\frac{D v^k}{dt}=0$, enabling analogical reasoning: the transformation that maps concept $A$ to $B$ can be applied to $C$ by parallel transporting the displacement along the geodesic from $A$ to $B$ and applying it to $C$.

4.3.3 Gauge-Invariant Attention and Symmetry Constraints

The self-attention mechanism in the temporal module is designed to be gauge-invariant under $GL(d)$ transformations of the latent space. We achieve this by using the metric to define attention weights based on geodesic distance rather than dot products:

\text{Attention}(Q,K,V)_{ij} = \text{softmax}\left(-\frac{d_{\text{geo}}(q_i, k_j)^2}{\tau}\right) v_j,

where $q_i, k_j, v_j$ are points in the latent manifold. This ensures that the model's computations are intrinsic to the geometry, not dependent on coordinate choices.

4.4 Temporal Dynamics Module

4.4.1 Neural Stochastic Differential Equations

We model the evolution of latent states as a neural SDE:

dz_t = \mu_\theta(z_t, t) dt + \sigma_\theta(z_t, t) dW_t,

where $\mu_\theta$ and $\sigma_\theta$ are neural networks. The initial condition $z_{t_0}$ is obtained from the ingestion layer. The SDE is integrated using techniques like the Euler-Maruyama method or more advanced solvers.

4.4.2 Transformer-Based Temporal Encoding

In parallel, we maintain a transformer that encodes the sequence of observed events and latent states to capture long-range dependencies:

h_t = \text{Transformer}_{\text{temp}}(\{z_s, a_s\}_{s \leq t}).

The transformer's self-attention uses the geodesic-based attention described above. The output $h_t$ conditions the SDE drift and diffusion, and also provides context for inference and action selection.

4.4.3 Lyapunov Spectrum Regularization

To encourage a healthy balance between stability and flexibility, we regularize the Lyapunov exponents of the learned dynamics. Let $\lambda_i$ be the Lyapunov exponents estimated from the SDE's Jacobian along trajectories. We add a loss:

\mathcal{L}_{\text{Lyap}} = \left(\sum_{\lambda_i>0} \lambda_i - \lambda_{\text{target}}^+\right)^2 + \left(\sum_{\lambda_i<0} \lambda_i - \lambda_{\text{target}}^-\right)^2,

where $\lambda_{\text{target}}^+ > 0$ and $\lambda_{\text{target}}^- < 0$ are hyperparameters. This encourages a small positive exponent for adaptability and a dominant negative exponent for stability.

4.5 Bayesian Inference Engine

4.5.1 Variational Inference with Structured Posteriors

Let $z_{1:T}$ be the latent path and $a_{1:T}$ the observations. We approximate the true posterior $p(z_{1:T}|a_{1:T})$ with a variational distribution $q_\phi(z_{1:T})$ that factorizes as:

q_\phi(z_{1:T}) = q_\phi(z_1) \prod_{t=2}^T q_\phi(z_t|z_{t-1}, a_{1:t}),

with each factor parameterized as a Gaussian whose mean and covariance are outputs of a neural network conditioned on $h_t$ and $z_{t-1}$.

4.5.2 Archive Free Energy and ELBO

The Archive Free Energy is defined as the negative evidence lower bound (ELBO):

\mathcal{F}_{\mathcal{A}}(\theta,\phi) = \mathbb{E}_{q_\phi}[\sum_{t=1}^T -\log p_\theta(a_t|z_t)] + D_{KL}(q_\phi(z_{1:T}) \| p(z_{1:T})),

where $p(z_{1:T})$ is a prior over paths (e.g., from the SDE). Minimizing $\mathcal{F}_{\mathcal{A}}$ corresponds to maximizing the ELBO.

4.5.3 Hallucination Constraint via Causal Grounding

To prevent hallucinations (generation of content inconsistent with the archive), we augment the free energy with a causal grounding term $\mathcal{G}(\Gamma)$ that penalizes paths violating causal constraints derived from the archive's causal graph $G$. Specifically:

\mathcal{G}(\Gamma) = \sum_{(i,j) \in \mathcal{C}} \text{CE}(\hat{P}(a_j|do(a_i)), P_{\text{archive}}(a_j|do(a_i))),

where $\hat{P}$ is the model's predicted interventional distribution and $P_{\text{archive}}$ is estimated from the archive using do-calculus (if identifiable). For edges not in $\mathcal{C}$, we encourage high entropy (uncertainty) rather than confident predictions. The total free energy becomes:

\mathcal{F}_{\mathcal{A}}^{\text{(total)}}(\Gamma) = \mathcal{F}_{\mathcal{A}}(\Gamma) + \lambda_{\text{causal}} \mathcal{G}(\Gamma).

4.6 Action Selection and Active Inference

4.6.1 Expected Caliber and Path Integrals

Following the Maximum Caliber principle, the system should choose actions that lead to paths of high caliber (path entropy) while satisfying constraints (e.g., achieving goals). Define the expected caliber of an action $a$ as:

\mathcal{C}(a) = \mathbb{E}_{p(\Gamma|a)}[\log p(\Gamma|a)] + \beta \mathbb{E}_{p(\Gamma|a)}[U(\Gamma)],

where $U(\Gamma)$ is a utility function (e.g., negative free energy, task reward). The optimal policy is:

\pi^*(a|z) = \frac{\exp(\mathcal{C}(a))}{\sum_{a'} \exp(\mathcal{C}(a'))}.

4.6.2 Variational Path Integral Policy

Computing $\mathcal{C}(a)$ exactly requires integrating over all paths, which is intractable. We use a variational approximation: learn a policy network $\pi_\psi(a|z)$ that maximizes a lower bound on expected caliber. This is akin to a reinforcement learning objective where the reward at each step is $r_t = \log p(a_t|z_t) + \beta U(z_t)$ (with appropriate discounting), and the policy is trained via policy gradient methods.

4.6.3 Sequential Monte Carlo for Path Sampling

To estimate expectations under $p(\Gamma|a)$, we use Sequential Monte Carlo (SMC) to sample plausible future paths conditioned on current state and action. These samples are used to compute Monte Carlo estimates of the expected caliber for policy improvement.

4.6.4 Relationship to Active Inference

Our framework aligns with the Free Energy Principle and Active Inference: the system minimizes free energy by updating beliefs (perception) and selects actions that minimize expected free energy (which combines risk and ambiguity). Here, expected free energy is a special case of negative expected caliber with $U = -\text{expected free energy}$.

---

5. Learning and Inference Algorithms

5.1 Overall Training Objective

The complete training objective combines several losses:

\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{recon}} + \alpha \mathcal{L}_{\text{KL}} + \beta \mathcal{L}_{\text{geom}} + \gamma \mathcal{L}_{\text{causal}} + \delta \mathcal{L}_{\text{Lyap}} + \epsilon \mathcal{L}_{\text{gauge}},

where each term is defined below.

5.1.1 Reconstruction Losses

For each modality, we have a decoder $D_m: \mathbb{R}^d \to \mathcal{X}_m$. The reconstruction loss is:

\mathcal{L}_{\text{recon}} = \sum_{t=1}^T \sum_{m \in \mathcal{M}_t} w(e_t) \cdot \ell_m(a_t^{(m)}, D_m(z_t)),

where $\ell_m$ is a modality-specific loss (e.g., cross-entropy for text, MSE for continuous). The epistemic weight $w(e_t)$ down-weights unreliable events.

5.1.2 KL Divergence

\mathcal{L}_{\text{KL}} = D_{KL}(q_\phi(z_{1:T}) \| p_\theta(z_{1:T})),

where $p_\theta(z_{1:T})$ is the prior from the SDE dynamics.

5.1.3 Geometric Regularization from Fisher Metric

We enforce that the latent manifold's metric matches the Fisher information implied by the decoder:

\mathcal{L}_{\text{geom}} = \sum_{t} \| g_{ij}(z_t) - \hat{g}_{ij}(z_t) \|_F^2,

where $\hat{g}_{ij}(z_t)$ is the empirical Fisher computed from samples of $p_\theta(a|z_t)$. This encourages the geometry to be consistent with the observation model.

5.1.4 Causal Consistency Loss

As defined in Section 4.5.3, this penalizes violations of known causal constraints and encourages high entropy for unknown causal relations.

5.1.5 Lyapunov Regularization

Defined in Section 4.4.3.

5.1.6 Gauge-Fixing Regularization

To prevent the gauge symmetry from causing degenerate representations, we add a small gauge-fixing term that encourages the latent coordinates to align with a reference frame (e.g., by penalizing deviations from a fixed metric). This is analogous to the Faddeev-Popov procedure in gauge theory.

5.2 Variational Inference Algorithm

Algorithm 1: Variational Inference for ABM-AGI

```
Input: Archive A = {e_t} with modalities, provenance, causal graph
Output: Model parameters θ (dynamics, decoders), φ (variational)

Initialize θ, φ
while not converged:
    # Sample a minibatch of sequences
    batch = sample_sequence(A, length T)
    
    # Encode multimodal events (Sec 4.2)
    z_t^0 = encode_multimodal(batch, provenance)
    
    # Run temporal dynamics forward (Sec 4.4)
    z_1:T_pred = integrate_sde(z_0, θ_dyn, T)
    
    # Compute variational posterior q_φ(z_1:T | a_1:T)
    q_params = inference_network(batch, φ)
    z_1:T_q = sample_from_q(q_params)
    
    # Compute losses
    recon_loss = compute_reconstruction(z_1:T_q, batch, θ_dec)
    kl_loss = compute_kl(z_1:T_q, z_1:T_pred, θ_dyn)
    geom_loss = compute_geometry(z_1:T_q, θ_dec)
    causal_loss = compute_causal_consistency(z_1:T_q, batch, G)
    lyap_loss = compute_lyapunov(z_1:T_pred, θ_dyn)
    gauge_loss = compute_gauge_fixing(z_1:T_q)
    
    # Total loss
    loss = recon_loss + α*kl_loss + β*geom_loss + γ*causal_loss + δ*lyap_loss + ε*gauge_loss
    
    # Update parameters using natural gradient (Sec 5.3)
    θ, φ = natural_gradient_step(loss, θ, φ)
    
return θ, φ
```

5.3 Natural Gradient Descent

We use natural gradient to account for the information geometry of the parameter space. Let $G(\theta)$ be the Fisher information matrix of the model distribution $p_\theta(a,z)$. The natural gradient update is:

\theta \leftarrow \theta - \eta G(\theta)^{-1} \nabla_\theta \mathcal{L}.

In practice, we approximate $G(\theta)$ using the empirical Fisher from a minibatch:

\hat{G}(\theta) = \frac{1}{N} \sum_{n=1}^N \nabla_\theta \log p_\theta(a_n, z_n) \nabla_\theta \log p_\theta(a_n, z_n)^T,

and use conjugate gradient or Kronecker-factored approximations (K-FAC) for efficiency.

5.4 Gauge-Fixing Regularization

The gauge-fixing loss is:

\mathcal{L}_{\text{gauge}} = \| \nabla_z \log p_\theta(a|z) - \text{reference} \|^2,

where the reference is a fixed direction (e.g., the gradient of a simple prior). This breaks the gauge symmetry without affecting the model's expressive power, analogous to choosing a coordinate system.

5.5 Causal Discovery from Archives

While the archive provides some causal edges $\mathcal{C}$, it may be incomplete. We can augment it using causal discovery algorithms on the latent states:

5.5.1 PC Algorithm with Conditional Independence Tests

Apply the PC algorithm to the set of latent variables $z_t$, using conditional independence tests based on partial correlations or kernel methods. The resulting graph $\hat{G}$ is merged with the known $\mathcal{C}$ (with higher confidence given to known edges).

5.5.2 Additive Noise Models

For pairs of variables, test causal direction using additive noise models: fit $Y = f(X) + \epsilon$ and check independence of $\epsilon$ and $X$; if holds, direction $X \to Y$ is plausible. Use this to orient undirected edges.

5.6 Path-Integral Policy Update

Algorithm 2: Variational Path Integral Policy Optimization

```
Input: Current policy π_ψ, value function V_φ, environment model (SDE + decoder)
Output: Updated policy ψ

for each iteration:
    # Sample starting states from replay buffer or current distribution
    z_0 ~ ρ
    
    # For each action a in action space (or sample actions)
    for each a:
        # Use SMC to sample K future paths of length H conditioned on a
        paths = SMC(initial_state=z_0, action=a, model=θ, horizon=H, K)
        
        # Compute empirical expected caliber
        C_emp(a) = (1/K) Σ_{path} [ Σ_t (log p(a_t|z_t) + β U(z_t)) ]
    
    # Compute target policy probabilities
    π_target(a|z_0) = softmax(C_emp(a) / τ)
    
    # Update policy to minimize KL divergence
    ψ ← ψ - η ∇_ψ KL(π_target(·|z_0) || π_ψ(·|z_0))
    
    # Optionally update value function via regression
```

This is a form of cross-entropy method for policy optimization.

---

6. Theoretical Analysis

6.1 Convergence Guarantees

6.1.1 Convergence of Variational Inference

Under standard regularity conditions (smoothness, bounded gradients, etc.), the variational inference algorithm (Algorithm 1) converges to a local optimum of the ELBO. Specifically, if we use stochastic gradient descent with learning rate $\eta_t = O(1/t)$, the parameters converge almost surely to a stationary point of $\mathcal{F}_{\mathcal{A}}$.

6.1.2 Convergence of Natural Gradient

Natural gradient descent on a convex objective in the space of distributions converges at a rate independent of parameterization. For the ELBO, which is convex in the variational parameters for certain families (e.g., exponential families), natural gradient achieves optimal convergence.

6.2 Generalization Bounds

6.2.1 Archive-Specific Generalization Bound

Let $\mathcal{A}$ be an archive of size $T$, and let $\ell(\theta, a)$ be the prediction loss on a future event $a$. Then with probability at least $1-\delta$ over the archive generation process,

\mathbb{E}[\ell(\theta, a_{\text{new}})] \leq \frac{1}{T} \sum_{t=1}^T \ell(\theta, a_t) + O\left(\sqrt{\frac{\text{Complexity}(\theta) + \log(1/\delta)}{T}}\right),

where $\text{Complexity}(\theta)$ is a measure like the VC dimension or Rademacher complexity. The bound leverages the temporal dependence; under mixing conditions, the effective sample size is $T/\tau_{\text{mix}}$.

6.3 Emergence of Generalization: Phase Transition

We define generalization as the ability to perform zero-shot causal inference on unseen interventions. We claim that this capability emerges when the latent manifold's dimension exceeds a threshold related to the data's topological dimension and the Lyapunov spectrum.

6.3.1 Topological Dimension and Embedding Capacity

Let $d_{\text{topo}}$ be the topological dimension of the data manifold (the minimal dimension needed to embed the data without self-intersection). According to the Whitney embedding theorem, a smooth $d_{\text{topo}}$-dimensional manifold can be embedded in $\mathbb{R}^{2d_{\text{topo}}}$. For successful generalization, we need $d > d_{\text{topo}}$ to allow for extra degrees of freedom to represent unseen variations.

6.3.2 Lyapunov Exponents and Flexibility

The Lyapunov exponents characterize the system's sensitivity to perturbations. A positive exponent indicates that nearby trajectories diverge, providing flexibility to adapt to novel inputs. However, too much chaos can destabilize representations. We require that the sum of positive exponents $\Lambda_+ = \sum_{\lambda_i>0} \lambda_i$ is positive but bounded.

6.3.3 Theorem: Condition for Zero-Shot Causal Inference

Theorem 1 (Emergence of Generalization). Let $\mathcal{A}$ be an archive generated by a dynamical system with topological dimension $d_{\text{topo}}$ and Lyapunov exponents $\lambda_i$. Let the ABM-AGI have latent dimension $d$ and be trained to minimize $\mathcal{F}_{\mathcal{A}}^{\text{(total)}}$ with causal consistency loss. If

d > 2 d_{\text{topo}} \quad \text{and} \quad \Lambda_+ > \lambda_{\text{crit}},

where $\lambda_{\text{crit}}$ is a problem-dependent threshold, then with high probability the system achieves zero-shot causal inference on a set of unseen interventions that are consistent with the archive's causal structure.

Proof Sketch. The first condition ensures that the latent space has enough capacity to represent the data manifold and its possible variations without topological obstructions. The second condition ensures that the dynamics are sufficiently sensitive to perturbations to adapt to new situations. The causal consistency loss forces the learned model to align with the true causal graph. By a covering argument, one can show that the model's predictions on unseen interventions are close to the true interventional distributions, provided the interventions are within the support of the training distribution's causal mechanisms. The Lyapunov condition guarantees that small changes in initial conditions lead to distinct trajectories, allowing the model to explore the space of possible interventions.

6.3.4 Phase Transition Interpretation

This theorem suggests a phase transition: as we increase latent dimension $d$ past the critical value $2d_{\text{topo}}$, and as the dynamics become sufficiently flexible (positive Lyapunov exponents), the system transitions from memorization (overfitting to the archive) to genuine world simulation (generalizing to new scenarios). This can be empirically observed by plotting generalization performance against $d$ and $\Lambda_+$.

6.4 Hallucination Constraint and Causal Consistency

6.4.1 Causal Grounding Term

Recall the causal grounding term $\mathcal{G}(\Gamma)$ measures divergence from known causal constraints. We prove that under dense archives (where every causal relation is observed in multiple contexts), this term effectively suppresses hallucinations.

6.4.2 Theorem: Hallucination Suppression under Dense Archives

Theorem 2 (Hallucination Suppression). Let $\mathcal{A}$ be an archive with causal graph $G$ and let $\Gamma$ be a path generated by the ABM-AGI. Suppose that for every causal relation $(i,j) \in \mathcal{C}$, the archive contains multiple instances with different contexts that identify the causal effect. Then any path $\Gamma$ that violates a causal constraint (i.e., predicts an interventional distribution different from the true one) incurs a penalty $\mathcal{G}(\Gamma) \geq \epsilon > 0$. Consequently, as training minimizes $\mathcal{F}_{\mathcal{A}}^{\text{(total)}}$, the probability of such hallucinated paths goes to zero.

Proof Sketch. The causal grounding term is a sum of divergences. Under dense identification, the true interventional distribution is uniquely determined from the archive. Any deviation yields a positive KL divergence. Since the total free energy includes this term with weight $\lambda_{\text{causal}}$, the optimal solution must have $\mathcal{G}=0$ almost surely. By standard concentration arguments, the learned model converges to the true causal mechanisms.

---

7. Experimental Evaluation (Proposed)

While this thesis does not include experimental results, we propose a comprehensive evaluation framework to be implemented in future work.

7.1 Synthetic Archives

7.1.1 Virtual Chemistry Lab

We propose generating a synthetic archive of a virtual chemistry lab with:

· Sensor logs (temperature, pressure, pH) from reactions.
· Experimenter notes (text) describing procedures and observations.
· Video sequences of reactions.
· A ground-truth causal graph of chemical reactions (e.g., mixing A and B produces C with heat).
· Provenance: primary sensors have high weight; human notes have lower weight.

This archive will be used to test all components: cross-modal alignment, temporal prediction, causal discovery, and generalization to new reactions.

7.1.2 Double Pendulum with Text Logs

A simple physical system (double pendulum) with state variables (angles, velocities) and text logs describing observations (e.g., "the pendulum is swinging chaotically"). The task is to predict future states and answer counterfactuals ("what if we increased the mass of the lower bob?"). This tests the SDE dynamics and causal reasoning.

7.2 Real-World Archives

7.2.1 NASA Mission Logs

Publicly available mission logs (e.g., Apollo, Space Shuttle) include telemetry, astronaut communications, images, and incident reports. These provide rich multimodal, temporal, and causal data. The task could be to predict anomalies or reconstruct mission timelines.

7.2.2 Historical News Archives

Datasets like the New York Times Archive (1851-present) contain text, images, and metadata. We can use these to test cross-modal reasoning and temporal narrative reconstruction.

7.3 Evaluation Metrics

7.3.1 Reconstruction Quality

· Perplexity for text.
· FID for images.
· MSE for sensor data.

7.3.2 Temporal Prediction

· Prediction error at various horizons.
· Continuous Ranked Probability Score (CRPS) for probabilistic forecasts.

7.3.3 Causal Inference

· Structural Hamming Distance (SHD) for recovered causal graphs.
· AUROC for causal direction classification.
· Intervention accuracy: compare predicted interventional distributions to ground truth using KL divergence.

7.3.4 Cross-Modal Transfer

· Zero-shot retrieval: given a query in one modality, retrieve corresponding events in another modality.
· Analogy completion: $z_A : z_B :: z_C : ?$ measured by parallel transport.

7.3.5 Generalization

· Zero-shot causal inference on unseen interventions.
· Few-shot learning on novel event types.

7.3.6 Hallucination Rate

· Percentage of generated content that contradicts archive evidence (as judged by humans or automated consistency checks).

7.4 Baselines and Ablations

We propose comparing against:

· Standard LLMs (GPT-4, Llama 3) with retrieval augmentation.
· Multimodal models (Flamingo, GATO).
· Pure Bayesian models (e.g., DBNs).
· Ablated versions of ABM-AGI (without geometry, without causal loss, without Lyapunov regularization).

---

8. Discussion and Limitations

8.1 Epistemic Uncertainty and the Closed-World Trap

A key limitation is that archives are necessarily incomplete; they do not cover all possible scenarios. Our framework addresses this by maintaining high entropy (uncertainty) for unseen causal relations, but it cannot guarantee correct extrapolation into genuinely novel domains. This is the closed-world trap: the system may fail when faced with situations outside the archive's coverage. Future work should explore mechanisms for safe extrapolation, perhaps by combining archival learning with first-principles physics or interactive learning.

8.2 Computational Complexity

The full architecture is computationally intensive: geodesic computations, SDE integration, SMC sampling, and natural gradient updates all scale poorly. Practical implementations will need approximations (e.g., using neural networks to approximate geodesics, using variational inference for SMC). The trade-off between fidelity and efficiency is an important engineering challenge.

8.3 Ethical Considerations

An AGI trained on historical archives may inherit biases present in those archives. Provenance weighting can mitigate some biases (by down-weighting unreliable sources), but cannot eliminate them entirely. Careful curation and transparency are essential.

8.4 Future Work

· Incorporate interactive learning: allow the system to query the archive or perform experiments to reduce uncertainty.
· Extend to multi-agent archives: archives of social interactions, enabling modeling of collective behavior.
· Theoretical extensions: prove identifiability conditions for latent dynamics under partial observability.
· Hardware acceleration: design specialized hardware for geodesic computations and SMC.

---

9. Conclusion

This thesis has presented a comprehensive mathematical and architectural framework for Archive-Based Multimodal AGI. By grounding learning in the rich structure of historical archives—temporal density, multimodal integration, provenance, and causal ground truth—we have argued that AGI systems can achieve genuine generalization beyond pattern matching. The framework unifies concepts from information geometry, non-equilibrium thermodynamics, dynamical systems, and Bayesian inference into a coherent whole.

Key contributions include: the formal definition of an archive, the Archive Free Energy functional, the Maximum Algorithmic Caliber principle, the geometrodynamic latent space with Fisher metric, a hybrid architecture with hallucination constraint, and theoretical conditions for emergent generalization. Detailed algorithms and loss functions provide a roadmap for implementation.

While experimental validation remains for future work, the theoretical foundations established here offer a rigorous starting point for building AGI systems that respect the epistemic authority of evidence while enabling creative, physically-plausible reasoning. The path to AGI lies not in scaling current architectures indefinitely, but in reimagining how intelligence models the world—through the lens of historical dynamics, causal structure, and geometric principles.

Appendices

Archive-Based Multimodal AGI: Mathematical Foundations and Proofs

---

Appendix A: Detailed Mathematical Derivations

A.1 Information Geometry of the Latent Manifold

A.1.1 Derivation of the Fisher Information Metric

Let $p_\theta(a|z)$ be the observation model, where $z \in \mathbb{R}^d$ is the latent state and $a \in \mathcal{A}$ is an observation. The Fisher information matrix at $z$ is defined as:

g_{ij}(z) = \mathbb{E}_{p(a|z)}\left[\frac{\partial \log p(a|z)}{\partial z^i} \frac{\partial \log p(a|z)}{\partial z^j}\right].

For exponential family distributions, this takes a particularly simple form. Suppose $p(a|z) = h(a) \exp\left(\eta(z)^T T(a) - A(\eta(z))\right)$, where $\eta(z)$ are the natural parameters. Then:

\frac{\partial \log p}{\partial z^i} = \frac{\partial \eta^T}{\partial z^i} (T(a) - \nabla_\eta A).

The Fisher information becomes:

g_{ij}(z) = \frac{\partial \eta^T}{\partial z^i} \mathbb{E}[(T - \nabla_\eta A)(T - \nabla_\eta A)^T] \frac{\partial \eta}{\partial z^j} = \frac{\partial \eta^T}{\partial z^i} \nabla^2_\eta A \frac{\partial \eta}{\partial z^j},

since $\mathbb{E}[T] = \nabla_\eta A$ and $\text{Cov}(T) = \nabla^2_\eta A$. Thus, the metric pulls back the Fisher information of the observation distribution to the latent space.

A.1.2 Geodesic Equation Derivation

The geodesic distance between two points $z_1, z_2$ on a Riemannian manifold with metric $g_{ij}$ minimizes the energy functional:

E[\gamma] = \frac{1}{2} \int_0^1 g_{ij}(\gamma(t)) \dot{\gamma}^i(t) \dot{\gamma}^j(t) dt.

The Euler-Lagrange equations yield:

\frac{d}{dt}\left(g_{ij} \dot{\gamma}^j\right) - \frac{1}{2} \frac{\partial g_{jk}}{\partial \gamma^i} \dot{\gamma}^j \dot{\gamma}^k = 0.

Expanding the first term:

g_{ij} \ddot{\gamma}^j + \frac{\partial g_{ij}}{\partial \gamma^k} \dot{\gamma}^k \dot{\gamma}^j - \frac{1}{2} \frac{\partial g_{jk}}{\partial \gamma^i} \dot{\gamma}^j \dot{\gamma}^k = 0.

Multiplying by the inverse metric $g^{li}$ and using symmetry:

\ddot{\gamma}^l + \frac{1}{2} g^{li}\left(\frac{\partial g_{ij}}{\partial \gamma^k} + \frac{\partial g_{ik}}{\partial \gamma^j} - \frac{\partial g_{jk}}{\partial \gamma^i}\right) \dot{\gamma}^j \dot{\gamma}^k = 0.

The Christoffel symbols are:

\Gamma^l_{jk} = \frac{1}{2} g^{li}\left(\frac{\partial g_{ij}}{\partial \gamma^k} + \frac{\partial g_{ik}}{\partial \gamma^j} - \frac{\partial g_{jk}}{\partial \gamma^i}\right).

Thus, the geodesic equation is:

\ddot{\gamma}^l + \Gamma^l_{jk} \dot{\gamma}^j \dot{\gamma}^k = 0.

A.1.3 Parallel Transport

A vector field $v(t)$ along a curve $\gamma(t)$ is parallel if its covariant derivative vanishes:

\frac{D v^k}{dt} = \frac{d v^k}{dt} + \Gamma^k_{ij} v^i \frac{d\gamma^j}{dt} = 0.

For analogical reasoning, suppose we have a relation $A \to B$ represented by the vector $v = \dot{\gamma}_{AB}(0)$ at $A$. To apply this relation to $C$, we parallel transport $v$ along the geodesic from $A$ to $C$, obtaining $v'$. The analog of $B$ for $C$ is then $\exp_C(\epsilon v')$ for small $\epsilon$, or more generally, the endpoint of the geodesic starting at $C$ with initial velocity $v'$.

A.2 Derivation of Archive Free Energy

A.2.1 Evidence Lower Bound

The log marginal likelihood of an archive $\mathcal{A} = a_{1:T}$ is:

\log p_\theta(a_{1:T}) = \log \int p_\theta(a_{1:T}, z_{1:T}) dz_{1:T}.

For any variational distribution $q_\phi(z_{1:T})$, we have:

\log p_\theta(a_{1:T}) = D_{KL}(q_\phi \| p_\theta(\cdot|a_{1:T})) + \mathcal{L}(\theta,\phi),

where $\mathcal{L}(\theta,\phi)$ is the ELBO:

\mathcal{L}(\theta,\phi) = \mathbb{E}_{q_\phi}[\log p_\theta(a_{1:T}, z_{1:T}) - \log q_\phi(z_{1:T})].

The Archive Free Energy is defined as the negative ELBO:

\mathcal{F}_{\mathcal{A}}(\theta,\phi) = -\mathcal{L}(\theta,\phi) = \mathbb{E}_{q_\phi}[-\log p_\theta(a_{1:T}|z_{1:T})] + D_{KL}(q_\phi(z_{1:T}) \| p_\theta(z_{1:T})).

A.2.2 Temporal Decomposition

For the structured variational family $q_\phi(z_{1:T}) = q_\phi(z_1) \prod_{t=2}^T q_\phi(z_t|z_{t-1}, a_{1:t})$, and prior $p_\theta(z_{1:T}) = p_\theta(z_1) \prod_{t=2}^T p_\theta(z_t|z_{t-1})$, the KL divergence decomposes as:

D_{KL}(q_\phi \| p_\theta) = D_{KL}(q_\phi(z_1) \| p_\theta(z_1)) + \sum_{t=2}^T \mathbb{E}_{q_\phi(z_{1:t-1})}[D_{KL}(q_\phi(z_t|z_{t-1}, a_{1:t}) \| p_\theta(z_t|z_{t-1}))].

A.2.3 Connection to Thermodynamic Free Energy

In statistical mechanics, the free energy is $F = U - TS$, where $U$ is internal energy, $T$ temperature, and $S$ entropy. Here, identify:

· Internal energy: $U = \mathbb{E}_{q_\phi}[-\log p_\theta(a_{1:T}|z_{1:T})]$ (negative log-likelihood, or "energy" of the data given latent state)
· Temperature: $T = 1$ (in appropriate units)
· Entropy: $S = -D_{KL}(q_\phi \| p_\theta) + \text{constant}$? More directly, the negative ELBO has the form of a free energy where the entropy term is the negative KL divergence.

A.3 Maximum Caliber Principle Derivation

A.3.1 Path Entropy (Caliber)

Consider an ensemble of paths $\Gamma = \{z_0, z_1, \ldots, z_T\}$. The caliber (path entropy) is:

\mathcal{C} = -\sum_{\Gamma} p(\Gamma) \log p(\Gamma).

We wish to maximize $\mathcal{C}$ subject to constraints $\mathbb{E}_p[g_m(\Gamma)] = G_m$ for $m=1,\ldots,M$, and $\sum_\Gamma p(\Gamma) = 1$.

Using Lagrange multipliers $\gamma_m$ and $\lambda$ for normalization, we maximize:

\mathcal{L} = -\sum_\Gamma p(\Gamma) \log p(\Gamma) - \sum_m \gamma_m \left(\sum_\Gamma p(\Gamma) g_m(\Gamma) - G_m\right) - \lambda \left(\sum_\Gamma p(\Gamma) - 1\right).

Taking derivative with respect to $p(\Gamma)$:

\frac{\partial \mathcal{L}}{\partial p(\Gamma)} = -\log p(\Gamma) - 1 - \sum_m \gamma_m g_m(\Gamma) - \lambda = 0.

Solving:

p(\Gamma) = \exp\left(-1 - \lambda - \sum_m \gamma_m g_m(\Gamma)\right).

Normalization gives:

p(\Gamma) = \frac{1}{\mathcal{Z}(\gamma)} \exp\left(-\sum_m \gamma_m g_m(\Gamma)\right),

where $\mathcal{Z}(\gamma) = \sum_\Gamma \exp\left(-\sum_m \gamma_m g_m(\Gamma)\right)$ is the path partition function.

A.3.2 Connection to Archive Free Energy

If we set constraints to match the expected Archive Free Energy, i.e., $g_1(\Gamma) = \mathcal{F}_{\mathcal{A}}(\Gamma)$ with $\gamma_1 = \beta$, we obtain:

p(\Gamma) \propto e^{-\beta \mathcal{F}_{\mathcal{A}}(\Gamma)}.

Thus, the Maximum Caliber principle yields the Gibbs distribution over paths, with the Archive Free Energy as the Hamiltonian.

A.3.3 Algorithmic Caliber

Following Tadaki, define the algorithmic caliber as:

\mathcal{C}_{\text{alg}} = -\sum_\Pi p(\Pi) \log p(\Pi) + \sum_m \gamma_m \mathbb{E}_p[K(g_m(\Pi))],

where $K(\cdot)$ is Kolmogorov complexity. This extends the principle to computational paths, where constraints are on the algorithmic complexity of observables.

A.4 Gauge Theory in Transformers

A.4.1 Gauge Invariance of Attention

Consider a transformer layer with query, key, value matrices $Q, K, V \in \mathbb{R}^{n \times d}$. The attention output is:

\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d}}\right) V.

Under a simultaneous transformation $Q \to Q\Lambda^{-1}$, $K \to K\Lambda^T$, $V \to V\Lambda$ for invertible $\Lambda \in GL(d)$, we have:

QK^T \to (Q\Lambda^{-1})(K\Lambda^T)^T = Q\Lambda^{-1} \Lambda K^T = QK^T,

so the attention matrix is invariant. The output becomes:

\text{Attention} \cdot (V\Lambda) = (\text{Attention} \cdot V) \Lambda,

which is not invariant unless we also transform the subsequent layers accordingly. In a full transformer, this gauge symmetry relates to the internal representation's coordinate freedom.

A.4.2 Gauge-Fixing Regularization

To break the gauge symmetry without affecting expressive power, we add a gauge-fixing term that penalizes deviations from a reference metric. In analogy with the Faddeev-Popov method, we introduce:

\mathcal{L}_{\text{gauge}} = \| \nabla_z \log p_\theta(a|z) - \text{ref}(z) \|^2,

where $\text{ref}(z)$ is a fixed direction (e.g., gradient of a simple prior). This selects a specific gauge without constraining the model's ability to represent distributions.

A.4.3 Holonomy and Parallel Transport

The attention mechanism can be viewed as a connection that parallel-transports token representations. The holonomy of this connection around a closed loop in token space measures the curvature of the representation manifold. In our geometrodynamic latent space, we explicitly construct the metric and connection, ensuring that the attention mechanism respects this geometry.

---

Appendix B: Detailed Proofs of Theorems

B.1 Proof of Theorem 1 (Emergence of Generalization)

Theorem 1 (Emergence of Generalization). Let $\mathcal{A}$ be an archive generated by a dynamical system with topological dimension $d_{\text{topo}}$ and Lyapunov exponents $\lambda_i$. Let the ABM-AGI have latent dimension $d$ and be trained to minimize $\mathcal{F}_{\mathcal{A}}^{\text{(total)}}$ with causal consistency loss. If

d > 2 d_{\text{topo}} \quad \text{and} \quad \Lambda_+ > \lambda_{\text{crit}},

where $\Lambda_+ = \sum_{\lambda_i>0} \lambda_i$, then with high probability the system achieves zero-shot causal inference on a set of unseen interventions that are consistent with the archive's causal structure.

Proof.

We proceed in several steps.

Step 1: Manifold Learning and Embedding

Let $\mathcal{M}$ be the data manifold of observations $a$, with topological dimension $d_{\text{topo}}$. The encoder $E$ maps $\mathcal{M}$ to the latent space $\mathbb{R}^d$. By the Whitney embedding theorem, a smooth $d_{\text{topo}}$-dimensional manifold can be embedded in $\mathbb{R}^{2d_{\text{topo}}}$. Since $d > 2d_{\text{topo}}$, there exists an embedding $f: \mathcal{M} \to \mathbb{R}^d$ that preserves the manifold structure. The training objective (reconstruction + geometric regularization) ensures that the learned encoder approximates such an embedding, up to a diffeomorphism. Thus, the latent representation is a faithful embedding of the data manifold.

Step 2: Learning the Dynamics

The neural SDE learns the latent dynamics $dz_t = \mu_\theta dt + \sigma_\theta dW_t$. By the universal approximation theorem for SDEs (given sufficient capacity), the learned dynamics can approximate the true generating dynamics arbitrarily well on the training archive. The Lyapunov regularization ensures that the learned dynamics have positive exponents $\Lambda_+$ matching the true system (which is assumed to be slightly chaotic, $\Lambda_+ > 0$).

Step 3: Causal Consistency

The causal consistency loss $\mathcal{L}_{\text{causal}}$ forces the model's interventional predictions to match the archive's causal graph $G$ on observed interventions. Under dense observations (each causal relation observed in multiple contexts), the true causal mechanisms are identified. By standard results in causal inference (e.g., Pearl's do-calculus completeness), the interventional distributions are uniquely determined from the observational distribution and the causal graph. The model, trained to minimize divergence from these distributions, converges to the true mechanisms.

Step 4: Generalization to Unseen Interventions

Consider an unseen intervention $do(X=x)$ on a variable $X$ in the causal graph. The intervention modifies the structural equation for $X$, replacing it with $X=x$. This induces a new distribution over the remaining variables. In the latent space, this corresponds to a perturbation of the latent state $z$ along the direction corresponding to $X$.

The latent dynamics, being a diffeomorphic image of the true dynamics, support parallel transport of the effect of interventions. Specifically, the effect of intervening on $X$ is encoded in the geometry: there is a vector field $v_X(z)$ representing the "causal direction" of $X$. For a new intervention, we apply this vector field to the current state.

The positive Lyapunov exponents ensure that small perturbations (like applying $v_X$) lead to distinct trajectories, allowing the system to explore the space of possible outcomes. The condition $\Lambda_+ > \lambda_{\text{crit}}$ ensures that the system is sufficiently sensitive to perturbations to distinguish different interventions, but not so chaotic that representations become unstable.

Step 5: Zero-Shot Accuracy

Let $I_{\text{new}}$ be an unseen intervention. The model's predicted interventional distribution $\hat{P}(Y|do(X=x))$ is obtained by:

1. Starting from a latent state $z_0$ representing the pre-intervention context.
2. Perturbing $z_0$ along the causal direction $v_X$ by an amount corresponding to $x$.
3. Evolving the SDE forward to obtain the distribution over future latent states.
4. Decoding to observations.

By the embedding faithfulness (Step 1), dynamics accuracy (Step 2), and causal consistency (Step 3), this procedure approximates the true interventional distribution. The approximation error is bounded by:

\|\hat{P} - P_{\text{true}}\|_{\text{TV}} \leq \epsilon_{\text{embed}} + \epsilon_{\text{dyn}} + \epsilon_{\text{causal}},

where each $\epsilon$ is small given sufficient training. The Lyapunov condition ensures that the sensitivity to the intervention magnitude is well-calibrated.

Step 6: Probability Bound

By standard concentration inequalities (e.g., Bernstein's inequality for mixing processes), with probability at least $1-\delta$, the errors are bounded by $O(\sqrt{(\text{complexity} + \log(1/\delta))/T})$, where $T$ is the archive size. Thus, for large $T$, the model achieves high accuracy on unseen interventions.

∎

B.2 Proof of Theorem 2 (Hallucination Suppression)

Theorem 2 (Hallucination Suppression). Let $\mathcal{A}$ be an archive with causal graph $G$ and let $\Gamma$ be a path generated by the ABM-AGI. Suppose that for every causal relation $(i,j) \in \mathcal{C}$, the archive contains multiple instances with different contexts that identify the causal effect. Then any path $\Gamma$ that violates a causal constraint incurs a penalty $\mathcal{G}(\Gamma) \geq \epsilon > 0$. Consequently, as training minimizes $\mathcal{F}_{\mathcal{A}}^{\text{(total)}}$, the probability of such hallucinated paths goes to zero.

Proof.

Step 1: Identifiability of Causal Effects

For each causal relation $(i,j) \in \mathcal{C}$, assume the archive contains multiple contexts $C$ such that the causal effect $P(a_j|do(a_i), C)$ is identifiable from the observational distribution via the do-calculus. By the completeness of do-calculus for Markovian models, the interventional distribution is uniquely determined by the observational distribution and the causal graph.

Step 2: Consistency of Empirical Estimates

From the archive, we can estimate the true interventional distribution $P_{\text{true}}(a_j|do(a_i), C)$ consistently (e.g., via plug-in estimators). Let $\hat{P}_{\text{archive}}$ be such an estimate. By the law of large numbers for dependent data (under mixing conditions), with high probability, $\|\hat{P}_{\text{archive}} - P_{\text{true}}\|_{\text{TV}} \leq \delta_T$, where $\delta_T \to 0$ as archive size $T \to \infty$.

Step 3: Hallucination Penalty

For a path $\Gamma$ that generates predictions, we compute the model's implied interventional distribution $\hat{P}_{\text{model}}(a_j|do(a_i), C)$. The causal grounding term is:

\mathcal{G}(\Gamma) = \sum_{(i,j) \in \mathcal{C}} \text{CE}(\hat{P}_{\text{model}}(a_j|do(a_i)), \hat{P}_{\text{archive}}(a_j|do(a_i))),

where CE is the cross-entropy (or KL divergence). If $\Gamma$ violates the causal constraint, then $\hat{P}_{\text{model}}$ differs from $\hat{P}_{\text{archive}}$ by at least some amount. More precisely, by the identifiability condition, if $\hat{P}_{\text{model}} \neq P_{\text{true}}$, then $\text{KL}(P_{\text{true}} \| \hat{P}_{\text{model}}) > 0$. Since $\hat{P}_{\text{archive}}$ is close to $P_{\text{true}}$, we have $\text{CE}(\hat{P}_{\text{model}}, \hat{P}_{\text{archive}}) \geq \text{KL}(P_{\text{true}} \| \hat{P}_{\text{model}}) - \delta_T \geq \epsilon/2$ for sufficiently large $T$, where $\epsilon = \min_{\text{violations}} \text{KL}(P_{\text{true}} \| \hat{P}_{\text{model}})$.

Step 4: Free Energy Minimization

The total free energy is $\mathcal{F}_{\mathcal{A}}^{\text{(total)}}(\Gamma) = \mathcal{F}_{\mathcal{A}}(\Gamma) + \lambda_{\text{causal}} \mathcal{G}(\Gamma)$. For any path $\Gamma$ that violates causal constraints, $\mathcal{G}(\Gamma) \geq \epsilon$. As training minimizes the expected free energy, the variational distribution $q_\phi$ will assign vanishing probability to such paths, because any positive probability would incur a penalty that cannot be offset by improvements in reconstruction or KL (which are bounded below by the optimal achievable value).

Formally, let $q^*$ be the minimizer of $\mathcal{F}_{\mathcal{A}}^{\text{(total)}}$. For any $\Gamma$ with $\mathcal{G}(\Gamma) \geq \epsilon$, we have $q^*(\Gamma) = 0$ almost surely, otherwise $\mathcal{F}_{\mathcal{A}}^{\text{(total)}}$ would be infinite. In practice, with finite samples, the probability of sampling such a path goes to zero as training converges.

∎

B.3 Proof of Convergence for Variational Inference

Lemma 1 (Convergence of Stochastic Variational Inference). Under standard regularity conditions (twice-differentiable ELBO, bounded gradients, Robbins-Monro learning rate), Algorithm 1 converges almost surely to a stationary point of $\mathcal{F}_{\mathcal{A}}$.

Proof Sketch. The ELBO is a smooth function of the variational parameters $\phi$ and model parameters $\theta$. The stochastic gradients computed from minibatches are unbiased estimates of the true gradient. The learning rate satisfies $\sum \eta_t = \infty$ and $\sum \eta_t^2 < \infty$. By the Robbins-Monro theorem, the parameters converge almost surely to a stationary point. The use of natural gradient (which is a Riemannian gradient descent) preserves these convergence properties while improving conditioning.

B.4 Proof of Generalization Bound

Theorem 3 (Archive Generalization Bound). Let $\mathcal{A}$ be an archive of size $T$ generated by a $\beta$-mixing process with mixing coefficient $\beta(k)$. Let $\ell(\theta, a)$ be a bounded loss function. Then with probability at least $1-\delta$,

\mathbb{E}[\ell(\theta, a_{\text{new}})] \leq \frac{1}{T} \sum_{t=1}^T \ell(\theta, a_t) + O\left(\sqrt{\frac{\mathcal{R}_T(\Theta) + \log(1/\delta)}{T}}\right),

where $\mathcal{R}_T(\Theta)$ is the Rademacher complexity of the hypothesis class $\Theta$ for dependent data.

Proof Sketch. For $\beta$-mixing processes, we can use a blocking technique to convert the dependent sequence into approximately independent blocks. The effective sample size is $T / \nu$, where $\nu$ is the mixing time. Standard Rademacher complexity bounds for i.i.d. data then apply, with a factor accounting for the dependence. The detailed proof follows Yu (1994) and Mohri & Rostamizadeh (2010).

---

Appendix C: Algorithmic Details and Pseudocode

C.1 Geodesic Distance Computation

Algorithm C.1: Geodesic Distance via Shooting Method

```
Input: Manifold points z1, z2, metric tensor g, step size η, tolerance ε
Output: Geodesic distance d(z1, z2)

# Initialize velocity estimate
v0 = (z2 - z1) / ||z2 - z1||

# Shooting method: iterate to find initial velocity that hits z2
while not converged:
    # Integrate geodesic equations from z1 with initial velocity v
    z, v = integrate_geodesic(z1, v0, T=1, η)
    
    # Compute error at final point
    error = ||z - z2||
    
    # Adjust initial velocity using sensitivity (adjoint method)
    v0 = v0 - α * J^T * error  # J is Jacobian of final point w.r.t. initial velocity
    
    if error < ε:
        break

# Compute distance along geodesic
d = ∫_0^1 sqrt(g_ij(z(t)) ˙z^i ˙z^j) dt

return d
```

Algorithm C.2: Geodesic Distance via Fast Marching (for offline computation)

```
Input: Set of latent points Z, metric tensor field g
Output: Distance matrix D_ij = d(z_i, z_j)

# Construct graph connecting nearby points
G = kNN_graph(Z, k)

# Assign edge weights based on metric approximation
for each edge (i,j):
    Δz = z_j - z_i
    w_ij = sqrt(Δz^T g((z_i+z_j)/2) Δz)

# Compute all-pairs shortest paths (Dijkstra or Floyd-Warshall)
D = all_pairs_shortest_paths(G, weights)

return D
```

C.2 Neural SDE Integration

Algorithm C.3: Euler-Maruyama Integration for Neural SDE

```
Input: Initial state z0, drift network μ, diffusion network σ, time steps t0,...,tN, Wiener process dW
Output: Trajectory z_0:N

z[0] = z0
for n = 0 to N-1:
    Δt = t_{n+1} - t_n
    z[n+1] = z[n] + μ(z[n], t_n) * Δt + σ(z[n], t_n) * dW[n]
    
return z
```

For improved accuracy, use higher-order methods like Milstein or stochastic Runge-Kutta.

C.3 Sequential Monte Carlo for Path Sampling

Algorithm C.4: SMC for Future Path Prediction

```
Input: Current latent state z_t, action a, horizon H, number of particles K, model θ
Output: Weighted samples of future paths

# Initialize particles
for k = 1 to K:
    z_k[0] = z_t
    log_w_k[0] = 0

for h = 1 to H:
    # Propagate particles using SDE
    for k = 1 to K:
        z_k[h] = sde_step(z_k[h-1], a, θ)
    
    # Compute importance weights (e.g., based on likelihood of any observations)
    for k = 1 to K:
        log_w_k[h] = log_w_k[h-1] + log p(o_h | z_k[h], θ)  # if observations available
    
    # Resample if effective sample size too low
    ESS = 1 / sum(exp(2*log_w_k[h]) )
    if ESS < K/2:
        indices = resample(log_w_k[h])
        z_k[0:h] = z_{indices}[0:h]
        log_w_k[h] = 0

# Final weights
for k = 1 to K:
    w_k = exp(log_w_k[H]) / sum(exp(log_w_k[H]))

return {z_k[0:H], w_k}
```

C.4 Natural Gradient with K-FAC Approximation

Algorithm C.5: K-FAC Natural Gradient Update

```
Input: Loss L, parameters θ (layerwise), learning rate η
Output: Updated parameters

for each layer l:
    # Compute gradients ∇L w.r.t. weights W_l and biases b_l
    gW = ∇_{W_l} L
    gb = ∇_{b_l} L
    
    # Compute input activations a and output gradients δ from backward pass
    # Estimate Fisher blocks
    A = E[a a^T]  # input covariance
    G = E[δ δ^T]  # output gradient covariance
    
    # K-FAC approximation: F ≈ A ⊗ G
    # Natural gradient update: ΔW = -η * (A^{-1} gW G^{-1})
    ΔW = -η * solve(A, gW)  # or use Cholesky for efficiency
    ΔW = ΔW * solve(G, I)   # careful with dimensions
    
    # Update parameters
    W_l = W_l + ΔW
    b_l = b_l - η * gb  # biases often use standard gradient
```

---

Appendix D: Causal Inference Details

D.1 Do-Calculus Rules

Pearl's do-calculus consists of three rules for transforming expressions involving interventions:

Rule 1 (Insertion/deletion of observations):
P(y|do(x), z, w) = P(y|do(x), w) \quad \text{if } Y \perp Z | X, W \text{ in } G_{\overline{X}}

Rule 2 (Action/observation exchange):
P(y|do(x), do(z), w) = P(y|do(x), z, w) \quad \text{if } Y \perp Z | X, W \text{ in } G_{\overline{X}\underline{Z}}

Rule 3 (Insertion/deletion of actions):
P(y|do(x), do(z), w) = P(y|do(x), w) \quad \text{if } Y \perp Z | X, W \text{ in } G_{\overline{X}\overline{Z(W)}}

where $G_{\overline{X}}$ is the graph with all incoming edges to $X$ removed, $G_{\underline{Z}}$ with all outgoing edges from $Z$ removed, and $Z(W)$ is the set of $Z$-nodes not ancestors of $W$.

D.2 PC Algorithm

Algorithm D.1: PC Algorithm for Causal Discovery

```
Input: Set of variables V, conditional independence test Indep(X,Y|S)
Output: Causal graph G

# Step 1: Learn skeleton
Start with complete undirected graph on V
n = 0
repeat:
    for each adjacent pair (X,Y) with |Adj(X)\{Y}| ≥ n:
        for each S ⊆ Adj(X)\{Y} with |S| = n:
            if Indep(X,Y|S):
                remove edge X-Y
                record separating set S(X,Y)
    n = n+1
until |Adj(X)\{Y}| < n for all pairs

# Step 2: Orient edges
for each unshielded triple X-Z-Y (X-Y not adjacent, X-Z and Z-Y adjacent):
    if Z not in S(X,Y):
        orient X → Z ← Y (v-structure)

# Step 3: Propagate orientations
repeat:
    apply Meek rules until no more edges can be oriented:
        R1: If X → Y, Y-Z, X-Z not adjacent, orient Y → Z
        R2: If X → Y, X → Z, Y-Z, orient Y → Z
        R3: If X → Y, X ← Z, Y-Z, orient Y → Z
        R4: If X → Y, Z → Y, X-Z, orient X → Z

return G
```

D.3 Additive Noise Models

For two variables $X, Y$, test causal direction $X \to Y$ by fitting:

Y = f(X) + \epsilon, \quad \epsilon \perp X.

If the residual $\epsilon$ is independent of $X$ (test via HSIC or other independence test), the direction is plausible. Then test the reverse direction $Y \to X$; if only one direction passes, we have identified the causal direction.

---

Appendix E: Hyperparameter Guidelines

E.1 Recommended Ranges

Parameter Symbol Recommended Range Notes
Latent dimension $d$ $2d_{\text{topo}} \leq d \leq 5d_{\text{topo}}$ Depends on data complexity
Geometric regularization weight $\beta$ $0.01 - 0.1$ Higher for noisy data
Causal consistency weight $\gamma$ $0.1 - 1.0$ Increase if hallucinations problematic
Lyapunov target sum $\lambda_{\text{target}}^+$ $0.01 - 0.1$ Small positive for flexibility
Lyapunov regularization weight $\delta$ $0.001 - 0.01$ Gentle regularization
Gauge-fixing weight $\epsilon$ $0.0001 - 0.001$ Very small, just to break symmetry
SDE integration step $\Delta t$ $0.01 - 0.1$ Depends on timescale of dynamics
Number of SMC particles $K$ $100 - 1000$ Trade accuracy for speed
Policy temperature $\tau$ $0.1 - 1.0$ Lower for more deterministic policies

E.2 Architecture Sizing

Component Size Guidelines
Text encoder BERT-base (768-dim) or smaller
Image encoder ViT-Base (768-dim)
Audio encoder 512-dim after CNN+transformer
Latent space 256-1024 dim
Transformer layers 6-12
SDE hidden layers 2-3 layers, 256-512 units
Variational network 2 layers, 256 units

---

Appendix F: Glossary of Notation

Symbol Meaning
$\mathcal{A}$ Archive
$T$ Time horizon (number of events)
$\mathcal{M}$ Set of modalities
$e_t = (m_t, a_t)$ Event at time $t$ with modality $m_t$ and content $a_t$
$\mathcal{C}$ Set of causal relations
$\mathcal{P}$ Set of provenance relations
$w(e)$ Epistemic weight of event $e$
$z_t \in \mathbb{R}^d$ Latent state at time $t$
$p_\theta(a z)$
$q_\phi(z_{1:T})$ Variational posterior
$g_{ij}(z)$ Fisher information metric
$\Gamma^k_{ij}$ Christoffel symbols
$d_{\text{geo}}(z_1, z_2)$ Geodesic distance
$\mathcal{F}_{\mathcal{A}}$ Archive Free Energy
$\mathcal{C}$ Caliber (path entropy)
$\mathcal{C}_{\text{alg}}$ Algorithmic caliber
$\lambda_i$ Lyapunov exponents
$\Lambda_+$ Sum of positive Lyapunov exponents
$d_{\text{topo}}$ Topological dimension of data manifold
$\mathcal{G}(\Gamma)$ Causal grounding term
$\pi(a z)$
$do(X=x)$ Intervention operator

---

Appendix G: Relationship to Other Frameworks

G.1 Connection to Active Inference

Active Inference (Friston) posits that biological agents minimize variational free energy through perception and action. In our framework:

· Perception corresponds to minimizing $\mathcal{F}_{\mathcal{A}}$ with respect to variational parameters (inferring latent states).
· Action corresponds to selecting actions that minimize expected free energy, which in our case is equivalent to maximizing expected caliber with $U = -\text{expected free energy}$.

The Archive Free Energy generalizes the standard free energy by incorporating causal constraints and geometric structure.

G.2 Connection to Reservoir Computing

Reservoir computers use a fixed recurrent network (reservoir) to project inputs into a high-dimensional space, then train a linear readout. Our SDE-based latent dynamics with learned $\mu_\theta, \sigma_\theta$ can be seen as a trainable reservoir, where the geometry of the latent space is shaped by the Fisher metric.

G.3 Connection to Neural ODEs

Neural ODEs (Chen et al.) model continuous-time dynamics with a neural network. Our neural SDE extends this to stochastic dynamics, with the added geometric structure of the latent manifold.

G.4 Connection to Causal Representation Learning

Recent work in causal representation learning aims to recover latent variables with causal structure from observations. Our framework explicitly incorporates causal constraints via the grounding term $\mathcal{G}$, and the geometrodynamic latent space ensures that causal directions correspond to geodesic flows.

---

Appendix H: Sample Code Structure

```python
# ABM-AGI High-Level Implementation Sketch

class MultimodalEncoder(nn.Module):
    def __init__(self, modalities):
        self.encoders = {m: create_encoder(m) for m in modalities}
        self.provenance_gnn = ProvenanceGNN()
        self.projections = nn.ModuleDict({m: nn.Linear(dim_m, d_latent)})
    
    def forward(self, events, provenance):
        # events: list of (t, m, a)
        raw_z = [self.encoders[m](a) for (t,m,a) in events]
        # Incorporate provenance via GNN
        z_prov = self.provenance_gnn(raw_z, provenance)
        # Project to common latent space
        z = [self.projections[m](z_prov_i) for (t,m,a), z_prov_i in zip(events, z_prov)]
        return torch.stack(z)  # (T, d_latent)

class GeometrodynamicLatentSpace:
    def __init__(self, d_latent):
        self.d = d_latent
        # Metric tensor network
        self.metric_net = MetricNet(d_latent)
    
    def metric(self, z):
        return self.metric_net(z)  # (d, d)
    
    def geodesic_distance(self, z1, z2):
        # Use shooting method or precomputed distances
        return compute_geodesic(z1, z2, self.metric)
    
    def parallel_transport(self, v, z_from, z_to):
        # Transport vector v along geodesic
        return parallel_transport(v, z_from, z_to, self.metric)

class NeuralSDE(nn.Module):
    def __init__(self, d_latent, hidden_size):
        self.drift = MLP(d_latent, hidden_size, d_latent)
        self.diffusion = MLP(d_latent, hidden_size, d_latent)
    
    def forward(self, z0, t_span, dt):
        # Euler-Maruyama integration
        z = [z0]
        for t in t_span[:-1]:
            dz = self.drift(z[-1]) * dt + self.diffusion(z[-1]) * torch.randn_like(z[-1]) * sqrt(dt)
            z.append(z[-1] + dz)
        return torch.stack(z)

class BayesianInferenceEngine(nn.Module):
    def __init__(self, d_latent, hidden_size):
        self.q_net = VariationalLSTM(d_latent, hidden_size)
    
    def forward(self, observations, z_prior):
        # Compute variational posterior parameters
        q_params = self.q_net(observations)
        # Sample from q
        z_q = reparameterize(q_params)
        # Compute KL divergence
        kl = kl_divergence(q_params, z_prior)
        return z_q, kl

class ActionSelector(nn.Module):
    def __init__(self, d_latent, n_actions):
        self.policy_net = MLP(d_latent, 256, n_actions)
    
    def forward(self, z):
        logits = self.policy_net(z)
        return Categorical(logits=logits)
    
    def expected_caliber(self, z, action, model, horizon):
        # Use SMC to estimate expected caliber
        paths, weights = smc_sampling(z, action, model, horizon)
        caliber = (weights * paths.rewards).sum()
        return caliber

class ABMAGI(nn.Module):
    def __init__(self, config):
        self.encoder = MultimodalEncoder(config.modalities)
        self.geometry = GeometrodynamicLatentSpace(config.d_latent)
        self.sde = NeuralSDE(config.d_latent, config.hidden_size)
        self.inference = BayesianInferenceEngine(config.d_latent, config.hidden_size)
        self.policy = ActionSelector(config.d_latent, config.n_actions)
        self.decoders = {m: create_decoder(m, config.d_latent) for m in config.modalities}
    
    def loss(self, batch):
        # Encode
        z0 = self.encoder(batch.events, batch.provenance)
        
        # Prior from SDE
        z_prior = self.sde(z0[0], batch.times, batch.dt)
        
        # Variational posterior
        z_q, kl = self.inference(batch.observations, z_prior)
        
        # Reconstruction loss
        recon_loss = 0
        for t, event in enumerate(batch.events):
            z_t = z_q[t]
            for m, a in event.modalities.items():
                a_hat = self.decoders[m](z_t)
                recon_loss += F.cross_entropy(a_hat, a) * event.weight
        
        # Geometric regularization
        geom_loss = 0
        for z in z_q:
            g = self.geometry.metric(z)
            g_fisher = compute_fisher(self.decoders, z, batch.samples)
            geom_loss += F.mse_loss(g, g_fisher)
        
        # Causal consistency loss
        causal_loss = compute_causal_loss(z_q, batch.causal_graph, self)
        
        # Lyapunov regularization
        lyap_loss = compute_lyapunov_regularization(self.sde, z_q)
        
        # Gauge fixing
        gauge_loss = compute_gauge_fixing(z_q, self.decoders)
        
        total_loss = recon_loss + alpha*kl + beta*geom_loss + gamma*causal_loss + delta*lyap_loss + eps*gauge_loss
        
        return total_loss
```

