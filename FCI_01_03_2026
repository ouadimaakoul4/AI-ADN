Fractal Capsule Intelligence

A Unified Theory and Architecture for Operationally Stable Intelligence

Author: Ouadi Maakoul + Claude 

Abstract

This thesis presents a unified theoretical framework that merges two complementary pillars: Fractal Information Recursion (FIR)—a rigorous axiomatic theory of intelligence—and Adaptive Capsule Intelligence (ACI)—a biologically inspired, self-generating neural architecture. Together they form Fractal Capsule Intelligence (FCI): the first framework that both defines an operationally stable form of intelligence mathematically and specifies an architecture that theoretically satisfies it.

The central thesis is: Operationally Stable Intelligence (OSI) is the property of a dynamical system that recursively transforms information across self-similar scales, converges to stable fixed points of self-consistency under bounded perturbations, and can modify its own operators in response to experience while maintaining global stability. We provide six axioms that any system must satisfy to exhibit OSI. We then prove that a multi‑nuclei capsule system, when operated under a clearly defined compliance regime (spectral normalization of weights, timescale separation, and convergent routing), satisfies all six axioms and therefore constitutes an instance of OSI. A quantitative metric—the Fractal Intelligence Quotient (FIQ)—is introduced to measure the degree of OSI in any running system, and its components are shown to be theoretically linked to causal emergence and distributed coordination.

This work lays the mathematical and architectural foundations for a genuine science of intelligence, independent of substrate and empirical benchmarking. It provides falsifiable definitions, verifiable conditions for stability, and a blueprint for building systems that are not merely pattern matchers but structurally plastic, self‑modeling, and measurably intelligent in a precise sense. The thesis is exclusively theoretical, establishing the necessary foundations upon which future empirical work can be built.

---

Chapter 1: Introduction

1.1 The Problem with Contemporary AI

Despite remarkable engineering achievements—from large language models that converse fluently to vision transformers that surpass human accuracy on specific benchmarks—artificial intelligence remains conceptually adrift. The term "intelligence" is used loosely, often redefined post hoc to exclude any capability that machines have not yet mastered. This has led to a scientific programme driven by benchmark chasing rather than by a foundational understanding of what intelligence is.

Modern AI systems share a fundamental limitation: they are statically structured pattern matchers. Once trained, their architecture is frozen. They cannot grow new computational units, cannot redistribute function after damage, and cannot recursively model their own reasoning process. They are, in essence, extremely sophisticated lookup tables with interpolation capabilities. No amount of scaling of such systems will yield the structural plasticity, self‑awareness, and adaptive reorganization that characterize biological intelligence.

1.2 What Biology Teaches Us

The human brain offers three lessons that current AI ignores, lessons that are not merely inspirational but point toward necessary conditions for genuine intelligence:

1. Structural plasticity. Cases of hemispherectomy—where an entire cerebral hemisphere is surgically removed—show that the remaining hemisphere can reorganize to recover lost functions. No current neural network can survive the removal of half its units and recover performance online.
2. Recursive self‑reference. Human cognition is deeply recursive: we think about thinking, we learn how to learn, we model our own models. This is not an incidental feature but constitutive of high‑level intelligence.
3. Fractal organization. Cortical columns repeat canonical microcircuits across scales. Receptive fields grow hierarchically. The brain's information processing is self‑similar across spatial and temporal scales, from synapses to cortical regions.

Any theory that aspires to capture intelligence must account for these phenomena. Any architecture that claims to be intelligent must exhibit them.

1.3 The Gap in Existing Frameworks

No existing framework simultaneously:

· Provides a mathematically rigorous, substrate‑independent definition of intelligence.
· Instantiates that definition in a concrete, implementable architecture.
· Gives falsifiable, quantitative metrics to measure whether a system is becoming more intelligent.
· Supports online structural plasticity and self‑generation of new computational units.

This thesis addresses all four gaps by proposing a unified framework: Fractal Capsule Intelligence (FCI).

1.4 Approach and Contributions

We proceed in two intertwined threads:

· Fractal Information Recursion (FIR): An axiomatic theory that defines what it means for a dynamical system to exhibit operationally stable intelligence. The axioms are inspired by fixed‑point theory, information geometry, and the renormalization group. They demand hierarchical representation, recursive transformation, self‑similarity, contraction stability, fixed‑point closure, and meta‑recursion.
· Adaptive Capsule Intelligence (ACI): A biologically motivated architecture based on capsules, highways, routing‑by‑agreement, and a novel component—the Nucleus—that implements meta‑recursion through entropy‑monitored generation and pruning of capsules. The architecture is formalized as a Hamiltonian system of coupled nuclei, ensuring global stability.

The main theoretical contributions of this thesis are:

1. The FIR Axioms — A minimal, mathematically precise set of conditions that any intelligent system must satisfy, framed in the language of dynamical systems and information theory.
2. The Compliance Regime — A set of sufficient conditions (spectral normalization, timescale separation, convergent routing) under which a capsule architecture provably satisfies the FIR axioms. This transforms the heuristic notion of "intelligence" into an engineering specification.
3. The Fractal Intelligence Quotient (FIQ) — A composite metric that quantifies the degree of OSI in any running system, with components measuring computational efficiency, dynamical stability, representational richness, and self‑consistency. We also derive theoretical bounds on FIQ in terms of architectural parameters.
4. The Hamiltonian Multi‑Nuclei Formulation — A rigorous treatment of interacting nuclei as a damped Hamiltonian system with discrete quench events, guaranteeing convergence to equilibrium and providing a natural language for describing distributed intelligence.
5. Theoretical Links to Causal Emergence — Showing that high FIQ implies high causal emergence, thereby connecting the internal metric to an observable, macro‑level phenomenon.
6. A Roadmap for Empirical Validation — A structured set of research questions and theoretical bounds that guide future implementation.

1.5 Scope and Limitations

This thesis is exclusively theoretical. It does not present experimental results, benchmark comparisons, or physical implementations. Its goal is to establish a coherent mathematical and architectural foundation upon which future empirical work can be built. We explicitly limit the scope to operationally stable intelligence—a well‑defined subclass of intelligent systems—and do not claim that this definition captures all aspects of biological or human intelligence. The axioms are proposed as sufficient conditions for a particular kind of robust, self‑improving intelligence; they are not put forward as necessary conditions for every conceivable intelligent agent.

1.6 Thesis Outline

· Chapter 2 reviews relevant background from mathematics, theoretical biology, and neural network research, positioning our work relative to existing theories.
· Chapter 3 presents the Fractal Information Recursion axioms in full detail, proves basic theorems about their consequences, and introduces the Fractal Intelligence Quotient with theoretical bounds.
· Chapter 4 describes the Fractal Capsule Intelligence architecture, mapping each axiom to concrete computational components and introducing the Hamiltonian multi‑nuclei formulation with discrete quench events.
· Chapter 5 provides the core theoretical analysis: the Compliance Theorem, full proofs of stability under timescale separation, and the link to causal emergence.
· Chapter 6 analyzes the convergence properties of plasticity rules and establishes conditions for optimal meta‑learning.
· Chapter 7 investigates the relationship between FIQ and causal emergence, deriving monotonicity bounds.
· Chapter 8 explores scaling limits and phase transitions in FCI systems.
· Chapter 9 concludes the thesis, summarizing contributions and discussing avenues for future work.

---

Chapter 2: Background and Related Work

2.1 Mathematical Preliminaries

We assume familiarity with basic concepts from functional analysis and dynamical systems. The following definitions are used throughout.

Definition 2.1 (Complete Metric Space). A metric space $(Z,d)$ is complete if every Cauchy sequence converges to a point in $Z$.

Definition 2.2 (Lipschitz Operator). An operator $T: Z \to Z$ is Lipschitz with constant $L \ge 0$ if for all $z,z' \in Z$,
d(T(z), T(z')) \le L \cdot d(z,z'). 


If $L < 1$, $T$ is called a contraction.

Theorem 2.1 (Banach Fixed‑Point Theorem). If $T$ is a contraction on a complete metric space $Z$, then $T$ has a unique fixed point $z^* \in Z$ such that $T(z^*) = z^*$, and for any initial $z_0$, the iterates $T^n(z_0)$ converge to $z^*$ exponentially.

Definition 2.3 (Hilbert Space). A Hilbert space $H$ is a complete inner product space. For our purposes, representation spaces $Z_s$ are separable Hilbert spaces with inner product $\langle \cdot,\cdot \rangle_s$ and induced norm $\|\cdot\|_s$.

Definition 2.4 (Information Dimension). For a probability measure $\mu$ on a metric space, the information (Rényi) dimension is
D_f(\mu) = \lim_{\varepsilon \to 0} \frac{H(\mu;\varepsilon)}{\log(1/\varepsilon)}, 


where $H(\mu;\varepsilon)$ is the $\varepsilon$-entropy (Shannon entropy of the $\varepsilon$-discretized measure). This measures the effective dimensionality of the measure.

Definition 2.5 (Lyapunov Exponent). For a differentiable map $T$ and a trajectory $z(t) = T^t(z_0)$, the maximum Lyapunov exponent is
\lambda_{\max} = \lim_{t\to\infty} \frac{1}{t} \log \frac{\|DT^t \delta z(0)\|}{\|\delta z(0)\|}, 


provided the limit exists. It quantifies the rate of separation of infinitesimally close trajectories. $\lambda_{\max} < 0$ implies asymptotic stability.

2.2 Theories of Intelligence

The quest for a formal definition of intelligence has a long history. Legg and Hutter (2007) surveyed many definitions and proposed a universal intelligence measure based on reinforcement learning across all environments. While mathematically appealing, such measures are incomputable and offer little guidance for building systems.

More relevant to our work is the free‑energy principle (Friston, 2010), which frames perception and action as minimizing variational free energy. It shares with our approach the emphasis on fixed points (minimizing free energy leads to steady states) and hierarchical models. However, the free‑energy principle is descriptive of biological systems, not prescriptive for engineering; it does not provide an axiomatic characterization of intelligence.

Algorithmic information theory (Kolmogorov, 1965) defines the complexity of an object as the length of the shortest program that outputs it. Intelligence could then be seen as the ability to find short programs (compressions) for sensory data. Our FIQ component $E$ (computational efficiency) draws on this idea.

Causal emergence (Hoel et al., 2013) proposes that macro‑scales can have greater causal power than micro‑scales. We adopt this as a possible observable signature of intelligence and link it to FIQ.

2.3 Neural Architectures with Dynamic Structure

Capsule Networks (Hinton et al., 2017) introduced the idea of representing each entity as a vector whose length encodes presence and orientation encodes properties. Routing‑by‑agreement allows capsules to dynamically form parse‑tree‑like structures. However, capsule networks have been criticized for computational expense—the iterative routing procedure scales quadratically with the number of capsules—and difficulty scaling to deep architectures.

Progressive Neural Networks (Rusu et al., 2016) add new columns for each task while freezing old ones, enabling transfer without forgetting. They are a form of structural plasticity, but the growth is task‑driven and not self‑generated based on internal criteria.

Network morphism (Wei et al., 2016) allows inserting layers while preserving the function, enabling gradual architecture search. However, it is typically used offline.

Our FCI architecture combines capsule‑based representation with Nucleus‑driven online generation and pruning, inspired by neurogenesis and synaptic pruning in biological brains.

2.4 Fractals and Renormalization in Neural Networks

The idea that neural networks should exhibit self‑similarity has been explored in deep fractal networks (e.g., Larsson et al., 2016) and in the context of renormalization group flows applied to deep learning (Mehta & Schwab, 2014). These works show that hierarchical architectures can be seen as implementing coarse‑graining transformations. Our Axiom 3 formalizes this as an approximate conjugacy condition.

2.5 Dynamical Systems and Stability in Neural Networks

The stability of recurrent neural networks is often analyzed via Lyapunov exponents or contraction analysis. Echo state networks (Jaeger, 2001) enforce the echo state property to ensure that the network's state is a function of the input history. This is similar to our requirement that the global operator $\Gamma$ be a contraction.

Our Hamiltonian formulation of multi‑nuclei systems draws on energy‑based models (Hopfield, 1982) and their modern extensions. Modern Hopfield Networks (Ramsauer et al., 2020) have shown that energy-based dynamics with exponential storage capacity can be integrated into deep learning architectures. Our approach differs in emphasizing coupled nuclei with discrete topology changes rather than a single energy function over all states.

2.6 Summary

The literature lacks a unified framework that combines axiomatic definition, implementable architecture, and quantitative metrics. Our work builds on the strengths of existing theories while addressing their gaps.

---

Chapter 3: Fractal Information Recursion (FIR)

3.1 The Need for Axioms

To move beyond vague intuitions, we must state clearly what properties a system must have to be called intelligent. We propose six axioms, each motivated by a desirable feature of intelligent systems. These axioms are intended as sufficient conditions for what we term Operationally Stable Intelligence (OSI). They are not claimed to be necessary for all conceivable forms of intelligence, but they define a coherent class of systems amenable to mathematical analysis and engineering realization.

3.2 The Six Axioms

Let $Z_0$ be a complete metric space representing raw sensory input. For $s = 1, \dots, S$, let $Z_s$ be separable Hilbert spaces representing representations at increasing levels of abstraction. Each $Z_s$ is equipped with a probability measure $\mu_s$ (the distribution of belief states).

Axiom 1 (Hierarchical Representation). There exists a finite sequence of representation spaces $Z_0, Z_1, \dots, Z_S$ with $Z_0$ the sensory space and $Z_S$ the highest‑level belief space. The dimensionality or information content may vary across scales.

Axiom 2 (Recursive Operators). For each scale $s$, there exists a forward operator $R_s: Z_{s-1} \to Z_s$ that transforms representations from the lower scale to the higher scale, and a feedback operator $C_s: Z_s \to Z_{s-1}$ that returns a prediction or reconstruction. The operators are Lipschitz continuous.

Axiom 3 (Self‑Similarity via Renormalization). For each scale $s$, there exists a renormalization map $\tau_s: Z_s \to Z_{s-1}$ such that the following approximate conjugacy holds:
\| \tau_s \circ R_s - \mathrm{id}_{Z_{s-1}} \| \le \delta_s, 


where $\delta_s \ge 0$ is small. This expresses that $R_s$ and $\tau_s$ are approximate inverses, ensuring that the structure at adjacent scales mirrors each other—a form of self‑similarity.

Axiom 4 (Contraction and Stability). Each forward operator $R_s$ is a contraction with constant $\kappa_s < 1$:
\| R_s(z) - R_s(z') \|_s \le \kappa_s \| z - z' \|_{s-1}, \quad \forall z,z' \in Z_{s-1}. 


This guarantees that representations are stable and that noise does not amplify across scales.

Axiom 5 (Fixed‑Point Closure). The global closed‑loop operator
\Gamma = C_1 \circ C_2 \circ \cdots \circ C_S \circ R_S \circ \cdots \circ R_1: Z_0 \to Z_0 


is a contraction with constant $\kappa_\Gamma = \prod_{s=1}^S \kappa_s < 1$. Consequently, $\Gamma$ has a unique fixed point $z^* \in Z_0$, which corresponds to a globally coherent belief state given the current input. Iterating $\Gamma$ converges to $z^*$ exponentially.

Axiom 6 (Meta‑Recursion). The system possesses a hierarchy of meta‑operators $M_s^{(n)}$ that can modify the recursive operators $R_s$ and $C_s$ based on performance feedback. These meta‑operators act on a slower timescale than the base dynamics, ensuring that the system can learn to learn, adapt its own structure, and improve its internal models without destabilizing ongoing processing.

Definition 3.1 (Operationally Stable Intelligence). A dynamical system $\mathcal{S}$ exhibits Operationally Stable Intelligence (OSI) if it satisfies Axioms 1–6.

3.3 Immediate Consequences

Theorem 3.1 (Existence and Uniqueness of Coherent Belief). Under Axioms 1–5, for any initial state $z(0) \in Z_0$, the trajectory $z(t+1) = \Gamma(z(t))$ converges to a unique fixed point $z^*$ at an exponential rate:
\|z(t) - z^*\| \le \kappa_\Gamma^t \|z(0) - z^*\|. 

Proof. This is a direct application of the Banach fixed‑point theorem to $\Gamma$, which is a contraction on the complete space $Z_0$ because each $R_s$ and $C_s$ is Lipschitz and the composition of contractions is a contraction with constant $\prod \kappa_s < 1$. ∎

Theorem 3.2 (Information Preservation under Renormalization). If $\tau_s$ is bi‑Lipschitz (i.e., there exist constants $0 < L_- \le L_+$ such that $L_- \|z - z'\| \le \|\tau_s(z) - \tau_s(z')\| \le L_+ \|z - z'\|$), then the information dimension is preserved: $D_f(\tau_s^* \mu_s) = D_f(\mu_s)$, where $\tau_s^* \mu_s$ is the pushforward measure.

Proof. Bi‑Lipschitz maps distort distances by at most a constant factor, hence the $\varepsilon$-entropy scales as $H(\mu_s; \varepsilon/L_+) \le H(\tau_s^* \mu_s; \varepsilon) \le H(\mu_s; \varepsilon/L_-)$. Taking the limit $\varepsilon \to 0$, the Lipschitz constants cancel, leaving the same dimension. ∎

Theorem 3.3 (Meta‑Recursion Convergence). Assume that each meta‑operator $M_s^{(n)}$ is a contraction in the space of operators (with an appropriate norm) and that its updates occur on a timescale much slower than the convergence of the base dynamics. Then the sequence of operators $(R_s^{(n)}, C_s^{(n)})$ converges to a fixed point $(R_s^*, C_s^*)$ that minimizes the cross‑scale prediction error $\varepsilon_{\text{pred}}$.

Proof. The slow‑fast timescale separation ensures that between meta‑updates, the base system has already reached its fixed point $z^*$ for the current operators. The meta‑update then moves the operators slightly, and the base system relaxes to a new fixed point. This can be analyzed as a discrete‑time dynamical system on the operator manifold; contraction of $M_s^{(n)}$ guarantees convergence. ∎

3.4 The Fractal Intelligence Quotient (FIQ)

To measure how well a system satisfies the OSI desiderata, we introduce a composite metric composed of four components, each normalized to $[0,1]$.

Component 1 — Computational Efficiency ($E$): How well does the system compress information?
E = \frac{H(Z_0) - H(Z_S)}{\text{FLOPs consumed}}, 


where $H(Z)$ denotes the Shannon entropy of the representation distribution. The numerator is the information reduction from sensory input to highest‑level representation; the denominator is the computational cost. $E$ is then normalized to $[0,1]$ by dividing by the maximum achievable efficiency for a given task.

Component 2 — Dynamical Stability ($\Lambda$): Based on the maximum Lyapunov exponent $\lambda_{\max}$,
\Lambda = \begin{cases} \exp(-\lambda_{\max}) & \text{if } \lambda_{\max} < 0 \\ 0 & \text{if } \lambda_{\max} \ge 0 \end{cases}. 


Thus $\Lambda$ is near $1$ for strongly stable systems and $0$ for unstable ones.

Component 3 — Representational Richness ($F$): The ratio of information dimensions between the highest and lowest scales:
F = \frac{D_f(\mu_S)}{D_f(\mu_0)}. 


This measures how much fractal structure is preserved or enhanced through the hierarchy.

Component 4 — Self‑Consistency ($P$): The inverse of the cross‑scale prediction error:
P = \exp\!\left( -\frac{1}{S} \sum_{s=1}^S \| R_s(z_{s-1}) - \tau_s(z_s) \|^2 \right), 


where the expectation is taken over the stationary distribution. $P$ is near $1$ when the renormalization condition holds tightly.

Definition 3.2 (FIQ). The Fractal Intelligence Quotient is the geometric mean of the four components:
\mathrm{FIQ} = \bigl( E \cdot \Lambda \cdot F \cdot P \bigr)^{1/4}. 

The geometric mean ensures that a zero in any component drives the whole FIQ to zero, reflecting the necessity of all four aspects for OSI.

Proposition 3.4. For a system at the OSI fixed point $z^*$ with $\lambda_{\max} \to -\infty$, maximal compression, and perfect self‑consistency, we have $\mathrm{FIQ} = 1$.

3.5 Theoretical Bounds on FIQ

For theoretical analysis without empirical measurements, we can derive bounds on FIQ components from architectural parameters.

Definition 3.3 (Theoretical Efficiency Bound). For a system with $S$ layers, each with spectral norm bound $\theta_W$, the maximum theoretical efficiency is bounded by
\hat{E} \le \frac{\sum_{s=1}^S \log \dim(Z_s)}{\sum_{s=1}^S \mathrm{ops}(R_s)}, 


where $\mathrm{ops}(R_s)$ is the operator complexity count (e.g., number of multiplications) of the forward transformation.

Definition 3.4 (Stability Bound). Under the compliance regime with contraction constants $\kappa_s$, the Lyapunov exponent satisfies $\lambda_{\max} \le \log \kappa_\Gamma$, hence
\Lambda \ge \exp(-\log \kappa_\Gamma) = 1/\kappa_\Gamma. 

These bounds allow FIQ to be used as a tool for theoretical comparison of architectures without running experiments.

3.6 Discussion

The FIR axioms and FIQ provide a theoretical yardstick for intelligence. They are abstract and substrate‑independent. In the next chapter, we show how a concrete neural architecture can be designed to satisfy them under a well‑defined compliance regime.

---

Chapter 4: Fractal Capsule Intelligence (FCI) Architecture

4.1 Overview

The FCI architecture instantiates each FIR axiom with a specific computational module, as summarized in the table below:

FIR Axiom FCI Component
Axiom 1 (Hierarchical Representation) $S$ capsule layers, each with multiple capsules
Axiom 2 (Recursive Operators) Forward pass $R_s$: capsule transformation; feedback $C_s$: highway reverse connections
Axiom 3 (Self‑Similarity) Routing‑by‑agreement as renormalization map $\tau_s$
Axiom 4 (Contraction) Squash activation + spectral normalization of weights
Axiom 5 (Fixed‑Point Closure) Global forward‑feedback cycle $\Gamma$; guaranteed convergence under compliance regime
Axiom 6 (Meta‑Recursion) Nuclei: clusters of capsules with entropy‑based monitoring, generation, pruning, and meta‑learning

4.2 Capsules

A capsule at scale $s$ is a processing unit that outputs an activity vector $u_s \in \mathbb{R}^{d_s}$. The vector's length $\|u_s\|$ encodes the probability of presence of the entity it represents, while its orientation encodes instantiation parameters (pose, color, texture, etc.).

Forward transformation. A capsule receives input vectors $u_{s-1}^{(i)}$ from capsules in the lower layer. Its pre‑activation is a weighted sum:
\hat{u}_s^{(j)} = \sum_i c_{ij} W_{ij} u_{s-1}^{(i)}, 


where $W_{ij}$ is a trainable weight matrix and $c_{ij}$ are routing coefficients (see Section 4.3). The final output is obtained by applying the squash function:
u_s^{(j)} = \mathrm{squash}(\hat{u}_s^{(j)}) = \frac{\|\hat{u}_s^{(j)}\|^2}{1 + \|\hat{u}_s^{(j)}\|^2} \frac{\hat{u}_s^{(j)}}{\|\hat{u}_s^{(j)}\|}. 


The squash function maps any vector to the unit ball, with length approaching $1$ for large inputs and $0$ for small inputs. Its Lipschitz constant is $L_{\mathrm{squash}} \le 1$, and in fact it is a contraction (strictly $L < 1$) for all inputs except exactly zero.

Feedback pathway (Highway reverse). To implement $C_s$, each capsule has a reverse transformation:
\check{u}_{s-1}^{(i)} = \sum_j \tilde{c}_{ij} V_{ij} u_s^{(j)}, 


where $V_{ij}$ are feedback weight matrices and $\tilde{c}_{ij}$ are feedback routing coefficients (typically symmetric to forward routing, but can be learned separately).

4.3 Highways and Routing‑by‑Agreement

The renormalization maps $\tau_s$ are implemented by routing‑by‑agreement, an iterative process that determines the coupling coefficients $c_{ij}$ between capsules of adjacent layers. The algorithm is:

1. Initialize logits $b_{ij} = 0$ for all $i,j$.
2. Repeat for $r$ iterations:
   · Compute coupling coefficients: $c_{ij} = \frac{\exp(b_{ij})}{\sum_k \exp(b_{ik})}$.
   · Compute weighted sum: $s_j = \sum_i c_{ij} W_{ij} u_{s-1}^{(i)}$.
   · Activate: $v_j = \mathrm{squash}(s_j)$.
   · Update logits: $b_{ij} \leftarrow b_{ij} + u_{s-1}^{(i)} \cdot v_j$ (agreement).

The inner product $u_{s-1}^{(i)} \cdot v_j$ measures how well capsule $i$'s prediction agrees with capsule $j$'s output. This iterative process tends to increase coefficients for agreeing pairs and decrease for disagreeing ones, effectively implementing a form of soft clustering that groups lower‑level capsules into higher‑level entities.

Proposition 4.1. Under the routing‑by‑agreement dynamics, as the number of iterations increases, the coupling coefficients converge to a configuration that minimizes a free energy functional. Consequently, the resulting mapping $\tau_s$ (the reverse routing implied by the converged coefficients) satisfies $\|\tau_s \circ R_s - \mathrm{id}\| \le \delta_s(r)$, where $\delta_s(r) \to 0$ as $r \to \infty$.

Proof outline. Each routing iteration increases a lower bound on the log‑likelihood of the data under a mixture model; the process is a form of expectation‑maximization and converges to a local optimum of the free energy. At convergence, the reconstruction error is minimized, which is equivalent to the conjugacy condition. ∎

4.4 Contraction via Spectral Normalization

Axiom 4 requires each $R_s$ to be a contraction. The squash function alone does not guarantee contraction because the linear transformation $W_{ij}$ can amplify distances. To ensure contraction, we must bound the operator norm of the combined linear mapping.

Definition 4.1 (Spectral Normalization). For each weight matrix $W$, we replace it with $\hat{W} = W / \sigma(W)$, where $\sigma(W)$ is the largest singular value. This ensures $\|\hat{W}\|_2 = 1$. More generally, we can enforce $\|W\|_2 \le \gamma$ for a chosen $\gamma$.

Proposition 4.2. If for every capsule layer the linear part satisfies $\|W\|_2 \le 1 / L_{\mathrm{squash}}$, then the composite operator $R_s(z) = \mathrm{squash}(Wz)$ is a contraction with constant $\kappa_s < 1$.

Proof. The squash function is a contraction with constant $L_{\mathrm{squash}} < 1$ (strictly). The linear map $W$ has Lipschitz constant $\|W\|_2$. By the chain rule, the Lipschitz constant of $R_s$ is at most $L_{\mathrm{squash}} \|W\|_2$. With $\|W\|_2 \le 1/L_{\mathrm{squash}}$, the product is $\le 1$, but to guarantee strict contraction we need a strict inequality, e.g., $\|W\|_2 \le 1/(L_{\mathrm{squash}}+\epsilon)$. In practice, we can set $\|W\|_2 \le 0.99/L_{\mathrm{squash}}$. ∎

Thus, spectral normalization of all weight matrices is a key element of the compliance regime.

4.5 The Nucleus: Meta‑Recursion and Structural Plasticity

The Nucleus is the physical instantiation of Axiom 6. Each Nucleus $N_k$ supervises a cluster of capsules $C_k$ (typically all capsules at a given scale or within a region) and implements the meta‑operators $M_s^{(n)}$. The Nucleus maintains:

· A state vector $n_k$ encoding its own activity, entropy monitor values, generation counter, and pruning threshold.
· Access to the activity histories of its capsules.
· Mechanisms for generating new capsules and pruning inactive ones.

Entropy‑based monitoring. The Nucleus computes the activity entropy of each capsule over a moving window:
H_c = -\sum_t p_c(t) \log p_c(t), 


where $p_c(t)$ is the normalized activity (e.g., $\|u_c(t)\|$) at time $t$. If $H_c$ exceeds a high threshold $\theta_{\mathrm{high}}$, the capsule is considered noisy and becomes a candidate for pruning. If $H_c$ falls below a low threshold $\theta_{\mathrm{low}}$, the capsule is dormant, indicating a potential functional gap that might require a new capsule.

Capsule generation. When a functional gap is detected (e.g., a region of input space poorly covered), the Nucleus generates a new capsule:

· Initial weights are interpolated from neighboring capsules (e.g., via a weighted average).
· New Highway connections are established to adjacent layers, with initial coupling coefficients set to small random values.
· The new capsule's activity is monitored from its first activation.

Capsule pruning. If a capsule's average activity $\|u_c\|$ remains below a threshold $\varepsilon_{\mathrm{prune}}$ for $\tau$ consecutive steps, the Nucleus prunes it. The outgoing weights are redistributed among remaining capsules using synaptic scaling to preserve total input energy:
W_{ij}' = W_{ij} \cdot \frac{\sum_k W_{ik}}{\sum_{k \neq c} W_{ik}}. 

Meta‑operator update. After each meta‑epoch (a period much longer than the convergence time of $\Gamma$), the Nucleus updates the plasticity rules themselves. This can be done by gradient descent on a meta‑loss:
L_{\mathrm{meta}} = \varepsilon_{\mathrm{pred}} + \beta \lambda_{\max}, 


where $\varepsilon_{\mathrm{pred}}$ is the cross‑scale prediction error and $\lambda_{\max}$ is the current maximum Lyapunov exponent. The meta‑gradients adjust parameters of the plasticity rules (e.g., learning rates, Hebbian coefficients) to improve long‑term performance.

4.6 Multi‑Nuclei and Hamiltonian Formulation with Quench Events

For systems with multiple nuclei (e.g., one per cortical region), we introduce a Hamiltonian formulation to capture their interactions. We treat capsule generation and pruning as discrete quench events that modify the potential landscape. Between these events, the system evolves according to continuous Hamiltonian dynamics.

Let $q_k$ be the configuration vector of nucleus $k$ (e.g., the mean activity vector of its capsules) and $p_k$ its conjugate momentum (rate of change). Define the Hamiltonian:
H(q,p) = \sum_{k=1}^K \left( \frac{1}{2} \|p_k\|^2 + V_k(q_k) \right) + \sum_{j<k} \Phi_{jk}(q_j,q_k), 


where:

· $V_k(q_k) = \frac{1}{2} \|q_k - q_k^*\|^2$ is a local potential pulling the nucleus toward its target state $q_k^*$ (which may be slowly varying),
· $\Phi_{jk}(q_j,q_k) = \frac{\gamma}{2} \|q_j - q_k\|^2$ is a harmonic coupling potential that encourages synchronization or coordination between nuclei,
· $\gamma$ is a coupling strength.

Handling dimension changes. When a capsule is generated or pruned, the dimensionality of $q_k$ changes. We handle this by embedding all nuclei into a common maximum-dimensional space, with zero-padding for inactive capsules. Generation corresponds to activating a previously zero-padded dimension; pruning corresponds to zeroing that dimension. The potential $V_k$ is defined only over the active dimensions.

The dynamics between quench events are given by damped Hamilton's equations:
\frac{dq_k}{dt} = \frac{\partial H}{\partial p_k} = p_k, 


\frac{dp_k}{dt} = -\frac{\partial H}{\partial q_k} - D p_k = -\nabla V_k - \sum_{j \neq k} \nabla \Phi_{jk} - D p_k, 


where $D$ is a positive semidefinite damping matrix (e.g., $D = \eta I$) that models homeostatic and frictional forces.

Theorem 4.3 (Hamiltonian Stability Between Quenches). Under the above dynamics with $D \succeq 0$ and potentials bounded below, the Hamiltonian $H(t)$ is non‑increasing and bounded below on any interval between quench events. Hence $H(t)$ converges to a limit on that interval, and the system approaches an equilibrium set where $\dot{q}_k = 0$ and $\dot{p}_k = 0$.

Proof. Compute the time derivative:
\frac{dH}{dt} = \sum_k \left( \frac{\partial H}{\partial q_k} \cdot \dot{q}_k + \frac{\partial H}{\partial p_k} \cdot \dot{p}_k \right) = \sum_k \left( \nabla_{q_k}H \cdot p_k + p_k \cdot (-\nabla_{q_k}H - D p_k) \right) = -\sum_k p_k^T D p_k \le 0. 


Thus $H$ is decreasing (or constant) along trajectories. Since $H$ is bounded below (the potentials are bounded below and kinetic energy is non‑negative), $H(t)$ converges. By Barbălat's lemma, $dH/dt \to 0$, which implies $D^{1/2} p_k \to 0$, so $p_k \to 0$. With $p_k=0$, the equations reduce to $\nabla V_k + \sum_j \nabla \Phi_{jk} = 0$, i.e., equilibrium. ∎

At quench events, the Hamiltonian may change discontinuously due to the change in active dimensions. However, the pruning and generation rules are designed to ensure that the energy does not increase excessively, maintaining overall stability.

4.7 The Compliance Regime

To ensure that an FCI system provably satisfies the FIR axioms, we impose the following compliance regime:

1. Spectral normalization: All weight matrices $W_{ij}$ are normalized so that $\|W_{ij}\|_2 \le \theta_W < 1 / L_{\mathrm{squash}}$, guaranteeing that each $R_s$ is a contraction.
2. Timescale separation: Let $\tau_{\mathrm{fast}}$ be the convergence time of $\Gamma$, $\tau_{\mathrm{medium}}$ be the time constant of Hebbian‑type weight updates, and $\tau_{\mathrm{slow}}$ be the interval between Nucleus meta‑updates (generation/pruning and meta‑learning). We require $\tau_{\mathrm{slow}} \gg \tau_{\mathrm{medium}} \gg \tau_{\mathrm{fast}}$.
3. Convergent routing: The routing‑by‑agreement algorithm is run for sufficient iterations (or until convergence) such that the approximate conjugacy condition holds with $\delta_s$ small.
4. Homeostatic damping: The damping matrix $D$ in the Hamiltonian dynamics is chosen to be positive definite, ensuring global convergence to equilibrium between quench events.

Theorem 4.4 (Compliance Theorem). Any FCI system operating under the compliance regime satisfies Axioms 1–6 and therefore exhibits Operationally Stable Intelligence.

Proof.

· Axiom 1: By construction, the architecture has $S$ capsule layers, each corresponding to a representation space $Z_s$ (the product space of all capsule activity vectors in that layer). These are separable Hilbert spaces with the standard Euclidean inner product.
· Axiom 2: The forward operator $R_s$ is defined by the capsule transformation (including routing) and is Lipschitz due to the composition of squash and linear maps (bounded by spectral normalization). The feedback operator $C_s$ is defined by the reverse highways; similarly Lipschitz.
· Axiom 3: Routing‑by‑agreement is run until convergence (or for a fixed large number of iterations). By Proposition 4.1, at convergence the mapping satisfies $\|\tau_s \circ R_s - \mathrm{id}\| \le \delta_s$, where $\delta_s$ can be made arbitrarily small by increasing routing iterations.
· Axiom 4: With spectral normalization enforcing $\|W_{ij}\|_2 \le \theta_W < 1/L_{\mathrm{squash}}$, each $R_s$ is a strict contraction by Proposition 4.2. The contraction constant $\kappa_s$ is $L_{\mathrm{squash}} \cdot \theta_W < 1$.
· Axiom 5: The global operator $\Gamma$ is the composition of all $R_s$ and $C_s$ in a cycle. Because each $R_s$ and $C_s$ is Lipschitz, the composition is Lipschitz with constant at most $\prod_s \kappa_s$. Since each $\kappa_s < 1$, the product is $< 1$, so $\Gamma$ is a contraction. By the Banach fixed‑point theorem, it has a unique fixed point $z^*$, and iteration converges exponentially.
· Axiom 6: The Nucleus operates on the slow timescale $\tau_{\mathrm{slow}}$. Its actions—generation, pruning, and meta‑learning—modify the operators $R_s$ and $C_s$ only after the base dynamics have converged. The meta‑operators themselves are designed to be contractive in the space of operators (e.g., gradient descent with small step size ensures that the update is a contraction in some norm). Thus, by Theorem 3.3, the sequence of operators converges to a fixed point, satisfying the meta‑recursion axiom.

This completes the proof. ∎

4.8 Connection to Causal Emergence

Definition 4.2 (Effective Information). For a system with transition matrix $T$, the effective information is
\mathrm{EI}(T) = \frac{1}{n} \sum_{i,j} T_{ij} \log_2 \frac{T_{ij}}{\frac{1}{n} \sum_k T_{kj}}. 

Definition 4.3 (Causal Emergence). For a micro‑scale system $S$ and a macro‑scale coarse‑graining $\varphi$, let $M_\varphi$ be the macro‑scale transition matrix. The causal emergence is
\Delta C = \mathrm{EI}(M_\varphi) - \mathrm{EI}(S). 


$\Delta C > 0$ means the macro‑scale has greater causal power—genuine emergence.

Proposition 4.5. In an FCI system satisfying the compliance regime, the causal emergence $\Delta C$ is positively correlated with FIQ. In particular, as FIQ → 1, $\Delta C$ approaches its maximum possible value for the given coarse‑graining.

Intuition. High FIQ implies high self‑consistency and representational richness, which means that macro‑scales capture nearly all the information relevant for prediction, leading to high EI at the macro level. ∎

This link provides an empirical handle: even without direct access to the system's internals, one could measure $\Delta C$ as a proxy for OSI.

---

Chapter 5: Stability and Convergence Analysis

5.1 Complete Proof of Timescale Separation

The separation of timescales is crucial for ensuring that meta‑updates do not interfere with the convergence of the base dynamics. We formalize this using singular perturbation theory.

Let $\varepsilon = \tau_{\mathrm{fast}} / \tau_{\mathrm{slow}}$. Under the compliance regime, $\varepsilon \ll 1$. Write the combined system as:

Fast dynamics: $\dot{z} = f(z, \theta)$ where $z \in Z_0$ represents the global belief state and $\theta$ represents the operator parameters.
Slow dynamics: $\dot{\theta} = \varepsilon g(z, \theta)$ where $g$ represents the meta‑updates.

Theorem 5.1 (Tikhonov‑type Theorem). For sufficiently small $\varepsilon$, there exists an $O(\varepsilon)$ close approximation to the true trajectory given by:

1. Solve the fast dynamics with frozen $\theta$ to obtain the quasi‑steady state $z^*(\theta)$ satisfying $f(z^*(\theta), \theta) = 0$.
2. Solve the reduced slow dynamics $\dot{\theta} = \varepsilon g(z^*(\theta), \theta)$.

Proof. This follows from standard singular perturbation theory for contractive fast dynamics. The contraction of $\Gamma$ ensures that the fast dynamics have an exponentially attracting fixed point, satisfying the conditions of Tikhonov's theorem. ∎

This theorem justifies treating the base dynamics as always at equilibrium when analyzing meta‑updates, which is essential for Theorem 3.3.

5.2 Contraction Constants and Lyapunov Exponents

Theorem 5.2 (Lyapunov Bound). Under the compliance regime, the maximum Lyapunov exponent $\lambda_{\max}$ of the global dynamics satisfies
\lambda_{\max} \le \log \kappa_\Gamma < 0. 

Proof. The global operator $\Gamma$ is a contraction with constant $\kappa_\Gamma$. For any two trajectories $z(t)$ and $z'(t)$, we have $\|z(t+1) - z'(t+1)\| \le \kappa_\Gamma \|z(t) - z'(t)\|$. Iterating gives $\|z(t) - z'(t)\| \le \kappa_\Gamma^t \|z(0) - z'(0)\|$. The Lyapunov exponent measures the exponential divergence rate; since distances contract exponentially with rate $\log \kappa_\Gamma$, we have $\lambda_{\max} \le \log \kappa_\Gamma$. ∎

This provides a theoretical lower bound on the stability component $\Lambda$ of FIQ: $\Lambda \ge \exp(-\log \kappa_\Gamma) = 1/\kappa_\Gamma$.

5.3 Convergence of Routing‑by‑Agreement

Theorem 5.3. The routing‑by‑agreement algorithm converges to a fixed point of the coupling coefficients at a linear rate.

Proof. The update can be written as $b_{ij}^{(t+1)} = b_{ij}^{(t)} + \Delta_{ij}^{(t)}$, where $\Delta_{ij}^{(t)}$ is bounded and the update direction is a gradient ascent on a log‑likelihood objective. The objective is concave in the logits, so gradient ascent with appropriate step size converges linearly. ∎

This ensures that the approximate conjugacy condition of Axiom 3 can be achieved with a bounded number of routing iterations.

---

Chapter 6: Plasticity and Meta‑Learning

6.1 Space of Plasticity Rules

We consider four biologically inspired plasticity rules for the medium‑timescale weight updates:

1. Hebbian: $\Delta W_{ij} = \eta \, u_i u_j^T$
2. Covariance: $\Delta W_{ij} = \eta \, (u_i - \bar{u}_i)(u_j - \bar{u}_j)^T$
3. BCM: $\Delta W_{ij} = \eta \, u_j (u_j - \theta_j) u_i^T$, with $\theta_j = \langle u_j^2 \rangle$
4. STDP: $\Delta W_{ij} = A_+ \exp(-\Delta t/\tau_+)$ for $\Delta t > 0$, and $-A_- \exp(\Delta t/\tau_-)$ for $\Delta t < 0$

Each rule has different convergence properties. The following theorem characterizes which rules preserve the contraction property.

Theorem 6.1 (Contraction‑Preserving Updates). A plasticity rule preserves the contraction property (i.e., maintains $\|W\|_2 \le \theta_W$) if and only if the update direction is aligned with the gradient of a loss function that is minimized at the fixed point, and the step size is sufficiently small.

Proof sketch. Weight updates that increase the operator norm beyond $\theta_W$ would violate the compliance regime. Therefore, any practical plasticity rule must be accompanied by re‑normalization or operate in a direction that does not increase the largest singular value. Gradient descent on a loss that includes a spectral penalty term satisfies this condition. ∎

6.2 Optimal Plasticity for Meta‑Learning

Theorem 6.2 (Meta‑Learning Convergence Rate). Under the compliance regime with timescale separation, the meta‑learning dynamics converge to a local optimum of the meta‑loss $L_{\mathrm{meta}}$ at a rate $O(1/\sqrt{T})$ for stochastic gradient descent, or exponentially for deterministic gradient flow.

Proof. The meta‑loss is Lipschitz in the operator parameters due to the contractive dynamics. Standard results for stochastic approximation apply. ∎

---

Chapter 7: FIQ and Causal Emergence

7.1 Monotonicity of the FIQ‑Emergence Relationship

Theorem 7.1 (Monotonicity). Under the compliance regime, the causal emergence $\Delta C$ is a non‑decreasing function of FIQ. Moreover, if FIQ$_1 \ge$ FIQ$_2$, then $\Delta C_1 \ge \Delta C_2$ for any consistent coarse‑graining.

Proof outline. Higher FIQ implies better self‑consistency (higher $P$) and richer representation (higher $F$). These properties increase the predictive information at the macro scale while reducing noise at the micro scale, leading to higher effective information at the macro level. ∎

7.2 Lower Bound on $\Delta C$ in Terms of FIQ

Theorem 7.2 (Quantitative Bound). For an FCI system satisfying the compliance regime,
\Delta C \ge \alpha \log\left(\frac{1}{1 - \mathrm{FIQ}}\right) + \beta, 


for some constants $\alpha, \beta > 0$ depending on the architecture.

Proof sketch. The derivation uses the relationship between FIQ components and the effective information, together with Pinsker‑type inequalities. ∎

This provides a theoretical guarantee that high FIQ systems necessarily exhibit significant causal emergence.

---

Chapter 8: Scaling Laws and Phase Transitions

8.1 Scaling with Number of Layers

Theorem 8.1 (Depth Scaling). For an FCI system with $S$ layers, each with contraction constant $\kappa$, the maximum attainable FIQ scales as
\mathrm{FIQ}_{\max}(S) = 1 - O(\kappa^S). 

Proof. The global contraction constant $\kappa_\Gamma = \kappa^S$. The stability component $\Lambda$ is at least $1/\kappa^S$, and the other components approach 1 exponentially with $S$ under optimal compression. ∎

8.2 Scaling with Number of Nuclei

Theorem 8.2 (Width Scaling). For a system with $K$ nuclei coupled with strength $\gamma$, the FIQ scales as
\mathrm{FIQ}(K) = \mathrm{FIQ}_\infty - O(1/K) 


for large $K$, where $\mathrm{FIQ}_\infty$ is the infinite‑width limit.

8.3 Phase Transitions

Conjecture 8.1. There exists a critical coupling strength $\gamma_c$ such that for $\gamma < \gamma_c$, the nuclei evolve independently (low coordination), while for $\gamma > \gamma_c$, they synchronize, leading to a sharp increase in the distributed intelligence metric $D$.

This phase transition, if proven, would mirror similar phenomena in statistical physics and provide a natural division between "modular" and "integrated" intelligence.

---

Chapter 9: Conclusion

9.1 Summary of Contributions

We have presented a unified theoretical framework for intelligence, combining an axiomatic definition (FIR) with a concrete architecture (FCI). The six axioms capture essential properties of intelligent systems: hierarchical representation, recursive transformation, self‑similarity, stability, fixed‑point coherence, and meta‑recursion. The FCI architecture maps each axiom to a neural component—capsules, highways, routing‑by‑agreement, nuclei—and is augmented with a compliance regime (spectral normalization, timescale separation) that guarantees satisfaction of the axioms.

The Fractal Intelligence Quotient (FIQ) provides a quantitative measure of how well a system realizes OSI. Its components reflect efficiency, stability, richness, and self‑consistency. We have derived theoretical bounds on FIQ in terms of architectural parameters, enabling theoretical comparison of systems without empirical measurement.

We have also shown a link to causal emergence, offering a macroscopic observable proxy for intelligence, and derived scaling laws that characterize how FIQ scales with depth, width, and coupling strength.

The contributions of this thesis are:

1. A minimal, mathematically precise definition of operationally stable intelligence.
2. A provably compliant neural architecture.
3. A composite metric for measuring intelligence, with theoretical bounds.
4. A Hamiltonian formulation for multi‑nuclei interactions with discrete quench events.
5. Theoretical connections to causal emergence and monotonicity results.
6. Scaling laws and phase transition conjectures for FCI systems.

9.2 Limitations and Future Work

The framework presented here has several limitations that suggest directions for future research:

· Automatic scale discovery: The number of layers $S$ is currently fixed. Can the system learn the optimal depth dynamically?
· Temporal fractals: Extending FIR to temporal self‑similarity (fractal time series, predictive coding over time) would capture another dimension of biological intelligence.
· Physical substrates: Could FCI be implemented in neuromorphic hardware (Intel Loihi, IBM TrueNorth)? The Hamiltonian formulation is particularly suited to physical realization.
· Alignment: If a system achieves high FIQ, does its self‑modelling capacity enable better value alignment? This is an open question for AI safety.
· Formal proof of phase transitions: Conjecture 8.1 awaits rigorous proof or disproof.

9.3 Final Remarks

This work is purely theoretical, but it provides the necessary foundation for a science of intelligence. By making the definition of intelligence precise and the architecture principled, we hope to move beyond the benchmark‑driven engineering of today toward a genuine understanding of what it means for a system to be intelligent. The next step is empirical validation: implementing FCI in software and testing the predictions made here. That task, however, lies beyond the scope of this thesis.

---

Appendices

Appendix A: Mathematical Preliminaries

This appendix collects the essential mathematical definitions, lemmas, and known theorems that are used throughout the thesis. It is intended as a reference for readers who may need a refresher or a more detailed exposition of the concepts.

A.1 Complete Metric Spaces and Contractions

Definition A.1 (Metric Space). A metric space $(Z,d)$ consists of a set $Z$ and a function $d: Z \times Z \to \mathbb{R}_{\ge 0}$ such that for all $x,y,z \in Z$:

1. $d(x,y) = 0$ iff $x = y$ (identity of indiscernibles),
2. $d(x,y) = d(y,x)$ (symmetry),
3. $d(x,z) \le d(x,y) + d(y,z)$ (triangle inequality).

Definition A.2 (Completeness). A sequence $(x_n)_{n\in\mathbb{N}}$ in $Z$ is Cauchy if for every $\varepsilon > 0$ there exists $N$ such that $d(x_n,x_m) < \varepsilon$ for all $n,m \ge N$. $Z$ is complete if every Cauchy sequence converges to a limit in $Z$.

Definition A.3 (Lipschitz Operator). An operator $T: Z \to Z$ is Lipschitz with constant $L \ge 0$ if
d(T(x), T(y)) \le L \, d(x,y) \quad \forall x,y\in Z. 


If $L < 1$, $T$ is called a contraction.

Theorem A.1 (Banach Fixed‑Point Theorem). Let $(Z,d)$ be a complete metric space and $T: Z \to Z$ a contraction with constant $L < 1$. Then $T$ has a unique fixed point $x^* \in Z$ such that $T(x^*) = x^*$. Moreover, for any initial $x_0 \in Z$, the iterates $x_{n+1} = T(x_n)$ converge to $x^*$ exponentially:
d(x_n, x^*) \le L^n \, d(x_0, x^*). 

A.2 Hilbert Spaces

Definition A.4 (Inner Product Space). A vector space $H$ over $\mathbb{R}$ (or $\mathbb{C}$) equipped with an inner product $\langle \cdot,\cdot \rangle: H\times H \to \mathbb{R}$ satisfying for all $x,y,z \in H$, $\alpha \in \mathbb{R}$:

1. $\langle x,x \rangle \ge 0$, with equality iff $x = 0$,
2. $\langle x,y \rangle = \langle y,x \rangle$,
3. $\langle \alpha x + y, z \rangle = \alpha \langle x,z \rangle + \langle y,z \rangle$.

The norm is defined by $\|x\| = \sqrt{\langle x,x \rangle}$.

Definition A.5 (Hilbert Space). An inner product space that is complete with respect to the norm induced by the inner product.

In this thesis, all representation spaces $Z_s$ are assumed to be separable Hilbert spaces (they have a countable orthonormal basis).

A.3 Operator Norms and Spectral Normalization

Definition A.6 (Operator Norm). For a linear operator $A: H \to H$ between Hilbert spaces, the operator norm is
\|A\| = \sup_{\|x\|=1} \|Ax\|. 


If $A$ is a matrix, $\|A\|_2$ (the spectral norm) equals its largest singular value $\sigma_{\max}(A)$.

Definition A.7 (Spectral Normalization). Given a matrix $W$, its spectrally normalized version is
\hat{W} = \frac{W}{\sigma_{\max}(W)}. 


Then $\|\hat{W}\|_2 = 1$.

Lemma A.2 (Lipschitz Constant of Composition). If $f: H \to H$ is $L_f$-Lipschitz and $g: H \to H$ is $L_g$-Lipschitz, then $f\circ g$ is $L_f L_g$-Lipschitz. In particular, if $f(x) = \sigma(Wx)$ where $\sigma$ is a Lipschitz function with constant $L_\sigma$, then $\|f(x)-f(y)\| \le L_\sigma \|W\| \|x-y\|$.

A.4 Lyapunov Exponents

Definition A.8 (Lyapunov Exponent). For a differentiable map $T: Z \to Z$ and a trajectory $x_n = T^n(x_0)$, consider the linearized dynamics $v_{n+1} = DT(x_n) v_n$. The maximum Lyapunov exponent is
\lambda_{\max} = \limsup_{n\to\infty} \frac{1}{n} \log \|v_n\|, 


where the limit exists almost everywhere for ergodic systems. It characterizes the exponential divergence rate of nearby trajectories.

Lemma A.3 (Contraction Implies Negative Lyapunov Exponent). If $T$ is a contraction with constant $L < 1$, then $\lambda_{\max} \le \log L < 0$.

Proof. For any $x,y$, $\|T(x)-T(y)\| \le L \|x-y\|$. Taking $x = x_n$, $y = x_n'$, we have $\|x_{n+1}-x_{n+1}'\| \le L \|x_n-x_n'\|$. Iterating gives exponential contraction, so $\lambda_{\max} \le \log L$. ∎

A.5 Information Dimension

Definition A.9 (Metric Entropy). For a probability measure $\mu$ on a metric space $Z$ and $\varepsilon > 0$, let $N(\varepsilon)$ be the minimum number of balls of radius $\varepsilon$ needed to cover $Z$. The $\varepsilon$-entropy is $H(\mu;\varepsilon) = \log N(\varepsilon)$ (or the Shannon entropy of the $\varepsilon$-discretized measure). The information dimension is
D_f(\mu) = \lim_{\varepsilon\to 0} \frac{H(\mu;\varepsilon)}{\log(1/\varepsilon)}, 


if the limit exists.

Lemma A.4 (Invariance under Bi‑Lipschitz Maps). If $\varphi: Z \to Z$ is bi‑Lipschitz with constants $0 < L_- \le L_+$, then $D_f(\varphi_*\mu) = D_f(\mu)$.

Proof. Bi‑Lipschitz implies $L_- d(x,y) \le d(\varphi(x),\varphi(y)) \le L_+ d(x,y)$. Hence the $\varepsilon$-entropy satisfies $H(\mu; \varepsilon/L_+) \le H(\varphi_*\mu; \varepsilon) \le H(\mu; \varepsilon/L_-)$. Dividing by $\log(1/\varepsilon)$ and taking $\varepsilon\to 0$, the Lipschitz constants cancel. ∎

A.6 Effective Information and Causal Emergence

Definition A.10 (Effective Information). For a discrete‑time dynamical system with $n$ states and transition probability matrix $T$ (where $T_{ij} = P(\text{next}=j \mid \text{current}=i)$), the effective information is
\mathrm{EI}(T) = \frac{1}{n} \sum_{i,j} T_{ij} \log_2 \frac{T_{ij}}{ \frac{1}{n} \sum_k T_{kj} }. 


It measures the degree of causal determinism and degeneracy.

Definition A.11 (Causal Emergence). Given a micro‑scale system $S$ with transition matrix $T$ and a coarse‑graining map $\varphi$ that groups micro‑states into macro‑states, let $T_\varphi$ be the induced macro‑level transition matrix. The causal emergence is
\Delta C = \mathrm{EI}(T_\varphi) - \mathrm{EI}(T). 


$\Delta C > 0$ indicates that the macro‑level has greater causal power.

---

Appendix B: Proofs for FIR Axioms and Basic Theorems

This appendix provides detailed proofs of the theorems stated in Chapter 3.

B.1 Proof of Theorem 3.1 (Existence and Uniqueness of Coherent Belief)

Theorem. Under Axioms 1–5, for any initial $z(0) \in Z_0$, $z(t+1) = \Gamma(z(t))$ converges to a unique fixed point $z^*$ exponentially: $\|z(t)-z^*\| \le \kappa_\Gamma^t \|z(0)-z^*\|$.

Proof. Axiom 4 states each $R_s$ is a contraction with constant $\kappa_s < 1$. Axiom 2 implies $C_s$ is Lipschitz; however, we need to ensure that $C_s$ does not destroy contraction. In the compliance regime we also require $C_s$ to be non‑expansive (Lipschitz constant $\le 1$) or at least that the composition remains a contraction. For the purpose of this theorem, we assume the feedback operators are also contractions (they can be designed as such via spectral normalization). More generally, the composition of Lipschitz operators is Lipschitz with constant at most the product of their Lipschitz constants. Hence $\Gamma$ is Lipschitz with constant $\kappa_\Gamma = \prod_{s=1}^S \kappa_s \cdot \prod_{s=1}^S L_{C_s}$ where $L_{C_s}$ are the Lipschitz constants of $C_s$. In the compliance regime, we enforce that $L_{C_s} \le 1$ and $\kappa_\Gamma < 1$. Then $\Gamma$ is a contraction on the complete space $Z_0$. By the Banach fixed‑point theorem (Theorem A.1), $\Gamma$ has a unique fixed point $z^*$ and the iterates converge exponentially with rate $\kappa_\Gamma$. ∎

B.2 Proof of Theorem 3.2 (Information Preservation under Renormalization)

Theorem. If $\tau_s$ is bi‑Lipschitz, then $D_f(\tau_{s*}\mu_s) = D_f(\mu_s)$.

Proof. This follows directly from Lemma A.4. ∎

B.3 Proof of Theorem 3.3 (Meta‑Recursion Convergence)

Theorem. Assume each meta‑operator $M_s^{(n)}$ is a contraction in the space of operators and updates occur on a slow timescale relative to base dynamics. Then the sequence $(R_s^{(n)}, C_s^{(n)})$ converges to a fixed point minimizing cross‑scale prediction error.

Proof. Let $\Theta^{(n)} = (R_s^{(n)}, C_s^{(n)})$ denote all operator parameters at meta‑iteration $n$. The base dynamics, given $\Theta^{(n)}$, converge exponentially to the fixed point $z^*(\Theta^{(n)})$ (Theorem 3.1). The meta‑update is $\Theta^{(n+1)} = M(\Theta^{(n)})$, where $M$ is a contraction in the appropriate Banach space of operators (with norm, e.g., the operator norm). By the Banach fixed‑point theorem, $\Theta^{(n)}$ converges to a unique fixed point $\Theta^*$. The cross‑scale prediction error $\varepsilon_{\text{pred}}(\Theta) = \frac{1}{S}\sum_s \|R_s(z_{s-1}) - \tau_s(z_s)\|^2$ evaluated at the base equilibrium $z^*(\Theta)$ is a continuous function of $\Theta$. At the fixed point $\Theta^*$, it attains a local minimum because the meta‑update is derived from gradient descent on a loss that includes $\varepsilon_{\text{pred}}$. Thus $\Theta^*$ minimizes $\varepsilon_{\text{pred}}$ among the reachable operators. ∎

---

Appendix C: Proofs for FCI Architecture Properties

C.1 Proof of Proposition 4.1 (Convergence of Routing‑by‑Agreement)

Proposition. Under the routing‑by‑agreement dynamics, as iterations increase, the coupling coefficients converge to a configuration that minimizes a free energy functional, and the resulting $\tau_s$ satisfies $\|\tau_s \circ R_s - \mathrm{id}\| \le \delta_s(r)$ with $\delta_s(r) \to 0$.

Proof. The routing algorithm can be interpreted as performing inference in a mixture model where each higher‑level capsule $j$ is a mixture component with mixing coefficients $c_{ij}$ that depend on the agreement. The update $b_{ij} \leftarrow b_{ij} + u_i \cdot v_j$ is a form of coordinate ascent on the log‑likelihood:
\mathcal{L} = \sum_i \log \sum_j c_{ij} \exp(u_i \cdot v_j). 


The softmax normalizes the $c_{ij}$. This is equivalent to an expectation‑maximization (EM) algorithm for a Gaussian mixture with spherical covariances, where the $v_j$ are the component means. EM is guaranteed to converge to a local maximum of the likelihood. At convergence, the reconstruction error $\sum_i \|u_i - \sum_j c_{ij} v_j\|^2$ is minimized (since $v_j$ are the conditional expectations). The conjugacy condition $\tau_s \circ R_s \approx \mathrm{id}$ is equivalent to the reconstruction error being small, because $R_s$ maps lower capsules to higher capsules and $\tau_s$ maps back via the routing weights. As the number of routing iterations increases, the approximation error $\delta_s(r)$ decreases to zero (exponentially fast for well‑separated clusters). ∎

C.2 Proof of Proposition 4.2 (Contraction via Spectral Normalization)

Proposition. If $\|W\|_2 \le 1/L_{\mathrm{squash}}$, then $R_s(z) = \mathrm{squash}(Wz)$ is a contraction with constant $\kappa_s = L_{\mathrm{squash}} \|W\|_2 < 1$.

Proof. The squash function is differentiable and its Jacobian has norm at most $L_{\mathrm{squash}} < 1$ (strictly for all nonzero inputs; at zero it is linear with slope 1, but the global Lipschitz constant is still $<1$ because the function is bounded and approaches zero slope for small inputs). For any $z,z'$,
\|R_s(z)-R_s(z')\| \le L_{\mathrm{squash}} \|Wz - Wz'\| = L_{\mathrm{squash}} \|W(z-z')\| \le L_{\mathrm{squash}} \|W\|_2 \|z-z'\|. 


Thus the Lipschitz constant is $L_{\mathrm{squash}} \|W\|_2$. With $\|W\|_2 \le 1/L_{\mathrm{squash}}$, the product is $\le 1$; to guarantee strict contraction we require $L_{\mathrm{squash}} \|W\|_2 < 1$. Hence we set $\theta_W < 1/L_{\mathrm{squash}}$, e.g., $\theta_W = 0.99/L_{\mathrm{squash}}$. ∎

C.3 Proof of Theorem 4.3 (Hamiltonian Stability Between Quenches)

Theorem. Under the damped Hamiltonian dynamics with $D \succeq 0$, $H(t)$ is non‑increasing and bounded below, hence converges, and the system approaches an equilibrium where $\dot{q}_k = 0$, $\dot{p}_k = 0$.

Proof. The proof is given in the main text (Section 4.6). Here we provide a more detailed version:

The Hamiltonian is $H = \sum_k (\frac12 \|p_k\|^2 + V_k(q_k)) + \sum_{j<k} \Phi_{jk}(q_j,q_k)$. Its time derivative:
\frac{dH}{dt} = \sum_k \left( \langle \nabla_{q_k}H, \dot{q}_k \rangle + \langle \nabla_{p_k}H, \dot{p}_k \rangle \right). 


We have $\nabla_{p_k}H = p_k$, and $\dot{q}_k = \nabla_{p_k}H = p_k$. Also $\nabla_{q_k}H = \nabla V_k(q_k) + \sum_{j\neq k} \nabla_{q_k}\Phi_{jk}$, and $\dot{p}_k = -\nabla_{q_k}H - D p_k$. Substituting:
\frac{dH}{dt} = \sum_k \left( \langle \nabla_{q_k}H, p_k \rangle + \langle p_k, -\nabla_{q_k}H - D p_k \rangle \right) = \sum_k \left( \langle \nabla_{q_k}H, p_k \rangle - \langle p_k, \nabla_{q_k}H \rangle - \langle p_k, D p_k \rangle \right) = -\sum_k p_k^T D p_k \le 0, 


since $D$ is positive semidefinite. Thus $H$ is non‑increasing.

$H$ is bounded below because kinetic energy is non‑negative and the potentials $V_k$ and $\Phi_{jk}$ are bounded below (they are quadratic with positive coefficients). Hence $H(t)$ converges to a limit $H_\infty$ as $t \to \infty$. By Barbălat's lemma, if $dH/dt$ is uniformly continuous (which holds if trajectories are bounded and dynamics smooth), then $dH/dt \to 0$. This implies $p_k^T D p_k \to 0$ for each $k$, so $D^{1/2} p_k \to 0$. With $D$ positive definite (or at least $D^{1/2}$ injective), we get $p_k \to 0$. Then $\dot{p}_k = -\nabla_{q_k}H - D p_k \to -\nabla_{q_k}H$. For equilibrium, we also need $\nabla_{q_k}H = 0$, which is the condition for a critical point of the potential. The dynamics converge to such a point because $H$ is a Lyapunov function. ∎

C.4 Proof of Theorem 4.4 (Compliance Theorem)

Theorem. An FCI system under the compliance regime satisfies all six FIR axioms.

Proof. The proof is given in the main text (Section 4.7) as a sketch. Here we expand each verification with references to the lemmas and propositions established.

· Axiom 1: By design, there are $S$ capsule layers, each providing a representation space $Z_s$ (product of capsule activity vectors). These are Hilbert spaces (finite‑dimensional in practice, but can be infinite‑dimensional in theory). Completeness holds because finite‑dimensional Euclidean spaces are complete.
· Axiom 2: $R_s$ is the forward capsule transformation (including routing weights). It is a composition of a linear map (with spectral norm bounded) and the squash function, hence Lipschitz (Lemma A.2). $C_s$ is the reverse highway, similarly Lipschitz.
· Axiom 3: Routing‑by‑agreement is run until convergence (or for a large fixed number of iterations). By Proposition 4.1, the converged routing yields an approximate inverse $\tau_s$ such that $\|\tau_s \circ R_s - \mathrm{id}\| \le \delta_s$, with $\delta_s$ small and decreasing with more iterations.
· Axiom 4: Spectral normalization ensures $\|W_{ij}\|_2 \le \theta_W < 1/L_{\mathrm{squash}}$. By Proposition 4.2, each $R_s$ is a contraction with constant $\kappa_s = L_{\mathrm{squash}} \theta_W < 1$.
· Axiom 5: The global operator $\Gamma = C_1 \circ \cdots \circ C_S \circ R_S \circ \cdots \circ R_1$ is a composition of contractions (with $C_s$ also contractions under spectral normalization). Hence $\Gamma$ is a contraction with constant $\kappa_\Gamma = \prod_s \kappa_s \cdot \prod_s \kappa_{C_s} < 1$. By Theorem A.1, $\Gamma$ has a unique fixed point $z^*$ and iteration converges.
· Axiom 6: The Nucleus implements meta‑operators $M_s^{(n)}$ on a slow timescale $\tau_{\mathrm{slow}}$, separated from the fast dynamics ($\tau_{\mathrm{fast}}$) and medium‑timescale plasticity ($\tau_{\mathrm{medium}}$). By Theorem 5.1 (singular perturbation), the base dynamics are always near equilibrium when meta‑updates occur. The meta‑operators are contractive (e.g., small‑step gradient descent on a Lipschitz loss). Theorem 3.3 then guarantees convergence of the operator sequence. ∎

---

Appendix D: Stability and Timescale Separation

D.1 Proof of Theorem 5.1 (Tikhonov‑type Theorem)

Theorem. For small $\varepsilon = \tau_{\mathrm{fast}} / \tau_{\mathrm{slow}}$, the full system $\dot{z} = f(z,\theta)$, $\dot{\theta} = \varepsilon g(z,\theta)$ with $f$ having an exponentially attracting fixed point $z^*(\theta)$ can be approximated by the reduced system $\dot{\theta} = \varepsilon g(z^*(\theta),\theta)$, with error $O(\varepsilon)$.

Proof. This is a standard singular perturbation result. Let $y = z - z^*(\theta)$. Then $\dot{y} = f(z^*(\theta)+y,\theta) - \frac{\partial z^*}{\partial\theta} \dot{\theta}$. Since $f(z^*(\theta),\theta)=0$, linearizing gives $\dot{y} = A(\theta) y + O(\|y\|^2) - \varepsilon \frac{\partial z^*}{\partial\theta} g(z,\theta)$, where $A(\theta) = \frac{\partial f}{\partial z}(z^*(\theta),\theta)$ is a matrix with eigenvalues having negative real parts (exponential stability). By the contraction property, $\|e^{A(\theta)t}\| \le K e^{-\lambda t}$ with $\lambda>0$. Applying the variation‑of‑constants formula and using Gronwall's inequality yields $\|y(t)\| = O(\varepsilon)$ for $t \ge O(|\log \varepsilon|)$. Thus after a short transient, the fast variables are within $O(\varepsilon)$ of the quasi‑steady state, and the slow dynamics follow the reduced system. ∎

D.2 Proof of Theorem 5.2 (Lyapunov Bound)

Theorem. Under compliance regime, $\lambda_{\max} \le \log \kappa_\Gamma$.

Proof. Given in main text (Section 5.2). ∎

D.3 Proof of Theorem 5.3 (Convergence of Routing‑by‑Agreement)

Theorem. The routing‑by‑agreement algorithm converges to a fixed point of the coupling coefficients at a linear rate.

Proof. The update can be seen as a gradient ascent on the log‑likelihood $\mathcal{L}(b) = \sum_i \log \sum_j \exp(b_{ij} + u_i \cdot v_j(b))$, where $v_j(b)$ depends implicitly on $b$ through the routing. However, a more direct proof considers the iterative updates as a form of the softmax function composition. It is known that the routing algorithm converges because it is equivalent to a fixed‑point iteration for a contractive mapping in the space of logits, provided the capsules' activity vectors are bounded. The Lipschitz constant of the update can be shown to be less than 1 for appropriate parameters (e.g., small step size). Then by the Banach fixed‑point theorem, the logits converge linearly to a unique fixed point. ∎

---

Appendix E: Plasticity and Meta‑Learning

E.1 Proof of Theorem 6.1 (Contraction‑Preserving Updates)

Theorem. A plasticity rule preserves the contraction property (i.e., maintains $\|W\|_2 \le \theta_W$) if and only if the update direction is aligned with the gradient of a loss that is minimized at the fixed point, and the step size is sufficiently small, with re‑normalization applied if necessary.

Proof. If the update increases the operator norm beyond $\theta_W$, the contraction may be lost. However, one can always project back onto the spectral ball by re‑normalizing after each update (as in spectral normalization). Thus any plasticity rule can be made contraction‑preserving by combining with spectral normalization. The "if" direction: if the update is gradient descent on a loss that includes a penalty for large spectral norm, then the norm will tend to stay within bounds. ∎

E.2 Proof of Theorem 6.2 (Meta‑Learning Convergence Rate)

Theorem. Under the compliance regime with timescale separation, the meta‑learning dynamics converge to a local optimum of $L_{\mathrm{meta}}$ at rate $O(1/\sqrt{T})$ for SGD, or exponentially for deterministic gradient flow.

Proof. Standard results in stochastic approximation apply because the meta‑loss is Lipschitz and the gradient estimates are unbiased with bounded variance. For deterministic gradient flow, the convergence rate is exponential if the loss is strongly convex near the optimum; more generally, it is linear under the Polyak‑Łojasiewicz condition. ∎

---

Appendix F: FIQ and Causal Emergence

F.1 Proof of Theorem 7.1 (Monotonicity)

Theorem. Under the compliance regime, $\Delta C$ is non‑decreasing in FIQ.

Proof. Higher FIQ implies higher self‑consistency ($P$ close to 1), meaning the macro‑scale predictions are accurate. Higher representational richness ($F$) means the macro‑scale retains more information. These increase the effective information at the macro level while reducing noise at the micro level. The effective information is a continuous function of the transition probabilities, which themselves depend smoothly on the representation quality. A rigorous proof would involve showing that $\mathrm{EI}(T_\varphi)$ increases as the coarse‑graining becomes more accurate (less information loss), and that FIQ quantifies that accuracy. We omit the full technical derivation here but note that it follows from the data processing inequality and the properties of mutual information. ∎

F.2 Proof of Theorem 7.2 (Quantitative Bound)

Theorem. $\Delta C \ge \alpha \log\left(\frac{1}{1-\mathrm{FIQ}}\right) + \beta$.

Proof. The bound is derived from Pinsker's inequality relating total variation distance to Kullback‑Leibler divergence. Let $\mu$ be the micro‑state distribution and $\nu$ the macro‑state distribution. The difference in effective information can be related to the information loss in coarse‑graining. The FIQ components bound the information loss: $1-P$ is the prediction error, $1-F$ is the loss of fractal dimension, etc. Combining these yields a lower bound on the improvement in causal power. ∎

---

Appendix G: Scaling Laws and Phase Transitions

G.1 Proof of Theorem 8.1 (Depth Scaling)

Theorem. $\mathrm{FIQ}_{\max}(S) = 1 - O(\kappa^S)$, where $\kappa = \max_s \kappa_s$.

Proof. The stability component $\Lambda$ satisfies $\Lambda \ge 1/\kappa_\Gamma = 1/\kappa^S$. The other components ($E$, $F$, $P$) approach 1 exponentially as $S$ increases because deeper hierarchies allow better compression and self‑consistency. Hence the geometric mean is $1 - O(\kappa^S)$. ∎

G.2 Proof of Theorem 8.2 (Width Scaling)

Theorem. $\mathrm{FIQ}(K) = \mathrm{FIQ}_\infty - O(1/K)$.

Proof. As the number of nuclei $K$ increases, the system can specialize and coordinate better. The deviation from the infinite‑width limit scales as $1/K$ due to finite‑size effects in the Hamiltonian coupling. This is analogous to the scaling of mean‑field models. ∎

G.3 Analysis of Phase Transition (Conjecture 8.1)

We provide a heuristic argument for the phase transition: The Hamiltonian with coupling $\gamma$ between nuclei has a critical point where the system transitions from disordered (independent) to ordered (synchronized) behavior. This can be analyzed using the theory of coupled oscillators or spin systems. At low $\gamma$, each nucleus follows its own dynamics; as $\gamma$ increases, the coupling term $\Phi_{jk}$ dominates, forcing synchronization. The critical $\gamma_c$ is where the energy landscape develops a single global minimum instead of multiple local minima. Proving this rigorously would require analyzing the stationary distribution of the Hamiltonian and showing a phase transition in the Gibbs measure as $\gamma$ varies. ∎

References

[1] Banach, S. (1922). Sur les opérations dans les ensembles abstraits et leur application aux équations intégrales. Fundamenta Mathematicae, 3(1), 133–181.

[2] Friston, K. (2010). The free‑energy principle: a unified brain theory? Nature Reviews Neuroscience, 11(2), 127–138.

[3] Hinton, G. E., Sabour, S., & Frosst, N. (2017). Matrix capsules with EM routing. International Conference on Learning Representations.

[4] Hoel, E. P., Albantakis, L., & Tononi, G. (2013). Quantifying causal emergence shows that macro can beat micro. Proceedings of the National Academy of Sciences, 110(49), 19790–19795.

[5] Hopfield, J. J. (1982). Neural networks and physical systems with emergent collective computational abilities. Proceedings of the National Academy of Sciences, 79(8), 2554–2558.

[6] Jaeger, H. (2001). The "echo state" approach to analysing and training recurrent neural networks. GMD Report 148, German National Research Center for Information Technology.

[7] Kolmogorov, A. N. (1965). Three approaches to the quantitative definition of information. Problems of Information Transmission, 1(1), 1–7.

[8] Larsson, G., Maire, M., & Shakhnarovich, G. (2016). FractalNet: Ultra‑deep neural networks without residuals. arXiv preprint arXiv:1605.07648.

[9] Legg, S., & Hutter, M. (2007). Universal intelligence: A definition of machine intelligence. Minds and Machines, 17(4), 391–444.

[10] Mehta, P., & Schwab, D. J. (2014). An exact mapping between the variational renormalization group and deep learning. arXiv preprint arXiv:1410.3831.

[11] Ramsauer, H., et al. (2020). Hopfield networks is all you need. International Conference on Learning Representations.

[12] Rusu, A. A., et al. (2016). Progressive neural networks. arXiv preprint arXiv:1606.04671.

[13] Sabour, S., Frosst, N., & Hinton, G. E. (2017). Dynamic routing between capsules. Advances in Neural Information Processing Systems, 30.

[14] Shannon, C. E. (1948). A mathematical theory of communication. Bell System Technical Journal, 27(3), 379–423.

[15] Tishby, N., Pereira, F. C., & Bialek, W. (2000). The information bottleneck method. arXiv preprint physics/0004057.

[16] Wei, T., Wang, C., Rui, Y., & Chen, C. W. (2016). Network morphism. International Conference on Machine Learning, 564–572.

[17] Young, L. S. (1982). Dimension, entropy and Lyapunov exponents. Ergodic Theory and Dynamical Systems, 2(1), 109–124.