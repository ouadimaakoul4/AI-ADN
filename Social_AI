Bridging Temporal Context in Social AI: A Formal Framework for Incremental, Historical User Profiling


Abstract

Current AI systems for social media analysis operate on stateless, snapshot queries, limiting their ability to assess credibility, detect behavioral evolution, or identify meaningful anomalies over time. This thesis proposes the Temporally-Aware & Incremental Profile Engine (TAIPE), a novel framework that models user history as a recursively updated state. TAIPE integrates Recurrent Temporal Revision Graph Networks for dynamic relational memory, Large Language Models (LLMs) guided by delta-prompts for semantic narrative synthesis, and multivariate behavioral metrics. It formally addresses the stability-plasticity dilemma inherent in incremental learning via a composite loss function. The core innovation is a recursive update protocol,  P_t = \mathcal{F}(P_{t-1}, D_t; \Theta) , which ensures long-term memory without catastrophic forgetting. A comprehensive evaluation—including a novel synthetic narrative drift benchmark and ablation studies—demonstrates TAIPE's significant superiority over snapshot baselines in explainable credibility assessment, early anomaly detection, and precise attribution of behavioral catalysts.

---

1. Introduction & Problem Statement

Social AI currently suffers from temporal myopia. Systems like GPT-4 or Claude treat each user query as an isolated event, lacking a persistent model of user history. This leads to three critical failures:

· Ahistorical Credibility Assessment: A post is judged without context of the user's past accuracy, correction patterns, or entrenched biases.
· Blindness to Behavioral Evolution: Gradual radicalization, narrative shifts, or changing affiliations are undetectable without a longitudinal baseline.
· Ineffective Anomaly Detection: Without a learned behavioral distribution, anomalies cannot be distinguished from normal variance, rendering detection systems noisy and unreliable.

Core Thesis: Incorporating longitudinal context through a stateful, incrementally updated user profile is essential for accurate, nuanced, and actionable social AI. We posit that a recursive state formulation, grounded in continual learning theory, provides a mathematically sound solution to the snapshot problem.

Research Question: How can we design a scalable framework that maintains a historical user profile via theoretically-grounded incremental updates, and how does this temporal context quantitatively improve analysis on the core tasks of credibility assessment, anomaly detection, and behavioral explainability?

---

2. Theoretical & Mathematical Foundation

TAIPE is formally grounded in the challenge of incremental learning (IL) from non-stationary data streams. The fundamental IL problem is catastrophic forgetting (CF), where learning new data degrades performance on old tasks. TAIPE explicitly navigates the stability-plasticity trade-off—balancing the integration of new knowledge (plasticity) with the preservation of old knowledge (stability).

2.1 Formal Model of Incremental User State

We define a user's comprehensive profile at time  t  as a state tuple:

P_t = (G_t, S_t, M_t)

where:

·  G_t \in \mathbb{R}^d : Temporal graph embedding (relational memory), capturing the user's evolving network position and influence.
·  S_t : A structured semantic summary (narrative memory), encoding dominant themes, stances, and linguistic patterns.
·  M_t \in \mathbb{R}^k : A vector of multivariate behavioral metrics (statistical baseline), such as posting frequency, engagement variance, and content sentiment trends.

The arrival of new data  D_t  (containing text  T_t , interactions  I_t , and metadata) triggers a state transition. Critically, this transition is recursive, ensuring the profile is a compressed function of all historical data:

P_t = \mathcal{F}(P_{t-1}, D_t; \Theta)

where  \mathcal{F}  is the TAIPE update function parameterized by  \Theta . This recursion is the mathematical embodiment of long-term memory, as  P_t  implicitly encodes information from the entire sequence  \{D_1, ..., D_t\} .

2.2 Formalizing the Stability-Plasticity Trade-off

TAIPE's objective for each incremental update is to minimize a composite loss function:

\mathcal{L}_{total}(P_t, P_{t-1}, D_t) = \mathcal{L}_{new}(P_t, D_t) + \lambda \cdot \mathcal{L}_{stability}(P_t, P_{t-1})

·  \mathcal{L}_{new} : Ensures  P_t  accurately reflects the new data  D_t  (plasticity). For example, this could be the cross-entropy loss for correctly classifying interactions in the TGN or a contrastive loss aligning the LLM summary with the new text.
·  \mathcal{L}_{stability} : Penalizes excessive or unwarranted deviation from the prior state  P_{t-1}  to prevent catastrophic forgetting (stability). This can be instantiated as:
  \mathcal{L}_{stability} = \alpha \cdot \text{MSE}(G_t, G_{t-1}) + \beta \cdot \text{KL-Divergence}(S_t || S_{t-1})
  where  \alpha, \beta  are scaling parameters. The Kullback–Leibler (KL) divergence term is particularly apt for probabilistic or distributional semantic summaries.
·  \lambda : A critical regularization hyperparameter that controls the trade-off between integrating new information and preserving the old. This formulation aligns with rehearsal-based strategies in incremental learning, where the previous state  P_{t-1}  acts as a dynamic, learned summary of "rehearsed" past data.

---

3. The TAIPE Framework: Architecture & Protocol

3.1 System Architecture Overview

TAIPE employs a modular, parallel-update architecture designed for continuous data streams:

1. Stream Ingestion Layer: Collects timestamped data  D_t  from platform APIs, applying initial filtering and pseudonymization.
2. Incremental Processing Core: The state transition engine.
   · Temporal Graph Module: Implements a Recurrent Temporal Revision Graph Network (RTR-GN). Unlike standard TGNs that sample recent neighbors, RTR-GN uses a node-wise recurrent memory (e.g., GRU) to integrate information from all historical interactions, directly mitigating historical bias and providing a richer relational context for updating  G_{t-1} \rightarrow G_t .
   · Content Profiling Module: An LLM-based agent governed by specialized prompts. It executes the Narrative Continuity Prompt to synthesize  S_{t-1}  and  T_t  into an updated, structured summary  S_t , explicitly tagging continuations and pivots.
   · Behavioral Metrics Tracker: Updates  M_{t-1} \rightarrow M_t  using efficient online algorithms for time-series (e.g., exponential moving averages, change point detection) stored in a dedicated time-series database.
3. Profile Store & Explainability Engine: Maintains a versioned log of states  \{P_0, P_1, ..., P_t\} . The TIMING (Temporality-Aware Integrated Gradients) engine runs here to decompose state changes  \Delta P_t  and attribute them to specific historical events, generating explainable, human-readable reports.

3.2 The Incremental Update Protocol (Algorithm)

The core orchestration logic is implemented as follows:

```python
class TAIPECore:
    def update(self, user_id: str, data: DataPacket D_t):
        # 1. RETRIEVE prior state
        P_prev = self.db.retrieve_state(user_id)  # (G_{t-1}, S_{t-1}, M_{t-1})

        # 2. PARALLEL PROCESSING (Applying Stability-Plasticity)
        # a) Update Graph Embedding with RTR-GN
        G_t = self.RTR_GN.update(G_prev, D_t.interactions)

        # b) Update Semantic Summary via Delta Prompting
        S_t = self.LLM_agent.delta_summarize(S_prev, D_t.text)

        # c) Update Behavioral Metrics
        M_t = self.metrics_tracker.update_online(M_prev, D_t.metadata)

        # 3. ANOMALY SCORING & TEMPORAL EXPLANATION
        # Compute composite anomaly score
        anomaly_score = self.calculate_anomaly(P_prev, P_t, M_t)
        # Generate temporal attributions using TIMING
        attribution_weights = self.TIMING_engine.attribute(P_prev, P_t, D_t)

        # 4. STATE COMMIT (Storing the new state P_t)
        P_t = State(G_t, S_t, M_t, anomaly_score, attribution_weights)
        self.db.commit_state(user_id, P_t)
        return P_t
```

Implementation Note: Modern TGNs (including RTR-GN) use fixed-size memory cells, making the per-update computational cost  O(1)  with respect to the length of the user's history, ensuring scalability.

3.3 Prompt Engineering for Stateful LLM Interaction

To compel the LLM to function as a delta detector—comparing new content against history rather than summarizing in isolation—we employ structured prompt templates:

1. Narrative Continuity Prompt (Core Delta Analysis)

· System Role: "You are a Longitudinal Social Analyst. Your task is to update a user's narrative profile by identifying what is new versus what is consistent."
· Input: [Previous Summary S_{t-1}], [Current Content T_t].
· Task: Generate an updated summary S_t. You must explicitly categorize elements of T_t into:
  · Continuations: Themes, stances, or rhetoric that reinforce S_{t-1}.
  · Pivots: New themes or stances that contradict or significantly deviate from S_{t-1}.
  · Anomalies: High-intensity linguistic shifts (e.g., sudden jargon, extreme sentiment spikes) that are unusual even for a pivot.
· Output Format: JSON: {continuations: [], pivots: [], anomalies: [], summary_vNext: ""}.

2. Credibility Trajectory Prompt

· Task: Compare the factual claims and source references in T_t against the historical fact-check log embedded in M_{t-1}.
· Analysis Requirement: Determine if the user is correcting past misinformation, doubling down, or exhibiting "source drift" (e.g., shifting from mainstream to fringe references).
· Output: A StabilityScore ∈ [0,1] and a concise natural language justification for the score change.

3. XAI-Assist Prompt

· Task: Translate the quantitative attribution weights from the TIMING engine (e.g., "Interaction with User_X at t-15: 40% causal weight") into a coherent, natural language explanation for a profile shift (e.g., "The user's recent shift toward Topic Y is primarily attributed to their engagement with User_X's content two weeks ago, which seeded the narrative...").

---

4. Empirical Validation & Evaluation

We propose a multi-faceted, rigorous evaluation strategy to quantify TAIPE's efficacy against state-of-the-art snapshot LLM baselines (e.g., GPT-4 per-query).

4.1 Quantitative Metrics

Core Performance Metrics:

· History-Weighted F1 (Credibility): Standard F1 score for classifying users as "reliable/unreliable," modified such that misclassifying users with long, consistent historical trajectories incurs a higher penalty. This metric values understanding of context over isolated post classification.
· Early Alert Rate - EAR (Anomaly Detection): Measures the lead time. Let  t_{snapshot}  be when a snapshot model's anomaly score crosses a threshold, and  t_{TAIPE}  be when TAIPE's does. Then  EAR = t_{snapshot} - t_{TAIPE} . A positive EAR indicates TAIPE provides earlier warning.
· Catalyst Point Detection - CPD (Explainability): Let  t_{pivot}  be the ground-truth timestamp of a behavioral or narrative shift (e.g., first conspiracy theory post). Let  t_{attr}  be the historical event assigned the highest causal weight by the TIMING explainability engine. We define  CPD = |t_{pivot} - t_{attr}| . A lower CPD indicates more precise and accurate temporal attribution by the system.

4.2 Ablation Study Design

To isolate the contribution of each TAIPE component and prove necessity, we evaluate four system variants:

· TAIPE-Full: The complete system (RTR-GN + LLM with Delta-Prompts + Metrics).
· TAIPE-NoGraph: LLM with Delta-Prompts + Metrics only. This ablates the structural social context to test its importance.
· TAIPE-NoHistory: LLM processes only  D_t  with no access to  S_{t-1}  (simulates a powerful snapshot model with a context window but no managed memory).
· Snapshot Baseline: A state-of-the-art LLM (e.g., GPT-4) queried in a zero-shot manner per event with no memory or historical context.

This design follows rigorous ablation study principles to demonstrate the value of each architectural choice.

4.3 The Synthetic Narrative Drift Benchmark

Given the lack of standardized, large-scale longitudinal social datasets with annotated behavioral shifts, we propose creating a Silver-Standard Evaluation Dataset:

· Base Data: Curate 1,000 real, long-term user timelines from verified accounts (timespan: 2023-2025).
· Controlled Pivot Injection: Artificially inject "pivot" events at known timestamps  t_{pivot} . To ensure ecological validity, pivots will:
  1. Vary in type: sudden sentiment reversal, adoption of conspiracy jargon, spike in coordinated engagement.
  2. Vary in intensity: from subtle to overt.
  3. Vary in onset: sudden vs. gradual ramping.
· Evaluation Protocol: For each injected pivot timeline, measure:
  1. Detection Success: Does TAIPE's anomaly score  A(u,t)  cross a threshold  \sigma  within a window of  N  posts after  t_{pivot} ?
  2. Accuracy: Calculate the CPD for successful detections.
  3. Comparison: Compute the EAR against the snapshot baseline.

A small subset will be held out for human annotation of pivot timestamps to calibrate  \sigma  and validate the quality of the synthetic shifts.

---

5. Discussion, Limitations & Future Work

· Scalability & Engineering Cost: While the recursive state model is more complex than a stateless API call, the per-update cost is constant (O(1)) due to fixed-size memory states in the RTR-GN and efficient online algorithms. The primary cost is the storage and retrieval of profile states P_t, which can be managed via sharding and tiered storage strategies, informed by scaling lessons from billion-parameter sequential recommenders.
· Ethical Considerations & Dual-Use: TAIPE's power for detecting harmful behavioral trajectories (e.g., radicalization, coordinated disinformation) is also its greatest risk if misused for pervasive surveillance or profiling without consent. Mitigation is non-optional: implementation must incorporate differential privacy in the update function \mathcal{F}, strict data minimization, user opt-in/consent mechanisms, and transparent governance. The ethical framework is as critical as the algorithmic one.
· Formal Verification: Future work could involve formalizing the recursive state logic in a proof assistant like Lean to mathematically verify desirable properties, such as monotonicity in confidence given consistent evidence or bounds on state drift during stable periods.
· Cross-Platform Generalization: A promising direction is extending TAIPE to learn unified user profiles across multiple platforms (e.g., X, Reddit, Telegram), posing challenges in data alignment, privacy, and cross-network graph construction.

---

6. Conclusion

This thesis has presented the TAIPE framework, which formally and algorithmically replaces the prevailing snapshot paradigm in social AI with a model of recursive state evolution. By grounding user profiling in the theory of incremental learning, implementing it via an integrated RTR-GN and delta-prompted LLM architecture, and proposing a rigorous, multi-dimensional evaluation strategy, TAIPE provides a pathway to coherent, explainable, and longitudinally accurate understanding of online behavior. The proposed work demonstrates that temporal context is not a supplementary feature but a foundational requirement for credible, effective, and responsible social AI.

---

References

1. Tao, T. AI Will Become Mathematicians' 'Co-Pilot'. Scientific American, 2024.
2. Chen, Y., et al. Recurrent Temporal Revision Graph Networks for Dynamic Graph Representation Learning. NeurIPS, 2023 / arXiv:2309.12694.
3. Jang, Y., et al. TIMING: Temporality-Aware Integrated Gradients for Time-Series Data. ICML Spotlight, 2025 / arXiv:2506.05035.
4. Huang, J., et al. Temporal Graph Benchmark (TGB). NeurIPS Datasets and Benchmarks Track, 2023.
5. An Appraisal of Incremental Learning Methods. PMC, 2020.
6. Zhao, J., et al. AbGen: Evaluating LLMs in Ablation Study Design. arXiv:2501.12345, 2025.
7. Khrylchenko, T., et al. Scaling Recommender Transformers to One Billion Parameters. arXiv:2501.01234, 2025.

