A Unified Mathematical Framework for Physics-Constrained Self-Reconfiguring Generative Intelligence

Abstract

This thesis introduces a unified mathematical and computational framework for Physics-Constrained Self-Reconfiguring Generative Intelligence (PC-SRGI). Contemporary generative models achieve remarkable performance through large-scale statistical learning yet lack intrinsic physical consistency, structural plasticity, and energy awareness. We propose a formalism in which generative intelligence is defined as constrained functional approximation under physical, dynamical, and energetic laws. The framework integrates: (1) physics-informed generative transformers, (2) differentiable world models governed by partial differential equations, (3) graph-theoretic structural plasticity through adaptive capsule architectures, (4) explicit computational energy regularization, and (5) symbolic extraction of discovered physical laws. A reference open-source implementation is provided in Python/PyTorch with a deterministic simulation core in Rust. The central claim is that embedding conservation laws, stability constraints, and energy minimization principles directly into generative reasoning yields more robust, adaptive, and autonomous artificial systems. This document presents the complete mathematical foundations, system architecture, and implementation design of version 0.4 of the framework.

---

Chapter 1: Introduction

1.1 Motivation

Large-scale generative models, such as transformers and diffusion models, have revolutionized machine learning by approximating high-dimensional distributions:

f_\theta : \mathcal{X} \rightarrow \mathcal{Y}

where \theta denotes learned parameters. These systems excel at pattern recognition and content generation but operate without regard for the physical laws governing the real world. Consequently, they often produce predictions that violate conservation of energy, momentum, or other invariants; they lack the ability to adapt their own computational structure to changing environments; and they consume vast amounts of energy without any awareness of efficiency.

In contrast, intelligent agents in nature are constrained by physics, exhibit structural plasticity (e.g., synaptic pruning and growth), and operate under metabolic energy budgets. To bridge this gap, we propose a framework that redefines intelligence as constrained functional approximation:

\mathcal{I} = \arg\min_{f_\theta} \mathcal{L}(f_\theta; \mathcal{X}, \mathcal{Y}) \quad \text{subject to} \quad \mathcal{C}(f_\theta) = 0

where \mathcal{C} encodes physical laws, dynamical stability, and energy bounds. This thesis develops the mathematical and architectural foundations of such a framework.

1.2 Contributions

The main contributions of this work are:

1. A mathematical formalism for physics-constrained generative modeling, integrating differential constraints, conservation laws, and energy bounds into a single objective.
2. A differentiable world model based on symplectic integration, ensuring long-term stability and energy conservation in learned dynamics.
3. A graph-theoretic structural plasticity mechanism that enables the model to reconfigure its own architecture (capsules and routing) in response to task demands and energy budgets.
4. An energy-aware optimization framework that balances task performance against computational cost, leading to Pareto-optimal trade-offs.
5. A symbolic extraction module that translates learned sparse representations into human-readable physical laws.
6. A hybrid Rust/Python implementation that combines the performance and safety of Rust for deterministic simulation with the flexibility of PyTorch for differentiable modeling.
7. Theoretical guarantees on stability, convergence, and conservation, supported by mathematical proofs.

1.3 Outline

The remainder of this thesis is organized as follows. Chapter 2 establishes the mathematical foundations, including constrained functional approximation, physics-informed learning, differentiable world models, symplectic integration, graph optimization, energy models, and symbolic regression. Chapter 3 describes the overall system architecture and the interaction between its components. Chapter 4 provides a detailed account of the implementation design, with code listings illustrating key modules. Chapter 5 presents theoretical analyses of stability, convergence, and conservation, including proofs of key theorems. Chapter 6 concludes the thesis.

---

Chapter 2: Mathematical Foundations

2.1 Constrained Functional Approximation

Let \mathcal{X} \subseteq \mathbb{R}^{d_x} be the input space (e.g., sensor readings or system states), \mathcal{Y} \subseteq \mathbb{R}^{d_y} the output space (e.g., future states or control actions), and \mathcal{P} \subseteq \mathbb{R}^{d_p} the space of physical parameters (e.g., mass, gravity). We seek a parameterized function f_\theta: \mathcal{X} \times \mathcal{P} \rightarrow \mathcal{Y} that minimizes a task loss \mathcal{L}_{\text{task}} while satisfying a set of constraints \mathcal{C}(f_\theta)=0.

Define the constraints as:

\mathcal{C}(f_\theta) = \begin{cases}
\mathcal{D}(f_\theta) - g = 0 & \text{(differential constraints)} \\
\nabla \cdot F = 0 & \text{(conservation laws)} \\
E(f_\theta) \leq E_{\max} & \text{(energy bounds)}
\end{cases}

Here \mathcal{D} is a differential operator (e.g., \frac{\partial}{\partial t} or \nabla), g is a known source term, and F is a flux. The energy bound E_{\max} limits the computational resources consumed by the model.

We convert the constrained problem into an unconstrained one via the method of Lagrange multipliers or penalty methods. The total loss is:

\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{task}} + \lambda_1 \mathcal{L}_{\text{physics}} + \lambda_2 E_{\text{comp}} + \lambda_3 S_{\text{instability}}

where \mathcal{L}_{\text{physics}} penalizes violations of differential and conservation constraints, E_{\text{comp}} is the computational energy, and S_{\text{instability}} is a measure of dynamical instability. The \lambda_i are hyperparameters that may be adapted during training.

2.2 Physics-Informed Generative Transformers

Let \mathcal{T}_\theta denote a transformer model that maps an input sequence (x_1,\dots,x_T) to an output sequence (y_1,\dots,y_T). We augment the training objective with a physics residual:

\mathcal{L}_{\text{physics}} = \left\| \mathcal{D}(\mathcal{T}_\theta(x)) - g(x) \right\|^2

where \mathcal{D} is applied pointwise or along the sequence dimension. For conservation of a quantity Q (e.g., energy, momentum), we impose:

\mathcal{L}_{\text{cons}} = \left\| \frac{dQ}{dt} \right\|^2

evaluated along predicted trajectories.

2.3 Differentiable World Models

We define a dynamical system in discrete time:

s_{t+1} = \Phi_\theta(s_t, a_t)

where s_t \in \mathbb{R}^n is the state, a_t is an action or control, and \Phi_\theta is a parameterized transition. In continuous time, we write:

\frac{ds}{dt} = F_\theta(s, a)

with F_\theta learned. Using the neural ODE framework, the state at time t is:

s(t) = s(0) + \int_0^t F_\theta(s(\tau), a(\tau)) \, d\tau

Stability of the learned dynamics is essential. A sufficient condition is that the Jacobian J_F = \frac{\partial F_\theta}{\partial s} has eigenvalues with negative real parts. In particular, we require:

\lambda_{\max}(J_F) < 0

where \lambda_{\max} denotes the maximum real part of the eigenvalues.

2.4 Symplectic Integration

For systems with Hamiltonian structure, symplectic integrators preserve the symplectic two-form dq \wedge dp and guarantee long-term energy stability. The Velocity Verlet (Störmer–Verlet) algorithm is a second-order symplectic method:

Given position q and momentum p at time t, and force F(q) = -\nabla V(q):

1. Half-step momentum: p_{t+\frac12} = p_t + \frac{\Delta t}{2} F(q_t)
2. Full-step position: q_{t+\Delta t} = q_t + \Delta t \, p_{t+\frac12}
3. Compute force at new position: F(q_{t+\Delta t})
4. Half-step momentum: p_{t+\Delta t} = p_{t+\frac12} + \frac{\Delta t}{2} F(q_{t+\Delta t})

This scheme is symplectic and time-reversible. In our framework, the force F is predicted by a neural network, making the integrator differentiable end-to-end.

2.5 Structural Plasticity via Graph Optimization

We model the architecture as a dynamic graph G_t = (V_t, E_t), where V_t are computational capsules (sub-networks) and E_t are weighted routing edges. The graph evolves according to:

G_{t+1} = \mathcal{R}(G_t, \nabla_\theta \mathcal{L}, E_{\text{comp}})

where \mathcal{R} is a reconfiguration function driven by gradients and energy constraints. The optimization objective for the graph is:

\min_{G_t} \left( \mathcal{L}_{\text{task}} + \alpha C_{\text{energy}}(G_t) + \beta C_{\text{complexity}}(G_t) \right)

To make this differentiable, we introduce a continuous relaxation of the binary activation variable z_i \in \{0,1\} for each capsule:

z_i \approx \sigma(\gamma_i / \tau)

where \gamma_i is a learnable gate parameter and \tau is a temperature that is annealed during training. The gated output of a capsule layer is:

\text{out} = \sum_{i} z_i \cdot \text{capsule}_i(x)

2.6 Energy-Aware Intelligence

Computational energy is modeled as a weighted sum of operations:

E_{\text{comp}} = \sum_i w_i \cdot \text{FLOPs}_i

where \text{FLOPs}_i is the floating-point operation count for module i and w_i are hardware-specific weights (e.g., energy per FLOP). During training, we impose a dynamic budget:

E_{\text{comp}}(t) \leq E_{\text{budget}}(t)

The energy-regularized optimization becomes:

\min_\theta \left[ \mathcal{L}_{\text{task}} + \lambda E_{\text{comp}} \right]

The trade-off between task loss and energy consumption defines a Pareto frontier:

\mathcal{P} = \{ (\mathcal{L}_{\text{task}}, E_{\text{comp}}) \}

2.7 Symbolic Extraction

After training, the sparse gate activations reveal which capsules are essential. We aim to extract a human-readable symbolic expression from the active capsules. Let each capsule represent a basis function \phi_i(x) (e.g., x, \sin(x), x^2). The overall model is:

f_\theta(x) \approx \sum_{i: z_i > \epsilon} w_i \phi_i(x)

We then apply symbolic regression (e.g., using PySR) to find a concise expression that fits the weighted combination. This step bridges the neural representation to interpretable scientific laws.

---

Chapter 3: System Architecture and Design

The PC-SRGI framework is implemented as a hybrid system:

· Python/PyTorch: High-level graph definition, transformer models, adaptive capsule layers, automatic differentiation, training loops, and symbolic extraction.
· Rust: Deterministic, high-performance symplectic integrator for world model simulation, energy-efficient capsule scheduling, and parallel batch processing.

Communication between Python and Rust is achieved via PyO3, exposing Rust structs as native Python classes.

```
┌─────────────────┐      PyO3      ┌─────────────────┐
│   Python Core   │ ◄─────────────► │    Rust Core    │
│ - Transformers  │                  │ - Symplectic    │
│ - Capsule Layers│                  │   Integrator    │
│ - Training Loop │                  │ - Batch Engine  │
│ - Symbolic Extr.│                  └─────────────────┘
└─────────────────┘
```

Data Flow:

1. Python receives input data (state sequences).
2. Transformer predicts forces \hat{F} and task outputs.
3. Forces are passed to Rust engine for symplectic integration, returning next state.
4. Task loss and physics residuals are computed in Python.
5. Capsule gates produce energy cost.
6. Gradients are backpropagated through the entire computation graph (if the integrator is differentiable via PyTorch, or via adjoint methods if Rust is used).
7. Gates are updated to optimize energy and task loss.
8. After training, symbolic extraction runs on active capsules.

---

Chapter 4: Core Implementation Design

4.1 Differentiable Symplectic Integrator in PyTorch

To ensure end-to-end differentiability, we design the Velocity Verlet integrator as a PyTorch module. For a single step:

```python
import torch

def velocity_verlet_step(q, p, force_fn, dt):
    """
    q, p: tensors of shape (batch, n)
    force_fn: callable returning force at q
    dt: float
    Returns new q, new p
    """
    dt_half = dt * 0.5
    # half kick
    p_half = p + dt_half * force_fn(q)
    # full drift
    q_new = q + dt * p_half
    # force at new position
    f_new = force_fn(q_new)
    # second half kick
    p_new = p_half + dt_half * f_new
    return q_new, p_new
```

For batched processing, we can use torch.vmap or simply loop over batch dimensions. The force_fn is typically the output of a neural network. The entire operation is differentiable via autograd.

4.2 Rust Symplectic Engine (High-Performance Version)

For large-scale simulations, we provide a Rust implementation with PyO3 bindings. The Rust engine performs the same Velocity Verlet steps but without retaining gradients. To maintain differentiability, we wrap it as a custom torch.autograd.Function that implements the forward pass in Rust and the backward pass via the adjoint method (solving the sensitivity ODE). This design choice prioritizes speed while preserving gradient flow.

Below is the simplified Rust engine (non‑differentiable) for reference:

```rust
use pyo3::prelude::*;
use rayon::prelude::*;

#[pyclass]
pub struct SymplecticEngine {
    dt: f64,
}

#[pymethods]
impl SymplecticEngine {
    #[new]
    fn new(dt: f64) -> Self {
        Self { dt }
    }

    fn integrate_batch(&self, q: Vec<f64>, p: Vec<f64>, forces: Vec<f64>) -> (Vec<f64>, Vec<f64>) {
        let n = q.len();
        let dt_half = self.dt * 0.5;
        let (new_q, new_p): (Vec<_>, Vec<_>) = (0..n)
            .into_par_iter()
            .map(|i| {
                let mut qi = q[i];
                let mut pi = p[i];
                let fi = forces[i];
                pi += dt_half * fi;
                qi += self.dt * pi;
                // Note: second half-kick requires force at new qi,
                // which would be computed by the network in the next step.
                (qi, pi)
            })
            .unzip();
        (new_q, new_p)
    }
}
```

4.3 Adaptive Capsule Layer with Sparse Structural Updates

The capsule layer supports both soft gating during training and hard pruning during inference. After each epoch, we compute the gradient of the total loss with respect to the gates and perform a structural update: capsules with gate values below a threshold are removed, and new capsules can be added (initialized randomly) if the energy budget permits.

```python
class AdaptiveCapsuleLayer(nn.Module):
    def __init__(self, num_capsules, input_dim, output_dim, capsule_cost=1.0):
        super().__init__()
        self.capsules = nn.ModuleList([nn.Linear(input_dim, output_dim) for _ in range(num_capsules)])
        self.gates = nn.Parameter(torch.ones(num_capsules))
        self.temp = 1.0
        self.capsule_cost = capsule_cost

    def forward(self, x):
        z = torch.sigmoid(self.gates / self.temp)
        out = sum(z[i] * self.capsules[i](x) for i in range(len(self.capsules)))
        energy_cost = self.capsule_cost * z.sum()
        return out, energy_cost, z

    def prune_and_grow(self, threshold=0.1, max_capsules=None):
        # Prune capsules with gate < threshold
        active = torch.sigmoid(self.gates) > threshold
        self.capsules = nn.ModuleList([cap for cap, a in zip(self.capsules, active) if a])
        self.gates = nn.Parameter(self.gates[active])
        # Optionally add new capsules if below max_capsules
        if max_capsules is not None and len(self.capsules) < max_capsules:
            new_caps = max_capsules - len(self.capsules)
            for _ in range(new_caps):
                self.capsules.append(nn.Linear(self.capsules[0].in_features, self.capsules[0].out_features))
                self.gates = nn.Parameter(torch.cat([self.gates, torch.zeros(1)]))
```

4.4 Physics-Informed Transformer

The transformer includes a physics residual head that computes differential constraints. For simplicity, we use a finite-difference approximation of the time derivative:

```python
class PhysicsConstrainedTransformer(nn.Module):
    def __init__(self, d_model, nhead, num_layers, input_dim, output_dim):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        self.fc_out = nn.Linear(d_model, output_dim)

    def forward(self, x, target_derivative=None):
        # x: (batch, seq_len, input_dim)
        x = self.embedding(x)
        x = self.transformer(x)
        forces = self.fc_out(x)  # (batch, seq_len, output_dim)
        physics_residual = 0.0
        if target_derivative is not None:
            # compute approximate time derivative via finite differences
            deriv = (forces[:, 1:, :] - forces[:, :-1, :])  # simple diff
            physics_residual = torch.mean((deriv - target_derivative) ** 2)
        return forces, physics_residual
```

4.5 Training Loop with Energy Regularization

The training loop integrates all components:

```python
def train_step(model, capsule_layer, optimizer, x, y_true, dt, energy_budget):
    forces, physics_residual = model(x, target_derivative=some_derivative)

    # Integrate using differentiable PyTorch symplectic step
    q = x[:, -1, 0]  # last position
    p = x[:, -1, 1]  # last momentum
    def force_fn(q):
        # We need to map q back to transformer input; simplified: use last forces
        return forces[:, -1, 0]
    q_new, p_new = velocity_verlet_step(q, p, force_fn, dt)

    task_loss = torch.mean((q_new - y_true[:, 0])**2 + (p_new - y_true[:, 1])**2)

    # Capsule layer
    capsule_out, energy_cost, gates = capsule_layer(forces)

    total_loss = task_loss + 0.1 * physics_residual + 0.01 * energy_cost

    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()

    # Anneal gate temperature
    capsule_layer.temp *= 0.999

    return total_loss.item(), gates.detach().cpu().numpy()
```

4.6 Symbolic Extraction with PySR

After training, we extract the active capsules and fit a symbolic expression using PySR.

```python
from pysr import PySRRegressor
import numpy as np

def extract_symbolic(capsule_layer, X_train, y_train):
    # Determine active capsules
    gates = torch.sigmoid(capsule_layer.gates).detach().cpu().numpy()
    active = gates > 0.5
    if not np.any(active):
        return "No active capsules"

    # Compute basis functions from active capsules
    # For each capsule, we need to know its primitive. Here we assume a fixed mapping.
    # In practice, we might store the primitive type per capsule.
    primitives = ["x", "x**2", "sin(x)", "cos(x)", "exp(x)", "1"]
    X_basis = []
    for i, is_active in enumerate(active):
        if is_active:
            # For demonstration, treat capsule as a linear combination of inputs
            # Actually we should evaluate the capsule's function on X_train
            # But here we simplify: use the capsule's output as a feature
            with torch.no_grad():
                out = capsule_layer.capsules[i](torch.tensor(X_train, dtype=torch.float32)).numpy()
            X_basis.append(out.reshape(-1, 1))
    if not X_basis:
        return "No active capsules"
    X_basis = np.hstack(X_basis)

    # Run symbolic regression
    model = PySRRegressor(
        niterations=100,
        binary_operators=["+", "*", "-", "/"],
        unary_operators=["sin", "cos", "exp", "log"],
        model_selection="accuracy",
        loss="L2DistLoss()",
    )
    model.fit(X_basis, y_train)
    return model.sympy()
```

This design yields a symbolic expression that approximates the neural model's output in terms of the active capsule basis functions.

---

Chapter 5: Theoretical Analysis

5.1 Lipschitz Bounding via Gated Capsules

Theorem 1 (Gated Lipschitz Constant). Let the force field F_\theta be a sum of gated capsule outputs: F_\theta(x) = \sum_{i=1}^N z_i \, f_i(x), where each f_i is L_i-Lipschitz. Then F_\theta is L-Lipschitz with L \leq \sum_i |z_i| L_i. In particular, if gates are bounded |z_i| \leq 1, then L \leq \sum_i L_i.

Proof. For any x, y:

\|F_\theta(x)-F_\theta(y)\| = \left\| \sum_i z_i (f_i(x)-f_i(y)) \right\| \leq \sum_i |z_i| \|f_i(x)-f_i(y)\| \leq \sum_i |z_i| L_i \|x-y\|.

Hence the Lipschitz constant is bounded by \sum_i |z_i| L_i. ∎

During training, the energy regularization penalizes large |z_i|, encouraging sparsity and reducing the effective Lipschitz constant, which promotes stability.

5.2 Convergence of Gradient Descent with Lipschitz Gradients

Theorem 2 (Convergence). Assume the loss \mathcal{L} is L-smooth (i.e., its gradient is L-Lipschitz) and bounded below. With learning rate \eta < 2/L, gradient descent converges to a stationary point.

Proof. Standard result from convex optimization. In our case, the gated architecture ensures that L can be controlled, allowing stable training.

5.3 Symplectic Integration and Energy Conservation

Theorem 3 (Symplectic Preservation). The Velocity Verlet integrator is symplectic: it preserves the symplectic two-form exactly. Consequently, for integrable Hamiltonian systems, the energy error remains bounded over exponentially long times (no secular drift).

Proof. See Hairer, Lubich, Wanner (2006). This property ensures that any energy drift observed in simulations must arise from the learned force field, not numerical integration.

5.4 Convergence of Structural Evolution

Theorem 4 (Structural Convergence). Let the structural update be a gradient flow on the energy-augmented loss:

\frac{d\gamma_i}{dt} = -\frac{\partial}{\partial \gamma_i} \left( \mathcal{L}_{\text{task}} + \alpha \sum_j \sigma(\gamma_j) + \beta \|\gamma\|_2^2 \right)

where \sigma is the sigmoid function. Assume \mathcal{L}_{\text{task}} is bounded below and \alpha, \beta > 0. Then the gates \gamma_i converge to a fixed point as t \to \infty.

Proof. The dynamics is a gradient descent on a function that is coercive (due to the \ell_2 regularization) and smooth. By the LaSalle invariance principle, trajectories converge to the set of stationary points.

5.5 Stability of the Differentiable World Model

Theorem 5 (Local Stability). If the learned dynamics F_\theta satisfies \lambda_{\max}(J_F) < -\delta for some \delta > 0 in a neighborhood of the attractor, then the system is locally exponentially stable.

Proof. By linearization, the evolution of perturbations \xi satisfies \dot{\xi} = J_F \xi. Under the eigenvalue condition, \|\xi(t)\| \leq Ce^{-\delta t} \|\xi(0)\|.

---

Chapter 6: Conclusion

We have presented PC-SRGI, a unified mathematical and architectural framework for physics-constrained, self-reconfiguring generative intelligence. By integrating symplectic integration, adaptive capsule gating, energy regularization, and symbolic extraction into a single constrained optimization objective, we provide a formal foundation for AI systems that respect physical laws, adapt their structure to computational budgets, and yield interpretable symbolic representations. The hybrid Rust/Python design ensures both performance and flexibility. Theoretical analyses establish Lipschitz bounds, convergence guarantees, symplectic preservation, and local stability. This work lays the groundwork for future implementations and extensions toward embodied AI, scientific discovery, and energy-efficient autonomous agents.

Appendices

Appendix A: Mathematical Background

This appendix provides the essential mathematical concepts underpinning the PC-SRGI framework. It covers constrained optimization, functional analysis, Hamiltonian mechanics, symplectic integration, graph theory, energy modeling, and symbolic regression.

A.1 Constrained Optimization and Lagrange Multipliers

Consider the problem of minimizing a function f(x) subject to equality constraints c_i(x)=0 for i=1,\dots,m. The method of Lagrange multipliers introduces variables \lambda_i and forms the Lagrangian:

\mathcal{L}(x,\lambda) = f(x) + \sum_{i=1}^m \lambda_i c_i(x).

A necessary condition for optimality is that the gradient of the Lagrangian vanishes:

\nabla_x \mathcal{L} = 0, \quad \nabla_\lambda \mathcal{L} = 0.

In our framework, we convert hard constraints into soft penalties via the augmented Lagrangian or simple penalty methods:

\min_x f(x) + \mu \sum_i c_i(x)^2.

The parameters \mu can be adaptively increased to enforce constraints more strictly.

A.2 Functional Analysis and Lipschitz Continuity

A function F: \mathbb{R}^n \to \mathbb{R}^m is Lipschitz continuous if there exists a constant L \geq 0 such that for all x,y:

\|F(x)-F(y)\| \leq L \|x-y\|.

The smallest such L is the Lipschitz constant. Lipschitz continuity is essential for proving convergence of gradient descent and stability of dynamical systems. For a differentiable function, the Lipschitz constant of its gradient is the supremum of the spectral norm of the Hessian.

A.3 Hamiltonian Mechanics and Symplectic Geometry

A Hamiltonian system is described by generalized coordinates q \in \mathbb{R}^n and momenta p \in \mathbb{R}^n. The Hamiltonian H(q,p) (usually the total energy) governs the dynamics via:

\dot{q} = \frac{\partial H}{\partial p}, \quad \dot{p} = -\frac{\partial H}{\partial q}.

These equations can be written in a compact form using the symplectic matrix J = \begin{pmatrix} 0 & I \\ -I & 0 \end{pmatrix}:

\frac{d}{dt} \begin{pmatrix} q \\ p \end{pmatrix} = J \nabla H.

A symplectic map preserves the symplectic two-form dq \wedge dp. Numerical integrators that are symplectic (e.g., Velocity Verlet) guarantee that the flow of the discrete map remains on a nearby Hamiltonian manifold, preventing artificial energy drift over long times.

A.4 Numerical Integration and Symplectic Methods

The Velocity Verlet algorithm for a separable Hamiltonian H = T(p) + V(q) (with T(p) = \frac{p^2}{2m} often) is:

\begin{aligned}
p_{n+1/2} &= p_n - \frac{\Delta t}{2} \nabla V(q_n), \\
q_{n+1} &= q_n + \Delta t \, p_{n+1/2}, \\
p_{n+1} &= p_{n+1/2} - \frac{\Delta t}{2} \nabla V(q_{n+1}).
\end{aligned}

This method is symplectic, time-reversible, and second-order accurate. It requires only one force evaluation per step (if the force is derived from a potential). In our framework, the force -\nabla V is predicted by a neural network.

A.5 Graph Theory and Dynamic Architectures

We model the computational graph as a directed graph G = (V,E) where each node v \in V is a capsule (a sub-network) and each edge (u,v) \in E carries a weight representing the strength of connection. Structural plasticity involves adding or removing nodes and edges based on gradient information and energy constraints. The evolution of the graph is governed by an update rule \mathcal{R} that depends on the current graph, the loss gradient, and the energy budget.

A.6 Energy Models and Pareto Optimality

Computational energy is approximated by a weighted sum of floating-point operations (FLOPs). For a given architecture, we can profile the energy consumption per operation on target hardware. The trade-off between task loss \mathcal{L}_{\text{task}} and energy E_{\text{comp}} defines a Pareto frontier: points where no improvement in one objective is possible without degrading the other. Multi-objective optimization techniques (e.g., scalarization, evolutionary algorithms) can be used to explore this frontier.

A.7 Symbolic Regression and Sparse Identification

Symbolic regression aims to find a mathematical expression that fits given data. Common approaches include genetic programming (e.g., PySR) and sparse regression over a library of basis functions (e.g., SINDy). In our framework, the active capsules provide a natural basis, and we apply symbolic regression to combine them into a concise formula.

---

Appendix B: Detailed Proofs

This appendix contains complete proofs of the theorems stated in Chapter 5.

B.1 Proof of Theorem 1 (Gated Lipschitz Constant)

Theorem 1. Let F_\theta(x) = \sum_{i=1}^N z_i \, f_i(x), where each f_i is L_i-Lipschitz and z_i \in \mathbb{R} are gate values satisfying |z_i| \leq 1. Then F_\theta is L-Lipschitz with L \leq \sum_i |z_i| L_i \leq \sum_i L_i.

Proof. For any x,y,

\|F_\theta(x)-F_\theta(y)\| = \left\| \sum_{i=1}^N z_i (f_i(x)-f_i(y)) \right\| \leq \sum_{i=1}^N |z_i| \|f_i(x)-f_i(y)\| \leq \sum_{i=1}^N |z_i| L_i \|x-y\|.

Thus the Lipschitz constant of F_\theta is at most \sum_i |z_i| L_i. Since |z_i| \leq 1, it is also bounded by \sum_i L_i. ∎

B.2 Proof of Theorem 2 (Gradient Descent Convergence)

Theorem 2. Let \mathcal{L} be L-smooth (i.e., \|\nabla \mathcal{L}(x) - \nabla \mathcal{L}(y)\| \leq L\|x-y\|) and bounded below. For gradient descent with step size \eta < 2/L, the iterates satisfy \mathcal{L}(x_{k+1}) \leq \mathcal{L}(x_k) - \frac{\eta}{2}(1 - \frac{\eta L}{2})\|\nabla \mathcal{L}(x_k)\|^2. Consequently, \lim_{k\to\infty} \|\nabla \mathcal{L}(x_k)\| = 0.

Proof. Using the descent lemma for smooth functions,

\mathcal{L}(x_{k+1}) \leq \mathcal{L}(x_k) + \nabla \mathcal{L}(x_k)^T (x_{k+1}-x_k) + \frac{L}{2}\|x_{k+1}-x_k\|^2.

Substituting x_{k+1} = x_k - \eta \nabla \mathcal{L}(x_k),

\mathcal{L}(x_{k+1}) \leq \mathcal{L}(x_k) - \eta \|\nabla \mathcal{L}(x_k)\|^2 + \frac{L\eta^2}{2}\|\nabla \mathcal{L}(x_k)\|^2 = \mathcal{L}(x_k) - \eta\left(1 - \frac{\eta L}{2}\right)\|\nabla \mathcal{L}(x_k)\|^2.

If \eta < 2/L, then 1 - \frac{\eta L}{2} > 0, so the loss strictly decreases unless the gradient is zero. Summing over iterations gives \sum_{k=0}^\infty \|\nabla \mathcal{L}(x_k)\|^2 < \infty, hence \|\nabla \mathcal{L}(x_k)\| \to 0. ∎

B.3 Proof of Theorem 3 (Symplectic Preservation of Velocity Verlet)

Theorem 3. The Velocity Verlet integrator is symplectic.

Proof. Consider the map (q_n, p_n) \mapsto (q_{n+1}, p_{n+1}) defined by:

\begin{aligned}
p_{n+1/2} &= p_n - \frac{\Delta t}{2} \nabla V(q_n), \\
q_{n+1} &= q_n + \Delta t \, p_{n+1/2}, \\
p_{n+1} &= p_{n+1/2} - \frac{\Delta t}{2} \nabla V(q_{n+1}).
\end{aligned}

This can be seen as a composition of two maps: a half-step of the momentum (a symplectic transformation) and a full-step of the position (also symplectic), followed by another half-step of momentum. Each of these maps is symplectic because it is a shear transformation in phase space. The composition of symplectic maps is symplectic. Therefore, the Velocity Verlet integrator preserves the symplectic two-form. ∎

Remark. A more rigorous proof involves showing that the Jacobian of the transformation satisfies J^T \Omega J = \Omega, where \Omega is the symplectic matrix.

B.4 Proof of Theorem 4 (Structural Convergence)

Theorem 4. Consider the gradient flow on the energy-augmented loss:

\frac{d\gamma_i}{dt} = -\frac{\partial}{\partial \gamma_i} \left( \mathcal{L}_{\text{task}}(\gamma) + \alpha \sum_j \sigma(\gamma_j) + \beta \|\gamma\|_2^2 \right),

where \sigma is the sigmoid function and \alpha,\beta > 0. Assume \mathcal{L}_{\text{task}} is bounded below and smooth. Then \gamma(t) converges to a stationary point as t \to \infty.

Proof. Define U(\gamma) = \mathcal{L}_{\text{task}}(\gamma) + \alpha \sum_j \sigma(\gamma_j) + \beta \|\gamma\|_2^2. The term \beta \|\gamma\|_2^2 makes U coercive: U(\gamma) \to \infty as \|\gamma\| \to \infty. U is also smooth. The gradient flow \dot{\gamma} = -\nabla U(\gamma) has the property that U decreases along trajectories: \frac{d}{dt} U(\gamma(t)) = -\|\nabla U(\gamma)\|^2 \leq 0. By LaSalle's invariance principle, bounded trajectories converge to the set of stationary points where \nabla U = 0. Coercivity ensures boundedness. Hence \gamma(t) converges to a stationary point. ∎

B.5 Proof of Theorem 5 (Local Stability)

Theorem 5. Let \dot{s} = F_\theta(s) be a dynamical system with an equilibrium at s^*. Suppose the Jacobian J_F(s^*) has eigenvalues all with real part less than -\delta < 0. Then the equilibrium is locally exponentially stable.

Proof. Linearizing around s^* gives \dot{\xi} = J_F(s^*) \xi + O(\|\xi\|^2). For sufficiently small perturbations, the nonlinear term is negligible. The solution to the linear system is \xi(t) = e^{J_F(s^*) t} \xi(0). The condition \text{Re}(\lambda) < -\delta implies that \|e^{J_F t}\| \leq C e^{-\delta t} for some constant C. Thus \|\xi(t)\| \leq C e^{-\delta t} \|\xi(0)\|, establishing exponential stability. ∎

B.6 Additional Lemmas

Lemma 1 (Gradient of Sigmoid Gate). For z = \sigma(\gamma/\tau), we have \frac{\partial z}{\partial \gamma} = \frac{1}{\tau} z (1-z). This is used in backpropagation through gates.

Lemma 2 (Energy Gradient). The gradient of the energy cost \frac{\partial E_{\text{comp}}}{\partial \gamma_i} = \sum_j w_j \cdot \frac{\partial \text{FLOPs}_j}{\partial \gamma_i} depends on how FLOPs change with gate values. In a simplified model where FLOPs_j is proportional to z_j, we get \frac{\partial E_{\text{comp}}}{\partial \gamma_i} \propto \frac{\partial z_i}{\partial \gamma_i}.

---

Appendix C: Implementation Architecture

This appendix describes the software architecture of the PC-SRGI framework, including the Rust core, PyO3 bindings, and PyTorch modules.

C.1 Overview of the Hybrid System

The system is divided into two main components:

· Rust Core: Provides high-performance, deterministic symplectic integration and parallel batch processing. It is responsible for simulating the physical world model.
· Python/PyTorch Layer: Handles high-level model definition (transformers, capsule layers), automatic differentiation, training loops, and symbolic extraction.

Communication between Rust and Python is facilitated by PyO3, which allows Rust functions to be called as if they were native Python modules.

C.2 Rust Core: SymplecticEngine and Parallel Batch Processing

The Rust crate pc_srgi_core defines a SymplecticEngine struct that performs Velocity Verlet integration on batches of states. It uses the rayon crate for parallel iteration.

```rust
// src/lib.rs
use pyo3::prelude::*;
use rayon::prelude::*;

#[pyclass]
pub struct SymplecticEngine {
    dt: f64,
}

#[pymethods]
impl SymplecticEngine {
    #[new]
    fn new(dt: f64) -> Self {
        Self { dt }
    }

    /// Integrate a batch of states.
    /// q: flat vector of positions (length n)
    /// p: flat vector of momenta (length n)
    /// forces: flat vector of forces at current q (length n)
    /// Returns (new_q, new_p) after one full time step.
    /// Note: The second half-kick requires forces at new_q, which should be computed by the network.
    fn integrate_batch(&self, q: Vec<f64>, p: Vec<f64>, forces: Vec<f64>) -> (Vec<f64>, Vec<f64>) {
        let n = q.len();
        assert_eq!(p.len(), n);
        assert_eq!(forces.len(), n);

        let dt_half = self.dt * 0.5;

        // Parallel iteration using rayon
        let (new_q, new_p): (Vec<_>, Vec<_>) = (0..n)
            .into_par_iter()
            .map(|i| {
                let mut qi = q[i];
                let mut pi = p[i];
                let fi = forces[i];

                // half kick
                pi += dt_half * fi;
                // drift
                qi += self.dt * pi;
                // second half-kick deferred
                (qi, pi)
            })
            .unzip();

        (new_q, new_p)
    }
}

#[pymodule]
fn pc_srgi_core(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_class::<SymplecticEngine>()?;
    Ok(())
}
```

C.3 PyO3 Bindings: Exposing Rust to Python

The Cargo.toml file specifies the crate type as cdylib and includes the necessary dependencies:

```toml
[package]
name = "pc_srgi_core"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib"]

[dependencies]
pyo3 = { version = "0.20", features = ["extension-module"] }
rayon = "1.7"
```

After building with maturin develop, the Rust module becomes available in Python as import pc_srgi_core.

C.4 PyTorch Modules: AdaptiveCapsuleLayer and PhysicsConstrainedTransformer

C.4.1 AdaptiveCapsuleLayer

```python
# models/capsule_layer.py
import torch
import torch.nn as nn

class AdaptiveCapsuleLayer(nn.Module):
    """
    A layer of capsules with learnable gates for structural plasticity.
    """
    def __init__(self, num_capsules, input_dim, output_dim, capsule_cost=1.0):
        super().__init__()
        self.capsules = nn.ModuleList([
            nn.Linear(input_dim, output_dim) for _ in range(num_capsules)
        ])
        self.gates = nn.Parameter(torch.ones(num_capsules))  # gamma
        self.temp = 1.0  # temperature for sigmoid relaxation
        self.capsule_cost = capsule_cost  # energy cost per active capsule

    def forward(self, x):
        # Soft gate values
        z = torch.sigmoid(self.gates / self.temp)  # shape: (num_capsules,)

        # Weighted sum of capsule outputs
        out = sum(z[i] * self.capsules[i](x) for i in range(len(self.capsules)))

        # Energy cost
        energy_cost = self.capsule_cost * z.sum()

        return out, energy_cost, z

    def prune_and_grow(self, threshold=0.1, max_capsules=None):
        """
        Hard prune capsules with gate < threshold, and optionally add new random capsules.
        """
        with torch.no_grad():
            z = torch.sigmoid(self.gates)
            active = z > threshold
            # Keep only active capsules
            self.capsules = nn.ModuleList([cap for cap, a in zip(self.capsules, active) if a])
            self.gates = nn.Parameter(self.gates[active])

            if max_capsules is not None and len(self.capsules) < max_capsules:
                n_new = max_capsules - len(self.capsules)
                for _ in range(n_new):
                    self.capsules.append(nn.Linear(self.capsules[0].in_features,
                                                   self.capsules[0].out_features))
                    self.gates = nn.Parameter(torch.cat([self.gates, torch.zeros(1)]))
```

C.4.2 PhysicsConstrainedTransformer

```python
# models/physformer.py
import torch
import torch.nn as nn

class PhysicsConstrainedTransformer(nn.Module):
    """
    Transformer that predicts forces and includes physics residual loss.
    """
    def __init__(self, d_model, nhead, num_layers, input_dim, output_dim):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        self.fc_out = nn.Linear(d_model, output_dim)

    def forward(self, x, target_derivative=None):
        """
        x: (batch, seq_len, input_dim)
        target_derivative: optional ground truth derivative for physics loss
        """
        x = self.embedding(x)
        x = self.transformer(x)
        forces = self.fc_out(x)  # (batch, seq_len, output_dim)

        physics_residual = torch.tensor(0.0, device=forces.device)
        if target_derivative is not None:
            # Finite difference approximation of time derivative
            deriv = (forces[:, 1:, :] - forces[:, :-1, :])  # simple diff
            physics_residual = torch.mean((deriv - target_derivative) ** 2)

        return forces, physics_residual
```

C.5 Training Loop and Loss Functions

The training loop integrates the transformer, capsule layer, and symplectic integrator. It computes task loss, physics residual, and energy cost.

```python
# training/train.py
import torch
import torch.optim as optim
from pc_srgi_core import SymplecticEngine  # Rust module

def velocity_verlet_step(q, p, force_fn, dt):
    """Differentiable PyTorch Velocity Verlet step."""
    dt_half = dt * 0.5
    p_half = p + dt_half * force_fn(q)
    q_new = q + dt * p_half
    f_new = force_fn(q_new)
    p_new = p_half + dt_half * f_new
    return q_new, p_new

def train_step(model, capsule_layer, optimizer, x, y_true, dt, energy_budget, device):
    model.train()
    capsule_layer.train()

    x = x.to(device)
    y_true = y_true.to(device)

    # Forward through transformer
    forces, physics_residual = model(x, target_derivative=None)  # can provide derivative if available

    # Extract last state from input sequence
    q = x[:, -1, 0]  # position
    p = x[:, -1, 1]  # momentum

    # Define force function using transformer output (simplified: use last force)
    def force_fn(q):
        # In a full implementation, we would feed q back through the transformer
        # Here we assume forces[:, -1, 0] is already computed and appropriate
        return forces[:, -1, 0]

    # Integrate
    q_new, p_new = velocity_verlet_step(q, p, force_fn, dt)

    # Task loss: MSE on next state
    task_loss = torch.mean((q_new - y_true[:, 0])**2 + (p_new - y_true[:, 1])**2)

    # Capsule layer forward (using forces as input to capsules)
    capsule_out, energy_cost, gates = capsule_layer(forces)

    # Total loss
    lambda_phys = 0.1
    lambda_energy = 0.01
    total_loss = task_loss + lambda_phys * physics_residual + lambda_energy * energy_cost

    # Backprop
    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()

    # Anneal gate temperature
    capsule_layer.temp *= 0.999

    return total_loss.item(), gates.detach().cpu().numpy()
```

C.6 Symbolic Extraction with PySR

After training, we extract symbolic expressions from the active capsules.

```python
# symbolic/extractor.py
import torch
import numpy as np
from pysr import PySRRegressor

class SymbolicExtractor:
    def __init__(self, capsule_layer, primitives=None):
        self.capsule_layer = capsule_layer
        if primitives is None:
            self.primitives = ["x", "x**2", "sin(x)", "cos(x)", "exp(x)", "1"]
        else:
            self.primitives = primitives

    def extract(self, X_train, y_train, threshold=0.5):
        """
        X_train: numpy array of input features (n_samples, n_features)
        y_train: numpy array of target values (n_samples,)
        """
        gates = torch.sigmoid(self.capsule_layer.gates).detach().cpu().numpy()
        active = gates > threshold
        if not np.any(active):
            return "No active capsules"

        # Compute basis functions from active capsules
        basis = []
        for i, is_active in enumerate(active):
            if is_active:
                with torch.no_grad():
                    out = self.capsule_layer.capsules[i](torch.tensor(X_train, dtype=torch.float32)).numpy()
                basis.append(out.reshape(-1, 1))
        X_basis = np.hstack(basis)

        # Run symbolic regression
        model = PySRRegressor(
            niterations=100,
            binary_operators=["+", "*", "-", "/"],
            unary_operators=["sin", "cos", "exp", "log"],
            model_selection="accuracy",
            loss="L2DistLoss()",
        )
        model.fit(X_basis, y_train)
        return model.sympy()
```

C.7 Utility Functions and Configuration

A configuration file (e.g., YAML) can specify hyperparameters, model dimensions, and paths.

```yaml
# config.yaml
model:
  d_model: 128
  nhead: 4
  num_layers: 3
  input_dim: 2   # (q, p)
  output_dim: 1  # force
capsule:
  num_capsules: 16
  input_dim: 128  # from transformer output
  output_dim: 1
  capsule_cost: 1.0
training:
  dt: 0.01
  energy_budget: 5.0
  lambda_phys: 0.1
  lambda_energy: 0.01
  lr: 0.001
  epochs: 100
device: cuda
```

---

Appendix D: Complete Code Listings

This appendix provides the full source code for the PC-SRGI framework, organized by file.

D.1 Rust Core: src/lib.rs

```rust
// src/lib.rs
use pyo3::prelude::*;
use rayon::prelude::*;

#[pyclass]
pub struct SymplecticEngine {
    dt: f64,
}

#[pymethods]
impl SymplecticEngine {
    #[new]
    fn new(dt: f64) -> Self {
        Self { dt }
    }

    fn integrate_batch(&self, q: Vec<f64>, p: Vec<f64>, forces: Vec<f64>) -> (Vec<f64>, Vec<f64>) {
        let n = q.len();
        assert_eq!(p.len(), n);
        assert_eq!(forces.len(), n);

        let dt_half = self.dt * 0.5;

        let (new_q, new_p): (Vec<_>, Vec<_>) = (0..n)
            .into_par_iter()
            .map(|i| {
                let mut qi = q[i];
                let mut pi = p[i];
                let fi = forces[i];

                pi += dt_half * fi;
                qi += self.dt * pi;
                (qi, pi)
            })
            .unzip();

        (new_q, new_p)
    }
}

#[pymodule]
fn pc_srgi_core(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_class::<SymplecticEngine>()?;
    Ok(())
}
```

D.2 Rust Core: Cargo.toml

```toml
[package]
name = "pc_srgi_core"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib"]

[dependencies]
pyo3 = { version = "0.20", features = ["extension-module"] }
rayon = "1.7"
```

D.3 Python Module: models/capsule_layer.py

```python
# models/capsule_layer.py
import torch
import torch.nn as nn

class AdaptiveCapsuleLayer(nn.Module):
    def __init__(self, num_capsules, input_dim, output_dim, capsule_cost=1.0):
        super().__init__()
        self.capsules = nn.ModuleList([nn.Linear(input_dim, output_dim) for _ in range(num_capsules)])
        self.gates = nn.Parameter(torch.ones(num_capsules))
        self.temp = 1.0
        self.capsule_cost = capsule_cost

    def forward(self, x):
        z = torch.sigmoid(self.gates / self.temp)
        out = sum(z[i] * self.capsules[i](x) for i in range(len(self.capsules)))
        energy_cost = self.capsule_cost * z.sum()
        return out, energy_cost, z

    def prune_and_grow(self, threshold=0.1, max_capsules=None):
        with torch.no_grad():
            z = torch.sigmoid(self.gates)
            active = z > threshold
            self.capsules = nn.ModuleList([cap for cap, a in zip(self.capsules, active) if a])
            self.gates = nn.Parameter(self.gates[active])
            if max_capsules is not None and len(self.capsules) < max_capsules:
                n_new = max_capsules - len(self.capsules)
                for _ in range(n_new):
                    self.capsules.append(nn.Linear(self.capsules[0].in_features,
                                                   self.capsules[0].out_features))
                    self.gates = nn.Parameter(torch.cat([self.gates, torch.zeros(1)]))
```

D.4 Python Module: models/physformer.py

```python
# models/physformer.py
import torch
import torch.nn as nn

class PhysicsConstrainedTransformer(nn.Module):
    def __init__(self, d_model, nhead, num_layers, input_dim, output_dim):
        super().__init__()
        self.embedding = nn.Linear(input_dim, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        self.fc_out = nn.Linear(d_model, output_dim)

    def forward(self, x, target_derivative=None):
        x = self.embedding(x)
        x = self.transformer(x)
        forces = self.fc_out(x)

        physics_residual = torch.tensor(0.0, device=forces.device)
        if target_derivative is not None:
            deriv = (forces[:, 1:, :] - forces[:, :-1, :])
            physics_residual = torch.mean((deriv - target_derivative) ** 2)

        return forces, physics_residual
```

D.5 Training Script: training/train.py

```python
# training/train.py
import torch
import torch.optim as optim
from models.capsule_layer import AdaptiveCapsuleLayer
from models.physformer import PhysicsConstrainedTransformer
from pc_srgi_core import SymplecticEngine

def velocity_verlet_step(q, p, force_fn, dt):
    dt_half = dt * 0.5
    p_half = p + dt_half * force_fn(q)
    q_new = q + dt * p_half
    f_new = force_fn(q_new)
    p_new = p_half + dt_half * f_new
    return q_new, p_new

def train_epoch(model, capsule_layer, optimizer, dataloader, dt, energy_budget, device):
    total_loss = 0.0
    for batch in dataloader:
        x, y_true = batch
        x, y_true = x.to(device), y_true.to(device)

        forces, physics_residual = model(x)

        q = x[:, -1, 0]
        p = x[:, -1, 1]

        # Simplified force function; in practice, we might need to recompute forces for new q
        def force_fn(q):
            # This is a placeholder; real implementation would map q back to transformer input
            return forces[:, -1, 0]

        q_new, p_new = velocity_verlet_step(q, p, force_fn, dt)

        task_loss = torch.mean((q_new - y_true[:, 0])**2 + (p_new - y_true[:, 1])**2)

        capsule_out, energy_cost, gates = capsule_layer(forces)

        total_loss_batch = task_loss + 0.1 * physics_residual + 0.01 * energy_cost

        optimizer.zero_grad()
        total_loss_batch.backward()
        optimizer.step()

        total_loss += total_loss_batch.item()

    return total_loss / len(dataloader)
```

D.6 Symbolic Extraction: symbolic/extractor.py

```python
# symbolic/extractor.py
import torch
import numpy as np
from pysr import PySRRegressor

class SymbolicExtractor:
    def __init__(self, capsule_layer, primitives=None):
        self.capsule_layer = capsule_layer
        self.primitives = primitives or ["x", "x**2", "sin(x)", "cos(x)", "exp(x)", "1"]

    def extract(self, X_train, y_train, threshold=0.5):
        gates = torch.sigmoid(self.capsule_layer.gates).detach().cpu().numpy()
        active = gates > threshold
        if not np.any(active):
            return "No active capsules"

        basis = []
        for i, is_active in enumerate(active):
            if is_active:
                with torch.no_grad():
                    out = self.capsule_layer.capsules[i](torch.tensor(X_train, dtype=torch.float32)).numpy()
                basis.append(out.reshape(-1, 1))
        X_basis = np.hstack(basis)

        model = PySRRegressor(
            niterations=100,
            binary_operators=["+", "*", "-", "/"],
            unary_operators=["sin", "cos", "exp", "log"],
            model_selection="accuracy",
            loss="L2DistLoss()",
        )
        model.fit(X_basis, y_train)
        return model.sympy()
```

D.7 Example Usage Script

```python
# run_example.py
import torch
from models.capsule_layer import AdaptiveCapsuleLayer
from models.physformer import PhysicsConstrainedTransformer
from training.train import train_epoch
from symbolic.extractor import SymbolicExtractor

# Hyperparameters
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
d_model = 64
nhead = 4
num_layers = 2
input_dim = 2
output_dim = 1
num_capsules = 8
capsule_cost = 1.0
dt = 0.01
energy_budget = 5.0
lr = 0.001
epochs = 10

# Initialize models
transformer = PhysicsConstrainedTransformer(d_model, nhead, num_layers, input_dim, output_dim).to(device)
capsule_layer = AdaptiveCapsuleLayer(num_capsules, d_model, output_dim, capsule_cost).to(device)
optimizer = torch.optim.Adam(list(transformer.parameters()) + list(capsule_layer.parameters()), lr=lr)

# Dummy dataloader (replace with actual data)
from torch.utils.data import DataLoader, TensorDataset
X = torch.randn(100, 5, input_dim)  # (batch, seq_len, input_dim)
y = torch.randn(100, 2)             # next (q, p)
dataset = TensorDataset(X, y)
dataloader = DataLoader(dataset, batch_size=16)

# Training
for epoch in range(epochs):
    loss = train_epoch(transformer, capsule_layer, optimizer, dataloader, dt, energy_budget, device)
    print(f"Epoch {epoch}, Loss: {loss:.4f}")
    if epoch % 5 == 0:
        capsule_layer.prune_and_grow(threshold=0.1, max_capsules=num_capsules)

# Symbolic extraction
extractor = SymbolicExtractor(capsule_layer)
X_train_np = X.view(-1, input_dim).numpy()[:100]  # sample
y_train_np = y.view(-1).numpy()[:100]             # sample
symbolic_eq = extractor.extract(X_train_np, y_train_np)
print("Discovered equation:", symbolic_eq)
```

---

This concludes the appendices. The provided code and mathematical background form the complete foundation for implementing and understanding the PC-SRGI framework.