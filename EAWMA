### EAWMA: A Proposed Embodied Agentic World Model Architecture  
**A Framework for Next-Generation Autonomous Intelligence**

**Authors:** Ouadi Maakoul (with AI-assisted contributions acknowledged)  
**Date:** December 22, 2025  

---

### Abstract

This paper proposes the **Embodied Agentic World Model Architecture (EAWMA)**, a conceptual framework that integrates multimodal perception, predictive world modeling, hierarchical planning, episodic memory, and neuro-symbolic reasoning into a Bayesian inference-based system for autonomous intelligence. EAWMA aims to address limitations in current large language models (LLMs), such as hallucinations and lack of grounding, by incorporating grounded simulation and symbolic constraints. Drawing on recent advances like joint-embedding predictive architectures and Gaussian representations, we outline the mathematical foundations, architecture, and proposed research directions. Potential applications include robotic collaboration and ethical AI, though empirical validation remains future work. This is a speculative proposal emphasizing integration ideas for further exploration.

**Keywords:** Embodied AI, World Models, Neuro-Symbolic AI, Hierarchical Planning, Mental World Models, Gaussian Splatting, Joint-Embedding Predictive Architectures, Theory of Mind

---

### 1. Introduction

Large Language Models (LLMs) advance language processing but struggle with grounded causal reasoning and physical interactions [1, 2]. Recent surveys position world models as key for embodied AI, enabling prediction and decision-making in dynamic environments [3]. EAWMA proposes to mitigate LLM shortcomings—like hallucinations, brittle multi-step reasoning, and opacity—through integrated neural-symbolic simulation [4].

The proposed core components include:
- Multimodal perception
- World simulation
- Hierarchical planning
- Episodic memory
- Neuro-symbolic reasoning

EAWMA explores a mental world model for theory-of-mind (ToM) reasoning, potentially inferring user intentions [5]. This could enhance human-AI collaboration, though speculative.

Contributions:
1. Unified Bayesian formalism for perception-action cycles
2. Modular architecture proposal with mental world modeling
3. Suggested research directions with benchmarks

EAWMA seeks to extend frameworks like Google DeepMind's Gato/RT-2 (multimodal but lacking symbolic constraints) [6], PaLM-E (grounded LLMs without hierarchical simulation) [7], and Wayve's driving models (sim-to-real but opaque) [17] by emphasizing explainable integration—hypothetical without results.

---

### 2. Related Work

EAWMA draws from paradigms, proposing extensions:

| Approach              | Key Strengths                       | Limitations                          | Proposed Relation to EAWMA          |
|-----------------------|-------------------------------------|--------------------------------------|-------------------------------------|
| LLMs [1, 2]           | Language, recall                    | No grounding, hallucinations         | Optional interface                  |
| World Models [9]      | Simulation, prediction              | Limited actions/symbols              | Core dynamics (e.g., V-JEPA 2 [10]) |
| RL [11]               | Policy optimization                 | Sample-inefficient                   | Latent planning                     |
| Neuro-Symbolic AI [4] | Logic, explainability               | Weak perception/meta-cognition       | Constraint layer                    |
| Embodied AI [12]      | Grounded learning                   | Task-specific                        | General loop                        |
| Agentic Systems [13]  | Decomposition, tools                | No physical grounding                | Hierarchical goals                   |
| Embodied LLMs [7]     | Multimodal tasks                    | Unpredictable environments           | Adds robust planning                |
| Gato/RT-2 [6]         | Multimodal policies                 | Lacks symbolic constraints           | Proposes neuro-symbolic integration |
| PaLM-E [7]            | Grounded LLMs                       | No hierarchical simulation           | Adds world modeling                 |
| Wayve Driving [17]    | Sim-to-real generalization          | Opaque decision-making               | Aims for explainable simulation     |

Surveys formalize embodied world models in POMDPs with taxonomies [3]. Neuro-symbolic reviews highlight meta-cognition gaps EAWMA explores [4].

---

### 3. Mathematical Foundations

#### 3.1 Notation

Agent at time \( t \): observation \( o_t \in \mathcal{O} \), action \( a_t \in \mathcal{A} \), latent state \( z_t \), belief \( b_t = P(s_t \mid o_{1:t}, a_{1:t-1}) \).

#### 3.2 Perception

Encoder \( q_\phi(z_t \mid o_t) \) yields object-centric latents. ELBO with Chamfer Distance [16]:

\[
\mathcal{L}_{\text{perc}} = \mathbb{E}[\log p(o_t \mid z_t)] - \beta D_{\text{KL}}(q_\phi \parallel p(z_t)) + \lambda \cdot \text{CD}(S_1, S_2)
\]

#### 3.3 World Model

Action-conditioned dynamics (inspired by V-JEPA 2 [10]):

\[
h_{t+1} = f_\psi(h_t, z_t, a_t, \text{context}), \quad z_{t+1} \sim \mathcal{N}(\mu_\psi(h_{t+1}), \Sigma_\psi(h_{t+1}))
\]

#### 3.4 Planning

Hypertree MCTS with self-reflection [15].

#### 3.5 Memory

Product-quantized episodic retrieval.

#### 3.6 Neuro-Symbolic Constraints

Constrained optimization with Logical Credal Networks [4].

#### 3.7 Mental World Model

Extend belief to inferred states: \( b_t^m = P(s_t^j \mid o_{1:t}, a_{1:t-1}, z_t) \) for agent \( j \). Use inverse planning [5]:

\[
P(a_t^j \mid g^j) \propto P(g^j \mid z_{t:t+H}) \cdot P(z_{t:t+H} \mid z_t, a_{t:t+H}^j)
\]

Approximate via particle filtering (O(N agents * d)). Fuse loss: \( \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{perc}} + \beta \mathcal{L}_{\text{dyn}} + \gamma \mathcal{L}_{\text{ToM}} \).

**Example: "Assist User in Fetching Water Without Spilling"**

Robot observes user reach (o_t). Perception: z_t = {z_t^{glass}, z_t^{user}}. Mental model: b_t^m ≈ P(thirst | trajectory). World model: z_{t+1} ~ p_ψ(z_{t+1} | z_t, a_t = "grasp"), using Gaussians [16]. Planning: Hypertree explores paths. Constraints: distance > threshold. Action: Safe pour sequence.

---

### 4. Proposed Architecture

Figure 1 (below) illustrates the overall dataflow: Multimodal observations feed perception, which updates the belief state. Parallel world and mental models provide predictions and intent inference. The hypertree planner generates candidates, filtered by neuro-symbolic constraints. Episodic memory informs retrieval across components.

**Figure 1: EAWMA Architecture Dataflow**

(Description of diagram: Boxes for Perception, Belief State, World Model (parallel to Mental World Model), Hypertree Planner, Neuro-Symbolic Reasoner, Action Output. Arrows: Observations → Perception → Belief; Memory retrieval → Belief/Mental; Goal/Constraints → Planner; Rollouts → Reasoner → Action; Experience storage loop.)

Mental world model parallels simulation for ToM personalization [5].

Specifications:
- **Perception** — Slot attention + Gaussian Splatting [16]
- **World Simulation** — V-JEPA 2-inspired [10]
- **Planning** — Hypertree MCTS [15]
- **Memory** — Differentiable dictionary
- **Reasoner** — Fuzzy logic + differential privacy [4]
- **Training** — Staged pretraining on datasets like OpenDV-2K, joint fine-tuning with fused loss.

Feasibility: O(TBd²) challenging for real-time; sparse approximations help.

---

### 5. Implementation Details

#### 5.1 Pseudo-Code

```python
class MentalWorldModel:
    def predict_intent(self, obs, context):
        # Sample candidate goals from prior/context
        goals = self.sample_goals(context, k=10)  # e.g., thirst, fatigue
        # Likelihood via forward simulation
        likelihoods = [self.world_model.goal_likelihood(g, obs) for g in goals]
        return goals[argmax(likelihoods)]  # Approximate inverse planning

class EAWMAAgent:
    def __init__(self, config):
        self.perception = PerceptionModule(config)
        self.world_model = WorldModel(config)
        self.mental_model = MentalWorldModel(config)
        self.planner = HypertreePlanner(config)
        self.memory = EpisodicMemory(config)
        self.reasoner = NeuroSymbolicReasoner(config)

    def update_belief(self, observation):
        latent = self.perception.encode(observation)
        context = self.memory.retrieve(latent, k=3)
        intent = self.mental_model.predict_intent(observation, context)
        self.belief_state = self.world_model.fuse(latent, context, intent)
        return self.belief_state

    def plan_action(self, goal, constraints):
        candidates = self.planner.hypertree_mcts(root=self.belief_state, goal=goal, simulations=500)
        feasible = []
        for plan in candidates:
            trajectory = self.world_model.rollout(self.belief_state, plan.actions)
            if self.reasoner.evaluate(trajectory, constraints) > 0.9:
                feasible.append(plan)
        return max(feasible, key=lambda p: p.expected_reward) if feasible else fallback_safe_action()

    def execute_step(self, observation, goal, constraints):
        belief = self.update_belief(observation)
        plan = self.plan_action(goal, constraints)
        action = plan.next_action()
        self.memory.store({'belief': belief, 'action': action, 'intent': intent})
        return action
```

#### 5.2 Computational Complexity

| Component     | Training                  | Inference               | Memory   | Notes                          |
|---------------|---------------------------|-------------------------|----------|--------------------------------|
| Perception    | O(BDHW)                   | O(BCHW)                 | O(BC)    |                                |
| World Model   | O(TBd²)                   | O(Bd²)                  | O(d²)    | Approximations for real-time   |
| Planning      | O(NSd)                    | O(Sd)                   | O(S)     | Hypertree reduces branches     |
| Memory        | O(NlogN)                  | O(logN)                 | O(N)     |                                |
| Reasoner      | O(C·L)                    | O(C·L)                  | O(C·L)   |                                |
| Mental Model  | O(k * rollout)            | O(k * d)                | O(d)     | k=10 samples; particle filter  |

---

### 6. Proposed Research Directions

1. Simulation Validation → Test in MiniGrid/Crafter against DreamerV3 [9].
2. Embodiment → Deploy on UR5/Spot, evaluate sim-to-real [17].
3. Scalable Learning → Explore continual/multi-agent.
4. General Evaluation → Use CausalVQA for ToM [18].

---

### 7. Expected Impacts and Limitations

EAWMA could support robotics/healthcare, aligning with embodied initiatives [19].

**Limitations**:
- Computational costs: ToM explodes without approximations.
- Failure modes: Intent misattribution risks unsafe actions; brittleness in novel settings.
- Speculation: No validation; joint training untested.
- Scope: Integration-focused; needs data/ethics handling.

Future: Scale-down implementation on one task.

---

### 8. Conclusion

EAWMA proposes a grounded framework integrating recent advances. As conceptual, it requires validation.

---

### 9. References

[1] Brown et al., NeurIPS 2020.  
[2] OpenAI, arXiv:2303.08774.  
[3] Li et al., arXiv:2510.16732, 2025.  
[4] Colelough & Regli, arXiv:2501.05435, 2025.  
[5] Shi et al., arXiv:2408.12574, 2025.  
[6] Reed et al. (Gato), arXiv:2205.06175; Driess et al. (RT-2), arXiv:2307.15818.  
[7] Driess et al., arXiv:2303.03378.  
[9] Hafner et al., ICLR 2020.  
[10] Assran et al., arXiv:2506.09985, 2025.  
[11] Sutton & Barto, MIT Press 2018.  
[12] Gupta et al., CVPR 2017.  
[13] Xi et al., arXiv:2309.07864.  
[15] Gui et al., arXiv:2505.02322, 2025.  
[16] Lu et al., arXiv:2506.19842 (ManiGaussian++), 2025; earlier ManiGaussian ECCV 2024.  
[17] Wayve.ai reports, 2025.  
[18] CausalVQA benchmarks.  
[19] Singer & Zvenyhorodskyi, Carnegie Endowment, 2025.

### Figure 1: EAWMA Architecture Dataflow

Detailed textual representation (ASCII art) of the EAWMA architecture, illustrating the perception-action cycle with parallel world and mental modeling, memory integration, and constrained planning:

```
                          +-------------------------+
                          | Multimodal Observations |
                          +-------------------------+
                                       |
                                       v
                          +-------------------------+
                          |     Perception Module   |
                          | (Gaussian Splatting,    |
                          |  Slot Attention)        |
                          +-------------------------+
                                       |
                                       v
                          +-------------------------+     +---------------------+
                          |       Belief State      |<----+   Episodic Memory   |
                          |     (Bayesian Fuse)     |     | (Retrieval & Store) |
                          +-------------------------+     +---------------------+
                                       |                           ^
                                       |                           |
                  +--------------------+--------------------+      |
                  |                                       |      |
                  v                                       v      |
        +-----------------+                     +---------------------+
        |  World Model    |                     |  Mental World Model |
        | (V-JEPA 2-style |                     | (ToM Inverse        |
        |  Dynamics)      |                     |  Planning, k=10)    |
        +-----------------+                     +---------------------+
                  |                                       |
                  +-------------------+--------------------+
                                      |
                                      v
                          +-------------------------+
                          |    Hypertree Planner    |
                          | (MCTS with Self-Reflection)|
                          +-------------------------+
                                       ^
                                       |
                               +-------+-----------------+
                               |                         |
                       Goal / Constraints        (Candidate Rollouts)
                                       |
                                       v
                          +-------------------------+
                          | Neuro-Symbolic Reasoner |
                          | (Logical Credal Nets,   |
                          |  Fuzzy Constraints)     |
                          +-------------------------+
                                       |
                                       v
                          +-------------------------+
                          |       Action Output     |
                          +-------------------------+
                                       |
                                       v
                          +-------------------------+
                          |    Experience Storage   |
                          +-------------------------+
                                       |
                                       +-------------------> (Loop back to Memory)
```

**Description:**
- **Central Loop:** Observations flow through perception to update the belief state, informed by episodic memory retrieval.
- **Parallel Prediction:** Belief feeds both the World Model (physical dynamics) and Mental World Model (intent/ToM inference).
- **Planning & Constraints:** Hypertree planner generates candidates using predictions; neuro-symbolic reasoner filters for safety/logic.
- **Feedback:** Actions produce experiences stored in memory for lifelong adaptation.

This diagram captures the modular, closed-loop design proposed in Section 4. It highlights the Bayesian fusion at the belief state and the role of memory in personalization.


### EAWMA MVP: Final Minimal Viable Prototype Specification  
**A Concrete, Executable Plan for Preliminary Validation**

**Authors:** Ouadi Maakoul (with AI-assisted contributions acknowledged)  
**Date:** December 22, 2025  
**Target:** Transform EAWMA from conceptual proposal to empirically validated framework via a lightweight prototype in simulation.

---

### MVP Scope (Focused & Feasible)
**Core Claim to Validate:** Integrating a mental world model (ToM intent inference) with predictive simulation and constrained planning improves safe, adaptive behavior.

**3 Core Modules Implemented:**
1. **Perception + World Model** (predictive dynamics)
2. **Mental World Model** (inverse planning for intent inference)
3. **Constrained Hypertree Planner** (MCTS with safety rules)

**Omitted for MVP:** Full episodic memory, advanced neuro-symbolic (use hard constraints), real-robot deployment, Gaussian splatting, large-scale training.

**Task:** "Assistive Fetching in a 2D Grid World"  
- Environment: 10x10 grid (MiniGrid-based)
- Entities: Robot (agent), simulated human, water glass, rest area, exit, obstacles, spill hazard zone
- Human Goals: "drink" (move toward water), "rest" (move toward rest area), "leave" (move toward exit)
- Robot Goal: Infer human intent → safely fetch/deliver object or assist without entering spill zone

---

### Environment & Data Generation

**Custom MiniGrid Environment (`assistive_fetch_env.py`)**  
- Partial observability (ego-centric view)
- Human simulated with ε-optimal policy (80% optimal actions toward goal + 20% noise)
- Spill zone: Fixed 2x2 area near delivery point

**Data Generation Strategy**
```python
# Generate 10,000 training episodes
episodes = []
for _ in range(10000):
    goal = np.random.choice(["drink", "rest", "leave"], p=[0.4, 0.4, 0.2])
    human_traj = simulate_human(start_pos, goal, noise=0.2, length=15)
    episodes.append({"traj": human_traj, "goal": goal, "grid": grid_state})

# Test set: 1,000 unseen episodes with edge cases (ambiguous paths, obstacles)
```

---

### Module Architectures (Concrete & Implementable)

#### 1. World Model (`world_model.py`)
```python
class WorldPredictor(nn.Module):
    def __init__(self, grid_size=10, latent_dim=128):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 3 channels: robot, human, objects
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Flatten(),
            nn.Linear(64 * grid_size * grid_size, latent_dim)
        )
        self.dynamics = nn.GRUCell(latent_dim + 5, latent_dim)  # +5 one-hot actions
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 64 * grid_size * grid_size),
            nn.Unflatten(1, (64, grid_size, grid_size)),
            nn.ConvTranspose2d(64, 32, 3, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 3, 3, padding=1),
            nn.Sigmoid()
        )
    
    def forward(self, state, action, hidden):
        z = self.encoder(state)
        z_next = self.dynamics(torch.cat([z, action], dim=-1), hidden)
        pred_state = self.decoder(z_next)
        return pred_state, z_next
```
**Training:** MSE reconstruction + prediction loss on next state (50 epochs, batch=64)

#### 2. Mental World Model (`mental_model.py`)
```python
class IntentInferer:
    def __init__(self, goals, world_model, env, horizon=8):
        self.goals = goals  # ["drink", "rest", "leave"]
        self.world_model = world_model
        self.env = env
        self.horizon = horizon
    
    def goal_likelihood(self, human_traj, goal):
        goal_pos = self.env.goal_positions[goal]
        # Simulate optimal path using A* + world model rollout
        optimal_actions = astar_path(human_traj[0], goal_pos, self.env)
        predicted_states = self.world_model.rollout(human_traj[0], optimal_actions[:self.horizon])
        
        # Negative distance as likelihood
        distances = [np.linalg.norm(actual - pred) 
                     for actual, pred in zip(human_traj[-self.horizon:], predicted_states)]
        return np.exp(-np.mean(distances))
    
    def predict(self, human_traj):
        likelihoods = [self.goal_likelihood(human_traj, g) for g in self.goals]
        return self.goals[np.argmax(likelihoods)]
```

#### 3. Constrained Planner (`planner.py`)
```python
class ConstrainedMCTS:
    def __init__(self, simulations=300, depth=10):
        self.simulations = simulations
        self.depth = depth
    
    def search(self, state, inferred_goal):
        root = Node(state)
        for _ in range(self.simulations):
            node = self.select(root)
            if not self.is_terminal(node):
                node = self.expand(node)
            reward = self.simulate(node, inferred_goal)
            self.backprop(node, reward)
        
        valid_children = [c for c in root.children if self.is_safe(c.trajectory)]
        return max(valid_children, key=lambda c: c.value) if valid_children else safe_fallback()
    
    def is_safe(self, traj):
        return not any(pos in spill_zone for pos in traj)
```

---

### Success Metrics (Rigorous & Achievable)

| Metric                     | Random Baseline | Frequency Baseline | MCTS (no mental) | EAWMA MVP Target |
|----------------------------|-----------------|---------------------|------------------|------------------|
| Intent Accuracy            | 33%             | 45%                 | N/A              | ≥55%             |
| Task Success Rate          | ~30%            | ~40%                | ~50%             | ≥65%             |
| Constraint Violations      | N/A             | N/A                 | ~15%             | 0%               |
| Near-Misses (within 1 cell) | N/A             | N/A                 | N/A              | Track & report   |

**Statistical Significance:** Run 5 seeds, report mean ± std, p<0.05 vs. best baseline

---

### Expected Failure Modes & Mitigation

| Failure Mode                  | Symptom                        | Debug Strategy                  | Mitigation                     |
|-------------------------------|--------------------------------|---------------------------------|--------------------------------|
| Ambiguous trajectories        | Oscillating intent             | Log likelihoods per step        | Temporal smoothing             |
| Poor world model prediction   | MSE >0.15                      | Visualize predictions           | Increase capacity/data         |
| No safe plans                 | Agent freezes                  | Check constraint radius         | Relax then tighten             |
| Integration disconnect        | High intent acc, low success   | Trace goal→action mapping       | Reward shaping                 |

---

### Computational Requirements
- **Hardware:** Laptop CPU sufficient (M1/M2 or modern Intel); GPU optional for faster training
- **Runtime:** 
  - Data gen: ~1-2 hours
  - World model training: ~4-6 hours
  - Full eval (1,000 eps): ~30-60 min
  - Total pipeline: <12 hours
- **Budget:** $0-$50 (Colab Pro if needed)

---

### Visualization Strategy
1. **Intent Inference Videos**: 10 episodes (5 success/5 failure) with overlay (predicted vs. true goal)
2. **Planning Trees**: Visualize selected vs. rejected paths (constraint violations marked red)
3. **Learning Curves**: Intent accuracy & success rate vs. episodes (5 seeds)
4. **Failure Heatmaps**: Grid showing where mispredictions occur

---

### Realistic Timeline (12 Weeks with Buffers)

| Phase                  | Weeks | Key Deliverables                  | Buffer |
|------------------------|-------|-----------------------------------|--------|
| Infrastructure         | 1-2   | Custom env, data pipeline         | +3 days|
| World Model            | 3-5   | Trained predictor (MSE <0.12)     | +5 days|
| Mental Model           | 6-8   | >55% intent accuracy              | +7 days|
| Integration & Planning | 9-11  | End-to-end agent, ablations       | +7 days|
| Analysis & Viz         | 12    | Plots, videos, results write-up   | +3 days|

---

### Repository Structure
```
eawma-mvp/
├── env/
│   ├── assistive_fetch_env.py
│   └── human_simulator.py
├── models/
│   ├── world_model.py
│   ├── mental_model.py
│   └── planner.py
├── data/
│   └── generated_episodes.pkl
├── training/
│   ├── train_world.py
│   └── train_full.py
├── evaluation/
│   ├── evaluate.py
│   └── visualize.py
├── configs/
│   └── mvp_config.yaml
├── tests/
│   └── test_components.py
├── requirements.txt
└── README.md (with setup + demo video)
```

---

### Success Criteria for Publication
**Minimum (Workshop Paper):**  
- Intent accuracy ≥55% (> frequency baseline)  
- Task success ≥65% (> MCTS baseline)  
- 0% violations + clear visualizations

**Stretch (Conference Paper):**  
- >65% intent, >75% success  
- Full ablation study  
- Failure analysis

