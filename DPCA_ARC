A Distributed Probabilistic Coordination Architecture for Autonomous Rover Swarms Using a Lightweight Cognitive Control Layer


Abstract

The deployment of multi-rover systems in real-world environments is hampered by challenges of partial observability, limited communication bandwidth, and dynamic task allocation. Existing solutions often rely on centralized planning or bandwidth-heavy consensus protocols that are ill-suited for low-cost, energy-constrained swarms. This thesis introduces a Lightweight Cognitive Coordination Layer (LCCL)—a distributed probabilistic architecture that enables robust and efficient coordination through entropy minimization over a dynamic communication graph. Each rover maintains a probabilistic belief of the global task state, and coordination is achieved via a gossip-based consensus protocol that aligns these beliefs while respecting energy and connectivity constraints. The LCCL operates asynchronously, requires minimal bandwidth, and is resilient to node failures and communication dropouts. The framework is formalized using information theory, graph theory, and stochastic processes, including convergence analysis of the proposed consensus update. We provide a comprehensive theoretical foundation, system architecture, and algorithmic design. Additionally, this thesis presents a detailed implementation blueprint including software modules, message formats, communication protocols, and an optional PHP-based coordination server for monitoring and experiment control. Concrete ROS 2 node boilerplate and launch scripts are provided as part of the design specification. This work lays the groundwork for scalable, resilient swarm robotics in applications ranging from agriculture to search and rescue.

---

Acknowledgements

[Placeholder]

---

Table of Contents

1. Introduction
2. Literature Review
3. Theoretical Foundations
4. System Architecture
5. Algorithm Design
6. Implementation Blueprint
7. Conclusion and Future Work

---

Chapter 1: Introduction

1.1 Background and Motivation

Autonomous mobile robots have transitioned from laboratory curiosities to tools deployed in warehouses, fields, and even other planets. While single-robot autonomy has matured—with robust solutions for localization, mapping, and obstacle avoidance—coordinating multiple robots remains a systems-level challenge. The future of robotics lies not in isolated machines but in distributed autonomous physical systems: swarms of rovers that collectively explore, map, transport, or monitor environments.

Such swarms promise scalability, robustness, and flexibility. However, they also introduce new complexities. In real-world deployments, rovers must cope with:

· Partial observability: No rover has a complete view of the environment or the states of its peers.
· Communication latency and dropouts: Wireless links are unreliable, especially in large areas or cluttered environments.
· Task conflicts: Without coordination, multiple rovers may converge on the same task while others remain idle.
· Energy constraints: Rovers operate on limited batteries; inefficient coordination can lead to premature depletion.

Current robotic middleware, such as ROS 2, provides powerful tools for local autonomy but offers limited support for distributed coordination. Existing approaches to multi-robot coordination fall into three categories:

1. Centralized planners: A single node computes optimal assignments and broadcasts commands. This creates a single point of failure and a communication bottleneck.
2. Deterministic consensus protocols: Algorithms like Paxos or Raft ensure agreement but require multiple rounds of message exchanges, incurring high latency and bandwidth.
3. Reactive swarming: Simple behaviors (e.g., flocking, dispersion) scale well but are insufficient for task-level coordination.

Recent advances in distributed optimization (e.g., consensus-ADMM) and probabilistic consensus (e.g., Gaussian Belief Propagation) have improved scalability, but they often assume reliable communication or fixed network topologies. There is a need for a middle ground: a coordination layer that is lightweight, probabilistic, and designed for the realities of low-cost hardware and unstable networks. This thesis proposes such a layer.

1.2 Problem Statement

Consider a swarm of $n$ autonomous rovers $\mathcal{N} = \{1,\dots,n\}$ operating in an environment $\mathcal{W} \subset \mathbb{R}^2$ containing $m$ tasks $\mathcal{T} = \{\tau_1,\dots,\tau_m\}$. Tasks may appear dynamically over time, and each task has a maximum capacity $\text{cap}_k$ (number of rovers that can simultaneously serve it). Each rover $i$ has a state $S_i(t)$ comprising its position $\mathbf{p}_i(t) \in \mathbb{R}^2$, energy level $E_i(t) \in [0,1]$, current task $\tau_i(t) \in \mathcal{T} \cup \{\text{idle}\}$, and communication confidence $\sigma_i(t)$. Rovers communicate via wireless links that are range-limited and subject to packet loss. The communication graph $G(t) = (V,E(t))$ is time-varying and may be disconnected.

No central server exists; coordination must be fully distributed. Each rover only has access to local observations and occasional messages from neighbors. The core problem is: How can the swarm achieve efficient, stable, and fault-tolerant task allocation under uncertainty and communication constraints?

More formally, we define the global coordination entropy $H_c(t)$ as a measure of uncertainty in task assignments across the swarm. The objective is to design a distributed control law that drives $H_c(t)$ to a minimum while satisfying energy and connectivity constraints.

1.3 Research Hypothesis

We hypothesize that a rover swarm can achieve higher global stability and task efficiency if coordination is modeled as entropy minimization over a dynamically evolving communication graph. Specifically, by having each rover maintain a probabilistic belief of the global task state and exchanging these beliefs via a lightweight gossip protocol with age-and-signal-strength weighting, the swarm can converge to a consistent and efficient allocation without requiring full state knowledge or high bandwidth.

1.4 Research Questions

1. Representation: How can a rover's uncertain knowledge of the global task allocation be compactly represented as a probability distribution, and how can this representation be updated with asynchronous, lossy communication?
2. Consensus: What gossip-based update rule ensures that beliefs converge to a common distribution under realistic network conditions, and how fast does this convergence occur?
3. Task Selection: Given a belief, how should a rover decide which task to execute, balancing task utility, energy cost, and uncertainty?
4. Entropy as a Metric: How can global coordination entropy be estimated from local beliefs, and how does it correlate with system performance?

1.5 Contributions

The main contributions of this thesis are:

1. Entropy-Based Coordination Metric (ECM): A novel metric that quantifies the uncertainty in task allocation across the swarm, enabling the coordination layer to monitor and optimize collective behavior.
2. Energy-Aware Probabilistic Task Allocation (EAPTA): A task allocation mechanism that uses each rover's energy level and local belief to generate a probability distribution over tasks, balancing exploration and exploitation.
3. Lightweight Graph-Based Consensus Protocol: A gossip-based protocol that propagates belief information through the swarm using only local interactions and stale data weighting, with theoretical guarantees on convergence under mild connectivity assumptions.
4. Asynchronous Operation with Age-Weighting: A method to handle delayed and dropped messages by exponentially decaying the influence of stale information, ensuring robustness in real-world networks.
5. Conflict Resolution via Repulsion: A decentralized mechanism to prevent task over-subscription by introducing a repulsion term in the task probability distribution based on neighbors' beliefs.
6. Comprehensive Theoretical Framework: Formalization of the coordination problem using information theory, graph theory, and stochastic processes, including convergence analysis of the proposed consensus update.
7. Implementation Blueprint: Detailed design of software modules, message formats, communication protocols, and an optional PHP-based coordination server for monitoring and experiment control.

1.6 Thesis Outline

Chapter 2 reviews related work in multi-robot coordination, swarm robotics, consensus algorithms, and information-theoretic approaches, concluding with a comparative analysis that highlights the gap filled by LCCL. Chapter 3 establishes the mathematical foundations, including probabilistic state models, graph theory, entropy, and stochastic processes, and provides convergence analysis for the proposed consensus update. Chapter 4 presents the overall system architecture of the LCCL, detailing the communication model, state aggregation, and task allocator. Chapter 5 describes the algorithms for distributed consensus, entropy-based commitment, and energy-aware task selection. Chapter 6 provides a concrete implementation blueprint, including software modules, message formats, and an optional PHP coordination server. Chapter 7 concludes the thesis and outlines future research directions.

---

Chapter 2: Literature Review

2.1 Multi-Robot Coordination

Early work in multi-robot coordination focused on centralized approaches, where a single computer plans trajectories and assigns tasks (Gerkey & Matarić, 2004). While optimal in small settings, centralization fails to scale and is vulnerable to single-point failures. Decentralized methods emerged to address these limitations, including market-based approaches (Dias et al., 2006) and auction algorithms (Zlot et al., 2002).

2.2 Swarm Robotics

Swarm robotics draws inspiration from social insects, using simple local rules to produce complex collective behaviors (Şahin, 2004). Common primitives include flocking (Olfati-Saber, 2006), dispersion (McLurkin & Yamins, 2005), and foraging (Liu et al., 2019). These approaches scale well but are typically reactive and lack explicit task-level coordination. Recent work has integrated task allocation into swarm behaviors using probabilistic finite state machines (Hamann, 2018).

2.3 Distributed Consensus

Consensus algorithms enable a group of distributed agents to agree on a common value. In robotics, consensus has been used for formation control (Ren et al., 2005) and map merging (Cunningham et al., 2012). Classic protocols like Paxos (Lamport, 2001) and Raft (Ongaro & Ousterhout, 2014) guarantee agreement but require reliable communication and multiple rounds. For swarms with unreliable links, gossip protocols (Boyd et al., 2006) offer a lightweight alternative, where agents randomly exchange information with neighbors. Recent advances include Gaussian Belief Propagation (GBP) for distributed inference (DANCeRS, 2025), which achieves consensus on continuous and discrete variables but requires bidirectional message passing and may be sensitive to loopy graphs.

2.4 Information Theory in Robotics

Information theory has been applied to robotics for exploration (Julian et al., 2012), active perception (Atanasov et al., 2016), and coordination (Best et al., 2020). The concept of mutual information guides robots to areas that reduce uncertainty. Entropy has been used as a measure of map uncertainty in SLAM (Stachniss et al., 2005). For task allocation, entropy can quantify the ambiguity in assignments. However, using entropy as a global metric to drive coordination in swarms is less explored; most works focus on local entropy minimization for individual decision-making (e.g., Strub & Gammell, 2020).

2.5 Probabilistic Robotics

Probabilistic methods dominate modern robotics, with Kalman filters (Kalman, 1960), particle filters (Thrun et al., 2005), and Bayesian approaches (Fox et al., 2003) handling uncertainty. The Partially Observable Markov Decision Process (POMDP) (Kaelbling et al., 1998) provides a rigorous framework for decision-making under uncertainty, though solving POMDPs exactly is intractable for large swarms. Recent work uses decentralized POMDPs (Dec-POMDPs) with factored representations (Oliehoek & Amato, 2016), but these remain computationally expensive.

2.6 Low-Bandwidth and Event-Triggered Methods

To reduce communication overhead, researchers have proposed event-triggered control (Dimarogonas et al., 2012) and asynchronous update schemes. In multi-robot task allocation, event-triggered methods (e.g., ACHORD, 2023) send messages only when local state changes significantly. These approaches can dramatically reduce bandwidth but may suffer from delayed information. The LCCL combines event-triggered updates (belief changes) with periodic heartbeats to maintain connectivity awareness.

2.7 Dynamic Task Allocation

Real-world scenarios often involve tasks that appear, disappear, or change priority over time. Recent work addresses dynamic task allocation using online algorithms (Turner et al., 2021), receding-horizon planning (Minaeian et al., 2020), and distributed optimization with task arrivals (Johnson et al., 2022). The LCCL is designed to handle dynamic tasks by continuously updating beliefs and adapting task probabilities.

2.8 Gaps and Positioning

To clearly position LCCL, Table 2.1 compares it with representative state-of-the-art methods across key dimensions: communication model, asynchrony support, energy awareness, entropy-based coordination, and hardware demonstration.

Method Communication Asynchronous? Energy-Aware? Entropy Metric? Hardware Demo?
Consensus-ADMM (2021) Synchronous rounds No Optional No Simulation only
Gaussian Belief Propagation (2025) Bidirectional messages Partially No Implicitly in beliefs Simulation
Event-Triggered Auction (2023) Event-driven Yes No No Yes (4 robots)
DSTA (2022) Periodic broadcast Yes Yes No Simulation
LCCL (proposed) Gossip, age-weighted Yes Yes Yes (explicit) Planned

LCCL uniquely combines:

· Fully asynchronous, gossip-based communication with age-weighting for robustness.
· Explicit entropy minimization as a global coordination objective.
· Energy-aware probabilistic task allocation.
· Conflict resolution via repulsion.
· A comprehensive theoretical framework ready for empirical validation.
· A detailed implementation blueprint for practical deployment.

---

Chapter 3: Theoretical Foundations

3.1 Probabilistic State Representation

Let the swarm consist of $n$ rovers indexed by $i \in \mathcal{N} = \{1,\dots,n\}$. At time $t$, each rover $i$ has an internal state $S_i(t)$. Due to sensor noise and localization drift, we model the state as a random variable with a Gaussian distribution for continuous components and a categorical distribution for the discrete task variable. We adopt a factored representation:

S_i(t) \sim \mathcal{N}(\boldsymbol{\mu}_i(t), \boldsymbol{\Sigma}_i(t)) \otimes \text{Cat}(\mathbf{q}_i(t))

where $\boldsymbol{\mu}_i(t) = [x_i(t), y_i(t), E_i(t)]^T$ includes position and energy, $\boldsymbol{\Sigma}_i(t)$ is a $3\times3$ covariance matrix, and $\mathbf{q}_i(t)$ is a probability vector over $\mathcal{T} \cup \{\text{idle}\}$ representing the rover's belief about its own current task (for local state estimation). However, for coordination, we are interested in each rover's belief about the global task allocation, i.e., which tasks are being executed by whom. This is a joint distribution over assignments, which is too large to represent explicitly. Instead, each rover maintains a marginal belief $b_i(\tau)$ for each task $\tau$, representing the probability that task $\tau$ is currently assigned to some rover (or that it is available). This is an approximation, but it enables scalable updates.

Formally, let $b_i(t) = \{b_i^\tau(t)\}_{\tau \in \mathcal{T}}$ be a probability distribution over tasks, with $b_i^\tau(t)$ the probability that task $\tau$ is "claimed" (i.e., at least one rover is executing it). This coarse representation suffices for coordination, as we will show.

3.2 Communication Graph and Algebraic Connectivity

Rovers communicate when within range. Define the proximity graph $G(t) = (V, E(t))$ with vertex set $V = \mathcal{N}$ and edges $(i,j) \in E(t)$ if the distance $d_{ij}(t) \le R_{\text{comm}}$, where $R_{\text{comm}}$ is the communication range. To account for signal degradation, we assign a weight $w_{ij}(t) \in [0,1]$ to each edge, representing communication confidence. A common model is:

w_{ij}(t) = e^{-\gamma \, d_{ij}(t)} \cdot \sigma_i(t) \cdot \sigma_j(t)

where $\gamma$ is a decay constant and $\sigma_i(t)$ is the signal-to-noise ratio at rover $i$.

The graph Laplacian $L(t) = D(t) - A(t)$, where $A(t)$ is the weighted adjacency matrix and $D(t)$ the degree matrix, characterizes connectivity. The algebraic connectivity $\lambda_2(t)$, the second smallest eigenvalue of $L(t)$, indicates whether the graph is connected ($\lambda_2 > 0$). Maintaining $\lambda_2(t) > \epsilon$ for some small $\epsilon$ prevents swarm fragmentation.

3.3 Coordination Entropy

We define the global coordination entropy $H_c(t)$ as the conditional entropy of task assignments given the aggregate state of the swarm. Since we only have marginal beliefs, we approximate $H_c(t)$ by the average entropy of the local beliefs:

H_c(t) \approx \frac{1}{n} \sum_{i=1}^n H(b_i(t))

where $H(b_i) = -\sum_{\tau} b_i(\tau) \log b_i(\tau)$ is the Shannon entropy. This approximation is reasonable when beliefs are well-aligned; if they diverge, the average entropy captures the overall uncertainty. Minimizing $H_c(t)$ encourages the swarm to reach a consensus on task assignments.

The divergence between neighboring beliefs is measured by the Kullback-Leibler divergence:

D_{\text{KL}}(b_i \parallel b_j) = \sum_{\tau} b_i(\tau) \log \frac{b_i(\tau)}{b_j(\tau)}.

A distributed algorithm that reduces pairwise KL divergences will reduce global entropy.

3.4 Distributed Consensus via Log-Linear Pooling

A standard consensus protocol for scalar values is:

x_i(t+1) = x_i(t) + \alpha \sum_{j \in \mathcal{N}_i} w_{ij} (x_j(t) - x_i(t))

where $\mathcal{N}_i$ is the set of neighbors of $i$. Under mild conditions, all $x_i$ converge to the average of initial values.

For probability distributions, we use log-linear pooling:

\log b_i^{(k+1)} = (1-\eta) \log b_i^{(k)} + \eta \sum_{j \in \mathcal{N}_i} \tilde{w}_{ij} \log b_j^{(k)}

where $\eta$ is a learning rate and $\tilde{w}_{ij}$ are normalized weights (summing to 1 over neighbors). This update minimizes the weighted sum of KL divergences to neighbors and, under appropriate conditions (connected graph, doubly stochastic weights), converges to a common distribution that is the geometric mean of the initial distributions.

In our setting, messages may be delayed or lost. We incorporate age-weighting by replacing $\tilde{w}_{ij}$ with:

\tilde{w}_{ij}(t) = \frac{ w_{ij}(t) \cdot e^{-\kappa (t - t_{ij}^{\text{last}})} }{ \sum_{j'} w_{ij'}(t) e^{-\kappa (t - t_{ij'}^{\text{last}})} }

where $t_{ij}^{\text{last}}$ is the timestamp of the last received message from $j$, and $\kappa$ controls the decay rate. This ensures stale information is downweighted.

3.5 POMDP Formulation for Task Selection

Each rover faces a decision problem: given its belief $b_i$, what task $\tau$ should it execute? This is a POMDP with state space $\mathcal{S}$ (the true global allocation), action space $\mathcal{T}$, observations (local sensor readings, neighbor messages), and reward function $R(s,a)$. Solving the POMDP exactly is intractable, but we can approximate by defining a belief-dependent reward that encourages actions that reduce local entropy and align with the global objective.

We define the reward for rover $i$ choosing task $k$ as:

R_i(k, b_i) = U(k) - C_{\text{energy}}(k, E_i) - \lambda H(b_i)

where $U(k)$ is the intrinsic utility of task $k$, $C_{\text{energy}}$ is an energy cost, and $\lambda$ weights the penalty for uncertainty. The energy cost is designed to become large when $E_i$ is low, forcing a return-to-charge behavior:

C_{\text{energy}}(k, E_i) = \alpha \cdot \frac{d_k}{E_i + \epsilon}

where $d_k$ is the estimated distance to task $k$, $\alpha$ is a scaling factor, and $\epsilon$ prevents division by zero. When $E_i < E_{\text{crit}}$, we set $C_{\text{energy}}$ to infinity for all non-charging tasks.

3.6 Constrained Optimization

The coordination problem can be framed as minimizing the time-averaged global entropy subject to constraints:

\min \lim_{T\to\infty} \frac{1}{T} \int_0^T H_c(t) \, dt

subject to:

· Connectivity: $\lambda_2(L(t)) > \epsilon \quad \forall t$
· Energy: $E_i(t) > E_{\min} \quad \forall i, t$
· Task capacity: $\sum_{i=1}^n \mathbb{1}(\tau_i = k) \le \text{cap}_k \quad \forall k$

This is a challenging stochastic control problem. The LCCL implements a heuristic that approximately solves it via distributed consensus and probabilistic task selection.

3.7 Convergence Analysis

We analyze the convergence of the weighted log-linear update with age-weighting under the assumption that the graph is connected and the weights are doubly stochastic in expectation. The age-weighting introduces a bias, but as long as messages are eventually received, the bias decays. We derive a bound on the expected reduction in KL divergence per iteration:

Theorem 1 (Expected KL reduction). Under the update with age-weighting, if the graph is connected and the weights are such that $\sum_j \tilde{w}_{ij}=1$, then for each rover $i$,

\mathbb{E}[D_{\text{KL}}(b_i^{(k+1)} \parallel \bar{b}^{(k)})] \le (1 - \eta \lambda_2) \mathbb{E}[D_{\text{KL}}(b_i^{(k)} \parallel \bar{b}^{(k)})] + \eta^2 \sigma^2

where $\bar{b}^{(k)}$ is the weighted geometric mean of the current beliefs, $\lambda_2$ is the algebraic connectivity, and $\sigma^2$ bounds the variance due to outdated messages.

Proof Sketch. The proof uses convexity of KL divergence and properties of the graph Laplacian. Let $d_i^{(k)} = D_{\text{KL}}(b_i^{(k)} \parallel \bar{b}^{(k)})$. The log-linear update can be seen as a gradient step on the KL divergence. Under the assumption that the expected weight matrix is doubly stochastic, the expected evolution of $d_i^{(k)}$ follows a contraction with factor $(1-\eta\lambda_2)$ plus a term due to the variance of the random weights caused by age. The full derivation is omitted for brevity. ∎

This theorem shows that beliefs converge exponentially to a common distribution, with a steady-state error bounded by the staleness variance.

---

Chapter 4: System Architecture

4.1 Overview

The Lightweight Cognitive Coordination Layer (LCCL) is a distributed software layer that runs on each rover, interfacing with the local autonomy stack and communicating with peers. It operates asynchronously, exchanging compact belief messages rather than raw sensor data. The architecture is shown in Figure 4.1 (described below).

```
+---------------------------+
|   Rover Autonomy Layer    |
| (SLAM, path planning,     |
|  obstacle avoidance)      |
+---------------------------+
            ↑
            | task commands
            ↓
+---------------------------+
|   Lightweight Cognitive   |
|   Coordination Layer      |
| - Belief maintenance      |
| - Consensus updates       |
| - Task allocation         |
| - Conflict resolution     |
+---------------------------+
            ↑
            | belief messages (UDP broadcast)
            ↓
+---------------------------+
|   Wireless Mesh Network   |
|   (Wi-Fi / Zigbee / etc.) |
+---------------------------+
```

Figure 4.1: Layered architecture of the LCCL. The LCCL sits atop the local autonomy stack, exchanging beliefs with peers and issuing task commands.

4.2 Layered Design

Layer 1: Rover Autonomy (Local)

· Handles low-level control: obstacle avoidance, path planning, localization (e.g., SLAM), and energy monitoring.
· Provides a standardized interface to the LCCL: publishes its local state estimate $S_i(t)$ and accepts task assignments $\tau_i$.
· Operates at high frequency (10–50 Hz) for real-time control.

Layer 2: Lightweight Cognitive Coordination Layer (LCCL)

· Maintains a probabilistic belief $b_i$ about global task allocation.
· Aggregates incoming beliefs from neighbors, weighting them by communication confidence and age.
· Runs the consensus update to refine $b_i$.
· Uses $b_i$ and local energy to compute a task utility distribution and decide whether to commit to a new task.
· Sends periodic belief messages to neighbors (1–2 Hz).

4.3 Communication Model

We assume a wireless mesh network (e.g., Wi-Fi ad-hoc, Zigbee, or ESP-NOW). Rovers broadcast short messages containing:

· Rover ID
· Timestamp
· Belief vector $b_i$ (a probability distribution over tasks, compressed as described in Section 4.8)
· Energy level $E_i$
· Optional: position estimate (if useful for weighting)

Messages are sent at a low frequency (e.g., 1–2 Hz) to conserve bandwidth. The LCCL does not require reliable delivery; missing messages are handled by the age-weighting mechanism.

4.4 State Aggregation and Graph Maintenance

Each rover maintains a local neighbor table, storing the most recent belief received from each peer, along with a timestamp and received signal strength (RSSI). The communication confidence $w_{ij}$ is computed as a function of RSSI and age:

w_{ij}(t) = \text{RSSI}_{\text{norm}} \cdot e^{-\kappa (t - t_{\text{last}})}

where $\kappa$ is a decay factor (e.g., $\kappa = 0.1$ for 1-second half-life). This ensures that stale information is downweighted. If no message is received from a neighbor for more than a timeout period (e.g., 5 seconds), the neighbor is removed from the table.

4.5 Probabilistic Task Allocator (EAPTA)

Given the current belief $b_i$ and energy $E_i$, the task allocator computes a probability distribution $P_i(\tau)$ over tasks:

P_i(\tau) \propto \exp\left( \frac{ \beta (U(\tau) - C_{\text{energy}}(\tau, E_i)) + (1-\beta) \log b_i(\tau) }{ T_{\text{sys}} } \right)

This is a softmax function that balances task utility and belief alignment. The parameter $\beta \in [0,1]$ controls the trade-off; $T_{\text{sys}}$ is a temperature that modulates randomness (higher $T$ encourages exploration). The energy cost $C_{\text{energy}}$ is as defined in Section 3.5.

4.6 Conflict Resolution Engine

Conflicts arise when multiple rovers assign high probability to the same task, potentially exceeding its capacity. The conflict resolution engine monitors the local belief $b_i$ and, if it detects that a task is oversubscribed (based on recent neighbor beliefs), it adjusts the distribution by applying a repulsion term:

P_i(\tau) \leftarrow P_i(\tau) \cdot \exp\left( -\mu \sum_{j \in \mathcal{N}_i} b_j(\tau) \right)

where $\mu$ controls the repulsion strength. This discourages rovers from piling onto the same task. The sum is over neighbors' beliefs; if no neighbor information is available, it defaults to zero.

4.7 Commitment Logic

A rover commits to a task $\tau^*$ when the entropy $H(b_i)$ falls below a threshold $\gamma$, indicating sufficient certainty. The threshold $\gamma$ is dynamically adjusted based on the swarm's algebraic connectivity $\lambda_2$ (estimated from local neighbor counts). When $\lambda_2$ is high (well-connected), a lower $\gamma$ can be used; when connectivity is poor, a higher $\gamma$ allows rovers to act on less certain beliefs to avoid deadlock. A simple heuristic:

\gamma = \gamma_{\min} + (\gamma_{\max} - \gamma_{\min}) \cdot e^{-\rho \hat{\lambda}_2}

where $\hat{\lambda}_2$ is an estimate of $\lambda_2$ (e.g., based on the number of neighbors), and $\rho$ controls the sensitivity.

Once committed, the rover informs the local autonomy layer and begins execution. If $H(b_i) > \gamma$, the rover remains in an information-gathering mode, moving to improve connectivity or explore uncertain areas.

4.8 Belief Compression and Transmission

To minimize bandwidth, beliefs are compressed before transmission. Since $b_i$ is a probability vector over $|\mathcal{T}|$ tasks, we can send only the top $K$ entries with highest probability, along with their values, and assume the rest are uniformly distributed or zero. Alternatively, we can use a Dirichlet representation and send its parameters. In our implementation, we use a simple threshold: send all probabilities that exceed a threshold $\delta$, and renormalize on the receiving end. This reduces message size significantly when $|\mathcal{T}|$ is large.

---

Chapter 5: Algorithm Design

5.1 Distributed Probabilistic Consensus (DPC)

The core of LCCL is the Distributed Probabilistic Consensus algorithm, which updates each rover's belief based on neighbor messages.

Algorithm 1: DPC Update (executed periodically by each rover)

```
Input: Local belief b_i, neighbor table with entries {b_j, t_j, RSSI_j}
Output: Updated belief b_i

1. For each neighbor j with age Δt = current_time - t_j:
       compute effective weight w_eff[j] = RSSI_j * exp(-κ * Δt)
   end
   If no neighbors, skip update.

2. Normalize w_eff to sum to 1 over neighbors.

3. Log-linear pooling:
       log b_i_new = (1 - η) * log b_i + η * sum_j (w_eff[j] * log b_j)
   (where log is taken element-wise, and we ensure b_i > 0 by adding a small epsilon)

4. Renormalize b_i_new to sum to 1.

5. If entropy H(b_i_new) < H(b_i):
       b_i = b_i_new
   else:
       // optional: keep old belief if update increases entropy (avoids instability)
       b_i = b_i
   end
```

Parameters: $\eta \in [0.1, 0.5]$, $\kappa$ (e.g., 0.1 for 10-second half-life). The entropy check prevents the update from increasing uncertainty, which can happen if neighbors have very divergent beliefs due to outdated info.

5.2 Entropy-Based Task Commitment

The commitment decision uses the dynamic threshold $\gamma$ computed as in Section 4.7. When $H(b_i) < \gamma$, the rover selects a task by sampling from $P_i(\tau)$ (or taking the maximum) and sends a command to the autonomy layer. After committing, the rover may continue to exchange beliefs but will not change task until the current task is completed or a timeout occurs.

5.3 Energy-Aware Reward Function

The energy cost function is implemented as:

```
def energy_cost(task_k, energy, rover_position):
    if energy < E_crit and task_k != "charge":
        return INF
    distance = estimate_distance(rover_position, task_k.position)
    return alpha * distance / (energy + EPS)
```

The parameter $\alpha$ is tuned so that a rover with 50% energy will prioritize a task within 10 m over a task at 20 m unless the latter has much higher utility.

5.4 Handling Asynchrony and Packet Loss

The age-weighting mechanism ($e^{-\kappa \Delta t}$) ensures that old messages are gradually forgotten. This makes the algorithm robust to temporary communication dropouts. Additionally, if no messages are received from a neighbor for a long time, that neighbor is removed from the neighbor table. When a rover rejoins, its beliefs will be integrated with a low initial weight (due to large $\Delta t$), preventing sudden swings.

5.5 Complexity Analysis

Each rover's LCCL update has complexity $O(|\mathcal{N}_i| \cdot |\mathcal{T}|)$, where $|\mathcal{N}_i|$ is the number of neighbors (typically limited by communication range, e.g., 5–10) and $|\mathcal{T}|$ is the number of tasks (e.g., 10–20). For a swarm of 50 rovers with 20 tasks, each update involves a few hundred operations, easily handled by a Raspberry Pi. Communication overhead is $O(|\mathcal{T}|)$ bytes per message (after compression), which is negligible compared to video or LIDAR data.

---

Chapter 6: Implementation Blueprint

6.1 Overview

This chapter provides a concrete blueprint for implementing the Lightweight Cognitive Coordination Layer (LCCL) on real rover hardware. The goal is to bridge the gap between theoretical design and practical deployment. We describe the software architecture for each rover, the communication protocols, message formats, and an optional centralized coordination server built with PHP for monitoring and experiment control. The design emphasizes lightweight operation, low bandwidth, and ease of integration with existing autonomy stacks such as ROS 2. All code provided in this chapter is intended as a design specification; no experimental results are reported.

6.2 Rover Software Architecture

Each rover runs a software stack consisting of:

· Operating System: Linux (e.g., Raspberry Pi OS) with ROS 2 Humble.
· Local Autonomy Layer: ROS 2 nodes for sensor processing, localization (e.g., SLAM), path planning (Nav2), and motor control.
· LCCL Node: A custom ROS 2 node implemented in Python that handles coordination.

Figure 6.1 shows the internal modules of the LCCL node:

```
+---------------------------+
|      LCCL Node            |
+---------------------------+
| - Belief Manager          |
| - Communication Handler   |
| - Task Allocator          |
| - Conflict Resolver       |
| - Commitment Logic        |
| - Energy Monitor          |
+---------------------------+
        | (subscribes)       | (publishes)
+--------+--------+    +-----+------+
| /odom, /battery |    | /task_cmd |
+-----------------+    +-----------+
```

Module Descriptions:

· Belief Manager: Maintains the local belief vector $b_i$ (probability distribution over tasks) and a neighbor table storing the most recent beliefs received from other rovers, along with timestamps and RSSI. Periodically triggers the consensus update (Algorithm 1) using neighbor data.
· Communication Handler: Sends and receives belief messages via UDP broadcast. Serializes/deserializes messages using a compact format (JSON or MessagePack). Runs in a separate thread to avoid blocking.
· Energy Monitor: Reads battery voltage and computes normalized energy $E_i$. Publishes to /battery for local use.
· Task Allocator: Implements EAPTA (Section 4.5), computing the task probability distribution $P_i(\tau)$ based on current belief and energy. Also applies repulsion if conflict is detected.
· Commitment Logic: Monitors entropy $H(b_i)$ and dynamic threshold $\gamma$. When $H(b_i) < \gamma$, selects a task and publishes a command to /task_cmd.
· Conflict Resolver: Adjusts task probabilities using neighbor beliefs to prevent over-subscription (repulsion term).

6.3 Message Formats

Belief messages are broadcast periodically (e.g., 1 Hz). Each message contains:

· Header:
  · rover_id (integer)
  · timestamp (float)
  · seq_num (integer)
· Payload:
  · belief (object): compressed probability vector.
  · energy (float)
  · Optional: position (float[2])

Example JSON message using top-3 compression:

```json
{
  "rover_id": 5,
  "timestamp": 1740012345.67,
  "seq_num": 42,
  "belief": {
    "top": [
      {"task": "explore_A", "prob": 0.6},
      {"task": "charge", "prob": 0.3},
      {"task": "explore_B", "prob": 0.1}
    ]
  },
  "energy": 0.75,
  "position": [12.3, 45.6]
}
```

Binary formats like MessagePack can further reduce size.

6.4 Communication Protocol

· Transport: UDP broadcast on port 12345.
· Rate: Adaptive, nominally 1 Hz.
· Neighbor Discovery: Implicit via received messages; timeout after 5 seconds.
· Age-weighting: Messages decay exponentially with factor $\kappa$.

6.5 ROS 2 Node Boilerplate

Below is the complete Python implementation of the LCCL node as a ROS 2 node. This code implements the asynchronous UDP receiver, log-linear pooling consensus, entropy-based commitment, and parameterization.

```python
import rclpy
from rclpy.node import Node
from nav_msgs.msg import Odometry
from sensor_msgs.msg import BatteryState
from std_msgs.msg import String
import socket
import json
import threading
import numpy as np
import time

class LCCLNode(Node):
    def __init__(self):
        super().__init__('lccl_coordination_node')

        # --- Parameters ---
        self.declare_parameter('rover_id', 1)
        self.declare_parameter('udp_port', 12345)
        self.declare_parameter('broadcast_rate', 1.0)  # Hz
        self.declare_parameter('eta', 0.3)             # Consensus learning rate
        self.declare_parameter('kappa', 0.1)           # Age decay constant
        self.declare_parameter('gamma_threshold', 0.5) # Entropy commitment threshold

        self.rover_id = self.get_parameter('rover_id').value
        self.udp_port = self.get_parameter('udp_port').value
        self.eta = self.get_parameter('eta').value
        self.kappa = self.get_parameter('kappa').value
        
        # --- Internal State ---
        self.local_pos = [0.0, 0.0]
        self.energy = 1.0
        self.current_task = None
        # Initial belief: uniform distribution over 5 dummy tasks
        self.tasks = ["explore_A", "explore_B", "mine_C", "charge", "idle"]
        self.belief = np.array([1.0/len(self.tasks)] * len(self.tasks))
        self.neighbor_table = {} # {id: {'belief': [], 'timestamp': float, 'snr': float}}

        # --- ROS 2 Subscriptions & Publications ---
        self.odom_sub = self.create_subscription(Odometry, '/odom', self.odom_callback, 10)
        self.batt_sub = self.create_subscription(BatteryState, '/battery', self.battery_callback, 10)
        self.task_pub = self.create_publisher(String, '/task_command', 10)

        # --- Networking Setup ---
        self.udp_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.udp_sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
        self.udp_sock.bind(('', self.udp_port))
        self.udp_sock.setblocking(False)

        # Threads for asynchronous communication
        self.receiver_thread = threading.Thread(target=self.udp_receiver_loop, daemon=True)
        self.receiver_thread.start()

        # Main Coordination Timer
        self.timer = self.create_timer(1.0/self.get_parameter('broadcast_rate').value, self.coordination_loop)

        self.get_logger().info(f"LCCL Node Started for Rover {self.rover_id}")

    # --- Callbacks ---
    def odom_callback(self, msg):
        self.local_pos = [msg.pose.pose.position.x, msg.pose.pose.position.y]

    def battery_callback(self, msg):
        self.energy = msg.percentage

    # --- UDP Logic ---
    def udp_receiver_loop(self):
        """Asynchronously listen for beliefs from other rovers."""
        while True:
            try:
                data, addr = self.udp_sock.recvfrom(1024)
                payload = json.loads(data.decode())
                if payload['rover_id'] != self.rover_id:
                    self.neighbor_table[payload['rover_id']] = {
                        'belief': np.array(payload['belief']),
                        'timestamp': time.time(),
                        'snr': 1.0 # Simplified RSSI
                    }
            except (BlockingIOError, json.JSONDecodeError):
                time.sleep(0.1)

    def broadcast_belief(self):
        msg = {
            "rover_id": self.rover_id,
            "timestamp": time.time(),
            "belief": self.belief.tolist(),
            "energy": self.energy
        }
        self.udp_sock.sendto(json.dumps(msg).encode(), ('<broadcast>', self.udp_port))

    # --- Core Algorithmic Approach ---
    def calculate_entropy(self, b):
        return -np.sum(b * np.log(b + 1e-9))

    def run_consensus(self):
        if not self.neighbor_table:
            return
        
        # Log-linear pooling
        log_b = np.log(self.belief + 1e-9)
        weighted_neighbor_sum = np.zeros(len(self.tasks))
        total_weight = 0
        
        now = time.time()
        for rid, data in list(self.neighbor_table.items()):
            age = now - data['timestamp']
            if age > 5.0: # Timeout neighbor
                del self.neighbor_table[rid]
                continue
            
            weight = data['snr'] * np.exp(-self.kappa * age)
            weighted_neighbor_sum += weight * np.log(data['belief'] + 1e-9)
            total_weight += weight

        if total_weight > 0:
            pooled_log = (1 - self.eta) * log_b + self.eta * (weighted_neighbor_sum / total_weight)
            new_belief = np.exp(pooled_log)
            self.belief = new_belief / np.sum(new_belief)

    def coordination_loop(self):
        """The primary LCCL control loop."""
        # 1. Consensus Step
        self.run_consensus()

        # 2. Broadcast Step
        self.broadcast_belief()

        # 3. Decision Step
        current_entropy = self.calculate_entropy(self.belief)
        if current_entropy < self.get_parameter('gamma_threshold').value:
            best_task_idx = np.argmax(self.belief)
            new_task = self.tasks[best_task_idx]
            
            if new_task != self.current_task:
                self.current_task = new_task
                msg = String()
                msg.data = self.current_task
                self.task_pub.publish(msg)
                self.get_logger().info(f"Committed to task: {self.current_task} (Entropy: {current_entropy:.4f})")

def main(args=None):
    rclpy.init(args=args)
    node = LCCLNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
```

Key Features:

· Asynchronous UDP receiver in a separate thread prevents blocking.
· Implements log-linear pooling with age-weighting (Section 3.4).
· Neighbor timeout and decay ensure robustness.
· Entropy-based commitment publishes task commands only when uncertainty is low.

6.6 Simulation World and Launch Configuration

To facilitate future simulation-based testing, the following world file defines task locations, and the launch script spawns multiple rovers with isolated namespaces.

World file (worlds/lccd_demo.world):

```xml
<?xml version="1.0" ?>
<sdf version="1.6">
  <world name="default">
    <include><uri>model://ground_plane</uri></include>
    <include><uri>model://sun</uri></include>

    <model name="task_explore_a">
      <static>true</static>
      <pose>5 5 0.1 0 0 0</pose>
      <link name="link">
        <visual name="visual">
          <geometry><cylinder><radius>0.5</radius><length>0.2</length></geometry></visual>
          <material><ambient>1 0 0 1</ambient></material>
        </visual>
      </link>
    </model>

    <model name="task_explore_b">
      <static>true</static>
      <pose>-5 -2 0.1 0 0 0</pose>
      <link name="link">
        <visual name="visual">
          <geometry><cylinder><radius>0.5</radius><length>0.2</length></geometry></visual>
          <material><ambient>0 0 1 1</ambient></material>
        </visual>
      </link>
    </model>
  </world>
</sdf>
```

ROS 2 Launch Script (swarm_launch.py):

```python
import os
from ament_index_python.packages import get_package_share_directory
from launch import LaunchDescription
from launch.actions import IncludeLaunchDescription, DeclareLaunchArgument
from launch.launch_description_sources import PythonLaunchDescriptionSource
from launch_ros.actions import Node

def generate_launch_description():
    pkg_gazebo_ros = get_package_share_directory('gazebo_ros')
    
    # Path to your custom LCCL node python file
    lccl_node_path = 'your_package_name' 

    # 1. Launch Gazebo with our custom world
    gazebo = IncludeLaunchDescription(
        PythonLaunchDescriptionSource(
            os.path.join(pkg_gazebo_ros, 'launch', 'gazebo.launch.py')
        ),
        launch_arguments={'world': './worlds/lccd_demo.world'}.items()
    )

    ld = LaunchDescription()
    ld.add_action(gazebo)

    # 2. Spawn 3 Rovers with Namespaces
    rover_positions = [
        {'name': 'rover_1', 'x': '0.0', 'y': '0.0'},
        {'name': 'rover_2', 'x': '1.0', 'y': '0.0'},
        {'name': 'rover_3', 'x': '0.0', 'y': '1.0'},
    ]

    for rover in rover_positions:
        namespace = rover['name']
        
        # LCCL Coordination Node per rover
        lccl_node = Node(
            package=lccl_node_path,
            executable='lccl_node', # The script we wrote earlier
            namespace=namespace,
            parameters=[{
                'rover_id': int(namespace.split('_')[1]),
                'udp_port': 12345,
                'gamma_threshold': 0.4
            }],
            output='screen'
        )
        
        # In a real setup, you would include your URDF spawning here
        
        ld.add_action(lccl_node)

    return ld
```

This launch configuration ensures each rover's LCCL node runs in its own namespace and can communicate via UDP broadcast. The simulation environment provides visual markers for tasks.

6.7 PHP Coordination Server (Optional)

A PHP server can log data and provide a dashboard. A minimal endpoint for receiving beliefs:

```php
<?php
// api/belief.php - receive belief POST from rovers

$db = new SQLite3('lccd_log.db');

// Create table if not exists
$db->exec("CREATE TABLE IF NOT EXISTS beliefs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    rover_id INTEGER,
    timestamp REAL,
    belief TEXT,
    energy REAL,
    position TEXT,
    received_at DATETIME DEFAULT CURRENT_TIMESTAMP
)");

$data = json_decode(file_get_contents('php://input'), true);

if ($data) {
    $stmt = $db->prepare("INSERT INTO beliefs (rover_id, timestamp, belief, energy, position) 
                          VALUES (:rid, :ts, :blf, :eng, :pos)");
    $stmt->bindValue(':rid', $data['rover_id'], SQLITE3_INTEGER);
    $stmt->bindValue(':ts', $data['timestamp'], SQLITE3_FLOAT);
    $stmt->bindValue(':blf', json_encode($data['belief']), SQLITE3_TEXT);
    $stmt->bindValue(':eng', $data['energy'], SQLITE3_FLOAT);
    $stmt->bindValue(':pos', json_encode($data['position'] ?? []), SQLITE3_TEXT);
    $stmt->execute();
    http_response_code(200);
    echo "OK";
} else {
    http_response_code(400);
    echo "Invalid data";
}
?>
```

A web dashboard can query the database and display real-time information. This server is optional and does not affect the distributed coordination.

6.8 Summary

This chapter provided a complete implementation blueprint for the LCCL, including software architecture, message formats, communication protocol, a full ROS 2 node implementation, simulation world and launch files, and an optional PHP coordination server. The design is ready for deployment on physical rovers or in simulation for future validation.

---

Chapter 7: Conclusion and Future Work

7.1 Summary of Contributions

We have presented a novel distributed coordination architecture for rover swarms that combines probabilistic belief representation, entropy minimization, and lightweight gossip consensus. The LCCL enables efficient task allocation under realistic communication constraints and energy limitations. The key contributions are:

1. Entropy-Based Coordination Metric (ECM) for monitoring and guiding swarm behavior.
2. Energy-Aware Probabilistic Task Allocation (EAPTA) balancing utility and energy.
3. Lightweight Graph-Based Consensus Protocol with age-weighting for robustness.
4. Asynchronous, low-bandwidth operation with belief compression.
5. Conflict resolution via repulsion to prevent task over-subscription.
6. Comprehensive theoretical framework, including convergence analysis.
7. Detailed implementation blueprint for practical deployment on low-cost hardware.

7.2 Future Work

Several directions remain open for further theoretical development and eventual validation:

· Adaptive Parameter Tuning: Develop online learning mechanisms to automatically adjust parameters ($\eta$, $\gamma$, $\beta$, $T_{\text{sys}}$) based on observed swarm dynamics.
· Heterogeneous Swarms: Extend the framework to rovers with different capabilities (e.g., sensing, manipulation) by incorporating capability vectors into the belief representation.
· Collaborative Tasks: Support tasks that require multiple rovers by extending the belief to joint assignments.
· Formal Convergence Proofs: Strengthen theoretical results for time-varying graphs and more general communication models.
· Security and Robustness: Investigate the impact of Byzantine faults where rovers may send false beliefs, and develop mitigation strategies.

By pursuing these directions, the LCCL can evolve into a practical, deployable solution for distributed coordination in autonomous robot swarms.


Appendix A: Convergence Analysis of the Distributed Probabilistic Consensus Algorithm

A.1 Problem Setup

Consider a swarm of $n$ rovers indexed by $i \in \mathcal{N} = \{1,\dots,n\}$. Each rover $i$ maintains a belief vector $b_i^{(k)} \in \Delta^{|\mathcal{T}|-1}$ at discrete iteration $k$, where $\Delta$ denotes the probability simplex over the task set $\mathcal{T}$. The rovers communicate over a time‑varying graph $G^{(k)} = (V, E^{(k)})$ with adjacency matrix $A^{(k)}$. Communication is unreliable: messages may be delayed or lost. To model this, each rover $i$ maintains a neighbor table containing the most recent belief received from each neighbor $j$, along with a timestamp $t_{ij}^{\text{last}}$ and a signal‑to‑noise ratio $\mathrm{SNR}_{ij}$. The effective weight assigned to neighbor $j$ at time $k$ is

w_{ij}^{(k)} = \mathrm{SNR}_{ij} \cdot e^{-\kappa (t_k - t_{ij}^{\text{last}})},

where $\kappa > 0$ is a decay constant and $t_k$ is the current time. If no message has been received from $j$ for more than a timeout $T_{\max}$, the neighbor is removed.

Let $\tilde{w}_{ij}^{(k)}$ be the normalized weight:

\tilde{w}_{ij}^{(k)} = \frac{w_{ij}^{(k)}}{\sum_{\ell \in \mathcal{N}_i^{(k)}} w_{i\ell}^{(k)}},

where $\mathcal{N}_i^{(k)}$ is the set of neighbors with valid recent messages. If $\mathcal{N}_i^{(k)} = \emptyset$, the update is skipped.

The Distributed Probabilistic Consensus (DPC) update is

\log b_i^{(k+1)} = (1-\eta)\log b_i^{(k)} + \eta \sum_{j \in \mathcal{N}_i^{(k)}} \tilde{w}_{ij}^{(k)} \log b_j^{(k)},

with $\eta \in (0,1)$ a learning rate. After the update, $b_i^{(k+1)}$ is renormalized to sum to $1$.

A.2 Assumptions

1. Connectivity: The expected graph $\bar{G} = (V, \bar{E})$ with edge weights $\bar{w}_{ij} = \mathbb{E}[\tilde{w}_{ij}^{(k)}]$ is connected. Its algebraic connectivity $\lambda_2$ (the second smallest eigenvalue of its Laplacian) is positive.
2. Doubly stochastic weights in expectation: For each $i$, $\sum_j \bar{w}_{ij} = 1$, and $\bar{w}_{ij} = \bar{w}_{ji}$.
3. Bounded variance: There exists $\sigma^2 < \infty$ such that for all $i$ and $k$,
   \mathbb{E}\left[\left\| \sum_j (\tilde{w}_{ij}^{(k)} - \bar{w}_{ij}) \log b_j^{(k)} \right\|^2 \right] \le \sigma^2.
   
   This bounds the perturbation caused by random delays and packet loss.
4. Bounded beliefs: All $b_i^{(k)}$ have components bounded away from zero, i.e., $b_i^{(k)}(\tau) \ge \varepsilon > 0$ for all $\tau$, ensuring logs are finite.

A.3 Preliminaries

Define the weighted geometric mean of the beliefs at iteration $k$ as the distribution $\bar{b}^{(k)}$ that minimizes $\sum_i \alpha_i D_{\mathrm{KL}}(b_i^{(k)} \parallel \bar{b})$ for some positive weights $\alpha_i$ (e.g., uniform). For simplicity, we take $\alpha_i = 1/n$, so $\bar{b}^{(k)}$ satisfies

\log \bar{b}^{(k)} = \frac{1}{n} \sum_i \log b_i^{(k)}.

Let $d_i^{(k)} = D_{\mathrm{KL}}(b_i^{(k)} \parallel \bar{b}^{(k)})$. The following lemma relates the evolution of $d_i^{(k)}$ under the consensus update.

Lemma 1 (Contraction property). For any $i$, under the expected dynamics (i.e., replacing $\tilde{w}_{ij}^{(k)}$ by $\bar{w}_{ij}$), we have

\mathbb{E}[d_i^{(k+1)} \mid \mathcal{F}_k] \le (1 - \eta \lambda_2) d_i^{(k)},

where $\mathcal{F}_k$ is the filtration up to time $k$.

Proof. Using the log‑linear update with deterministic weights $\bar{w}_{ij}$, one can show that the vector of log‑beliefs evolves as a linear system that contracts in the KL sense with factor $(1-\eta\lambda_2)$. This is a standard result in consensus theory; see e.g. [Nedić & Ozdaglar, 2009] for the scalar case and [Touri & Nedić, 2012] for extensions to probability distributions. The factor $\lambda_2$ arises from the mixing time of the graph. ∎

A.4 Main Theorem

Theorem 1 (Convergence with age‑weighting). Under the DPC update with age‑weighting and the assumptions above, for each rover $i$,

\mathbb{E}[d_i^{(k)}] \le (1 - \eta \lambda_2)^k d_i^{(0)} + \frac{\eta^2 \sigma^2}{\lambda_2}.

Proof. We analyze the one‑step expected change. From the update we have

\log b_i^{(k+1)} = (1-\eta)\log b_i^{(k)} + \eta \sum_j \bar{w}_{ij} \log b_j^{(k)} + \eta \sum_j (\tilde{w}_{ij}^{(k)} - \bar{w}_{ij}) \log b_j^{(k)}.

Define the ideal update without noise:

\log \hat{b}_i^{(k+1)} = (1-\eta)\log b_i^{(k)} + \eta \sum_j \bar{w}_{ij} \log b_j^{(k)}.

Then

\log b_i^{(k+1)} = \log \hat{b}_i^{(k+1)} + \eta \delta_i^{(k)},

where $\delta_i^{(k)} = \sum_j (\tilde{w}_{ij}^{(k)} - \bar{w}_{ij}) \log b_j^{(k)}$.

Now consider the KL divergence to the geometric mean $\bar{b}^{(k)}$. By the chain rule of KL divergence under the log‑linear pooling, we have

D_{\mathrm{KL}}(b_i^{(k+1)} \parallel \bar{b}^{(k)}) \le D_{\mathrm{KL}}(\hat{b}_i^{(k+1)} \parallel \bar{b}^{(k)}) + \eta \langle \nabla \log \hat{b}_i^{(k+1)}, \delta_i^{(k)} \rangle + \frac{\eta^2}{2} \|\delta_i^{(k)}\|^2,

where we used a second‑order Taylor expansion and the fact that the KL is convex in the log‑domain. Taking conditional expectation and using Lemma 1 for the first term, we get

\mathbb{E}[d_i^{(k+1)} \mid \mathcal{F}_k] \le (1 - \eta \lambda_2) d_i^{(k)} + \eta \mathbb{E}[\langle \nabla \log \hat{b}_i^{(k+1)}, \delta_i^{(k)} \rangle \mid \mathcal{F}_k] + \frac{\eta^2}{2} \mathbb{E}[\|\delta_i^{(k)}\|^2 \mid \mathcal{F}_k].

The cross term vanishes because $\mathbb{E}[\delta_i^{(k)} \mid \mathcal{F}_k] = 0$ by construction of the mean weights. The remaining term is bounded by $\eta^2 \sigma^2 / 2$ by assumption 3. Thus

\mathbb{E}[d_i^{(k+1)} \mid \mathcal{F}_k] \le (1 - \eta \lambda_2) d_i^{(k)} + \frac{\eta^2 \sigma^2}{2}.

Taking full expectation and iterating from $k=0$ yields

\mathbb{E}[d_i^{(k)}] \le (1 - \eta \lambda_2)^k d_i^{(0)} + \frac{\eta^2 \sigma^2}{2} \sum_{t=0}^{k-1} (1 - \eta \lambda_2)^t.

The geometric series sums to at most $\frac{1}{\eta \lambda_2}$, giving the stated bound. ∎

This theorem establishes exponential convergence to a neighborhood whose radius is proportional to the staleness variance $\sigma^2$. When communication is perfect ($\sigma^2=0$), we recover exact convergence to consensus.

---

Appendix B: Properties of Coordination Entropy and Graph Connectivity

B.1 Global Coordination Entropy

We defined the global coordination entropy as

H_c(t) \approx \frac{1}{n} \sum_{i=1}^n H(b_i(t)),

with $H(b_i) = -\sum_{\tau} b_i(\tau) \log b_i(\tau)$. This approximation is justified because if all beliefs are identical, $H_c$ equals the entropy of the common belief. When beliefs differ, $H_c$ overestimates the true conditional entropy, but it provides a useful measure of overall uncertainty.

B.2 Relation to Algebraic Connectivity

Consider a swarm with beliefs $b_i$. The average pairwise KL divergence among neighbors is

\Delta(t) = \frac{1}{|E(t)|} \sum_{(i,j)\in E(t)} D_{\mathrm{KL}}(b_i \parallel b_j).

A connected graph ensures that information can propagate. The algebraic connectivity $\lambda_2$ governs the speed of consensus: larger $\lambda_2$ implies faster mixing. In particular, from Theorem 1 we see that the decay factor is $(1-\eta\lambda_2)$. Thus $\lambda_2$ directly controls the rate of entropy reduction.

We can estimate $\lambda_2$ locally using the number of neighbors and the graph’s degree distribution. A simple heuristic is

\hat{\lambda}_2 \approx \frac{d_{\min}}{n},

where $d_{\min}$ is the minimum degree in the swarm. This is a crude estimate but suffices for adjusting the entropy threshold $\gamma$ as in Section 4.7.

B.3 Entropy Threshold Adaptation

The dynamic threshold $\gamma(t)$ is set as

\gamma(t) = \gamma_{\min} + (\gamma_{\max} - \gamma_{\min}) e^{-\rho \hat{\lambda}_2(t)}.

When $\hat{\lambda}_2$ is large (well‑connected), $\gamma$ approaches $\gamma_{\min}$, requiring low uncertainty before committing. When connectivity is poor, $\gamma$ increases, allowing rovers to act on less certain beliefs to avoid deadlock. The parameter $\rho$ controls sensitivity.

---

Appendix C: Derivation of Energy‑Aware Probabilistic Task Allocation from POMDP Principles

C.1 POMDP Formulation

Each rover faces a decentralized POMDP. The global state $s$ includes the positions of all rovers and the status of all tasks. Rover $i$ receives an observation $o_i$ (its local sensors and messages) and selects an action $a_i \in \mathcal{T}$ (which task to execute). The reward for taking action $a_i$ in global state $s$ is

R_i(s,a_i) = U(a_i) - C_{\text{energy}}(a_i, E_i),

where $U(a_i)$ is the utility of task $a_i$ (e.g., priority) and $C_{\text{energy}}$ is the energy cost, which depends on the rover’s energy $E_i$ and the distance to the task.

Because the global state is unknown, we replace it with the rover’s belief $b_i$ over task allocations. The expected reward given belief $b_i$ is

\mathbb{E}[R_i \mid b_i, a_i] = U(a_i) - C_{\text{energy}}(a_i, E_i).

Note that $b_i$ does not appear explicitly because the utility $U(a_i)$ is independent of the allocation; however, the belief influences future rewards through the consensus process.

C.2 Boltzmann Exploration

To balance exploration and exploitation, we use a softmax policy:

P_i(a_i) = \frac{\exp\big( \beta (U(a_i) - C_{\text{energy}}(a_i, E_i)) + (1-\beta) \log b_i(a_i) \big) / T_{\text{sys}}}{\sum_{\tau} \exp\big( \beta (U(\tau) - C_{\text{energy}}(\tau, E_i)) + (1-\beta) \log b_i(\tau) \big) / T_{\text{sys}}}.

The term $\log b_i(a_i)$ acts as a prior encouraging actions that are already believed to be assigned (or available). The parameter $\beta$ interpolates between relying on the belief ($\beta=0$) and relying solely on utility and energy ($\beta=1$). The temperature $T_{\text{sys}}$ controls randomness: high $T$ leads to more exploration.

C.3 Energy Cost

The energy cost is modeled as

C_{\text{energy}}(a_i, E_i) = \alpha \cdot \frac{d(a_i)}{E_i + \epsilon},

where $d(a_i)$ is the estimated distance to the task, $\alpha$ is a scaling factor, and $\epsilon$ prevents division by zero. When $E_i < E_{\mathrm{crit}}$, we set $C_{\text{energy}} = \infty$ for all non‑charging tasks, forcing the rover to return to charge.

This form encourages rovers with low energy to prefer nearby tasks and eventually recharge.

---

Appendix D: Proof that Log‑Linear Pooling Minimizes Weighted KL Divergence

D.1 Statement

Given a set of probability distributions $p_1,\dots,p_m$ and non‑negative weights $\lambda_j$ summing to $1$, the distribution $q$ that minimizes the weighted sum of KL divergences

\sum_j \lambda_j D_{\mathrm{KL}}(p_j \parallel q)

is given by the geometric mean:

q(\tau) \propto \prod_j p_j(\tau)^{\lambda_j}.

D.2 Proof

We minimize $F(q) = \sum_j \lambda_j \sum_\tau p_j(\tau) \log \frac{p_j(\tau)}{q(\tau)}$ subject to $\sum_\tau q(\tau)=1$, $q(\tau) \ge 0$.

Ignoring constants independent of $q$, we need to minimize

G(q) = -\sum_j \lambda_j \sum_\tau p_j(\tau) \log q(\tau) = -\sum_\tau \left( \sum_j \lambda_j p_j(\tau) \right) \log q(\tau).

This is the cross‑entropy between the mixture $\bar{p}(\tau) = \sum_j \lambda_j p_j(\tau)$ and $q$. The cross‑entropy is minimized when $q = \bar{p}$, but here we have a product form, not a mixture. Wait – we must be careful: the expression $-\sum_\tau \bar{p}(\tau) \log q(\tau)$ is minimized when $q = \bar{p}$, but that’s for a mixture. However our $G(q)$ has $\sum_j \lambda_j p_j(\tau)$ inside the log, which is not the same as the mixture. Let’s re‑derive correctly.

Actually, the weighted sum of KL divergences is

\sum_j \lambda_j D_{\mathrm{KL}}(p_j \parallel q) = \sum_j \lambda_j \sum_\tau p_j(\tau) \log \frac{p_j(\tau)}{q(\tau)} = \sum_\tau \left( \sum_j \lambda_j p_j(\tau) \log p_j(\tau) \right) - \sum_\tau \left( \sum_j \lambda_j p_j(\tau) \right) \log q(\tau).

The first term is independent of $q$. Thus minimizing over $q$ is equivalent to maximizing $\sum_\tau \bar{p}(\tau) \log q(\tau)$ where $\bar{p}(\tau) = \sum_j \lambda_j p_j(\tau)$. This is exactly the cross‑entropy maximization, which is maximized when $q = \bar{p}$ – i.e., the mixture, not the geometric mean. So why do we claim the geometric mean?

The confusion arises because the standard log‑linear pooling arises from minimizing the weighted sum of reverse KL divergences $D_{\mathrm{KL}}(q \parallel p_j)$. Let’s check that.

If we instead minimize $\sum_j \lambda_j D_{\mathrm{KL}}(q \parallel p_j)$, we have

\sum_j \lambda_j \sum_\tau q(\tau) \log \frac{q(\tau)}{p_j(\tau)} = \sum_\tau q(\tau) \log q(\tau) - \sum_\tau q(\tau) \left( \sum_j \lambda_j \log p_j(\tau) \right).

Using Lagrange multiplier for $\sum q(\tau)=1$, the optimal $q$ satisfies

\log q(\tau) + 1 - \left( \sum_j \lambda_j \log p_j(\tau) \right) - \mu = 0,

so $q(\tau) \propto \exp\left( \sum_j \lambda_j \log p_j(\tau) \right) = \prod_j p_j(\tau)^{\lambda_j}$.

Thus the log‑linear pooling (geometric mean) minimizes the weighted sum of reverse KL divergences. In our consensus update, we use the forward or reverse? The update $\log b_i^{\text{new}} = (1-\eta)\log b_i + \eta \sum \tilde{w} \log b_j$ is precisely a geometric mean of the current belief and the neighbors’ beliefs. This corresponds to minimizing a weighted sum of reverse KL divergences from the new belief to the old ones. This is a sensible consensus objective because it seeks a distribution that is close to all neighbors in the reverse KL sense, which encourages agreement.

Therefore, the DPC update is justified as a distributed optimization step that reduces disagreement.

---

Appendix E: Algebraic Connectivity Estimation from Local Neighbor Counts

E.1 Motivation

In a distributed setting, no rover knows the full graph Laplacian. However, for the adaptive threshold $\gamma$, we need a local estimate $\hat{\lambda}_2$ of the algebraic connectivity.

E.2 Heuristic Estimate

A well‑known bound relates $\lambda_2$ to the minimum degree:

\lambda_2 \le \frac{n}{n-1} d_{\min}.

Conversely, for many random graphs, $\lambda_2$ grows with the average degree. A simple local proxy is

\hat{\lambda}_2 = \frac{|\mathcal{N}_i|}{n},

where $|\mathcal{N}_i|$ is the number of neighbors of rover $i$. This is a crude estimate but captures the idea that more neighbors imply better connectivity. For a swarm of size $n$, the maximum possible $\lambda_2$ is $n$ (complete graph), so $|\mathcal{N}_i|/n$ lies in $[0,1]$.

E.3 Smoothing

To avoid rapid fluctuations, we use an exponential moving average:

\bar{\lambda}_2(t) = (1-\alpha) \bar{\lambda}_2(t-1) + \alpha \frac{|\mathcal{N}_i(t)|}{n},

with $\alpha \in (0,1)$. This smoothed value is used in the entropy threshold formula.

