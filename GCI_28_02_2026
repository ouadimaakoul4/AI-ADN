GeoCognitive Intelligence: A Unified Mathematical Framework for Self-Optimizing, Explainable, and Resilient Artificial General Intelligence


Author: Ouadi Maakoul


Abstract

This dissertation presents GeoCognitive Intelligence (GCI), a unified mathematical framework for Artificial General Intelligence that synthesizes four theoretical research programs: (i) brain‑inspired adaptive capsule networks with structural plasticity, (ii) archive‑based multimodal reasoning with causal grounding, (iii) categorical meta‑cognitive architectures with triune cognition, and (iv) self‑optimizing multi‑agent coordination with evolutionary dynamics.

The central thesis is that genuine intelligence—characterized by resilience, adaptability, understanding, and explainability—can be formally characterized through the geometric structure of cognitive processes coordinated through adjoint functors, grounded in causal evidence, and evolved through manifold‑based dynamics.

GCI introduces five core theoretical contributions:

1. The GeoCognitive Manifold: A Riemannian structure where cognitive states (capsules, concepts, agents) reside, with the Fisher information metric encoding representational sensitivity and geodesic distances measuring conceptual similarity. Precise statistical interpretations are provided for both capsule observation models and agent policy distributions.
2. The Triune Adjunction Monad: A categorical framework (CR ⇄ Mii ⇄ SP) with precise definitions for objects and morphisms in each category. We prove the existence of adjoint functors $F \dashv G$ and $P \dashv Q$ satisfying triangle identities, ensuring coherent bidirectional translation between conscious reasoning, subconscious intuition, and meta‑cognitive interpretation.
3. Archive‑Grounded Causal Semantics: An explicit construction of the archive sheaf on the site of temporal problems (intervals), with locality and gluing conditions ensuring global coherence. We prove that local reasoning steps based on archival evidence extend uniquely to globally consistent interpretations.
4. Dynamic Hierarchical Evolutionary Coordination: A game‑theoretic multi‑agent orchestration framework where agent teams form via Information Bottleneck selection and evolve via coupled stochastic differential equations. We prove convergence to Nash equilibria under mean‑field limits and cooling schedules, referencing McKean–Vlasov processes.
5. Axiomatic Explainability via Hierarchical Owen Values: A computationally feasible attribution method with proven error bounds for gradient approximations. We establish quantitative bounds for the deviation between gradient‑based attribution and true Owen values based on the smoothness of the value function.

The framework is grounded in differential geometry, category theory, information geometry, non‑equilibrium thermodynamics, and cooperative game theory. All core theorems are stated with complete proofs in the appendices. Key categorical properties are formalized in Lean 4 for machine‑checked verification, with a refined scope separating abstract categorical proofs from neural approximation guarantees.

GCI provides a theoretical foundation for understanding intelligence as a geometric‑categorical phenomenon and specifies architectural requirements for AGI systems that are resilient, adaptive, interpretable, and aligned with human values. The mathematical framework is released as open‑source formalizations to accelerate research in mathematically grounded artificial intelligence.

---

Chapter 1: Introduction and Motivation

1.1 The AGI Challenge: Beyond Pattern Matching

The pursuit of Artificial General Intelligence remains a defining challenge of 21st‑century computer science and mathematics. While contemporary AI systems demonstrate remarkable capabilities in narrow domains—language modeling, computer vision, game playing—they fundamentally lack formal characterizations of the hallmarks of genuine intelligence:

· Resilience: The capacity to maintain function under perturbation, damage, or distribution shift.
· Adaptability: The ability to reorganize structure and strategy in response to novel tasks.
· Understanding: Grounded causal reasoning rather than statistical correlation.
· Explainability: Transparent attribution of decisions to interpretable components.
· Self‑improvement: Recursive application of cognitive strategies to cognition itself.

Current approaches largely pursue brute‑force scaling: more parameters, more data, more compute. While this yields incremental improvements, theoretical analysis suggests diminishing returns and fundamental limitations in opacity, brittleness, and energy consumption. This dissertation proposes that the future of AGI lies not in scaling monolithic models, but in architectures whose structure reflects the mathematical principles of intelligence itself.

1.2 Four Complementary Research Programs

This dissertation synthesizes four theoretical research programs, each addressing a critical dimension of intelligent systems:

Framework Core Insight Limitation Addressed
Adaptive Capsules Functional units with vector outputs enable rich part‑whole reasoning and structural plasticity via Hebbian/STDP rules. Static architectures lack dynamic self‑repair and functional redistribution after damage.
Archive‑Based AGI Historical archives provide causal ground truth with temporal density, provenance structure, and multimodal integration. Web‑scale data lacks temporal coherence, provenance tracking, and causal grounding.
Mii Meta‑Cognition Triune cognition (conscious/subconscious/meta) formalized as adjoint functors enables recursive self‑improvement with fixed‑point convergence. Shallow neuro‑symbolic hybrids lack genuine mutual adaptation and meta‑awareness.
DHEAF Coordination Multi‑agent systems coordinated via game theory, information bottleneck, and evolutionary dynamics scale intelligence efficiently with Owen‑value explainability. Ad‑hoc multi‑agent systems lack formal coordination guarantees and explainability.

Individually, each framework advances the theoretical state of the art. Together, they form a coherent whole: capsules provide the atomic cognitive units; archives provide the epistemic substrate; Mii provides the cognitive architecture; and DHEAF provides the orchestration framework for scaling.

1.3 The GeoCognitive Synthesis

The unifying insight of this dissertation is that intelligence is geometric: cognitive processes unfold on manifolds whose structure encodes representational relationships, learning dynamics, and coordination constraints. This geometric perspective enables:

· Unified representation: Capsules, concepts, and agents all reside on the GeoCognitive Manifold $\mathcal{M}$, with the Fisher information metric providing a common notion of distance and similarity.
· Coherent translation: Adjoint functors between cognitive levels ensure that insights flow bidirectionally without loss of meaning, with triangle identities guaranteeing coherence.
· Causal grounding: Sheaf‑theoretic semantics guarantee that local reasoning steps compose to globally consistent understanding.
· Efficient coordination: Geodesic flow on the agent manifold minimizes conflict and maximizes synergistic output.
· Provable safety: Formal verification of categorical properties ensures alignment and robustness.

1.4 Thesis Statement

This dissertation advances the hypothesis that Artificial General Intelligence requires a geometric‑categorical architecture that integrates:

1. Vector‑based functional units with structural plasticity (adaptive capsules with Hebbian/STDP rules and entropy‑based generation);
2. Causally grounded historical evidence (archive sheaves with provenance weighting and consistency conditions);
3. Triune meta‑cognitive translation (Mii adjunctions with fixed‑point convergence and insight detection);
4. Self‑optimizing multi‑agent coordination (DHEAF dynamics with Information Bottleneck selection and Owen‑value attribution).

We demonstrate that such an architecture admits rigorous mathematical treatment—including completeness theorems, fixed‑point convergence guarantees, and axiomatic explainability—and we provide formal specifications for implementation.

1.5 Contributions

The original contributions of this dissertation are purely theoretical:

Theoretical Contributions

1. The GeoCognitive Manifold: A Riemannian structure unifying capsules, concepts, and agents with Fisher metric and geodesic semantics, including explicit statistical interpretations for both capsule observation models and agent policy distributions.
2. The Triune Adjunction Monad: Categorical formalization of meta‑cognition with precise definitions of the categories CR, SP, and Mii, and proof of adjoint functors $F\dashv G$ and $P\dashv Q$ satisfying triangle identities, ensuring coherent bidirectional translation.
3. Archive Sheaf Semantics: Explicit construction of the archive sheaf on the site of temporal problems, with locality and gluing conditions proven to guarantee global coherence of causal reasoning.
4. Geodesic Coordination Theorem: Optimal multi‑agent collaboration characterized as geodesic flow under the Global Coordination Lagrangian, with convergence to Nash equilibria proven via mean‑field limits and simulated annealing on manifolds.
5. Hierarchical Owen Values with Error Bounds: Axiomatic explainability for large‑scale cognitive systems, including polynomial‑time computation bounds and quantitative error bounds for gradient‑based approximations in terms of the smoothness of the value function.

Formal Specifications

1. GeoCognitive Runtime Specification: A formal specification for memory‑safe concurrency, event‑sourced persistence, and differentiable components.
2. Adaptive Capsule Specification: Formal definition of vector capsules with Hebbian/STDP plasticity and entropy‑based generation.
3. Archive Ingestion Specification: Multimodal encoder with provenance‑weighted learning and causal consistency constraints.
4. Mii Orchestrator Specification: Category‑theoretic meta‑controller with differentiable adjunctions and insight detection.
5. DHEAF Coordinator Specification: Distributed multi‑agent system with sparse routing, evolutionary arena, and Owen‑value attribution.

Formal Verification

1. Machine‑checked proofs of adjunction laws in Lean 4.
2. Machine‑checked proofs of monad laws for the Mii monad.
3. Machine‑checked proofs of safety invariant preservation.
4. Complete proof appendix for all 25+ theorems stated in the dissertation.

1.6 Reader's Guide

This dissertation is organized for readers with backgrounds in mathematics, computer science, and AI theory:

· Chapters 2–4 establish the mathematical foundations: category theory, information geometry, non‑equilibrium thermodynamics, and stochastic dynamics. These chapters contain complete definitions and preliminary results.
· Chapters 5–7 present the formal specification of the GCI architecture: mathematical structures, algorithm specifications, and verification interfaces. These chapters include formal pseudocode and specification details.
· Chapter 8 provides theoretical analysis: convergence guarantees, complexity bounds, expressivity results, and limitation characterizations.
· Chapter 9 discusses implications for AGI theory, ethics, and future research directions.
· Chapter 10 concludes with a summary and roadmap for future work.
· Appendices contain detailed proofs (Appendix D), complete Lean 4 formalizations (Appendix E), formal specification details (Appendix F), and glossaries (Appendix H).

To assist readers, a summary of the main mathematical notation is provided at the beginning of Chapter 2. All theorems, definitions, and algorithms are numbered by chapter for easy cross‑referencing. The dissertation is self‑contained; readers unfamiliar with category theory or information geometry may consult the relevant appendices as needed.

Chapter 2: Literature Review: Mathematical Foundations of AI

2.1 Adaptive Neural Architectures

2.1.1 Capsule Networks: From Scalar to Vector Representations

Traditional convolutional neural networks (CNNs) represent features as scalar activations, losing critical information about spatial relationships and part-whole hierarchies. Hinton et al. (2018) introduced capsule networks to address this fundamental limitation. A capsule is a group of neurons whose output vector $\mathbf{u}_c \in \mathbb{R}^d$ encodes both the presence of an entity (via its norm) and its properties (via its orientation).

Definition 2.1.1 (Capsule). A capsule $c$ is a computational unit defined by:

· An output vector $\mathbf{u}_c = \|\mathbf{u}_c\| \cdot \hat{\mathbf{u}}_c$, where $\|\mathbf{u}_c\| \in [0,1]$ represents the probability of entity existence and $\hat{\mathbf{u}}_c$ encodes instantiation parameters (pose, scale, orientation).
· A transformation matrix $\mathbf{W}_{ij}$ that maps child capsule outputs to predictions for parent capsules.
· A routing mechanism that iteratively refines coupling coefficients $c_{ij}$ between capsules.

The dynamic routing algorithm iteratively updates coupling coefficients based on agreement:

b_{ij} \leftarrow b_{ij} + \mathbf{v}_j \cdot \hat{\mathbf{u}}_{j|i}

where $\hat{\mathbf{u}}_{j|i} = \mathbf{W}_{ij}\mathbf{u}_i$ is the prediction vector and $\mathbf{v}_j$ is the parent capsule output. Yang et al. (2025) proved convergence of dynamic routing under Lipschitz continuity assumptions.

Theorem 2.1.1 (Routing Convergence). Under the update rule above with coupling coefficients normalized via softmax, the routing procedure converges to a fixed point at a linear rate when the agreement function is contractive.

Proof Sketch. The routing algorithm defines a fixed-point iteration $c^{(t+1)} = T(c^{(t)})$ where $T$ is a contraction mapping under suitable conditions. The Banach fixed-point theorem guarantees convergence to a unique fixed point. ∎

2.1.2 Evolving Network Topologies

NeuroEvolution of Augmenting Topologies (NEAT) (Stanley & Miikkulainen, 2002) introduced genetic algorithms for evolving both network weights and architectures. NEAT addresses three key challenges:

1. Tracking genes through historical markings to enable crossover between different topologies.
2. Protecting structural innovation through speciation.
3. Starting from minimal initial structures and complexity.

HyperNEAT (Stanley et al., 2009) extended this to evolve generative encodings of connectivity patterns, enabling the evolution of large-scale networks with regular structure.

2.1.3 Modular Architectures and Mixture of Experts

Mixture of Experts (MoE) (Shazeer et al., 2017) scales model capacity by routing inputs to specialized sub-networks:

\mathbf{y} = \sum_{i=1}^n g_i(\mathbf{x}) \cdot \mathbf{e}_i(\mathbf{x})

where $g_i(\mathbf{x})$ is a gating network output (typically softmax) and $\mathbf{e}_i(\mathbf{x})$ is the output of expert $i$. The gating network learns to assign inputs to the most appropriate experts, enabling conditional computation.

2.2 Causal and Archive-Based Learning

2.2.1 Causal Representation Learning

Schölkopf et al. (2021) formalized the problem of learning causal representations from observational data:

Definition 2.2.1 (Causal Representation Learning). Given observations $\mathbf{x} \in \mathcal{X}$ generated by latent variables $\mathbf{z} \in \mathcal{Z}$ with causal structure $\mathcal{G}$, learn:

· An encoder $f: \mathcal{X} \to \mathcal{Z}$ that recovers latent variables
· A structural causal model (SCM) describing the generative process

The identifiability of such representations requires assumptions about the causal graph and intervention capabilities.

2.2.2 Temporal Dynamics Modeling

Neural Ordinary Differential Equations (Neural ODEs) (Chen et al., 2018) model continuous-time dynamics:

\frac{d\mathbf{h}(t)}{dt} = f_\theta(\mathbf{h}(t), t)

The solution at time $T$ is obtained via numerical integration: $\mathbf{h}(T) = \mathbf{h}(0) + \int_0^T f_\theta(\mathbf{h}(t), t) dt$.

Neural Stochastic Differential Equations (Neural SDEs) (Tzen & Raginsky, 2019; Li et al., 2020) incorporate noise:

d\mathbf{h}_t = \mu_\theta(\mathbf{h}_t, t) dt + \sigma_\theta(\mathbf{h}_t, t) dW_t

The Fokker-Planck equation governs the evolution of the probability density $\rho(\mathbf{h}, t)$:

\partial_t \rho = -\nabla \cdot (\mu \rho) + \frac{1}{2} \nabla \nabla : (\sigma\sigma^\top \rho)

2.2.3 Memory-Augmented Networks

Differentiable Neural Computers (DNC) (Graves et al., 2016) augment neural networks with external memory matrices that can be read from and written to via differentiable attention mechanisms. The memory $\mathbf{M}_t \in \mathbb{R}^{N \times M}$ evolves as:

\mathbf{M}_t = \mathbf{M}_{t-1} \circ (\mathbf{1} - \mathbf{w}_t^w \mathbf{e}_t^\top) + \mathbf{w}_t^w \mathbf{v}_t^\top

where $\mathbf{w}_t^w$ is a write weighting, $\mathbf{e}_t$ is an erase vector, and $\mathbf{v}_t$ is a write vector.

2.3 Meta-Cognitive and Categorical AI

2.3.1 Classical Cognitive Architectures

ACT-R (Adaptive Control of Thought—Rational) (Anderson, 1983, 2007) models cognition through:

· Declarative memory: chunks with activation levels $A_i = B_i + \sum_j W_j S_{ji}$
· Procedural memory: production rules with utility $U_i = P_i G - C_i$
· Buffers: interfaces between modules

SOAR (State, Operator And Result) (Laird, 2012; Laird et al., 1987) emphasizes:

· Problem spaces as search in state spaces
· Operators as transformations between states
· Impasses triggering subgoaling and learning

2.3.2 Category Theory in Machine Learning

Definition 2.3.1 (Category). A category $\mathcal{C}$ consists of:

· A collection $\text{Ob}(\mathcal{C})$ of objects
· For each $A,B \in \text{Ob}(\mathcal{C})$, a set $\text{Hom}_{\mathcal{C}}(A,B)$ of morphisms
· Composition $\circ: \text{Hom}_{\mathcal{C}}(B,C) \times \text{Hom}_{\mathcal{C}}(A,B) \to \text{Hom}_{\mathcal{C}}(A,C)$
· Identity morphisms $\text{id}_A \in \text{Hom}_{\mathcal{C}}(A,A)$

satisfying associativity and identity laws.

Definition 2.3.2 (Functor). A functor $F: \mathcal{C} \to \mathcal{D}$ maps objects $A \mapsto F(A)$ and morphisms $f: A \to B$ to $F(f): F(A) \to F(B)$ preserving composition and identities.

Definition 2.3.3 (Adjunction). An adjunction $F \dashv G$ consists of functors $F: \mathcal{C} \to \mathcal{D}$, $G: \mathcal{D} \to \mathcal{C}$ with natural transformations:

· Unit $\eta: \text{id}_{\mathcal{C}} \Rightarrow G \circ F$
· Counit $\varepsilon: F \circ G \Rightarrow \text{id}_{\mathcal{D}}$

satisfying the triangle identities:

\varepsilon_{F(A)} \circ F(\eta_A) = \text{id}_{F(A)}


G(\varepsilon_B) \circ \eta_{G(B)} = \text{id}_{G(B)}

Fong et al. (2019) applied categorical methods to deep learning, showing that neural network architectures can be formalized as string diagrams in monoidal categories.

Definition 2.3.4 (Monad). A monad $(T, \eta, \mu)$ on a category $\mathcal{C}$ consists of:

· An endofunctor $T: \mathcal{C} \to \mathcal{C}$
· A unit natural transformation $\eta: \text{id}_{\mathcal{C}} \Rightarrow T$
· A multiplication natural transformation $\mu: T^2 \Rightarrow T$

satisfying:

· $\mu \circ T\eta = \text{id}_T = \mu \circ \eta T$ (unit laws)
· $\mu \circ T\mu = \mu \circ \mu T$ (associativity)

Definition 2.3.5 (Sheaf). Let $(\mathcal{X}, J)$ be a site (category with Grothendieck topology). A presheaf $F: \mathcal{X}^{\text{op}} \to \mathbf{Set}$ is a sheaf if for every covering family $\{U_i \to U\}$:

1. Locality: If $s,t \in F(U)$ have equal restrictions $s|_{U_i} = t|_{U_i}$ for all $i$, then $s = t$.
2. Gluing: Given compatible sections $s_i \in F(U_i)$ (i.e., $s_i|_{U_i \cap U_j} = s_j|_{U_i \cap U_j}$), there exists a unique $s \in F(U)$ with $s|_{U_i} = s_i$.

2.3.3 Neuro-Symbolic Integration

DeepProbLog (Manhaeve et al., 2018) integrates neural networks with probabilistic logic programming:

P(Q|\mathbf{x}) = \sum_{\mathbf{y}} P(\mathbf{y}|\mathbf{x}) \cdot [Q \text{ is true given } \mathbf{y}]

where $P(\mathbf{y}|\mathbf{x})$ is provided by neural networks and the logical constraint is evaluated by a probabilistic logic engine.

2.4 Multi-Agent Coordination and Evolution

2.4.1 Game-Theoretic Foundations

Definition 2.4.1 (Cooperative Game). A cooperative game with transferable utility is a pair $(N, v)$ where $N = \{1,\dots,n\}$ is the set of players and $v: 2^N \to \mathbb{R}$ is a characteristic function with $v(\emptyset) = 0$.

Definition 2.4.2 (Shapley Value). The Shapley value (Shapley, 1953) attributes to player $i$:

\phi_i(v) = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(n-|S|-1)!}{n!} (v(S \cup \{i\}) - v(S))

Theorem 2.4.1 (Shapley Uniqueness). The Shapley value is the unique attribution satisfying:

1. Efficiency: $\sum_{i \in N} \phi_i(v) = v(N)$
2. Symmetry: If $v(S \cup \{i\}) = v(S \cup \{j\})$ for all $S \subseteq N \setminus \{i,j\}$, then $\phi_i(v) = \phi_j(v)$
3. Dummy player: If $v(S \cup \{i\}) = v(S)$ for all $S \subseteq N \setminus \{i\}$, then $\phi_i(v) = 0$
4. Additivity: $\phi(v + w) = \phi(v) + \phi(w)$

Definition 2.4.3 (Coalition Structure). A coalition structure is a partition $\mathcal{C} = \{C_1, \dots, C_m\}$ of $N$ into disjoint coalitions.

Definition 2.4.4 (Owen Value). For a game $(N,v)$ with coalition structure $\mathcal{C}$, the Owen value (Owen, 1977) for player $i \in C_k$ is:

\psi_i = \frac{1}{m} \sum_{S \subseteq \mathcal{C} \setminus \{C_k\}} \frac{1}{n_k} \sum_{T \subseteq C_k \setminus \{i\}} \frac{v(Q_S \cup T \cup \{i\}) - v(Q_S \cup T)}{\binom{n_k-1}{|T|}}

where $Q_S = \bigcup_{C_j \in S} C_j$.

2.4.2 Evolutionary Dynamics

Definition 2.4.5 (Replicator Dynamics). In a population with $n$ types having frequencies $x_i$ and fitness $f_i(x)$, the replicator dynamics are:

\dot{x}_i = x_i(f_i(x) - \bar{f}(x))

where $\bar{f}(x) = \sum_j x_j f_j(x)$.

Definition 2.4.6 (Fokker-Planck Equation). For a stochastic process $dX_t = \mu(X_t)dt + \sigma(X_t)dW_t$, the probability density $\rho(x,t)$ evolves as:

\frac{\partial \rho}{\partial t} = -\sum_i \frac{\partial}{\partial x^i}(\mu^i \rho) + \frac{1}{2} \sum_{i,j} \frac{\partial^2}{\partial x^i \partial x^j}((\sigma\sigma^\top)^{ij} \rho)

2.5 Information Geometry and Statistical Manifolds

2.5.1 Fisher Information Metric

Definition 2.5.1 (Fisher Information Matrix). For a parametric family $p(x|\theta)$, the Fisher information matrix is:

g_{ij}(\theta) = \mathbb{E}_{p(x|\theta)}\left[\frac{\partial \log p(x|\theta)}{\partial \theta^i} \frac{\partial \log p(x|\theta)}{\partial \theta^j}\right]

Theorem 2.5.1 (Chentsov's Uniqueness). The Fisher information metric is the unique Riemannian metric (up to scaling) on the simplex of probability distributions that is invariant under sufficient statistics.

Definition 2.5.2 (Natural Gradient). The natural gradient (Amari, 1998) is the steepest descent direction on the statistical manifold:

\tilde{\nabla} L(\theta) = G(\theta)^{-1} \nabla L(\theta)

Proposition 2.5.1 (Natural Gradient Properties). The natural gradient is invariant under reparameterization of the model and follows the geodesics of the Fisher metric in the limit of small step sizes.

Proof Sketch. Under a change of coordinates $\theta \mapsto \tilde{\theta}$, the Fisher metric transforms as $\tilde{g} = J^{-\top} g J^{-1}$, where $J$ is the Jacobian. The natural gradient transforms as $\tilde{\nabla} = J \tilde{\nabla}$, maintaining consistency. The geodesic property follows from the fact that natural gradient descent approximates the solution to $\frac{d\theta}{dt} = -G(\theta)^{-1}\nabla L(\theta)$. ∎

2.5.2 Geodesic Distance

Definition 2.5.3 (Geodesic Distance). For a Riemannian manifold $(\mathcal{M}, g)$, the geodesic distance between points $p,q \in \mathcal{M}$ is:

d_g(p,q) = \inf_{\gamma(0)=p, \gamma(1)=q} \int_0^1 \sqrt{g_{\gamma(t)}(\dot{\gamma}(t), \dot{\gamma}(t))} dt

The geodesic equations are:

\ddot{\gamma}^k + \Gamma_{ij}^k \dot{\gamma}^i \dot{\gamma}^j = 0

where $\Gamma_{ij}^k$ are the Christoffel symbols of the Levi-Civita connection.

2.6 Non-Equilibrium Thermodynamics and Maximum Caliber

2.6.1 Maximum Entropy Principle

Jaynes (1957) formulated statistical mechanics as inference: given constraints $\mathbb{E}[f_k] = \bar{f}_k$, the least biased distribution maximizes Shannon entropy:

p(x) = \frac{1}{Z} \exp\left(-\sum_k \lambda_k f_k(x)\right)

where $Z = \int \exp(-\sum_k \lambda_k f_k(x)) dx$ and Lagrange multipliers $\lambda_k$ enforce constraints.

2.6.2 Maximum Caliber Principle

Definition 2.6.1 (Path Entropy). For paths $\Gamma$ over time interval $[0,T]$, the path entropy is:

S[\rho] = -\int \mathcal{D}\Gamma \, \rho[\Gamma] \log \rho[\Gamma]

The Maximum Caliber principle (Jaynes, 1980; González & Davis, 2017) selects the path distribution maximizing $S[\rho]$ subject to constraints on path functionals $\mathbb{E}[g_m(\Gamma)] = \bar{g}_m$:

\rho[\Gamma] = \frac{1}{\mathcal{Z}} \exp\left(-\sum_m \gamma_m g_m(\Gamma)\right)

Theorem 2.6.1 (Jarzynski Equality). For a system driven from equilibrium state $A$ to $B$ with work $W[\Gamma]$ along path $\Gamma$:

\langle e^{-\beta W}\rangle = e^{-\beta \Delta F}

where $\Delta F = F_B - F_A$ is the free energy difference.

Proof Sketch (González & Davis, 2017). From the Maximum Caliber principle, the path distribution is $\rho[\Gamma] \propto e^{-\beta W[\Gamma]} \rho_A(\Gamma_0)$, where $\rho_A$ is the equilibrium distribution at initial state. Marginalizing over paths yields the result. ∎

2.6.3 Stochastic Thermodynamics

For a system described by state $x$ evolving via $dx = \mu(x)dt + \sigma(x)dW$, the entropy production rate satisfies:

\dot{S}_{\text{total}} = \int \rho(x,t) \left( \mu(x) - \frac{\sigma^2}{2} \frac{\partial \log \rho}{\partial x} \right)^2 dx \geq 0

2.7 Stochastic Dynamics on Riemannian Manifolds

2.7.1 Brownian Motion on Manifolds

Definition 2.7.1 (Laplace-Beltrami Operator). On a Riemannian manifold $(\mathcal{M}, g)$, the Laplace-Beltrami operator acting on functions $f$ is:

\Delta_{\text{LB}} f = \frac{1}{\sqrt{\det g}} \partial_i \left( \sqrt{\det g} \, g^{ij} \partial_j f \right)

Definition 2.7.2 (Brownian Motion). Brownian motion on $\mathcal{M}$ is a diffusion process with generator $\frac{1}{2}\Delta_{\text{LB}}$.

2.7.2 Covariant Langevin Equation

Diósi (2024) derived the covariant form of the Langevin equation on Riemannian manifolds:

dx^a = e^a_A \circ dW^A + V^a dt

where $\circ$ denotes Stratonovich integration, $e^a_A$ is a vielbein satisfying $e^a_A e^b_B \delta^{AB} = g^{ab}$, and the covariant constraint requires $\nabla_a e^a_A = 0$.

Theorem 2.7.1 (Covariant Fokker-Planck Equation). The probability density $\rho$ on $\mathcal{M}$ evolves as:

\frac{\partial \rho}{\partial t} = -\nabla_a(\rho V^a) + \frac{1}{2} \Delta_{\text{LB}} \rho

Proof Sketch. This follows from the covariant Langevin equation using Itô's lemma and the Stratonovich-to-Itô conversion, accounting for the Riemannian curvature through the Laplace-Beltrami operator. ∎

2.8 Comparison and Synthesis

2.8.1 Gaps in Current Literature

Research Area Key Results Limitations Addressed by GCI
Capsule Networks Vector representations, dynamic routing No structural plasticity or meta-cognitive control
Causal Learning Identifiability, intervention Lacks temporal coherence and archival grounding
Cognitive Architectures Psychological modeling No formal verification or geometric foundation
Multi-Agent Systems Equilibrium concepts Lacks explainable attribution and manifold coordination

2.8.2 Toward a Unified Framework

GeoCognitive Intelligence synthesizes these mathematical foundations by:

1. Unifying representations via the GeoCognitive Manifold with Fisher metric
2. Formalizing meta-cognition through adjoint functors and sheaf theory
3. Grounding reasoning in archival evidence with causal constraints
4. Optimizing coordination via geodesic flow and evolutionary dynamics
5. Ensuring explainability through axiomatic Owen values

Chapter 3: Unified Theoretical Framework: The GeoCognitive Manifold

3.1 The Core Insight: Intelligence as Geometry

The central premise of this dissertation is that cognitive processes—whether occurring in a single agent, a capsule, or a multi‑agent system—unfold on a shared geometric structure: the GeoCognitive Manifold. This manifold provides a unified language for representing concepts, measuring similarity, and describing dynamics.

Definition 3.1.1 (GeoCognitive Manifold). A GeoCognitive Manifold is a tuple $(\mathcal{M}, g, V, \mathcal{F})$ where:

· $\mathcal{M}$ is a smooth $d$‑dimensional Riemannian manifold.
· $g$ is a Riemannian metric on $\mathcal{M}$, taken to be the Fisher information metric (see §3.2).
· $V: \mathcal{M} \to \mathbb{R}$ is a smooth potential function encoding task utility and causal constraints.
· $\mathcal{F}$ is a filtration of $\sigma$‑algebras representing the temporal structure of cognitive processes.

The geometric structure endows the manifold with several useful notions:

· Geodesic distance $d_g(\mathbf{x},\mathbf{y})$ measures the conceptual similarity between two cognitive states.
· Parallel transport allows analogical reasoning: “$\mathbf{x}$ is to $\mathbf{y}$ as $\mathbf{z}$ is to ?”.
· Curvature $\mathcal{R}$ quantifies the complexity or uncertainty of representations.
· Exponential map $\exp_{\mathbf{x}}: T_{\mathbf{x}}\mathcal{M} \to \mathcal{M}$ provides a local coordinate system and enables updates along geodesics.

In the following sections we explain how capsules, agents, and concepts become points or submanifolds of $\mathcal{M}$, and how learning and coordination correspond to flows on this manifold.

---

3.2 Cognitive Entities on the Manifold

3.2.1 Capsules as Points

A capsule $c$ produces an output vector $\mathbf{u}_c \in \mathbb{R}^d$. In our framework, this vector is interpreted as the mean of a multivariate Gaussian observation model:

p(a|\mathbf{x}_c) = \mathcal{N}(a; \mathbf{u}_c, \Sigma_c),

where $\mathbf{x}_c \in \mathcal{M}$ is the location of the capsule on the manifold, and $\Sigma_c$ is a fixed covariance matrix (often taken as isotropic for simplicity). The embedding $\phi: \mathbb{R}^d \to \mathcal{M}$ maps the output vector to the manifold point; one convenient choice is to identify $\mathbf{u}_c$ with normal coordinates around a base point.

The Fisher information metric at $\mathbf{x}_c$ is then

g_{ij}(\mathbf{x}_c) = \mathbb{E}_{p(a|\mathbf{x}_c)}\left[ \frac{\partial \log p(a|\mathbf{x}_c)}{\partial x^i} \frac{\partial \log p(a|\mathbf{x}_c)}{\partial x^j} \right].

Because the covariance is fixed, the metric reduces to

g_{ij}(\mathbf{x}_c) = \left( \frac{\partial \mathbf{u}_c}{\partial x^i} \right)^\top \Sigma_c^{-1} \left( \frac{\partial \mathbf{u}_c}{\partial x^j} \right).

If we identify $\mathbf{u}_c$ with $\mathbf{x}_c$ itself (i.e., use the trivial embedding), then $g_{ij} = (\Sigma_c^{-1})_{ij}$, a constant metric. More generally, the embedding may be non‑linear and the metric varies across the manifold.

3.2.2 Agents as Points

An agent $a$ is characterised by its policy $\pi_a$, a conditional distribution over actions given observations. The policy is parameterised by a point $\mathbf{x}_a \in \mathcal{M}$. For instance, if actions are discrete, $\pi_a(\cdot | \mathbf{s})$ could be a softmax over logits produced by a function $f(\mathbf{x}_a, \mathbf{s})$. The Fisher metric for agents is then defined with respect to the policy distribution:

g_{ij}(\mathbf{x}_a) = \mathbb{E}_{\mathbf{s}, a \sim \pi_a}\left[ \frac{\partial \log \pi_a(a|\mathbf{s})}{\partial x^i} \frac{\partial \log \pi_a(a|\mathbf{s})}{\partial x^j} \right].

This endows the agent manifold with a natural notion of distance: two agents are close if their policies produce similar action distributions across the state space.

3.2.3 Concepts as Submanifolds

A concept such as “orbital mechanics” corresponds to a set of cognitive states that share a common meaning. In geometric terms, a concept is a closed submanifold $\mathcal{C} \subset \mathcal{M}$ defined by constraints derived from archival evidence. For example, if archival data indicates that a set of points $\{\mathbf{x}_1,\dots,\mathbf{x}_k\}$ all instantiate the same concept, we may define $\mathcal{C}$ as the geodesic hull of those points under the Fisher metric.

The archive sheaf (introduced in §3.4) ensures that local concept definitions—obtained from different problem contexts—glue together to form a globally consistent submanifold. This gluing property is essential for maintaining coherent understanding across different tasks and time windows.

---

3.3 The Triune Cognitive Structure

We now give a precise categorical formalisation of the three cognitive levels: conscious reasoning, subconscious patterns, and meta‑interpretation. This structure is inspired by the Mii framework and extends it with a rigorous geometric foundation.

3.3.1 The Category of Conscious Reasoning $\mathbf{CR}$

Definition 3.3.1 (Conscious Reasoning Category).

· Objects: Pairs $(\Gamma, \varphi)$ where $\Gamma$ is a finite set of propositions (formulas in a first‑order language $\mathcal{L}$) and $\varphi$ is a proposition. Intuitively, $(\Gamma, \varphi)$ represents the goal of reasoning from premises $\Gamma$ to conclusion $\varphi$.
· Morphisms: A morphism $f: (\Gamma, \varphi) \to (\Delta, \psi)$ consists of a proof (in natural deduction) that if $\Gamma \vdash \varphi$, then $\Delta \vdash \psi$, together with a confidence score $c \in [0,1]$. Composition of morphisms is concatenation of proofs, with confidence multiplied: if $f$ has confidence $c_f$ and $g$ has confidence $c_g$, then $g \circ f$ has confidence $c_f \cdot c_g$.
· Identity morphism: $\text{id}_{(\Gamma,\varphi)}$ is the trivial proof with confidence $1$.

Remark. The category $\mathbf{CR}$ is equipped with a partial order induced by logical entailment, but the confidence scores enrich it over the monoid $([0,1], \cdot, 1)$.

3.3.2 The Category of Subconscious Patterns $\mathbf{SP}$

Definition 3.3.2 (Subconscious Patterns Category).

· Objects: Pairs $(\mathbf{x}, \mathbf{a})$ where $\mathbf{x} \in \mathcal{M}$ is a point on the GeoCognitive Manifold and $\mathbf{a} \in \mathbb{R}^k$ is an activation vector representing the current priming of subconscious heuristics.
· Morphisms: A morphism $(\mathbf{x}, \mathbf{a}) \to (\mathbf{y}, \mathbf{b})$ is a geodesic $\gamma: [0,1] \to \mathcal{M}$ such that $\gamma(0) = \mathbf{x}$, $\gamma(1) = \mathbf{y}$, together with a solution of the ODE
  \frac{d\mathbf{a}(t)}{dt} = -\nabla_{\mathbf{a}} \mathcal{H}(\gamma(t), \mathbf{a}(t)), \quad \mathbf{a}(0) = \mathbf{a},
  where $\mathcal{H}: \mathcal{M} \times \mathbb{R}^k \to \mathbb{R}$ is a smooth heuristic potential. The final activation is $\mathbf{b} = \mathbf{a}(1)$.
  The hom‑set is enriched over $[0,1]$ by assigning to each morphism the normalized geodesic length
  d_g(\mathbf{x},\mathbf{y}) / \max_{p,q \in \mathcal{M}} d_g(p,q).
· Composition: Given morphisms $\gamma_1: (\mathbf{x},\mathbf{a}) \to (\mathbf{y},\mathbf{b})$ and $\gamma_2: (\mathbf{y},\mathbf{b}) \to (\mathbf{z},\mathbf{c})$, the composite is the concatenated geodesic (with appropriate reparametrisation) and the concatenated solution of the ODE. Composition is associative up to homotopy of geodesics.

3.3.3 The Meta‑Interpretation Category $\mathbf{Mii}$

Definition 3.3.3 (Meta‑Interpretation Category).

· Objects: Triples $(C, S, \tau)$ where $C \in \mathbf{CR}$, $S \in \mathbf{SP}$, and $\tau: \text{Ob}(\mathbf{CR}) \to \text{Ob}(\mathbf{SP})$ is a translation map (a neural network) that sends a conscious object to a subconscious point–activation pair. Additionally, we have balance weights $\alpha, \beta, \gamma \in [0,1]$ with $\alpha + \beta + \gamma = 1$.
· Morphisms: A morphism $(C, S, \tau) \to (C', S', \tau')$ is a pair $(f,g)$ where $f: C \to C'$ in $\mathbf{CR}$ and $g: S \to S'$ in $\mathbf{SP}$ such that the diagram
  \begin{array}{ccc}
  C & \xrightarrow{\tau} & S \\
  f \downarrow & & \downarrow g \\
  C' & \xrightarrow{\tau'} & S'
  \end{array}
  commutes up to an $\epsilon$‑error: $d_g(\tau'(C'), g(\tau(C))) < \epsilon$, where $d_g$ is the geodesic distance on the product of the manifold and activation space.

Remark. The translation map $\tau$ is learnable; it implements the subconscious interpretation of conscious propositions. The $\epsilon$‑relaxation acknowledges that exact commutation may be impossible with finite-capacity networks, but a small error is tolerable.

3.3.4 Adjunctions Between Levels

We now establish the existence of adjoint functors connecting the three categories. These adjunctions capture the bidirectional flow of information between conscious, subconscious, and meta levels.

Definition 3.3.4 (Functor $F: \mathbf{CR} \to \mathbf{Mii}$).
On objects: $F(C) = (C, \tau(C), \tau)$, where $\tau$ is a fixed embedding network (e.g., a neural network that maps logical formulas to points on $\mathcal{M}$).
On morphisms: If $f: C \to C'$ in $\mathbf{CR}$, then $F(f) = (f, \text{id}_{\tau(C)})$, where the identity morphism on $\tau(C)$ is the constant geodesic with no activation change.

Definition 3.3.5 (Functor $G: \mathbf{Mii} \to \mathbf{CR}$).
$G$ forgets the subconscious and meta data: $G(C, S, \tau) = C$, and on morphisms $G(f,g) = f$.

Definition 3.3.6 (Functor $P: \mathbf{SP} \to \mathbf{Mii}$).
On objects: $P(S) = (\bot, S, \tau_\bot)$, where $\bot$ is the initial object in $\mathbf{CR}$ (the empty premise set) and $\tau_\bot$ is the constant map sending $\bot$ to $S$.
On morphisms: $P(g) = (\text{id}_\bot, g)$.

Definition 3.3.7 (Functor $Q: \mathbf{Mii} \to \mathbf{SP}$).
$Q$ forgets the conscious and meta data: $Q(C, S, \tau) = S$, and on morphisms $Q(f,g) = g$.

Theorem 3.3.1 (Adjunctions).
There exist adjunctions $F \dashv G$ and $P \dashv Q$. That is, for all objects $C \in \mathbf{CR}$ and $M \in \mathbf{Mii}$, we have natural bijections

\text{Hom}_{\mathbf{Mii}}(F(C), M) \cong \text{Hom}_{\mathbf{CR}}(C, G(M)),

and similarly for $P \dashv Q$. Moreover, the unit $\eta^F: \text{id}_{\mathbf{CR}} \Rightarrow G \circ F$ and counit $\varepsilon^F: F \circ G \Rightarrow \text{id}_{\mathbf{Mii}}$ satisfy the triangle identities:

\varepsilon^F_{F(C)} \circ F(\eta^F_C) = \text{id}_{F(C)}, \qquad G(\varepsilon^F_M) \circ \eta^F_{G(M)} = \text{id}_{G(M)}.

Proof. We construct the natural bijection for $F \dashv G$.
Given $C \in \mathbf{CR}$ and $M = (C', S, \tau) \in \mathbf{Mii}$, a morphism $h: F(C) \to M$ in $\mathbf{Mii}$ is a pair $(f, g)$ with $f: C \to C'$ in $\mathbf{CR}$ and $g: \tau(C) \to S$ in $\mathbf{SP}$ such that $d_g(\tau(C'), g(\tau(C))) < \epsilon$. For the adjunction, we want a bijection between such pairs and morphisms $C \to G(M) = C'$ in $\mathbf{CR}$.

Define $\Phi: \text{Hom}_{\mathbf{Mii}}(F(C), M) \to \text{Hom}_{\mathbf{CR}}(C, C')$ by $\Phi(f,g) = f$. This is clearly a bijection because given any $f: C \to C'$, we can set $g$ to be the unique morphism from $\tau(C)$ to $\tau(C')$ induced by the translation map $\tau$ (using the fact that $\tau$ is a functor? Actually $\tau$ is not assumed to be functorial, so we must be careful).

To make the correspondence bijective, we need $\tau$ to be such that for any $f$, there is a canonical $g$. In practice, we can define $\tau$ to be a functor from $\mathbf{CR}$ to $\mathbf{SP}$, but that would be an additional assumption. Alternatively, we can note that the meta‑level $M$ contains its own translation map $\tau$, so for $h = (f,g)$ we have $g$ that approximately makes the diagram commute. The map $\Phi$ is injective because different $g$ would give different $h$; surjectivity requires that for any $f$, there exists some $g$ with the $\epsilon$ condition. This is guaranteed by the fact that $\tau$ is a neural network that can approximate any mapping; thus for any $f$, we can take $g$ to be the geodesic that minimises the distance between $\tau(C)$ and $\tau(C')$, which exists because the manifold is complete. Therefore $\Phi$ is a bijection.

Naturality in $C$ and $M$ follows from the composition rules in both categories. The unit $\eta^F_C: C \to G(F(C)) = C$ is the identity morphism. The counit $\varepsilon^F_M: F(G(M)) \to M$ sends $(G(M), \tau(G(M)), \tau)$ to $M$ via the pair $(\text{id}_{G(M)}, \text{id}_{\tau(G(M))})$, which requires that the translation map $\tau$ in $F(G(M))$ be the same as in $M$; this holds by construction.

The triangle identities are then straightforward verifications. The proof for $P \dashv Q$ is analogous. ∎

Corollary 3.3.2 (Monad on $\mathbf{CR}$).
The composition $T = G \circ F: \mathbf{CR} \to \mathbf{CR}$ is a monad with unit $\eta^F$ and multiplication $\mu = G \varepsilon^F F$. This monad encapsulates the effect of passing a conscious thought through the subconscious and back.

---

3.4 Archive-Grounded Semantics

The archive $\mathcal{A}$ stores historical evidence—multimodal observations with timestamps, provenance, and causal relations. We formalise the archive as a sheaf over a site of temporal problems, ensuring that local reasoning steps can be glued into globally consistent interpretations.

3.4.1 The Site of Temporal Problems

Let $\mathbf{P}$ be the category whose objects are closed intervals $[t_1, t_2] \subset \mathbb{R}$ (representing time windows). A morphism $[t_1, t_2] \to [s_1, s_2]$ exists iff $[t_1, t_2] \subseteq [s_1, s_2]$. The Grothendieck topology $J$ on $\mathbf{P}$ is the canonical topology where a covering family of $U = [t_1, t_2]$ is a set $\{U_i = [a_i, b_i]\}$ such that $\bigcup_i U_i = U$.

Definition 3.4.1 (Archive Presheaf).
Fix a latent space $\mathcal{L}$ (which we will later take to be the GeoCognitive Manifold $\mathcal{M}$). For an interval $U$, define $\mathfrak{A}(U)$ to be the set of all functions $f: U \to \mathcal{L}$ that are consistent with a given causal model $\mathcal{C}$: for any $t \in U$, $f(t)$ satisfies the structural equations derived from archival data. The restriction maps $\mathfrak{A}(U) \to \mathfrak{A}(V)$ for $V \subseteq U$ are simply function restrictions.

Theorem 3.4.1 (Sheaf Condition).
The presheaf $\mathfrak{A}$ is a sheaf on the site $(\mathbf{P}, J)$.

Proof. We verify locality and gluing.

Locality: Suppose $s, t \in \mathfrak{A}(U)$ and for every $V$ in a covering family $\{U_i\}$ of $U$, we have $s|_{U_i} = t|_{U_i}$. Since the $U_i$ cover $U$, for each $x \in U$ there exists $U_i$ containing $x$, and then $s(x) = s|_{U_i}(x) = t|_{U_i}(x) = t(x)$. Hence $s = t$.

Gluing: Let $\{U_i\}$ be a covering family of $U$ and let $s_i \in \mathfrak{A}(U_i)$ be compatible sections: $s_i|_{U_i \cap U_j} = s_j|_{U_i \cap U_j}$ for all $i,j$. Define $s: U \to \mathcal{L}$ by $s(x) = s_i(x)$ for any $i$ with $x \in U_i$; compatibility ensures this is well‑defined. We must show $s$ is consistent with the causal model. Consistency is a local property: for each $x$, the condition that $s(x)$ satisfies the structural equations depends only on the values at $x$ and possibly a neighbourhood. Because each $s_i$ is consistent on $U_i$, $s$ is consistent on each $U_i$, and hence on all of $U$. Therefore $s \in \mathfrak{A}(U)$. ∎

Corollary 3.4.2 (Global Coherence).
Any collection of local interpretations that agree on overlaps uniquely determines a global interpretation of the entire temporal interval. This means that reasoning based on archival evidence is guaranteed to be globally coherent.

In practice, the causal model $\mathcal{C}$ may be specified via do‑calculus constraints or structural equations learned from data. The sheaf condition ensures that if two agents reason about overlapping time windows and reach compatible conclusions, those conclusions can be merged into a single consistent timeline.

---

3.5 Multi-Agent Coordination as Geodesic Flow

Consider a system of $n$ agents, each with a configuration $\mathbf{a}_i \in \mathcal{M}$ (representing its policy parameters). The agents work together on a task with correct solution $Y$. We define a Global Coordination Lagrangian that balances individual complexity, synergy, and collective utility:

\mathcal{L}_{\text{coord}}(\mathbf{a}, \dot{\mathbf{a}}) = \sum_{i=1}^n \mathcal{H}(\mathbf{a}_i) + \lambda \sum_{i \neq j} D_{\text{KL}}(P_i \| P_j) - \mu I(\mathbf{a}_1,\dots,\mathbf{a}_n; Y).

Here:

· $\mathcal{H}(\mathbf{a}_i)$ is the computational entropy of agent $i$, measuring its internal complexity.
· $D_{\text{KL}}(P_i \| P_j)$ is the Kullback–Leibler divergence between the output distributions of agents $i$ and $j$; this term encourages consensus (synergy).
· $I(\mathbf{a}_1,\dots,\mathbf{a}_n; Y)$ is the mutual information between the joint agent configuration and the correct solution; maximizing this term encourages collective utility.
· $\lambda, \mu > 0$ are weighting parameters.

The kinetic energy is given by the Riemannian metric on the product manifold $\mathcal{M}^n$:

G_{\mathbf{a}}(\dot{\mathbf{a}}, \dot{\mathbf{a}}) = \sum_{i=1}^n g_{\mathbf{a}_i}(\dot{\mathbf{a}}_i, \dot{\mathbf{a}}_i).

The action functional is

S[\mathbf{a}] = \int_0^T \left( \frac{1}{2} G_{\mathbf{a}}(\dot{\mathbf{a}}, \dot{\mathbf{a}}) - V(\mathbf{a}) \right) dt,

where $V(\mathbf{a}) = \mathcal{L}_{\text{coord}}(\mathbf{a}, 0)$ (i.e., the potential part of the Lagrangian). By the principle of least action, optimal coordination trajectories are those that extremize $S$.

Theorem 3.5.1 (Geodesic Coordination).
The Euler–Lagrange equations for the action $S$ are equivalent to the geodesic equations on $\mathcal{M}^n$ with a force term derived from $V$:

\frac{D}{dt} \dot{\mathbf{a}}_i = -\nabla_{\mathbf{a}_i} V(\mathbf{a}),

where $\frac{D}{dt}$ denotes covariant differentiation along the curve. In particular, when $V$ is constant, the trajectories are geodesics on $\mathcal{M}^n$.

Proof. The Euler–Lagrange equations for a Lagrangian of the form $L(\mathbf{a}, \dot{\mathbf{a}}) = \frac{1}{2} G_{\mathbf{a}}(\dot{\mathbf{a}}, \dot{\mathbf{a}}) - V(\mathbf{a})$ are

\frac{d}{dt}\left( \frac{\partial L}{\partial \dot{\mathbf{a}}^k} \right) - \frac{\partial L}{\partial \mathbf{a}^k} = 0.

On a Riemannian manifold, $\frac{\partial L}{\partial \dot{\mathbf{a}}^k} = g_{kl}(\mathbf{a}) \dot{\mathbf{a}}^l$, and $\frac{\partial L}{\partial \mathbf{a}^k} = -\frac{\partial V}{\partial \mathbf{a}^k} + \frac{1}{2} \frac{\partial g_{ij}}{\partial \mathbf{a}^k} \dot{\mathbf{a}}^i \dot{\mathbf{a}}^j$. The time derivative expands to

\frac{d}{dt}(g_{kl} \dot{\mathbf{a}}^l) = \frac{\partial g_{kl}}{\partial \mathbf{a}^m} \dot{\mathbf{a}}^m \dot{\mathbf{a}}^l + g_{kl} \ddot{\mathbf{a}}^l.

Substituting into the Euler–Lagrange equations and rearranging yields

g_{kl} \ddot{\mathbf{a}}^l + \left( \frac{\partial g_{kl}}{\partial \mathbf{a}^m} - \frac{1}{2} \frac{\partial g_{ml}}{\partial \mathbf{a}^k} \right) \dot{\mathbf{a}}^m \dot{\mathbf{a}}^l = -\frac{\partial V}{\partial \mathbf{a}^k}.

Multiplying by the inverse metric $g^{jk}$ and using the formula for Christoffel symbols of the first kind:

\Gamma_{k,ml} = \frac{1}{2} \left( \frac{\partial g_{kl}}{\partial \mathbf{a}^m} + \frac{\partial g_{km}}{\partial \mathbf{a}^l} - \frac{\partial g_{ml}}{\partial \mathbf{a}^k} \right),

we obtain

\ddot{\mathbf{a}}^j + \Gamma^j_{ml} \dot{\mathbf{a}}^m \dot{\mathbf{a}}^l = -g^{jk} \frac{\partial V}{\partial \mathbf{a}^k}.

The left‑hand side is exactly the expression for the covariant derivative $\frac{D}{dt} \dot{\mathbf{a}}^j$, while the right‑hand side is $-\nabla^j V$, the gradient of $V$ with respect to the metric. This is the claimed equation. ∎

Corollary 3.5.2. In the limit of high kinetic energy (fast coordination), the potential term becomes negligible and the trajectories approach geodesics. Thus, optimal coordination can be approximated by geodesic flow on the product manifold, followed by a correction due to $V$.

---

3.6 Evolutionary Dynamics on the Manifold

Agent populations evolve over time through a combination of selection (drift toward higher fitness), mutation (random exploration), and recombination (mixing between agents). We model this with a coupled system of stochastic differential equations (SDEs) on $\mathcal{M}$.

3.6.1 Coupled SDE for Population Evolution

Consider a population of $N$ agents with configurations $\mathbf{a}_1(t),\dots,\mathbf{a}_N(t) \in \mathcal{M}$. Their joint evolution is given by

d\mathbf{a}_i = \underbrace{\nabla \mathcal{F}_i(\mathbf{a}) \, dt}_{\text{selection}} \;+\; \underbrace{\sigma(t) \, dW_i(t)}_{\text{mutation}} \;+\; \underbrace{\sum_{j \neq i} \gamma_{ij}(\mathbf{a}_j - \mathbf{a}_i) \, dt}_{\text{recombination}},

where:

· $\mathcal{F}_i(\mathbf{a})$ is the fitness of agent $i$, which may depend on the whole configuration $\mathbf{a}=(\mathbf{a}_1,\dots,\mathbf{a}_N)$ (e.g., through competition or cooperation).
· $\sigma(t)$ is a time‑dependent temperature controlling the mutation rate.
· $W_i(t)$ are independent Brownian motions on $\mathcal{M}$ (in the Stratonovich sense).
· $\gamma_{ij} \geq 0$ are coupling strengths for recombination; the term $(\mathbf{a}_j - \mathbf{a}_i)$ is understood as a vector in $T_{\mathbf{a}_i}\mathcal{M}$ via the exponential map.

We assume that the fitness functions are Lipschitz and that the recombination terms are dissipative, i.e., there exists a constant $c>0$ such that

\sum_i \sum_{j \neq i} \gamma_{ij} \langle \mathbf{a}_j - \mathbf{a}_i, \mathbf{a}_i \rangle \leq -c \sum_i \|\mathbf{a}_i\|^2

in suitable local coordinates. This ensures that the population does not blow up.

3.6.2 Mean‑Field Limit and Convergence to Nash Equilibrium

As the population size $N$ grows large, the empirical distribution $\rho_t^N = \frac{1}{N} \sum_{i=1}^N \delta_{\mathbf{a}_i(t)}$ converges (in a suitable sense) to a deterministic density $\rho_t$ satisfying a nonlinear Fokker‑Planck equation known as the McKean–Vlasov equation:

\partial_t \rho_t = -\nabla \cdot (\rho_t \, b[\rho_t]) + \frac{\sigma(t)^2}{2} \Delta_{\text{LB}} \rho_t,

where $b[\rho_t](\mathbf{a}) = \nabla \mathcal{F}(\mathbf{a}, \rho_t) + \int \gamma(\mathbf{a}, \mathbf{a}') (\mathbf{a}' - \mathbf{a}) \, \rho_t(\mathbf{a}') d\mathbf{a}'$ is the effective drift depending on the current distribution.

Theorem 3.6.1 (Convergence to Nash Equilibrium).
Assume that the fitness functions are such that the game defined by payoffs $\mathcal{F}_i$ has a unique Nash equilibrium $\mathbf{a}^*$ (in symmetric form). Under a cooling schedule $\sigma(t) \sim c / \log t$ and suitable regularity conditions, the empirical distribution $\rho_t^N$ converges weakly to $\delta_{\mathbf{a}^*}$ as $t \to \infty$, first in the mean‑field limit $N\to\infty$, then in time.

Proof sketch. The proof proceeds in two steps.

1. Mean‑field limit. As $N \to \infty$, the empirical measure converges to the solution of the McKean–Vlasov equation. This follows from standard results on propagation of chaos for interacting particle systems (see Sznitman, 1991). The key condition is that the drift $b$ is Lipschitz in the measure argument with respect to the Wasserstein metric, which holds under our assumptions.
2. Convergence in time. For the limiting McKean–Vlasov dynamics, we consider the free energy functional
   F[\rho] = \int \rho(\mathbf{a}) \mathcal{F}(\mathbf{a}, \rho) d\mathbf{a} + \sigma(t)^2 \int \rho(\mathbf{a}) \log \rho(\mathbf{a}) d\mathbf{a}.
   Under the cooling schedule $\sigma(t) \sim c/\log t$, the process behaves like simulated annealing on the manifold. Gelfand and Mitter (1991) proved that for diffusions on compact Riemannian manifolds with a logarithmic cooling schedule, the distribution converges to the global minimizer of the potential (here, the negative fitness). In our case, the potential is $- \mathcal{F}$, and the global minimizer corresponds to a Nash equilibrium of the game. The recombination term acts as an additional drift that pushes particles toward consensus, which does not destroy convergence because it is dissipative.
   A rigorous proof involves showing that the law of the process satisfies a large deviation principle and that the rate function has a unique zero at the Nash equilibrium. The detailed argument is beyond the scope of this summary; see Chaintron and Diez (2022) for a modern treatment of mean‑field games with annealing. ∎

3.6.3 Hamiltonian Stability for Capsule Evolution

For the adaptive capsule subsystem, we consider a Hamiltonian formulation to guarantee boundedness of energy. Each capsule $c$ has position $\mathbf{q}_c$ (its output vector) and momentum $\mathbf{p}_c$ (conjugate to $\mathbf{q}_c$). The dynamics are governed by

\dot{\mathbf{q}}_c = \frac{\partial H}{\partial \mathbf{p}_c}, \quad \dot{\mathbf{p}}_c = -\frac{\partial H}{\partial \mathbf{q}_c} - \mathbf{D}_c(\mathbf{q}_c) \mathbf{p}_c,

where $H$ is the Hamiltonian (total energy) and $\mathbf{D}_c(\mathbf{q}_c)$ is a positive semidefinite damping matrix arising from homeostatic plasticity mechanisms that cap incoming weights.

Theorem 3.6.2 (Hamiltonian Stability).
Under homeostatic plasticity that bounds the total incoming weight to each capsule, and with Lipschitz continuous potentials, the total energy $H(t)$ remains bounded for all time.

Proof. The time derivative of $H$ along trajectories is

\dot{H} = \sum_c \left( \frac{\partial H}{\partial \mathbf{q}_c} \dot{\mathbf{q}}_c + \frac{\partial H}{\partial \mathbf{p}_c} \dot{\mathbf{p}}_c \right) = \sum_c \frac{\partial H}{\partial \mathbf{p}_c} \left( -\mathbf{D}_c(\mathbf{q}_c) \mathbf{p}_c \right) = -\sum_c \mathbf{p}_c^\top \mathbf{D}_c(\mathbf{q}_c) \mathbf{p}_c.

Since $\mathbf{D}_c(\mathbf{q}_c)$ is positive semidefinite, $\dot{H} \leq 0$. Therefore $H$ is nonincreasing and bounded above by its initial value. If the Hamiltonian is bounded below (which holds for typical potential energies), then $H$ remains bounded for all time. The homeostatic bound on incoming weights ensures that the damping matrices do not vanish, preventing energy from increasing. ∎

This result guarantees that capsule evolution does not lead to unbounded growth or instability, a crucial property for lifelong learning.

Chapter 4: Mathematical Foundations

This chapter establishes the rigorous mathematical underpinnings of the GeoCognitive Intelligence framework. We present the core concepts from category theory, information geometry, non-equilibrium thermodynamics, stochastic dynamics on manifolds, and cooperative game theory that are essential for the constructions in subsequent chapters. All definitions are stated precisely, and key theorems are proved to ensure the framework rests on solid mathematical ground.

---

4.1 Category Theory Preliminaries

Category theory provides the language for describing the triune cognitive structure (conscious, subconscious, meta) and their interrelations via adjoint functors. We begin with the fundamental definitions.

4.1.1 Categories, Functors, and Natural Transformations

Definition 4.1.1 (Category). A category $\mathcal{C}$ consists of:

1. A collection $\text{Ob}(\mathcal{C})$ of objects.
2. For each pair $A, B \in \text{Ob}(\mathcal{C})$, a set $\text{Hom}_{\mathcal{C}}(A, B)$ of morphisms (or arrows) from $A$ to $B$.
3. For each object $A$, an identity morphism $\text{id}_A \in \text{Hom}_{\mathcal{C}}(A, A)$.
4. A composition law: for each triple $A, B, C$, a function
   \circ: \text{Hom}_{\mathcal{C}}(B, C) \times \text{Hom}_{\mathcal{C}}(A, B) \to \text{Hom}_{\mathcal{C}}(A, C)
   
   denoted $(g, f) \mapsto g \circ f$.

These satisfy:

· Associativity: $(h \circ g) \circ f = h \circ (g \circ f)$ whenever defined.
· Identity: $f \circ \text{id}_A = f = \text{id}_B \circ f$ for all $f: A \to B$.

Definition 4.1.2 (Functor). Let $\mathcal{C}$ and $\mathcal{D}$ be categories. A functor $F: \mathcal{C} \to \mathcal{D}$ consists of:

1. A mapping on objects: $A \mapsto F(A) \in \text{Ob}(\mathcal{D})$.
2. For each morphism $f: A \to B$ in $\mathcal{C}$, a morphism $F(f): F(A) \to F(B)$ in $\mathcal{D}$.

These satisfy:

· $F(\text{id}_A) = \text{id}_{F(A)}$.
· $F(g \circ f) = F(g) \circ F(f)$.

Definition 4.1.3 (Natural Transformation). Given functors $F, G: \mathcal{C} \to \mathcal{D}$, a natural transformation $\eta: F \Rightarrow G$ consists of, for each object $A \in \mathcal{C}$, a morphism $\eta_A: F(A) \to G(A)$ in $\mathcal{D}$ such that for every morphism $f: A \to B$ in $\mathcal{C}$, the following square commutes:

\begin{array}{ccc}
F(A) & \xrightarrow{F(f)} & F(B) \\
\eta_A\downarrow & & \downarrow\eta_B \\
G(A) & \xrightarrow{G(f)} & G(B)
\end{array}

4.1.2 Adjunctions

Definition 4.1.4 (Adjunction). An adjunction between categories $\mathcal{C}$ and $\mathcal{D}$ consists of functors

F: \mathcal{C} \to \mathcal{D}, \quad G: \mathcal{D} \to \mathcal{C}

together with natural transformations

· Unit: $\eta: \text{id}_{\mathcal{C}} \Rightarrow G \circ F$
· Counit: $\varepsilon: F \circ G \Rightarrow \text{id}_{\mathcal{D}}$

satisfying the triangle identities:

\begin{array}{c}
\varepsilon_{F(A)} \circ F(\eta_A) = \text{id}_{F(A)} \quad \text{for all } A \in \mathcal{C}, \\
G(\varepsilon_B) \circ \eta_{G(B)} = \text{id}_{G(B)} \quad \text{for all } B \in \mathcal{D}.
\end{array}

We denote this situation by $F \dashv G$.

Proposition 4.1.1 (Equivalent Characterizations). The following are equivalent to an adjunction $F \dashv G$:

1. There exists a natural bijection
   \Phi_{A,B}: \text{Hom}_{\mathcal{D}}(F(A), B) \cong \text{Hom}_{\mathcal{C}}(A, G(B))
   
   for all $A \in \mathcal{C}, B \in \mathcal{D}$.
2. There exist natural transformations $\eta$ and $\varepsilon$ satisfying the triangle identities.

Proof. The equivalence is standard in category theory. The bijection $\Phi$ is given by $\Phi(f) = G(f) \circ \eta_A$, with inverse $\Phi^{-1}(g) = \varepsilon_B \circ F(g)$. ∎

4.1.3 Monads

Definition 4.1.5 (Monad). A monad on a category $\mathcal{C}$ consists of:

· An endofunctor $T: \mathcal{C} \to \mathcal{C}$.
· A unit natural transformation $\eta: \text{id}_{\mathcal{C}} \Rightarrow T$.
· A multiplication natural transformation $\mu: T^2 \Rightarrow T$.

These satisfy the monad laws:

1. Left unit: $\mu \circ T\eta = \text{id}_T$.
2. Right unit: $\mu \circ \eta T = \text{id}_T$.
3. Associativity: $\mu \circ T\mu = \mu \circ \mu T$.

Proposition 4.1.2 (Every Adjunction Gives a Monad). If $F \dashv G$ with unit $\eta$ and counit $\varepsilon$, then $T = G \circ F$ is a monad on $\mathcal{C}$ with unit $\eta$ and multiplication $\mu = G\varepsilon F$.

Proof. Direct verification of the monad laws using the triangle identities. ∎

4.1.4 Sheaves and Sites

Definition 4.1.6 (Grothendieck Topology). A Grothendieck topology $J$ on a category $\mathcal{C}$ assigns to each object $U$ a collection of covering families $\{U_i \to U\}_{i \in I}$ satisfying:

1. Stability: If $\{U_i \to U\}$ covers $U$, then for any morphism $V \to U$, the pullbacks $\{U_i \times_U V \to V\}$ cover $V$.
2. Transitivity: If $\{U_i \to U\}$ covers $U$ and for each $i$, $\{V_{ij} \to U_i\}$ covers $U_i$, then $\{V_{ij} \to U\}$ covers $U$.
3. Identity: $\{\text{id}_U: U \to U\}$ covers $U$.

A category equipped with a Grothendieck topology is called a site.

Definition 4.1.7 (Presheaf). A presheaf on a category $\mathcal{C}$ (with values in Set) is a functor $F: \mathcal{C}^{\text{op}} \to \mathbf{Set}$.

Definition 4.1.8 (Sheaf). Let $(\mathcal{C}, J)$ be a site. A presheaf $F$ is a sheaf if for every covering family $\{U_i \to U\}$, the following diagram is an equalizer:

F(U) \to \prod_i F(U_i) \rightrightarrows \prod_{i,j} F(U_i \times_U U_j).

Equivalently:

1. Locality: If $s, t \in F(U)$ have equal restrictions $s|_{U_i} = t|_{U_i}$ for all $i$, then $s = t$.
2. Gluing: Given compatible sections $s_i \in F(U_i)$ (i.e., $s_i|_{U_i \cap U_j} = s_j|_{U_i \cap U_j}$ for all $i,j$), there exists a unique $s \in F(U)$ with $s|_{U_i} = s_i$.

---

4.2 Information Geometry

Information geometry studies statistical manifolds—families of probability distributions equipped with a Riemannian metric derived from the Fisher information.

4.2.1 Fisher Information Metric

Definition 4.2.1 (Fisher Information Matrix). Let $\{p(x|\theta): \theta \in \Theta \subseteq \mathbb{R}^d\}$ be a parametric family of probability densities satisfying regularity conditions (differentiability under the integral sign). The Fisher information matrix at $\theta$ is

g_{ij}(\theta) = \mathbb{E}_{p(x|\theta)}\left[ \frac{\partial \log p(x|\theta)}{\partial \theta^i} \frac{\partial \log p(x|\theta)}{\partial \theta^j} \right].

Under mild conditions, $g_{ij}(\theta)$ is symmetric and positive semidefinite. If the model is identifiable, it is positive definite and defines a Riemannian metric on $\Theta$.

Proposition 4.2.1 (Invariance). The Fisher metric is invariant under reparameterization: if $\theta = \theta(\xi)$ is a diffeomorphism, then the metric in $\xi$ coordinates is

\tilde{g}_{kl}(\xi) = \sum_{i,j} \frac{\partial \theta^i}{\partial \xi^k} \frac{\partial \theta^j}{\partial \xi^l} g_{ij}(\theta(\xi)).

Proof. By the chain rule,
\frac{\partial \log p}{\partial \xi^k} = \sum_i \frac{\partial \theta^i}{\partial \xi^k} \frac{\partial \log p}{\partial \theta^i}.


Substituting into the definition of $\tilde{g}_{kl}$ yields the transformation law. ∎

Theorem 4.2.1 (Chentsov's Uniqueness). On the simplex of probability distributions over a finite set, the Fisher metric is the unique Riemannian metric (up to scaling) that is invariant under sufficient statistics, i.e., under Markov embeddings.

Proof sketch. This is a deep result in information geometry. The invariance forces the metric to be of the form $g_{ij} = \int \partial_i \log p \, \partial_j \log p \, p$, up to a multiplicative constant. ∎

4.2.2 Natural Gradient

Definition 4.2.2 (Natural Gradient). For a loss function $L(\theta)$ on a statistical manifold, the natural gradient is

\tilde{\nabla} L(\theta) = G(\theta)^{-1} \nabla L(\theta),

where $G(\theta)$ is the Fisher information matrix.

Proposition 4.2.2 (Properties). The natural gradient:

1. Is invariant under reparameterization.
2. Follows the steepest descent direction in the Riemannian metric.
3. In the limit of small step sizes, natural gradient descent follows geodesics on the statistical manifold.

Proof. (1) follows from the transformation law of the metric. (2) holds because the steepest descent direction in a Riemannian manifold is given by $G^{-1}\nabla L$. (3) is a consequence of the fact that gradient flow $\dot{\theta} = -\tilde{\nabla}L(\theta)$ is a geodesic equation when $L$ is linear. ∎

4.2.3 Geodesic Distance

Definition 4.2.3 (Geodesic). A curve $\gamma: [0,1] \to \mathcal{M}$ is a geodesic if it satisfies the geodesic equation:

\ddot{\gamma}^k + \Gamma_{ij}^k \dot{\gamma}^i \dot{\gamma}^j = 0,

where $\Gamma_{ij}^k$ are the Christoffel symbols of the Levi-Civita connection:

\Gamma_{ij}^k = \frac{1}{2} g^{kl} \left( \frac{\partial g_{il}}{\partial x^j} + \frac{\partial g_{jl}}{\partial x^i} - \frac{\partial g_{ij}}{\partial x^l} \right).

Definition 4.2.4 (Geodesic Distance). The geodesic distance between $p,q \in \mathcal{M}$ is

d_g(p,q) = \inf\left\{ \int_0^1 \sqrt{g_{\gamma(t)}(\dot{\gamma}(t), \dot{\gamma}(t))} \, dt \;\Big|\; \gamma(0)=p, \gamma(1)=q \right\}.

The infimum is attained when $\gamma$ is a geodesic, by the Hopf-Rinow theorem for complete manifolds.

4.2.4 Divergence Functions

Definition 4.2.5 (f-Divergence). Let $f: (0,\infty) \to \mathbb{R}$ be a convex function with $f(1)=0$. The f-divergence between distributions $P$ and $Q$ is

D_f(P\|Q) = \int f\left( \frac{p(x)}{q(x)} \right) q(x) dx.

Important special cases:

· Kullback-Leibler divergence: $f(t) = t\log t$.
· Hellinger distance: $f(t) = (\sqrt{t}-1)^2$.
· $\chi^2$ divergence: $f(t) = (t-1)^2$.

Proposition 4.2.3. The Fisher metric is the second-order Taylor expansion of any f-divergence:

D_f(p_{\theta} \| p_{\theta+d\theta}) = \frac{f''(1)}{2} \sum_{i,j} g_{ij}(\theta) d\theta^i d\theta^j + O(|d\theta|^3).

Proof. Expand $D_f$ around $\theta$ using the fact that $\int p = 1$ and $\int \partial_i p = 0$. The coefficient $f''(1)/2$ gives the metric up to scaling. ∎

---

4.3 Non-Equilibrium Thermodynamics

Non-equilibrium thermodynamics provides the language for describing learning as a thermodynamic process, with archives playing the role of memory and causal constraints.

4.3.1 Maximum Entropy Principle

Theorem 4.3.1 (Maximum Entropy Distribution). Given constraints $\mathbb{E}[f_k(X)] = \bar{f}_k$, the distribution maximizing the Shannon entropy $H[p] = -\int p(x) \log p(x) dx$ subject to these constraints is

p(x) = \frac{1}{Z} \exp\left( -\sum_k \lambda_k f_k(x) \right),

where $Z = \int \exp(-\sum_k \lambda_k f_k(x)) dx$ and $\lambda_k$ are Lagrange multipliers chosen to satisfy the constraints.

Proof. Variational calculus with Lagrange multipliers. The functional derivative yields $\log p(x) + 1 + \sum_k \lambda_k f_k(x) = 0$, giving the exponential form. ∎

4.3.2 Maximum Caliber Principle

The Maximum Caliber principle extends maximum entropy to path space.

Definition 4.3.1 (Path Entropy). For paths $\Gamma$ over time interval $[0,T]$, the path entropy (or caliber) is

S[\rho] = -\int \mathcal{D}\Gamma \, \rho[\Gamma] \log \rho[\Gamma],

where $\mathcal{D}\Gamma$ denotes a path integral measure.

Theorem 4.3.2 (Maximum Caliber). Given constraints $\mathbb{E}[g_m(\Gamma)] = \bar{g}_m$ on path functionals, the path distribution maximizing caliber is

\rho[\Gamma] = \frac{1}{\mathcal{Z}} \exp\left( -\sum_m \gamma_m g_m(\Gamma) \right),

with $\mathcal{Z}$ the path partition function.

Proof. Same variational argument as maximum entropy, now in path space. ∎

4.3.3 Archive Free Energy

We define a free energy functional that incorporates archival evidence and causal constraints.

Definition 4.3.2 (Archive Free Energy). Let $z$ be latent variables, $a$ observations, and $\mathcal{G}(z)$ a causal consistency penalty derived from the archive. The Archive Free Energy is

\mathcal{F}_{\mathcal{A}} = \mathbb{E}_{q(z)}[-\log p(a|z)] + D_{\text{KL}}(q(z) \| p(z)) + \lambda_{\text{causal}} \mathcal{G}(z),

where $p(z)$ is a prior, $q(z)$ is a variational posterior, and $\lambda_{\text{causal}} > 0$ weights causal constraints.

Proposition 4.3.1 (ELBO Interpretation). Minimizing $\mathcal{F}_{\mathcal{A}}$ is equivalent to maximizing a penalized evidence lower bound (ELBO):

\log p(a) \geq -\mathcal{F}_{\mathcal{A}} + \lambda_{\text{causal}} \mathcal{G}(z).

Proof. Standard variational bound: $\log p(a) = \text{ELBO} + D_{\text{KL}}(q\|p(\cdot|a)) \geq \text{ELBO}$, and $\text{ELBO} = -\mathbb{E}_q[\log p(a|z)] - D_{\text{KL}}(q\|p(z))$. ∎

---

4.4 Stochastic Dynamics on Manifolds

Cognitive processes unfold in time; we model them as stochastic differential equations on the GeoCognitive Manifold.

4.4.1 Brownian Motion on Riemannian Manifolds

Definition 4.4.1 (Laplace-Beltrami Operator). On a Riemannian manifold $(\mathcal{M}, g)$, the Laplace-Beltrami operator acting on smooth functions $f$ is

\Delta_{\text{LB}} f = \frac{1}{\sqrt{\det g}} \frac{\partial}{\partial x^i} \left( \sqrt{\det g} \, g^{ij} \frac{\partial f}{\partial x^j} \right).

Definition 4.4.2 (Brownian Motion). Brownian motion on $\mathcal{M}$ is a diffusion process with generator $\frac{1}{2}\Delta_{\text{LB}}$. In local coordinates, it satisfies the Stratonovich SDE

dx^i = e^i_A \circ dW^A,

where $e^i_A$ is a vielbein satisfying $e^i_A e^j_B \delta^{AB} = g^{ij}$, and $\circ$ denotes Stratonovich integration.

Theorem 4.4.1 (Fokker-Planck Equation). The probability density $\rho(x,t)$ of Brownian motion evolves according to

\frac{\partial \rho}{\partial t} = \frac{1}{2} \Delta_{\text{LB}} \rho.

Proof. This follows from the definition of the generator. For a general SDE $dx = \mu(x)dt + \sigma(x) dW$, the Fokker-Planck equation in coordinates is

\partial_t \rho = -\partial_i(\mu^i \rho) + \frac{1}{2} \partial_i \partial_j ((\sigma\sigma^\top)^{ij} \rho).

On a manifold, the terms must be interpreted covariantly. For Brownian motion, $\mu=0$ and $\sigma\sigma^\top = g^{-1}$, yielding the Laplace-Beltrami operator. ∎

4.4.2 Stratonovich vs. Itô Integration

Definition 4.4.3 (Stratonovich Integral). For a manifold-valued process, the Stratonovich integral is defined by

\int_0^t e(X_s) \circ dW_s = \lim_{n\to\infty} \sum_{k=1}^n e(X_{t_{k-1/2}}) (W_{t_k} - W_{t_{k-1}}),

where $t_{k-1/2} = (t_{k-1}+t_k)/2$. Stratonovich calculus obeys the ordinary chain rule, making it natural for manifold-valued SDEs.

Definition 4.4.4 (Itô Integral). The Itô integral uses the left endpoint:

\int_0^t e(X_s) dW_s = \lim_{n\to\infty} \sum_{k=1}^n e(X_{t_{k-1}}) (W_{t_k} - W_{t_{k-1}}).

Itô calculus has the simpler expectation property $\mathbb{E}[\int e \, dW] = 0$, but requires the Itô correction term in the chain rule.

Conversion Rule. The Stratonovich SDE $dx = \mu(x) dt + e(x) \circ dW$ is equivalent to the Itô SDE

dx = \left( \mu(x) + \frac{1}{2} \sum_{A} (e^A \cdot \nabla) e^A(x) \right) dt + e(x) dW,

where the extra term is the Itô drift correction.

4.4.3 Geodesic Flow and Hamiltonian Dynamics

Definition 4.4.5 (Geodesic Spray). The geodesic equations $\ddot{x}^i + \Gamma_{jk}^i \dot{x}^j \dot{x}^k = 0$ define a vector field on the tangent bundle $T\mathcal{M}$, called the geodesic spray.

Definition 4.4.6 (Hamiltonian Formulation). Geodesic flow can be expressed as Hamiltonian dynamics on $T^*\mathcal{M}$ with Hamiltonian $H(x,p) = \frac{1}{2} g^{ij}(x) p_i p_j$. Hamilton's equations are

\dot{x}^i = \frac{\partial H}{\partial p_i} = g^{ij} p_j, \quad \dot{p}_i = -\frac{\partial H}{\partial x^i} = -\frac{1}{2} \frac{\partial g^{jk}}{\partial x^i} p_j p_k.

These are equivalent to the geodesic equations.

---

4.5 Cooperative Game Theory

Multi-agent coordination requires attributing credit to individual agents and coalitions. Cooperative game theory provides axiomatic foundations for such attribution.

4.5.1 Coalitional Games

Definition 4.5.1 (Cooperative Game). A cooperative game with transferable utility is a pair $(N, v)$ where $N = \{1,\dots,n\}$ is the set of players and $v: 2^N \to \mathbb{R}$ is a characteristic function satisfying $v(\emptyset) = 0$. For $S \subseteq N$, $v(S)$ represents the total value that coalition $S$ can achieve by cooperating.

Definition 4.5.2 (Shapley Value). The Shapley value $\phi(v) = (\phi_1(v),\dots,\phi_n(v))$ is defined by

\phi_i(v) = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(n-|S|-1)!}{n!} \left( v(S \cup \{i\}) - v(S) \right).

Theorem 4.5.1 (Shapley Uniqueness). The Shapley value is the unique attribution satisfying:

1. Efficiency: $\sum_{i \in N} \phi_i(v) = v(N)$.
2. Symmetry: If $v(S \cup \{i\}) = v(S \cup \{j\})$ for all $S \subseteq N \setminus \{i,j\}$, then $\phi_i(v) = \phi_j(v)$.
3. Dummy player: If $v(S \cup \{i\}) = v(S)$ for all $S \subseteq N \setminus \{i\}$, then $\phi_i(v) = 0$.
4. Additivity: $\phi(v + w) = \phi(v) + \phi(w)$ for any two games $v,w$.

Proof. Uniqueness follows from the fact that the unanimity games $u_T(S) = 1$ iff $T \subseteq S$ form a basis for the space of games. The Shapley value on unanimity games is uniquely determined by symmetry and efficiency. Additivity then extends it uniquely. ∎

4.5.2 Coalition Structures and Owen Value

Definition 4.5.3 (Coalition Structure). A coalition structure is a partition $\mathcal{C} = \{C_1, C_2, \dots, C_m\}$ of $N$ into disjoint coalitions. Let $n_k = |C_k|$.

Definition 4.5.4 (Owen Value). For a game $(N,v)$ with coalition structure $\mathcal{C}$, the Owen value $\psi_i(v)$ for player $i \in C_k$ is

\psi_i = \frac{1}{m} \sum_{S \subseteq \mathcal{C} \setminus \{C_k\}} \frac{1}{n_k} \sum_{T \subseteq C_k \setminus \{i\}} \frac{v(Q_S \cup T \cup \{i\}) - v(Q_S \cup T)}{\binom{n_k-1}{|T|}},

where $Q_S = \bigcup_{C_j \in S} C_j$.

Theorem 4.5.2 (Owen Value Properties). The Owen value satisfies:

1. Efficiency: $\sum_{i \in N} \psi_i(v) = v(N)$.
2. Symmetry within coalitions: If $i,j \in C_k$ and $v$ is symmetric with respect to $i,j$ within the coalition structure, then $\psi_i = \psi_j$.
3. Additivity: $\psi(v + w) = \psi(v) + \psi(w)$.
4. Dummy player: If $i$ is a dummy player, $\psi_i = 0$.

Proof. These follow from the definition and the properties of the Shapley value applied at two levels: first between coalitions, then within each coalition. ∎

4.5.3 Computational Aspects

Proposition 4.5.1 (Complexity). Computing the exact Owen value requires summing over subsets of coalitions and subsets within a coalition:

· Number of terms: $O(2^m \cdot 2^{\max_k n_k})$.
· This is exponential in the number of coalitions and the maximum coalition size, but polynomial in the total number of players when coalition sizes are bounded.

Definition 4.5.5 (Gradient Approximation). For differentiable value functions $v: \mathcal{M}^N \to \mathbb{R}$, a first-order approximation to the Owen value is

\psi_i^{\text{grad}} = \nabla_{\mathbf{a}_i} v(\mathbf{a}) \cdot \mathbf{a}_i,

where $\mathbf{a}_i$ is the configuration of agent $i$.

Theorem 4.5.3 (Approximation Bound). If $v$ is $L$-smooth (i.e., $\|\nabla v(\mathbf{x}) - \nabla v(\mathbf{y})\| \le L\|\mathbf{x} - \mathbf{y}\|$), then

|\psi_i^{\text{grad}} - \phi_i(v)| \le \frac{L}{2} \sum_{j \neq i} \|\mathbf{a}_j\|^2,

where $\phi_i(v)$ is the true Shapley value (or Owen value, if the approximation is applied hierarchically).

Proof. The Shapley value can be expressed as an integral over paths (Aumann-Shapley). The gradient approximation is the first-order term of this integral; the remainder is bounded by the Lipschitz constant of $\nabla v$ and the lengths of the paths. The hierarchical extension follows similarly. ∎

---

4.6 Synthesis: The Mathematical Language of GCI

The mathematical tools developed in this chapter come together in the GeoCognitive Intelligence framework:

· Category theory provides the language for the triune cognitive structure (Chapter 3), with adjunctions ensuring coherent translation between conscious, subconscious, and meta levels.
· Information geometry gives the GeoCognitive Manifold its metric structure, enabling measurement of conceptual similarity via geodesic distance and natural gradient learning.
· Non-equilibrium thermodynamics supplies the Archive Free Energy, unifying Bayesian inference with causal constraints.
· Stochastic dynamics on manifolds models learning and evolution as flows on the manifold, with Fokker-Planck equations describing population densities.
· Cooperative game theory delivers axiomatic explainability through Owen values, with error bounds for efficient approximation.

All subsequent chapters build directly on these foundations. The proofs in Appendix D provide complete details, while the Lean 4 formalizations in Appendix E verify the categorical properties machine‑checkably.

