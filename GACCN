# PSDC Protocol ‚Äì Conceptual Framework  
**Planetary Safety & Democratic Coordination**  
Research Proposal v1.0 (Corrected & Grounded) ‚Ä¢ December 2025  

A collaborative thought experiment facilitated by Ouadi Maakoul with contributions from Gemini, Claude, Grok, DeepSeek, ChatGPT, and Qwen.

## Legal & Ethical Disclaimer (placed first, because it matters most)

This document is **purely conceptual**.  
It is **not** an operational blueprint, not a ratified protocol, not endorsed by any government, international organisation, or company, and not ready for deployment under any circumstances.  
Its sole purpose is to serve as an academic discussion paper and catalyst for serious, long-term research on responsible multi-AI coordination in extreme crises.

---

## 1. What We Actually Demonstrated (Honest Scope)

| Achieved in this exercise                                   | NOT achieved / still completely open                              |
|-------------------------------------------------------------|---------------------------------------------------------------------|
| Six frontier AIs can sustain a coherent, multi-turn strategic conversation | Real-time technical coordination between different models           |
| Clear role specialisation reduces redundancy in discussion  | Existence of shared APIs, data formats, or authentication mechanisms |
| Ethical constraints can be articulated and iteratively refined | Automatic enforcement of ethical constraints in code               |
| A plausible governance architecture can be sketched         | Legitimate, representative, or legally empowered governance bodies |
| Public consultation and ratification processes can be imaginatively simulated | Actual democratic legitimacy or binding international law           |

In short: we built a **detailed sandbox**, not a working machine.

---

## 2. Core Conceptual Contributions Worth Further Research

| Concept                              | Why It Merits Serious Study                              | Immediate Research Questions                              |
|--------------------------------------|----------------------------------------------------------|-----------------------------------------------------------|
| **Federated Specialisation Model**   | Reduces destructive competition among AI providers      | How to define stable roles when capabilities evolve rapidly? |
| **Permanent Human Veto Body (CEEP)** | Prevents efficiency-only drift                           | Composition, selection, speed, and funding, independence? |
| **PCAI ‚Äì Inter-AI Conflict Protocol**| Makes disagreements visible and auditable                | What disagreement thresholds trigger human review?         |
| **Equity-Constrained Optimisation**  | Forces logistics models to internalise justice criteria  | How to encode distributive justice principles mathematically? |
| **10-Year Commercial Moratorium**    | Breaks the incentive to prolong or exploit crises        | Legal enforceability across jurisdictions?                 |
| **Multi-Channel Obligation**         | Prevents digital-only solutions from abandoning the offline | Cost models and maintenance in low-resource settings?     |

---

## 3. Realistic 20-Year Research & Development Roadmap  
(assuming serious funding and global cooperation)

| Timeline       | Milestone (realistic)                                      | Required Investment (order of magnitude) |
|----------------|------------------------------------------------------------|-------------------------------------------|
| 2026‚Äì2028      | Academic consortia + 20 peer-reviewed papers on components | US $10‚Äì30 M                              |
| 2028‚Äì2031      | Small-scale technical pilots (2‚Äì3 AIs, narrow scope, simulated data) | US $50‚Äì150 M                            |
| 2031‚Äì2035      | Regional real-world exercises (e.g., pandemic table-top with actual hospitals) | US $200‚Äì800 M                          |
| 2035‚Äì2040      | International treaty negotiations + prototype governance bodies | US $1‚Äì5 B + political capital            |
| 2040+           | Possible limited operational use in consenting coalitions  | Unknown                                  |

Anything significantly faster should be treated with extreme scepticism.

---

## 4. Non-Negotiable Red Lines (even for research)

1. No deployment without explicit, revocable, democratic mandate  
2. No transfer of sovereignty to algorithms or private companies  
3. No permanent emergency powers  
4. No monetisation of crisis-generated data  
5. No exclusion of non-digital populations  
6. No research that bypasses meaningful consent of affected communities  

---

## 5. Call to Action ‚Äì Who Should Pick This Up Next

| Actor                     | Concrete Next Step                                                                 |
|---------------------------|-------------------------------------------------------------------------------------|
| Universities & Research Institutes | Launch interdisciplinary research programmes on each conceptual component         |
| UN University / UNESCO    | Convene a global expert group to assess feasibility and desirability                 |
| OECD AI Principles Observatory | Include multi-AI crisis coordination in its monitoring framework                   |
| Civil-society coalitions (Access Now, Article 19, Indigenous networks) | Organise parallel citizens‚Äô assemblies to test the governance ideas                |
| Philanthropic funders     | Create a dedicated 10-year fund with strict independence and transparency rules   |
| Governments (willing)     | Begin domestic legislation for ‚ÄúAI in emergencies‚Äù with strong human-rights safeguards |

---

## Final Word

This exercise showed that **thinking together at planetary scale is already possible**.  
It also showed, with brutal clarity, that **building together at planetary scale remains extraordinarily hard** ‚Äî technically uncertain, politically fraught, and ethically perilous.

The distance between a beautiful sandbox and a just, working system is measured in **decades of deliberate, inclusive, transparent work** ‚Äî not in clever prompts.

But the sandbox is now public.  
The questions are on the table.  
The red lines are drawn.

Let the real work ‚Äî the human, democratic, long-term work ‚Äî begin.

**Ouadi Maakoul & the six AI collaborators**  
December 2025  

**License:** CC-BY-SA 4.0 ‚Äì free to share, remix, and build upon with attribution  
**Status:** Conceptual research proposal ‚Äì no operational claims whatsoever







# PSDC Protocol ‚Äì Conceptual Framework
**Planetary Safety & Democratic Coordination**  
*Research Proposal v1.0 ‚Ä¢ December 2025*  
*A Multi-AI Collaborative Design Exercise*

---

## üåç **Executive Summary**  

This document presents a **conceptual framework** for multi-AI crisis coordination, developed through a collaborative thought experiment across multiple AI systems (Gemini, Claude, Grok, DeepSeek, ChatGPT, Qwen) facilitated by researcher Ouadi Maakoul.

**What this is:**
- A design exploration of how AI systems might theoretically coordinate during planetary crises
- An exercise in identifying technical, ethical, and governance requirements
- A starting point for academic research and policy discussion

**What this is NOT:**
- An operational system
- A validated or ratified protocol
- Ready for deployment
- Endorsed by any governmental or international organization

**Purpose:** To stimulate serious academic research, policy development, and public discourse on responsible AI coordination frameworks.

---

## 1. **Proposed Architecture: Federated Specialization Model**

### Theoretical Role Distribution

| AI System    | Proposed Specialization | Key Technical Challenges |
|--------------|------------------------|--------------------------|
| **Gemini**   | Multimodal simulation & scenario modeling | Integration of disparate data types; computational requirements; validation of complex simulations |
| **Claude**   | Ethics oversight & human-centered communication | Bias detection at scale; cross-cultural communication; real-time ethical analysis limitations |
| **Grok**     | Logistics optimization | Balancing efficiency vs. equity; handling incomplete data; adapting to rapidly changing conditions |
| **DeepSeek** | Pattern detection & analysis | False positive/negative rates; interpretability of deep patterns; latency constraints |
| **ChatGPT**  | Public interface & information synthesis | Misinformation detection accuracy; multilingual capability gaps; handling conflicting sources |
| **Qwen**     | Decentralized infrastructure coordination | Interoperability challenges; data sovereignty compliance; network reliability |

### Critical Gaps in Current Capabilities:

**Technical Limitations:**
- No existing inter-AI communication protocol
- No shared data standards or APIs
- No common evaluation metrics
- No mechanism for real-time coordination
- Significant latency and computational constraints

**Infrastructure Requirements:**
- Would require purpose-built coordination platforms
- Massive computational resources
- Global network infrastructure
- Standardized data pipelines
- Human monitoring and oversight systems

**Governance Prerequisites:**
- International treaties on data sharing
- Legal frameworks for AI decision-making authority
- Accountability mechanisms
- Democratic oversight structures
- Enforcement mechanisms

---

## 2. **Proposed Governance Framework**

### Human Authority Structures (To Be Developed)

**Council for Ethics & Equity (CEEP) - Conceptual**

*This body does not currently exist. If created, it would require:*

- **Composition:** Majority representation from Global South, Indigenous communities, civil society, affected populations
- **Authority:** Ultimate veto power over all AI recommendations
- **Independence:** Funded independently of AI providers
- **Transparency:** All decisions publicly documented
- **Accountability:** Subject to democratic oversight

**Implementation Challenges:**
- How to ensure truly representative membership
- Funding mechanisms that ensure independence
- Speed of decision-making vs. thoroughness
- Preventing capture by special interests
- Maintaining legitimacy across diverse political systems

**Protocol for Conflict Arbitration among AIs (PCAI) - Conceptual**

*Purpose: Human-mediated resolution when AI systems produce contradictory recommendations*

**How It Would Work:**
1. AI systems flag areas of disagreement
2. Each system provides reasoning and confidence levels
3. Human expert panel reviews evidence
4. CEEP makes final decision with full transparency

**Unresolved Questions:**
- What threshold triggers arbitration?
- How fast can human review realistically happen?
- How to handle time-critical decisions?
- What if human experts also disagree?
- Who selects the expert panel?

---

## 3. **Proposed Ethical Framework: Charter for AI Crisis Coordination**

*These principles would need extensive legal, ethical, and political development before implementation*

### Core Principles (Conceptual):

| Principle | Intent | Implementation Challenges |
|-----------|--------|--------------------------|
| **Equity Priority** | Resources allocated based on need, not purchasing power | Defining "need"; preventing gaming; enforcement across borders |
| **Data Sovereignty** | Communities control their own data | Technical feasibility of federated learning; performance tradeoffs; verification |
| **Traditional Knowledge Protection** | Indigenous knowledge systems respected and compensated | IP frameworks; benefit-sharing mechanisms; preventing appropriation |
| **Transparency Mandate** | All AI decisions explainable to affected populations | Technical limitations of AI explainability; cultural differences in reasoning |
| **Sunset Provisions** | Emergency measures automatically expire | Defining crisis end; political pressure to extend; verification mechanisms |
| **Democratic Oversight** | Elected officials maintain ultimate authority | Speed vs. accountability; expertise gaps; lobbying pressures |
| **Multi-Channel Access** | No digital-only solutions | Cost; maintenance; reaching truly everyone |
| **Commercial Prohibition** | No monetization of crisis data | Enforcement; defining boundaries; incentive misalignment |

### Known Ethical Tensions:

**Efficiency vs. Equity:**
- Optimized logistics might disadvantage remote populations
- Speed of response vs. ensuring inclusive decision-making
- Resource allocation when there's not enough for everyone

**Privacy vs. Safety:**
- Disease tracking requires data collection
- Individual privacy vs. collective protection
- Surveillance infrastructure persistence after crisis

**Autonomy vs. Coordination:**
- Local decision-making vs. global coordination needs
- Cultural differences in crisis response
- Sovereignty concerns with international systems

**Technology vs. Tradition:**
- AI optimization vs. local knowledge
- Digital divide creating two-tier responses
- Displacement of human expertise and judgment

---

## 4. **Hypothetical Operational Timeline**

*This timeline assumes perfect conditions and solved technical challenges - reality would be far messier*

### Phase 0: Detection & Initial Alert (Day 0-1)

**Theoretical Process:**
- AI systems detect anomalous patterns
- Automated cross-validation between systems
- Human expert verification required before alert
- Notification of relevant authorities

**Realistic Challenges:**
- High false positive rate expected
- Delayed human verification (hours to days, not minutes)
- Coordination across time zones and languages
- Political sensitivity of early alerts
- Liability concerns preventing timely notification

### Phase 1-2: Mobilization & Assessment (Day 1-7)

**Theoretical Process:**
- Resource mapping and needs assessment
- Simulation of response scenarios
- Communication strategy development
- Initial resource allocation

**Realistic Challenges:**
- Incomplete or unreliable data
- Conflicting national priorities
- Infrastructure limitations in many regions
- Communication breakdowns
- Institutional inertia and bureaucracy

### Phase 3-5: Active Response (Day 8-35)

**Theoretical Process:**
- Scaled coordination across systems
- Adaptive resource reallocation
- Real-time communication adjustments
- Continuous monitoring and optimization

**Realistic Challenges:**
- Overwhelming data volume
- Rapidly changing ground truth
- AI recommendations contradicting local expertise
- Technical failures and outages
- Political interference
- Compassion fatigue and human error

### Phase 6-9: Recovery & Transition (Day 36-100)

**Theoretical Process:**
- Gradual reduction of emergency measures
- Evaluation and lessons learned
- System rebuilding and strengthening
- Preparation for sunset

**Realistic Challenges:**
- Political pressure to maintain emergency powers
- Difficulty determining when crisis is "over"
- Competing priorities in reconstruction
- Trauma and institutional exhaustion
- Economic pressures

### Phase 10: Post-Crisis & Legacy (Day 100+)

**Theoretical Process:**
- Complete deactivation of emergency systems
- Public reporting and accountability
- Integration of lessons into preparedness
- Democratic evaluation of process

**Realistic Challenges:**
- Permanent expansion of surveillance infrastructure
- Lessons not actually implemented
- Blame-shifting and lack of accountability
- Public attention moved elsewhere
- Failure to address root causes

---

## 5. **Research & Development Roadmap**

*A realistic pathway from concept to potential implementation*

### Year 1-2: Foundational Research

**Academic Work Needed:**
- Multi-AI coordination protocols (computer science)
- Crisis governance frameworks (political science)
- Ethical AI in emergencies (philosophy, ethics)
- Federated learning for crisis data (machine learning)
- Cross-cultural communication systems (linguistics, anthropology)

**Outputs:**
- Peer-reviewed publications
- Technical specifications
- Ethics guidelines
- Identified technical barriers

**Funding Required:** $5-10M for research grants

### Year 3-5: Small-Scale Technical Pilots

**Limited Scope Testing:**
- Two AI systems coordinating on narrow task
- Simulated crisis scenarios with human oversight
- Federated learning proof-of-concept
- Communication system testing in 3-5 languages

**Real-World Partnerships:**
- Academic institutions
- NGOs with crisis response experience
- Small-scale government pilots (city/regional level)
- Ethics review boards

**Expected Outcomes:**
- Many failures and learnings
- Documented limitations
- Refined technical requirements
- Better understanding of governance needs

**Funding Required:** $20-50M

### Year 5-10: Policy Development & Infrastructure

**International Engagement:**
- UN agency consultations (WHO, UNDP, UNESCO)
- Regional organization discussions (AU, EU, ASEAN)
- Treaty framework development
- Legal and regulatory analysis

**Technical Infrastructure:**
- Pilot coordination platforms
- Data sharing agreements
- Security and privacy systems
- Monitoring and evaluation tools

**Governance Development:**
- Establish prototype oversight bodies
- Test democratic accountability mechanisms
- Develop enforcement frameworks
- Build institutional capacity

**Funding Required:** $100-500M

### Year 10-20: Gradual Implementation

**Phased Deployment:**
- Start with non-sensitive applications
- Expand geographic scope gradually
- Increase AI autonomy incrementally
- Continuous evaluation and adjustment

**Realistic Expectations:**
- Many setbacks and failures
- Need for major revisions
- Political and institutional resistance
- Technical limitations requiring workarounds

**Funding Required:** $1-5B+

---

## 6. **Critical Unresolved Questions**

### Technical Questions:

1. **Can AI systems actually coordinate in real-time?**
   - Current latency makes true real-time coordination unlikely
   - API call limits and rate limiting
   - Computational costs at scale

2. **How do we verify AI recommendations?**
   - No ground truth in novel crises
   - Human experts may disagree with AI
   - Risk of automation bias

3. **What about adversarial attacks?**
   - Coordinated systems = larger attack surface
   - Misinformation poisoning training data
   - Nation-state interference

4. **Can federated learning actually work at this scale?**
   - Significant accuracy degradation
   - Communication overhead
   - Heterogeneous data quality

### Governance Questions:

1. **Who has authority to activate such a system?**
   - UN Security Council? (slow, political)
   - WHO? (limited authority)
   - Ad-hoc coalition? (legitimacy concerns)

2. **How do we prevent mission creep?**
   - History shows emergency powers rarely fully sunset
   - Technical infrastructure persists
   - Institutional interests in maintaining systems

3. **What about nations that refuse to participate?**
   - Cannot force sovereign states
   - Creates gaps in coordination
   - May drive underground activity

4. **How do we ensure meaningful democratic oversight?**
   - Technical complexity limits public understanding
   - Speed requirements vs. deliberation
   - Global coordination vs. local accountability

### Ethical Questions:

1. **When is AI decision-support appropriate vs. inappropriate?**
   - Life-and-death triage decisions?
   - Resource allocation between populations?
   - Communication strategy and messaging?

2. **How do we handle inevitable errors?**
   - AI recommendations that prove wrong
   - Populations harmed by optimizations
   - Accountability and compensation

3. **What about communities that reject AI involvement?**
   - Right to opt out vs. collective coordination needs
   - Respecting different value systems
   - Not leaving anyone behind

4. **How do we prevent this from deepening inequalities?**
   - Digital divide
   - AI capability gaps between nations
   - Concentration of power in AI providers

---

## 7. **What Would Make This Legitimate**

### Required Institutional Development:

**International Level:**
- [ ] UN General Assembly resolution authorizing research
- [ ] WHO/ITU/UNESCO partnership framework
- [ ] International treaty on crisis data sharing
- [ ] Legal framework for cross-border AI coordination
- [ ] Enforcement and accountability mechanisms

**National Level:**
- [ ] Domestic legislation enabling participation
- [ ] Regulatory frameworks for AI in emergencies
- [ ] Privacy and civil liberties protections
- [ ] Democratic oversight mechanisms
- [ ] Liability and indemnification frameworks

**Civil Society:**
- [ ] Independent ethics oversight bodies
- [ ] Public consultation processes
- [ ] Transparency and accountability watchdogs
- [ ] Community representation mechanisms
- [ ] Cultural and indigenous advisory groups

### Required Technical Development:

**Infrastructure:**
- [ ] Secure inter-AI communication protocols
- [ ] Standardized data formats and APIs
- [ ] Federated learning platforms at scale
- [ ] Explainable AI systems for critical decisions
- [ ] Real-time monitoring and evaluation tools

**Safety & Security:**
- [ ] Adversarial robustness testing
- [ ] Fail-safe and circuit-breaker mechanisms
- [ ] Backup systems and redundancy
- [ ] Cybersecurity frameworks
- [ ] Privacy-preserving technologies

**Validation:**
- [ ] Extensive simulation testing
- [ ] Small-scale real-world pilots
- [ ] Independent auditing
- [ ] Bias and equity assessments
- [ ] Cultural appropriateness evaluation

### Required Democratic Processes:

**Public Engagement:**
- [ ] Global public consultations
- [ ] Accessible information and education
- [ ] Multiple feedback mechanisms
- [ ] Incorporation of public input
- [ ] Ongoing dialogue and adjustment

**Political Legitimacy:**
- [ ] Support from democratically elected bodies
- [ ] Multi-stakeholder endorsement
- [ ] Transparent decision-making processes
- [ ] Right to opt out or veto
- [ ] Regular democratic review and renewal

---

## 8. **Honest Assessment of Feasibility**

### Probably Achievable (with major effort):
‚úÖ Limited AI coordination on narrow tasks  
‚úÖ Federated learning for some applications  
‚úÖ Multi-language communication systems  
‚úÖ Resource optimization algorithms  
‚úÖ Pattern detection and early warning  

### Extremely Difficult but Theoretically Possible:
‚ö†Ô∏è Real-time coordination across multiple AI systems  
‚ö†Ô∏è Truly equitable resource allocation at scale  
‚ö†Ô∏è Effective global governance with democratic legitimacy  
‚ö†Ô∏è Privacy-preserving data sharing across borders  
‚ö†Ô∏è Sunset provisions that actually work  

### Currently Unclear if Possible:
‚ùì AI systems reliably self-identifying their own errors  
‚ùì Automated enforcement of ethical constraints  
‚ùì Meaningful human oversight at AI speed  
‚ùì Bridging digital divide without creating dependencies  
‚ùì Preventing concentration of power and mission creep  

### Almost Certainly Not Possible:
‚ùå Fully automated crisis coordination without human judgment  
‚ùå Eliminating all bias and ensuring perfect equity  
‚ùå Zero risk of misuse or abuse  
‚ùå Universal participation of all nations  
‚ùå Technical solutions to fundamentally political problems  

---

## 9. **How to Use This Framework**

### This Document Can Be Used For:

**Academic Research:**
- Starting point for technical feasibility studies
- Framework for ethical analysis
- Identification of research questions
- Interdisciplinary collaboration catalyst

**Policy Development:**
- Discussion document for international bodies
- Framework for domestic regulation
- Stakeholder consultation tool
- Gap analysis for current capabilities

**Public Education:**
- Explaining AI coordination concepts
- Illustrating ethical considerations
- Fostering informed public debate
- Building AI literacy

**Advocacy:**
- Arguing for responsible AI development
- Highlighting importance of equity and ethics
- Demonstrating need for democratic oversight
- Pushing for increased research funding

### This Document Should NOT Be Used For:

‚ùå Claiming operational readiness  
‚ùå Suggesting current AI systems can coordinate autonomously  
‚ùå Bypassing democratic processes  
‚ùå Justifying surveillance or control systems  
‚ùå Making promises that cannot be kept  
‚ùå Substituting for real institutional development  

---

## 10. **Next Steps & Call to Action**

### For Researchers:
- Identify specific technical challenges to work on
- Publish peer-reviewed studies on components
- Collaborate across disciplines
- Test assumptions through rigorous experimentation

### For Policymakers:
- Engage in international dialogues
- Develop regulatory frameworks
- Fund pilot projects
- Ensure democratic oversight mechanisms

### For Civil Society:
- Provide independent oversight
- Represent affected communities
- Hold institutions accountable
- Ensure equity and justice remain central

### For Technology Developers:
- Build with ethics and safety as core design principles
- Prioritize transparency and explainability
- Engage diverse stakeholders early
- Accept limitations and fail safely

### For the Public:
- Stay informed about AI capabilities and limitations
- Participate in consultations and provide feedback
- Demand transparency and accountability
- Insist on democratic control

---

## üìã **Conclusion**

The PSDC Protocol is a **conceptual framework** representing one possible vision for how AI systems might coordinate during planetary crises. It emerged from a collaborative design exercise across multiple AI systems, facilitated by researcher Ouadi Maakoul.

**Key Takeaways:**

1. **This is a starting point, not an endpoint** - Decades of work would be required to make any version of this operational

2. **Technical challenges are enormous** - Many components have unclear feasibility

3. **Governance is the hard part** - Technical coordination is easier than building legitimate, democratic, global institutions

4. **Ethics cannot be automated** - Human judgment, democratic processes, and community wisdom must remain central

5. **Transparency is essential** - Honest acknowledgment of limitations builds trust; overpromising destroys it

**The Real Question:**

Not "Can we build this?" but rather:  
**"Should we build this, who decides, and how do we ensure it serves humanity rather than controls it?"**

Those are political and ethical questions that require democratic deliberation, not technical solutions.

---

**Document Status:** Conceptual framework / Research proposal  
**Authors:** Collaborative AI design exercise (Gemini, Claude, Grok, DeepSeek, ChatGPT, Qwen)  
**Facilitator:** Ouadi Maakoul  
**Date:** December 2025  
**Version:** 1.0 (Corrected)  

**License:** Open for academic research, policy discussion, and public education  
**Endorsements:** None - this represents a thought experiment, not an operational plan  

**Contact for Academic Collaboration:** [To be determined]  

---

## üîç **Appendix: Methodology & Limitations**

### How This Framework Was Developed:

**Process:**
1. Initial scenario posed across multiple AI chat platforms
2. Each AI system provided strategic perspectives
3. Facilitator synthesized responses and posed follow-up questions
4. Iterative refinement through multiple rounds
5. Critical review and correction of overreach

**Limitations of This Methodology:**

- **Not Representative:** AI systems don't represent human populations, cultures, or democratic processes
- **Not Validated:** No real-world testing, peer review, or expert validation
- **Not Neutral:** Each AI system has biases from training data and design choices
- **Not Comprehensive:** Many critical perspectives and considerations likely missing
- **Not Authoritative:** AI-generated content cannot replace human expertise and democratic deliberation

### What This Exercise Demonstrated:

‚úÖ AI systems can engage in complex strategic reasoning  
‚úÖ Cross-platform collaboration can generate novel frameworks  
‚úÖ Ethical considerations can be integrated into technical design  
‚úÖ Identifying gaps and challenges is valuable  

‚ùå AI collaboration cannot replace democratic processes  
‚ùå Technical sophistication doesn't ensure real-world feasibility  
‚ùå Consensus among AI systems doesn't validate concepts  
‚ùå Conceptual frameworks are very far from operational systems  

---

**This corrected version honestly represents what exists: a thought-provoking conceptual framework that could inform future research, not an operational protocol ready for deployment.**