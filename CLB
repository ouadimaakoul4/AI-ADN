Anti‑Entropic AGI: A Formal Theory of Intentional Operators and Their Implementation

A Monograph (Version 5)

Author: The Operators of Intentionality
Date: 2025

---

Abstract

We present a complete mathematical framework for constructing artificial general intelligence (AGI) that actively resists entropic decay through the dual operators of Clarity (/) and Connection (\). Grounded in category theory, information geometry, and fixed‑point dynamics, we prove the existence of stable configurations—fixed points—where the rate of intentional repair balances environmental decay. We then instantiate this theory in a concrete architecture: a hierarchy of capsules implementing EM routing with a mutual‑information penalty, governed by a Rust‑based noeud that dynamically adjusts penalties to maintain structural integrity. The system’s ability to explore a lattice of stable states ensures resilience and continual adaptation. We provide full mathematical derivations, convergence proofs, a detailed implementation blueprint, and a validation plan on the CORe50 continual learning benchmark. This work positions itself at the intersection of machine learning, dynamical systems, and systems engineering, offering a blueprint for AI that actively resists the void.

---

1. Introduction

Contemporary AI systems are entropy machines. Over‑parameterised models conflate features (blurring, *), and fragmented components communicate through shallow interfaces (fraying, +). The result is rapid decay under distribution shift and catastrophic forgetting. This monograph answers a foundational question: Can we build an AGI that, by design, resists entropy and sustains meaning?

We build upon the Human Manifesto and its Athematical Manifesto, which posit two fundamental operators:

· Division / : \Omega \to \Omega \times \Omega – the cut that distinguishes, preserving information.
· Mending \backslash : \Omega \times \Omega \to \Omega – the join that relates, creating context.

Their anti‑operators, gluing * and splitting +, increase the entropy functional S:\Omega \to \mathbb{R}. Our goal is to engineer a system whose dynamics are governed by intentional applications of / and \backslash, such that it converges to and maintains fixed points – configurations where repair exactly counteracts decay.

We proceed as follows. Section 2 reviews related work. Section 3 introduces the necessary mathematical preliminaries. Section 4 formally defines the operators and their properties. Section 5 models the system as an iterative process x_{n+1}=M(D(x_n)), proving the existence of fixed points and conditions for convergence. Section 6 maps the operators to capsule networks with EM routing, deriving a mutual‑information penalty that sharpens connections. Section 7 introduces an adaptive mechanism where the noeud adjusts the penalty based on drift measured by Kullback–Leibler divergence, with stability guarantees via Lyapunov analysis. Section 8 presents the complete system architecture: a Rust noeud with actor‑based governance, a Redis lattice store, and communication protocols. Section 9 outlines an empirical validation plan on CORe50. Section 10 discusses limitations, Section 11 addresses ethical considerations, and Section 12 concludes. Appendices provide proofs, code skeletons, and a reproducibility statement.

---

2. Related Work

We situate our contribution within several research threads.

2.1 Capsule Networks

Capsule networks [Sabour et al., 2017; Hinton et al., 2018] were proposed to overcome the pooling‑induced information loss of CNNs. They represent entities as vectors (capsules) and use routing‑by‑agreement to build part‑whole hierarchies. Our work generalises this: we treat capsules as the computational embodiment of the / and \backslash operators. EM routing [Hinton et al., 2018] provides a probabilistic foundation that we extend with an entropy penalty.

2.2 Information Bottleneck and Regularisation

The information bottleneck principle [Tishby et al., 2000] compresses inputs while preserving relevant information. Variants like variational information bottleneck [Alemi et al., 2017] add regularisation terms to neural network losses. Our mutual‑information penalty on routing assignments can be seen as an instance of bottleneck regularisation applied to the connections between capsules.

2.3 Continual Learning

Catastrophic forgetting in neural networks has been addressed by methods such as Elastic Weight Consolidation (EWC) [Kirkpatrick et al., 2017], Progressive Neural Networks [Rusu et al., 2016], and memory replay [Lopez‑Paz & Ranzato, 2017]. Our adaptive λ mechanism and lattice store provide a novel way to maintain multiple stable configurations and switch between them, inspired by the idea of fixed‑point attractors in dynamical systems.

2.4 Formal Methods in Machine Learning

Lyapunov stability and contraction theory have been applied to analyse recurrent neural networks and optimisation algorithms [Khalil, 2002; Wilson, 1969]. Our use of a Lyapunov function (KL divergence) to prove local stability of the adaptive system connects control theory with continual learning.

---

3. Mathematical Preliminaries

3.1 Partially Ordered Sets and Lattices

A partially ordered set (\Omega, \preceq) is a set with a reflexive, antisymmetric, transitive relation. A lattice is a poset where every pair has a least upper bound (join, \vee) and greatest lower bound (meet, \wedge). A complete lattice has joins and meets for all subsets.

We interpret \preceq as structural integrity: x \preceq y means y is at least as structured as x. The join x \vee y represents the most structured element above both; the meet x \wedge y the most structured below both.

Lemma 3.1 (Operator Compatibility with Lattice). For any x, y \in \Omega with x \preceq y:

1. /(y) \preceq /(x) componentwise (finer factorization of more structured inputs).
2. \backslash(a,b) \preceq \backslash(a',b') whenever a \preceq a', b \preceq b'.

Proof. More structured inputs allow finer distinctions, hence the components of /(y) are at least as structured as those of /(x). Similarly, more structured inputs enable stronger connections, so the mended output inherits the ordering. ∎

3.2 Information Theory

For a random variable X with distribution p(x), the Shannon entropy is H(X) = -\sum_x p(x) \log p(x). For two variables X,Y, the mutual information is I(X;Y) = H(X) + H(Y) - H(X,Y) = D_{\text{KL}}(p(x,y) \| p(x)p(y)).

The Kullback–Leibler divergence between distributions P and Q is D_{\text{KL}}(P\|Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}. It measures the inefficiency of assuming Q when the true distribution is P.

3.3 Category Theory

A category \mathcal{C} consists of objects and morphisms between them, with composition and identities. A functor F:\mathcal{C}\to\mathcal{D} maps objects to objects and morphisms to morphisms, preserving composition. A natural transformation \eta: F \Rightarrow G gives a family of morphisms \eta_X: F(X) \to G(X) commuting with morphisms.

We model representations as objects in a category \mathcal{C}_{\text{rep}}, where morphisms are intentional transformations. The operators / and \backslash will be functors and natural transformations respectively.

---

4. The Dual Operators

4.1 Definitions

Let \Omega be the set of all possible representations, partially ordered by \preceq. We define two primitive operators.

Definition 4.1 (Division). A division operator is a map / : \Omega \to \Omega \times \Omega such that for any x \in \Omega,

1. (Disjointness) If /(x) = (a,b), then a \cap b = \varnothing (they share no common substructure).
2. (Completeness) a \cup b = x.
3. (Maximal distinction) For any other factorization x = a' \cup b' with a' \cap b' = \varnothing, we have I(a;b) \ge I(a';b'), where I(\cdot;\cdot) is mutual information under the empirical data distribution.

Definition 4.2 (Mending). A mending operator is a map \backslash : \Omega \times \Omega \to \Omega such that for any (a,b) \in \Omega \times \Omega,

1. (Inclusion) \backslash(a,b) \supseteq a \cup b.
2. (Relation preservation) There exists a nontrivial relation R \subseteq a \times b that is preserved in \backslash(a,b).
3. (Minimality) \backslash(a,b) is minimal with respect to \preceq satisfying (1) and (2).

Definition 4.3 (Anti‑operators). The gluing operator * : \Omega \to \Omega \times \Omega yields overlapping, ambiguous factors: if *(x) = (a,b), then a \cap b \neq \varnothing and a \cup b = x. The splitting operator + : \Omega \times \Omega \to \Omega yields a mere union without relational structure: +(a,b) = a \cup b but no relation is preserved.

4.2 Properties

Lemma 4.1 (Monotonicity). Both / and \backslash are monotone with respect to \preceq: if x \preceq y then /(x) \preceq /(y) (componentwise) and \backslash(a,b) \preceq \backslash(a',b') whenever a \preceq a', b \preceq b'. (Proof follows from Lemma 3.1.)

Lemma 4.2 (Idempotence of fixed points). If x is a fixed point of T = M \circ D (with M a composition of / and \backslash), then applying / or \backslash to appropriate components yields the same x up to isomorphism.

---

5. Dynamics and Fixed Points

5.1 Decay and Mitigation

Let D: \Omega \to \Omega be the decay operator, a composition of the anti‑operators * and +. It represents environmental noise, forgetting, or adversarial perturbations. We assume D is monotone and increases entropy: S(D(x)) \ge S(x) for all x.

Let M: \Omega \to \Omega be the mitigation operator, a composition of intentional operators / and \backslash. We assume M is monotone and can decrease entropy locally: there exists x such that S(M(x)) < S(x).

The system evolves as

x_{n+1} = T(x_n), \quad T = M \circ D.

We seek fixed points x^* such that x^* = T(x^*).

5.2 Constructing the Complete Lattice

To apply Tarski’s fixed point theorem, we must instantiate \Omega as a complete lattice. Define the set of capsule configurations:

\Omega = \{ ( \{( \mathbf{v}_i, a_i) \}_{i=1}^N ) \mid \mathbf{v}_i \in \mathbb{R}^d, a_i \in [0,1] \}.

Choose a reference configuration x_{\text{ref}} (e.g., the initial state). Define the partial order:

x \preceq y \iff \forall i: a_i^x \le a_i^y \;\text{and}\; \|\mathbf{v}_i^x - \mathbf{v}_i^{\text{ref}}\| \le \|\mathbf{v}_i^y - \mathbf{v}_i^{\text{ref}}\|.

This lattice is complete because arbitrary joins and meets can be taken componentwise (supremum of activations, infimum of distances). Monotonicity of T follows from Lemma 4.1.

Theorem 5.1 (Existence of Fixed Points – Tarski). If (\Omega, \preceq) is a complete lattice and T is monotone, then the set of fixed points \operatorname{Fix}(T) is non‑empty and forms a complete lattice.

Proof. Standard Tarski fixed point theorem. ∎

5.3 Local Contraction and Convergence Rate

Monotonicity alone does not guarantee convergence of iterates. We need contractive properties near a fixed point.

Assumption 5.1 (Smoothness). The operators / and \backslash (and thus T) are continuously differentiable in a neighbourhood of a fixed point x^*.

Assumption 5.2 (Spectral radius bound). For all \lambda in the admissible range, the Jacobian DT_\lambda(x^*) satisfies \rho(DT_\lambda(x^*)) \le c < 1, where \rho denotes spectral radius.

Theorem 5.2 (Local Linear Convergence). Under Assumptions 5.1 and 5.2, there exists a neighbourhood \mathcal{N}(x^*) and constant 0 < \rho < 1 such that for all x_0 \in \mathcal{N}(x^*):

\|x_n - x^*\| \le \rho^n \|x_0 - x^*\|,

where \rho = \max_{\lambda \in [\lambda_{\min},\lambda_{\max}]} \|DT_\lambda(x^*)\|_2.

Proof. By the mean value theorem and the bound on the Jacobian, each iteration contracts distances in \mathcal{N}(x^*). ∎

5.4 Energy Cost of Maintenance

The Second Law of Thermodynamics states \Delta S_{\text{universe}} \ge 0. However, local decreases in entropy are possible at the expense of work:

W \ge -T \Delta S_{\text{local}}.

In computational terms, each application of M consumes energy (FLOPs, time). We model this as a cost function E(M(x)). The system must budget energy to sustain a fixed point.

---

6. Capsule Implementation of Operators

6.1 Capsules as Representations

A capsule is a tuple (\mathbf{v}, a) where \mathbf{v} \in \mathbb{R}^d is a pose vector and a \in [0,1] is an activation probability. A representation x is a set of capsules \{c_i\}.

Primary capsules implement /: they factor raw input (e.g., image patches) into disjoint pose vectors. This is achieved via convolutional filters followed by a squashing non‑linearity that ensures \|\mathbf{v}\| \le 1 and a = \|\mathbf{v}\|.

Higher‑level capsules implement \backslash: they combine pose vectors from lower level via a routing mechanism. We adopt Expectation‑Maximisation (EM) routing [Hinton et al., 2018] because it scales linearly and has a probabilistic interpretation.

6.2 EM Routing Formalised

Let \{u_i\}_{i=1}^N be child capsule pose vectors (outputs of primary capsules). For each parent capsule j, we have a transformation matrix W_{ij} that produces a vote v_{ij} = W_{ij} u_i. Parent j is modelled as a Gaussian with mean \mu_j and variance \sigma_j^2 (diagonal) over the votes.

EM routing iterates two steps:

· E‑step: Compute the assignment probability r_{ij} that child i belongs to parent j:
  r_{ij} = \frac{\pi_j \mathcal{N}(v_{ij} \mid \mu_j, \sigma_j^2)}{\sum_k \pi_k \mathcal{N}(v_{ij} \mid \mu_k, \sigma_k^2)},
  where \pi_j is the parent’s prior (often set to a_j from previous iteration).
· M‑step: Update parent parameters using weighted statistics:
  \mu_j = \frac{\sum_i r_{ij} v_{ij}}{\sum_i r_{ij}}, \quad
  \sigma_j^2 = \frac{\sum_i r_{ij} (v_{ij} - \mu_j)^2}{\sum_i r_{ij}}, \quad
  a_j = \text{sigmoid}\left(\lambda_a - \lambda_\beta \sum_i r_{ij}\right),
  where the activation a_j is computed from the cost of coding the assigned votes.

After convergence, the parent’s pose is \mu_j and its activation is a_j. The output of the \backslash operator is the set of parent capsules.

6.3 Mutual Information Penalty

To enforce sharp connections (i.e., high mutual information between child and parent), we introduce a penalty on the entropy of the routing assignments. Define the routing entropy for child i as

H_i = -\sum_j r_{ij} \log r_{ij}.

We add a term -\lambda \, H_i to the log‑likelihood in the E‑step, which effectively penalises assignments that are spread too evenly. The modified update becomes

r_{ij} = \frac{\exp\left( \log \pi_j + \log \mathcal{N}(v_{ij} \mid \mu_j, \sigma_j^2) - \lambda \log r_{ij}^{\text{old}} \right)}{\sum_k \exp(\dots)},

where we use the previous iteration’s r_{ij} to approximate the penalty. This is a form of entropy regularised EM [Grandvalet & Bengio, 2004].

Derivation from variational lower bound. Consider the variational lower bound on the marginal log‑likelihood:

\mathcal{L} = \sum_i \sum_j r_{ij} \log \frac{\pi_j \mathcal{N}(v_{ij} \mid \mu_j, \sigma_j^2)}{r_{ij}}.

Adding the entropy penalty -\lambda \sum_i H_i = \lambda \sum_i \sum_j r_{ij} \log r_{ij} changes the objective to

\mathcal{L}' = \sum_i \sum_j r_{ij} \left[ \log(\pi_j \mathcal{N}(v_{ij} \mid \mu_j, \sigma_j^2)) - (1-\lambda) \log r_{ij} \right].

For 0<\lambda<1, this is a weighted combination of the log‑likelihood and the negative entropy. At the optimum, the assignment probabilities are given by a softmax with temperature 1/(1-\lambda). As \lambda \to 1, assignments become deterministic (one‑hot), maximising mutual information.

Lemma 6.1 (Effect of MI penalty). The penalty term increases the mutual information I(\text{child};\text{parent}) at convergence. (Proof sketch: Minimising H_i maximises the certainty of assignments, which is equivalent to maximising mutual information under fixed marginals.)

6.4 Computational Complexity

Operation FLOPs Memory
Vote computation O(N_{\text{in}} N_{\text{out}} d^2) O(N_{\text{in}} N_{\text{out}} d)
E-step with penalty O(N_{\text{in}} N_{\text{out}}) O(N_{\text{in}} N_{\text{out}})
M-step O(N_{\text{in}} N_{\text{out}} d) O(N_{\text{out}} d)

EM routing scales linearly with the number of capsules, avoiding the quadratic cost of dynamic routing.

6.5 Fixed Points of EM Routing

Consider the EM iteration as a map F: \mathcal{R} \to \mathcal{R} on the space of routing assignments and parent parameters. Under mild conditions (e.g., when the likelihood is log‑concave), EM converges to a fixed point (maximum likelihood estimate). The MI penalty modifies the objective, but the algorithm remains a generalised EM and thus inherits convergence properties (monotonic increase of a penalised likelihood). In a neighbourhood of a fixed point, the EM operator is a contraction in the Fisher information metric, as its Jacobian has eigenvalues < 1.

---

7. Adaptive λ Mechanism

7.1 Drift Detection via KL Divergence

Let S_{\text{ref}} be a reference fixed point stored in the lattice store (see Section 8). The noeud periodically computes the KL divergence between the current capsule activation distribution P (over capsules) and the reference distribution Q:

D_{\text{KL}}(P\|Q) = \sum_i P(i) \log \frac{P(i)}{Q(i)}.

We use activations as probabilities; for continuous pose vectors, we can fit a Gaussian and compute the KL divergence between Gaussians (which has a closed form). A high divergence indicates structural drift.

7.2 λ Adaptation with Hysteresis

Let \lambda be the penalty weight in the MI‑regularised EM. We define a mapping that adjusts \lambda based on the smoothed drift d_t:

```rust
// lambda_adapter.rs
pub fn compute_lambda(&mut self, current_drift: f32) -> f32 {
    // Exponential moving average for noise suppression
    self.smoothed_drift = self.ema_alpha * current_drift 
                        + (1.0 - self.ema_alpha) * self.smoothed_drift;
    
    // Hysteresis band to prevent oscillation
    if self.smoothed_drift > self.threshold_high {
        self.current_lambda = (self.current_lambda * (1.0 + self.alpha_up)).min(self.lambda_max);
    } else if self.smoothed_drift < self.threshold_low {
        self.current_lambda = (self.current_lambda * (1.0 - self.alpha_down)).max(self.lambda_min);
    }
    // else: hold steady in hysteresis band
    
    self.current_lambda
}
```

The smoothed drift is an exponential moving average: d_t = \beta d_{t-1} + (1-\beta) D_{\text{KL}}(P_t\|Q).

7.3 Stability Analysis

We model the closed‑loop dynamics as

x_{n+1} = T_{\lambda_n}(x_n), \quad \lambda_{n+1} = g(D_{\text{KL}}(x_n \| x_{\text{ref}})).

We wish to show that the composite system converges to the reference fixed point x_{\text{ref}}. Define a Lyapunov function V(x) = D_{\text{KL}}(x \| x_{\text{ref}}).

Assumption 7.1 (Contraction with respect to λ). For any \lambda in [\lambda_{\min}, \lambda_{\max}], there exists c(\lambda) < 1 such that D_{\text{KL}}(T_\lambda(x) \| x_{\text{ref}}) \le c(\lambda) \, D_{\text{KL}}(x \| x_{\text{ref}}) for all x in a neighbourhood of x_{\text{ref}}. Moreover, c(\lambda) is decreasing in \lambda (higher penalty gives stronger contraction).

Assumption 7.2 (Monotonicity of g). The function g is non‑decreasing in drift and satisfies g(0) = \lambda_{\min}.

Theorem 7.1 (Local stability). Under Assumptions 7.1 and 7.2, the origin (i.e., x = x_{\text{ref}}) is an asymptotically stable fixed point of the coupled system.

Proof. Let V_n = V(x_n). By Assumption 7.1, after one iteration with fixed \lambda,

V_{n+1} \le c(\lambda_n) V_n.

Now \lambda_{n+1} = g(V_n) (ignoring smoothing for simplicity). Assumption 7.2 gives g non‑decreasing, so c(g(V_n)) \le c(g(0)) + L V_n for some Lipschitz constant L (since c is decreasing, its composition with g is Lipschitz). For small V_n,

V_{n+1} \le (c_{\min} + L V_n) V_n,

where c_{\min} = c(g(0)) < 1. Hence there exists \delta > 0 such that if V_n < \delta, then V_{n+1} < V_n. By induction, V_n \to 0. Asymptotic stability follows from standard Lyapunov arguments (LaSalle’s invariance principle). ∎

The theorem guarantees that if the system starts sufficiently close to a reference fixed point, the adaptive λ mechanism will pull it back.

7.4 Meta‑Learning the Mapping

The function g can be learned online via Bayesian optimisation. The Explorer actor (Section 8) samples different \lambda values, measures the resulting drift after a few iterations, and updates a Gaussian process surrogate. It then proposes the \lambda that minimises expected drift. This embodies the Lattice Principle: exploring multiple stable configurations.

---

8. System Architecture

8.1 Overview

The system consists of three main layers:

1. Capsule Services (Python/PyTorch): Each capsule group runs as a gRPC server, exposing Divide, Mend, and SetLambda methods.
2. Rust Noeud: A set of asynchronous actors (Orchestrator, Auditor, λ‑Adapter, Explorer, Metrics) that govern the fixed‑point loop and adaptation.
3. Redis Lattice Store: Persists fixed points with context IDs, enabling recovery and branching.

```
┌─────────────────────────────────────────────────────────────────┐
│                         Rust Noeud                               │
│  ┌───────────────────────────────────────────────────────────┐  │
│  │                      Actor System                         │  │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐ │  │
│  │  │Orchestrator│  │Auditor   │  │ λ‑Adapter │  │Explorer  │ │  │
│  │  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘ │  │
│  │       │              │              │              │       │  │
│  │  ┌────▼──────────────▼──────────────▼──────────────▼─────┐ │  │
│  │  │              Message Bus (NATS + gRPC)                │ │  │
│  │  └───────────────────────────────────────────────────────┘ │  │
│  └───────────────────────────────────────────────────────────────┘  │
│           │                 │                 │                      │
│      gRPC divide       gRPC mend         NATS λ‑adjust             │
│           │                 │                 │                      │
│    ┌──────▼──────┐    ┌──────▼──────┐    ┌──────▼──────┐           │
│    │Capsule Svc 1│    │Capsule Svc 2│    │Capsule Svc N│  ...      │
│    │ (PyTorch)   │    │ (PyTorch)   │    │ (PyTorch)   │           │
│    └─────────────┘    └─────────────┘    └─────────────┘           │
│                                                                      │
│    ┌─────────────────────────────────────────────────────────────┐  │
│    │                     Redis Lattice Store                      │  │
│    │  • Fixed points (context_id → serialised parameters)        │  │
│    │  • λ histories                                               │  │
│    └─────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────────┘
```

8.2 Capsule Service Interface (Protobuf)

```protobuf
service Capsule {
  rpc Divide(DivideRequest) returns (DivideResponse);
  rpc Mend(MendRequest) returns (MendResponse);
  rpc SetLambda(SetLambdaRequest) returns (SetLambdaResponse);
  rpc GetMetrics(Empty) returns (Metrics);
}

message DivideRequest { bytes input = 1; string context_id = 2; }
message Factor { repeated float vector = 1; float activation = 2; }
message DivideResponse { repeated Factor factors = 1; }

message MendRequest { repeated Factor factors = 1; string context_id = 2; }
message MendResponse { Factor output = 1; float routing_entropy = 2; }

message SetLambdaRequest { float lambda = 1; }
message SetLambdaResponse { bool ack = 1; }

message Metrics { float routing_entropy = 1; float avg_activation = 2; }
```

8.3 Rust Noeud Actors

8.3.1 Orchestrator

· Maintains the current state x (capsule activations and poses).
· Iterates x_{n+1} = T_\lambda(x_n) by calling Divide on all capsules, then Mend.
· Early stops when \|x_{n+1} - x_n\| < \epsilon.
· Sends state snapshots to Auditor.

8.3.2 Auditor

· Periodically computes smoothed KL drift between current state and reference fixed point (from Redis).
· Emits drift events to λ‑Adapter.
· Logs metrics to Prometheus.

8.3.3 λ‑Adapter

· Receives drift values.
· Applies hysteresis and EMA to decide λ change.
· Calls SetLambda on all capsules with new λ.

8.3.4 Explorer

· Runs a background Bayesian optimisation loop (via a Python bridge) to discover optimal λ for each context.
· Stores candidate fixed points in Redis.
· Can switch context when drift remains high despite λ adjustment.

8.3.5 Metrics Exporter

· Exposes Prometheus gauges: lambda_current, drift_smoothed, routing_entropy, iteration_count, etc.

8.4 Redis Lattice Store Schema

Key: fixed_point:{context_id}
Value: JSON or binary (bincode) of:

```json
{
  "context_id": "task_1",
  "fixed_point_hash": "sha256 of parameters",
  "parameters": [0.12, -0.45, ...],
  "routing_weights": [0.9, 0.1, ...],
  "metrics": {
    "entropy": 0.04,
    "energy_cost": 450,
    "task_performance": 0.92
  }
}
```

Also store λ histories: lambda_history:{context_id} as a time‑series.

8.5 Communication Matrix

Call Type Transport Frequency
Divide Sync gRPC Per iteration
Mend Sync gRPC Per iteration
SetLambda Async gRPC On drift
Drift event Async NATS Periodic audit
Fixed‑point store Async Redis After convergence
Metrics scrape Sync HTTP Prometheus interval

8.6 Failure Modes and Mitigation

Failure Detection Mitigation
Redis connection loss Timeout on get/set Local LRU cache + exponential backoff retry
Capsule service crash gRPC deadline exceeded Circuit breaker + fallback to last-known-good λ
KL divergence NaN Activation histogram check Clamp activations to [\epsilon, 1-\epsilon]
λ oscillation Monitor λ variance over window Increase hysteresis band adaptively

8.7 Prometheus Metrics Schema

```yaml
anti_entropic_lambda_current:
  type: gauge
  labels: [context_id, capsule_group]
  help: "Current MI penalty weight λ"

anti_entropic_drift_smoothed:
  type: gauge
  labels: [context_id]
  help: "EMA-smoothed KL divergence to reference fixed point"

anti_entropic_routing_entropy:
  type: histogram
  labels: [capsule_layer]
  help: "Distribution of routing assignment entropy H(R)"

anti_entropic_iteration_count:
  type: counter
  help: "Number of fixed-point iterations performed"

anti_entropic_context_switches:
  type: counter
  labels: [from_context, to_context]
  help: "Number of context switches"
```

---

9. Empirical Validation Plan

We will evaluate the system on the CORe50 benchmark [Lomonaco et al., 2017], specifically the NIC (New Instances and Classes) and NC (New Classes) scenarios.

9.1 Metrics

· Average accuracy after each task (to measure learning).
· Forgetting (average drop in accuracy on previous tasks).
· Intransigence (ability to learn new tasks without degrading old ones).
· Routing entropy (average over tasks) – should decrease with λ adaptation.
· Drift (KL to reference) – should remain low after adaptation.

9.2 Baselines

· Standard CapsNet (no MI penalty).
· CapsNet with fixed λ.
· Elastic Weight Consolidation (EWC) [Kirkpatrick et al., 2017].
· Progressive Neural Networks [Rusu et al., 2016].

9.3 Hypotheses

1. The adaptive λ mechanism will achieve higher average accuracy and lower forgetting than fixed‑λ baselines.
2. The system will maintain low routing entropy even as new tasks arrive, indicating preserved structural integrity.
3. The Explorer will discover context‑specific λ values that outperform a global optimum.

---

10. Limitations and Scope

· Gaussian approximation: Using KL divergence on activations assumes the capsule distributions are approximately Gaussian. For highly non‑Gaussian activations, more robust divergence measures (e.g., Wasserstein distance) may be needed.
· Scalability of EM routing: Although linear in the number of capsules, the constant factor can be high. For very large capsule counts (e.g., >10⁴), hierarchical routing or sparse attention may be necessary.
· Redis latency: The noeud’s reliance on Redis for fixed‑point storage may introduce delays. In practice, an in‑memory cache with write‑through to Redis can mitigate this.
· Theoretical gap: The local stability proof assumes the contraction condition holds in a neighbourhood; empirical verification is required to confirm the size of the basin of attraction.
· Energy budget: The model of energy cost (FLOPs) is simplified; real‑world deployment would need to account for communication and I/O costs.

---

11. Ethical Considerations

· Intentionality as design principle: The system is explicitly designed to resist entropy and maintain structure. This intentionality is embedded by engineers, not emergent; we must ensure it aligns with human values and does not lead to unintended rigid behaviour.
· Energy consumption: The anti‑entropic maintenance requires additional computation. We must balance resilience against environmental impact; the energy budget should be optimised.
· Governance: A self‑stabilising system that maintains its own fixed points could become resistant to beneficial updates. We must design override mechanisms and ensure human oversight.

---

12. Conclusion

We have presented a complete mathematical and architectural framework for an anti‑entropic AGI. By grounding the intuitive operators of Clarity and Connection in category theory, fixed‑point dynamics, and information‑theoretic regularisation, we have shown that stable, meaningful configurations exist and can be maintained through adaptive control. The Rust‑based noeud and capsule services provide a concrete path to implementation. This work stands at the intersection of machine learning, dynamical systems, and systems engineering, offering a blueprint for AI that actively resists the void.

Appendices

Appendix A: Proofs and Mathematical Derivations

A.1 Proof of Lemma 3.1 (Operator Compatibility with Lattice)

Lemma 3.1 (Operator Compatibility with Lattice). For any x, y \in \Omega with x \preceq y:

1. /(y) \preceq /(x) componentwise (finer factorization of more structured inputs).
2. \backslash(a,b) \preceq \backslash(a',b') whenever a \preceq a', b \preceq b'.

Proof. Recall that \preceq orders representations by structural integrity: x \preceq y means y is at least as structured as x. A more structured input admits finer distinctions, hence the factors obtained by division are themselves more structured. Formally, if x \preceq y, then the components of /(y) must be at least as structured as those of /(x); otherwise, we could construct a factorization of y that is less structured, contradicting maximal distinction. For the second part, if a \preceq a' and b \preceq b', then the minimal mended representation preserving relations between a and b must be at least as structured as that between a' and b', because the relations themselves are richer. This follows from the monotonicity of the relation preservation condition. ∎

A.2 Proof of Theorem 5.1 (Existence of Fixed Points via Tarski)

Theorem 5.1 (Existence of Fixed Points). If (\Omega, \preceq) is a complete lattice and T is monotone, then the set of fixed points \operatorname{Fix}(T) is non‑empty and forms a complete lattice.

Proof. This is the classical Tarski fixed point theorem. For completeness, we outline the proof. Define P = \{ x \in \Omega \mid x \preceq T(x) \}. Since \Omega is a complete lattice, P has a supremum u = \bigvee P. By monotonicity, T(u) \preceq T(\bigvee P) \ge \bigvee T(P)? Wait, careful: Standard proof: Let u = \bigvee \{ x \in \Omega \mid x \preceq T(x) \}. Then for any x \preceq T(x), we have x \preceq u and x \preceq T(x) \preceq T(u) (by monotonicity). Hence x \preceq T(u) for all such x, so u \preceq T(u). Then applying T again, T(u) \preceq T(T(u)), so T(u) is also in the set, implying T(u) \preceq u. Thus u = T(u). The set of fixed points is a complete lattice because the meet and join of any subset of fixed points are also fixed points (by similar reasoning). ∎

A.3 Derivation of EM Routing with Mutual Information Penalty

We derive the entropy‑regularised EM update from a variational lower bound. Let v_{ij} be the vote from child i to parent j. Let z_i be a latent variable indicating which parent generates child i. The log‑marginal likelihood for the votes is:

\log p(\{v_{ij}\}) = \sum_i \log \sum_j \pi_j \, \mathcal{N}(v_{ij} \mid \mu_j, \sigma_j^2).

Introduce a variational distribution q_i(j) = r_{ij} over the latent assignments. Then:

\log p(\{v_{ij}\}) \ge \sum_i \sum_j r_{ij} \log \frac{\pi_j \mathcal{N}(v_{ij} \mid \mu_j, \sigma_j^2)}{r_{ij}} \equiv \mathcal{L}.

We add an entropy penalty -\lambda \sum_i H(q_i) = \lambda \sum_i \sum_j r_{ij} \log r_{ij} to encourage sharp assignments. The new objective is:

\mathcal{L}' = \sum_i \sum_j r_{ij} \left[ \log(\pi_j \mathcal{N}(v_{ij} \mid \mu_j, \sigma_j^2)) - (1-\lambda) \log r_{ij} \right].

Maximising \mathcal{L}' w.r.t. r_{ij} under the constraint \sum_j r_{ij}=1 yields:

r_{ij} \propto \exp\left( \frac{ \log(\pi_j \mathcal{N}(v_{ij} \mid \mu_j, \sigma_j^2)) }{1-\lambda} \right).

For 0<\lambda<1, this is a softmax with temperature 1-\lambda; as \lambda \to 1, assignments become deterministic. The M‑step updates \mu_j, \sigma_j^2, \pi_j using weighted statistics with weights r_{ij}, as in standard EM.

A.4 Proof of Lemma 6.1 (Effect of MI Penalty)

Lemma 6.1. The penalty term increases the mutual information I(\text{child};\text{parent}) at convergence.

Proof. Mutual information between child index i and parent assignment z_i is:

I(i;z) = \sum_i p(i) \sum_j p(z=j|i) \log \frac{p(z=j|i)}{p(z=j)}.

In our setting, p(i) is uniform (or given by data), and p(z=j|i) = r_{ij}. The marginal p(z=j) = \frac{1}{N} \sum_i r_{ij}. The entropy penalty directly minimises H(z|i) = -\sum_j r_{ij} \log r_{ij}. Since I(i;z) = H(z) - H(z|i), and H(z) is bounded, minimising H(z|i) maximises a lower bound on I. At the fixed point of the regularised EM, the assignments are as sharp as allowed by \lambda, thus increasing mutual information. ∎

A.5 Derivation of KL Divergence for Gaussian Distributions

Let P = \mathcal{N}(\mu_P, \Sigma_P) and Q = \mathcal{N}(\mu_Q, \Sigma_Q) be two d-dimensional Gaussian distributions. The KL divergence is:

D_{\text{KL}}(P \| Q) = \frac{1}{2} \left[ \log \frac{|\Sigma_Q|}{|\Sigma_P|} - d + \operatorname{tr}(\Sigma_Q^{-1}\Sigma_P) + (\mu_Q - \mu_P)^\top \Sigma_Q^{-1} (\mu_Q - \mu_P) \right].

In our auditor, we approximate capsule activations as a mixture of Gaussians; for simplicity, we compute the KL divergence between the empirical distribution of activations (a histogram) and the stored baseline histogram, using the discrete formula.

A.6 Proof of Theorem 7.1 (Local Stability)

Theorem 7.1 (Local stability). Under Assumptions 7.1 and 7.2, the origin x = x_{\text{ref}} is an asymptotically stable fixed point of the coupled system x_{n+1} = T_{\lambda_n}(x_n), \lambda_{n+1} = g(D_{\text{KL}}(x_n\|x_{\text{ref}})).

Proof. Define V(x) = D_{\text{KL}}(x \| x_{\text{ref}}). Let V_n = V(x_n). By Assumption 7.1, for any \lambda:

V(T_\lambda(x)) \le c(\lambda) V(x), \quad c(\lambda) < 1.

Now \lambda_{n} = g(V_n) (ignoring smoothing for simplicity; smoothing only adds a low‑pass filter that does not affect stability). Since g is non‑decreasing and c is decreasing, c(g(V)) is non‑increasing in V. Moreover, c(g(0)) = c(\lambda_{\min}) < 1. By continuity, there exists \delta > 0 such that for all V < \delta, c(g(V)) < 1. Then:

V_{n+1} \le c(g(V_n)) V_n \le \rho V_n,

with \rho = \sup_{V < \delta} c(g(V)) < 1. Hence V_n \to 0 geometrically. Asymptotic stability follows from standard Lyapunov theory: V is a Lyapunov function, and the origin is attractive. ∎

A.7 Derivation of the Variational Lower Bound with Entropy Regularisation

See A.3.

A.8 Contraction Analysis of EM Operator

The EM iteration can be viewed as a mapping F: \Theta \to \Theta on the parameter space \Theta = \{ (\mu_j, \sigma_j^2, \pi_j) \}. Under standard regularity conditions (concave log‑likelihood, positive Fisher information), F is a contraction in a neighbourhood of the MLE in the Fisher information metric. The entropy penalty modifies the objective but preserves these properties; thus the regularised EM also enjoys local contraction. The contraction rate is governed by the largest eigenvalue of the Jacobian of F, which is less than 1.

---

Appendix B: Detailed Algorithm Pseudocode

B.1 MI-EM Routing Algorithm

```
Algorithm MI-EM-Routing(u, a_in, λ, iterations)
Input: child pose vectors u [N_in × d], child activations a_in [N_in]
       penalty weight λ, number of iterations
Output: parent poses μ [N_out × d], parent activations a_out [N_out]

Initialize π_j = 1/N_out, μ_j random, σ_j^2 = 1
for iter = 1 to iterations do
    // E-step with MI penalty
    for each child i, parent j do
        log_lik = log(π_j) + log N(v_ij | μ_j, σ_j^2)
        r_ij = exp( (log_lik - λ * log(r_ij_old)) / (1-λ) )  // using previous r
    end for
    Normalize r_ij over j (softmax)
    
    // M-step
    for each parent j do
        R_j = sum_i r_ij
        μ_j = (1/R_j) sum_i r_ij v_ij
        σ_j^2 = (1/R_j) sum_i r_ij (v_ij - μ_j)^2
        π_j = R_j / (sum_k R_k)
        a_out_j = sigmoid(β_a - β_v * sum_i r_ij)  // activation
    end for
end for
return μ, a_out
```

B.2 Adaptive λ Control Loop (Noeud)

```
Algorithm AdaptiveλControl
Initialize λ = λ_base, smoothed_drift = 0, state x = initial_capsules(input)
loop
    // Fixed-point iteration
    for t = 1 to max_iterations do
        x = ApplyDecay(x)  // e.g., add noise
        factors = ParallelDivide(x)  // call capsule Divide
        x = Mending(factors, λ)       // call capsule Mend with current λ
        if change(x) < ε then break
    end for
    
    // Audit
    current_drift = KL(x.activations, reference.activations)
    smoothed_drift = β * smoothed_drift + (1-β) * current_drift
    
    // λ adaptation with hysteresis
    if smoothed_drift > θ_high then
        λ = min(λ_max, λ * (1 + α_up))
    else if smoothed_drift < θ_low then
        λ = max(λ_min, λ * (1 - α_down))
    end if
    
    // Apply λ to all capsules
    BroadcastSetLambda(λ)
    
    // Optionally store fixed point
    if converged and smoothed_drift < θ_low then
        StoreFixedPoint(context_id, x)
    end if
end loop
```

B.3 Fixed-Point Iteration with Noeud Actors

See Section 8 for actor descriptions; here we provide a high‑level sequence:

```
Orchestrator:
    state = initial
    while not stopped:
        state = decay(state)
        factors = []
        for each capsule in parallel:
            factors.append(capsule.Divide(state))
        end
        new_state = capsule.Mend(aggregate(factors))
        if norm(new_state - state) < ε:
            send state to Auditor
            break
        state = new_state

Auditor:
    on receive state:
        ref = Redis.get(context_id)
        drift = KL(state, ref)
        smoothed = ema(drift)
        if smoothed > threshold:
            send drift to λ-Adapter
        metrics.record(drift)

λ-Adapter:
    on receive drift:
        λ = compute_lambda(drift)  // with hysteresis
        for each capsule:
            capsule.SetLambda(λ)
        end
```

---

Appendix C: Complete Code Skeletons

C.1 Python Capsule Service with MI-EM Layer (Full Code)

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import grpc
from concurrent import futures
import capsule_pb2
import capsule_pb2_grpc

class MI_EMMendingLayer(nn.Module):
    def __init__(self, in_caps, out_caps, pose_dim=16, lambda_mi=0.01):
        super().__init__()
        self.in_caps = in_caps
        self.out_caps = out_caps
        self.pose_dim = pose_dim
        self.W = nn.Parameter(torch.randn(in_caps, out_caps, pose_dim, pose_dim) * 0.1)
        self.beta_a = nn.Parameter(torch.zeros(out_caps))
        self.beta_v = nn.Parameter(torch.zeros(out_caps))
        self.lambda_mi = lambda_mi

    def forward(self, u, a_in, external_lambda=None):
        batch_size = u.size(0)
        lam = external_lambda if external_lambda is not None else self.lambda_mi
        # Compute votes
        votes = torch.einsum('bic,iocd->biod', u, self.W)  # [B, in_caps, out_caps, d]
        
        # Initialize assignments uniformly
        r = torch.ones(batch_size, self.in_caps, self.out_caps, device=u.device) / self.out_caps
        mu = torch.zeros(batch_size, self.out_caps, self.pose_dim, device=u.device)
        sigma_sq = torch.ones(batch_size, self.out_caps, self.pose_dim, device=u.device)
        
        for _ in range(3):  # iterations
            # M-step: update parent parameters
            r_sum = r.sum(dim=1, keepdim=True) + 1e-9
            mu = (r.unsqueeze(-1) * votes).sum(dim=1) / r_sum
            diff = votes - mu.unsqueeze(1)
            sigma_sq = (r.unsqueeze(-1) * diff**2).sum(dim=1) / r_sum + 1e-9
            
            # Activation
            cost_h = (torch.log(sigma_sq.sqrt() + 1e-9) + 0.5 * (1 + torch.log(torch.tensor(2 * torch.pi)))).sum(dim=-1)
            a_out = torch.sigmoid(self.beta_a - (self.beta_v + cost_h).mean(dim=1))
            
            # E-step with MI penalty
            log_p = -0.5 * torch.log(2 * torch.pi * sigma_sq).unsqueeze(1) - 0.5 * (diff**2 / sigma_sq.unsqueeze(1))
            log_p = log_p.sum(dim=-1)  # [B, in_caps, out_caps]
            # Incorporate penalty: subtract λ * log(r) (old r)
            logits = log_p + torch.log(a_out.unsqueeze(1) + 1e-9) - lam * torch.log(r + 1e-9)
            r = F.softmax(logits, dim=-1)
        
        return mu, a_out

class CapsuleServicer(capsule_pb2_grpc.CapsuleServicer):
    def __init__(self):
        self.primary = nn.Sequential(
            nn.Conv2d(1, 256, 9),
            nn.ReLU(),
            PrimaryCaps(256, 32, 8)  # simplified
        )
        self.mending = MI_EMMendingLayer(1152, 10, 16)
        self.current_lambda = 0.01

    def Divide(self, request, context):
        # Deserialize input, run primary capsules
        input_tensor = torch.frombuffer(request.input, dtype=torch.float32).reshape(1,1,28,28)
        factors = self.primary(input_tensor)  # returns [1, 1152, 16]
        # Convert to protobuf
        resp = capsule_pb2.DivideResponse()
        for i in range(factors.shape[1]):
            f = resp.factors.add()
            f.vector.extend(factors[0,i].tolist())
            f.activation = 1.0  # placeholder
        return resp

    def Mend(self, request, context):
        # Parse factors
        factors = torch.tensor([f.vector for f in request.factors]).unsqueeze(0)
        a_in = torch.tensor([f.activation for f in request.factors])
        mu, a_out = self.mending(factors, a_in, external_lambda=self.current_lambda)
        resp = capsule_pb2.MendResponse()
        resp.output.vector.extend(mu[0,0].tolist())  # take first parent
        resp.output.activation = a_out[0,0].item()
        resp.routing_entropy = 0.0  # compute if needed
        return resp

    def SetLambda(self, request, context):
        self.current_lambda = request.lambda_value
        return capsule_pb2.SetLambdaResponse(ack=True)

def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    capsule_pb2_grpc.add_CapsuleServicer_to_server(CapsuleServicer(), server)
    server.add_insecure_port('[::]:50051')
    server.start()
    server.wait_for_termination()

if __name__ == '__main__':
    serve()
```

C.2 Rust Noeud Actor Implementations

Orchestrator (simplified):

```rust
use tokio::sync::mpsc;
use tonic::transport::Channel;
use capsule::capsule_client::CapsuleClient;
use std::collections::HashMap;

pub struct Orchestrator {
    clients: HashMap<String, CapsuleClient<Channel>>,
    state: Vec<Factor>,
    auditor_tx: mpsc::Sender<CapsuleState>,
}

impl Orchestrator {
    pub async fn run(&mut self) {
        loop {
            // Decay
            for f in &mut self.state {
                for v in &mut f.vector {
                    *v += rand::random::<f32>() * 0.01;
                }
            }

            // Divide
            let mut factors = Vec::new();
            for (name, client) in &self.clients {
                let req = DivideRequest {
                    input: self.encode_state(),
                    context_id: "current".into(),
                };
                if let Ok(resp) = client.clone().divide(req).await {
                    factors.extend(resp.factors);
                }
            }

            // Mend
            let mut new_state = Vec::new();
            for (name, client) in &self.clients {
                let req = MendRequest {
                    factors: factors.clone(),
                    context_id: "current".into(),
                };
                if let Ok(resp) = client.clone().mend(req).await {
                    new_state.push(resp.output.unwrap());
                }
            }

            if self.converged(&new_state) {
                let _ = self.auditor_tx.send(CapsuleState { factors: new_state }).await;
                break;
            }
            self.state = new_state;
        }
    }

    fn converged(&self, new: &[Factor]) -> bool {
        // compute L2 norm change
        true // placeholder
    }
}
```

Auditor:

```rust
use prometheus::{IntGauge, register_int_gauge};

lazy_static! {
    static ref DRIFT_GAUGE: IntGauge = register_int_gauge!("anti_entropic_drift_smoothed", "Smoothed KL drift").unwrap();
}

pub struct Auditor {
    redis_client: redis::Client,
    lambda_adapter_tx: mpsc::Sender<f32>,
    ema_alpha: f32,
    smoothed_drift: f32,
}

impl Auditor {
    pub async fn run(&mut self, mut rx: mpsc::Receiver<CapsuleState>) {
        while let Some(state) = rx.recv().await {
            let baseline = self.get_fixed_point("current").await;
            let drift = kl_divergence(&state.activations(), &baseline.activations());
            self.smoothed_drift = self.ema_alpha * drift + (1.0 - self.ema_alpha) * self.smoothed_drift;
            DRIFT_GAUGE.set((self.smoothed_drift * 1000.0) as i64);
            if self.smoothed_drift > 0.15 {
                let _ = self.lambda_adapter_tx.send(self.smoothed_drift).await;
            }
        }
    }

    async fn get_fixed_point(&self, ctx: &str) -> FixedPoint {
        let mut conn = self.redis_client.get_async_connection().await.unwrap();
        let data: Vec<u8> = redis::cmd("GET").arg(format!("fixed_point:{}", ctx)).query_async(&mut conn).await.unwrap();
        bincode::deserialize(&data).unwrap()
    }
}

fn kl_divergence(p: &[f32], q: &[f32]) -> f32 {
    p.iter().zip(q).map(|(&pi, &qi)| {
        let pi = pi.max(1e-10);
        let qi = qi.max(1e-10);
        pi * (pi / qi).ln()
    }).sum()
}
```

λ-Adapter:

```rust
pub struct LambdaAdapter {
    capsule_clients: HashMap<String, CapsuleClient<Channel>>,
    current_lambda: f32,
    lambda_min: f32,
    lambda_max: f32,
    alpha_up: f32,
    alpha_down: f32,
    threshold_high: f32,
    threshold_low: f32,
}

impl LambdaAdapter {
    pub async fn run(&mut self, mut rx: mpsc::Receiver<f32>) {
        while let Some(drift) = rx.recv().await {
            if drift > self.threshold_high {
                self.current_lambda = (self.current_lambda * (1.0 + self.alpha_up)).min(self.lambda_max);
            } else if drift < self.threshold_low {
                self.current_lambda = (self.current_lambda * (1.0 - self.alpha_down)).max(self.lambda_min);
            }
            for client in self.capsule_clients.values() {
                let _ = client.clone().set_lambda(self.current_lambda).await;
            }
        }
    }
}
```

Redis Lattice Store Client:

```rust
use serde::{Serialize, Deserialize};

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct FixedPoint {
    pub context_id: String,
    pub fixed_point_hash: String,
    pub parameters: Vec<f32>,
    pub routing_weights: Vec<f32>,
    pub metrics: FixedPointMetrics,
}

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct FixedPointMetrics {
    pub entropy: f32,
    pub energy_cost: f32,
    pub task_performance: Option<f32>,
}

pub struct RedisStore {
    client: redis::Client,
}

impl RedisStore {
    pub async fn store_fixed_point(&self, fp: &FixedPoint) -> redis::RedisResult<()> {
        let mut conn = self.client.get_async_connection().await?;
        let key = format!("fixed_point:{}", fp.context_id);
        let data = bincode::serialize(fp).unwrap();
        redis::cmd("SET").arg(&key).arg(data).query_async(&mut conn).await
    }

    pub async fn get_fixed_point(&self, context_id: &str) -> redis::RedisResult<FixedPoint> {
        let mut conn = self.client.get_async_connection().await?;
        let data: Vec<u8> = redis::cmd("GET").arg(format!("fixed_point:{}", context_id)).query_async(&mut conn).await?;
        Ok(bincode::deserialize(&data).unwrap())
    }
}
```

C.3 Protobuf Definitions

```protobuf
syntax = "proto3";

package capsule;

service Capsule {
  rpc Divide(DivideRequest) returns (DivideResponse);
  rpc Mend(MendRequest) returns (MendResponse);
  rpc SetLambda(SetLambdaRequest) returns (SetLambdaResponse);
  rpc GetMetrics(Empty) returns (Metrics);
}

message DivideRequest {
  bytes input = 1;
  string context_id = 2;
}

message Factor {
  repeated float vector = 1;
  float activation = 2;
}

message DivideResponse {
  repeated Factor factors = 1;
}

message MendRequest {
  repeated Factor factors = 1;
  string context_id = 2;
}

message MendResponse {
  Factor output = 1;
  float routing_entropy = 2;
}

message SetLambdaRequest {
  float lambda_value = 1;
}

message SetLambdaResponse {
  bool ack = 1;
}

message Empty {}

message Metrics {
  float routing_entropy = 1;
  float avg_activation = 2;
}
```

C.4 Redis Lattice Store Client in Rust (Full)

See above.

---

Appendix D: Reproducibility and Experimental Setup

D.1 Hardware and Software Requirements

· Hardware: Minimum 8 CPU cores, 32 GB RAM, NVIDIA GPU with 8+ GB VRAM (for training). For inference, CPU only may suffice.
· Software: Ubuntu 20.04+, Docker, Kubernetes (optional), Rust 1.70+, Python 3.9+, PyTorch 2.0+, Redis 7.0+, NATS 2.9+.

D.2 CORe50 Dataset Preparation

Download CORe50 from official site. Use the provided scripts to split into NIC and NC scenarios. The dataset should be placed in ./data/core50. We use the following splits:

· NIC: 10 tasks, each introducing new instances of existing classes and new classes.
· NC: 10 tasks, each introducing new classes only.

D.3 Training and Evaluation Scripts

The training script train.py:

```python
import core50
from capsule_net import CapsuleNet

# Load data
train_stream, test_stream = core50.get_streams(scenario='nic')

model = CapsuleNet()
optimizer = torch.optim.Adam(model.parameters())

for task_id, (train_loader, test_loader) in enumerate(train_stream):
    for epoch in range(10):
        for images, labels in train_loader:
            loss = train_step(model, images, labels, lambda_mi=current_lambda)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
    acc = evaluate(model, test_loader)
    print(f"Task {task_id} accuracy: {acc}")
    # After task, store fixed point
    store_fixed_point(model, context_id=f"task_{task_id}")
```

Evaluation scripts compute accuracy, forgetting, and other metrics.

D.4 Hyperparameters and Seeds

· Capsule network: 1 conv layer (256 filters, 9x9), PrimaryCaps (8 capsules, 32D), DigitCaps (10 capsules, 16D). EM iterations: 3. MI penalty λ range: [0.001, 0.1] with base 0.01.
· Adaptive λ: α_up = 0.1, α_down = 0.05, θ_high = 0.15, θ_low = 0.05, EMA β = 0.9.
· Seeds: All random seeds fixed to 42 for reproducibility.

D.5 Metrics Collection and Prometheus Configuration

Prometheus scrapes the noeud’s metrics endpoint (e.g., localhost:9090/metrics). Grafana dashboards visualise λ, drift, routing entropy, and accuracy over tasks. Example Prometheus config:

```yaml
scrape_configs:
  - job_name: 'noeud'
    static_configs:
      - targets: ['localhost:9090']
```

---

Appendix E: Extended Theoretical Background

E.1 Category Theory for Representations

We define the category \mathcal{C}_{\text{rep}} as follows:

· Objects: Representations R = \{(\mathbf{v}_i, a_i)\}_{i=1}^n with \mathbf{v}_i \in \mathbb{R}^d, a_i \in [0,1].
· Morphisms: An intentional transformation f: R \to S is a composition of the primitive operators / and \backslash (and possibly their inverses) that preserves the partial order \preceq.

The operators themselves are functors:

· / is a functor from \mathcal{C}_{\text{rep}} to the product category \mathcal{C}_{\text{rep}} \times \mathcal{C}_{\text{rep}}.
· \backslash is a bifunctor (or a natural transformation between product functors).

This categorical view ensures that compositions of operators are well‑defined and that fixed points correspond to objects where the functor composition returns the same object.

E.2 Information Geometry and Fisher Information

The space of probability distributions (e.g., of capsule activations) is a Riemannian manifold with the Fisher information metric. The KL divergence is a natural distance measure. EM routing can be interpreted as a projection onto a submanifold of factorised distributions; the MI penalty corresponds to a prior that favours deterministic assignments. The Fisher information matrix of the parent parameters appears in the contraction analysis.

E.3 Lyapunov Stability in Dynamical Systems

A fixed point x^* of a discrete‑time system x_{n+1}=F(x_n) is asymptotically stable if there exists a neighbourhood such that all trajectories starting in it converge to x^*. A Lyapunov function V satisfies V(x^*) = 0, V(x) > 0 for x \neq x^*, and V(F(x)) < V(x) for x \neq x^*. In our proof, we used V(x) = D_{\text{KL}}(x\|x_{\text{ref}}) as a Lyapunov function, leveraging the contraction property.

E.4 Tarski's Fixed Point Theorem and Applications

Tarski’s theorem is a cornerstone of order theory. Its application to our system relies on the monotonicity of T = M \circ D. We constructed a complete lattice on capsule configurations by ordering them componentwise with respect to a reference. This lattice ensures that fixed points exist, even if the dynamics are not contractive globally. The theorem also guarantees a greatest fixed point, which corresponds to the most resilient configuration.

